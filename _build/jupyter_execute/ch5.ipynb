{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Using `BeautifulSoup`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{contents} Table of Contents\n",
    ":depth: 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction: Is Web Scraping Legal?\n",
    "Web scraping is the practice of downloading the raw HTML code that generates a website, and instead of parsing the code to display it like we do with a web browser whenever we navigate to a page, we dig through the code for data. \n",
    "\n",
    "There are **significant legal and ethical questions** regarding web scraping. Right now, there is a court case - [HiQ Labs vs. LinkedIn](https://en.wikipedia.org/wiki/HiQ_Labs_v._LinkedIn) - that will establish whether and under what conditions web scraping is legal. \n",
    "\n",
    "<img src=\"https://crowdjustice.imgix.net/pictures/courtroom5-gray_uI7BCRV.png?auto=enhance%2Cformat&crop=faces&fit=crop&q=80&w=1200\" width=\"600\">\n",
    "\n",
    "HiQ is a company that scraps data from individuals' LinkedIn profiles to compile data to use to build models that predict whether employees will leave their positions for new jobs. They use the insights from these models to consult with businesses to reduce employee turnover. In 2017 LinkedIn issued a Cease and Desist order to HiQ and took steps to prevent anyone including HiQ from deploying scrapers on profiles. Because HiQ's business model is entirely dependent on collecting data from LinkedIn profiles, this action by LinkedIn would have caused HiQ to go out of business. Instead, HiQ filed a lawsuit against LinkedIn in federal court. HiQ argued that user profiles contain data that are owned by the LinkedIn users themselves who intend to make that information public using the LinkedIn platform -- and so, because the data owners are sharing their own data, HiQ should be able to access that data. LinkedIn argued that the HiQ's scraping of user data amounts to theft, is a violation of the [Consumer Fraud and Abuse Act](https://en.wikipedia.org/wiki/Computer_Fraud_and_Abuse_Act), and violates LinkedIn users' privacy. \n",
    "\n",
    "In 2017 a federal district court issued an injunction that prevented LinkedIn from blocking HiQ's scraping scripts. The case was appealed to the Circuit Court, where [this injuction was upheld in 2019](https://www.reuters.com/article/us-microsoft-linkedin-profiles/microsofts-linkedin-loses-appeal-over-access-to-user-profiles-idUSKCN1VU21W). In March 2020 LinkedIn filed for the case to be appealed to the U.S. Supreme Court. It is likely that this case will be decided at the highest level in the United States sometime in the next year. What the Supreme Court decides will have [massive ramifications](https://www.natlawreview.com/print/article/linkedin-files-petition-to-supreme-court-hiq-web-scraping-case) on the use of web scraping, data science, and on the tech industry at large. It will establish whether web scraping is legal, legal with restrictions, or illegal, and it will have implications for data ownership and the extent to which large tech companies control and own the data that exist on their platforms.\n",
    "\n",
    "If this debate is interesting to you, here's a longer, philosophically-oriented article about the virtues of web scraping for academic research: https://research.gold.ac.uk/6768/1/Marres_Weltrevede_Scraping_the_Social_draft.pdf\n",
    "\n",
    "Even if scraping is legal, it might not be ethical. Scraping calls a server that is not designed for the transference of data the way an API is. As such, many repeated calls (from bots) to a website for the purpose of scraping data might overwhelm the server, keeping the website's owners from being able to achieve their purpose for having the website. This [article by James Densmore](https://towardsdatascience.com/ethics-in-web-scraping-b96b18136f01) outlines some ethical considerations for scrapers and for website owners, and lays out the following code of conduct: \n",
    "\n",
    "\"I, the web scraper will live by the following principles:\n",
    "\n",
    "* If you have a public API that provides the data I’m looking for, I’ll use it and avoid scraping all together.\n",
    "\n",
    "* I will always provide a User Agent string that makes my intentions clear and provides a way for you to contact me with questions or concerns.\n",
    "\n",
    "* I will request data at a reasonable rate. I will strive to never be confused for a DDoS attack.\n",
    "\n",
    "* I will only save the data I absolutely need from your page. If all I need it OpenGraph meta-data, that’s all I’ll keep.\n",
    "\n",
    "* I will respect any content I do keep. I’ll never pass it off as my own.\n",
    "\n",
    "* I will look for ways to return value to you. Maybe I can drive some (real) traffic to your site or credit you in an article or post.\n",
    "\n",
    "* I will respond in a timely fashion to your outreach and work with you towards a resolution.\n",
    "\n",
    "* I will scrape for the purpose of creating new value from the data, not to duplicate it.\n",
    "\n",
    " . . . . I, the site owner will live by the following principles:\n",
    "\n",
    "* I will allow ethical scrapers to access my site as long as they are not a burden on my site’s performance.\n",
    "\n",
    "* I will respect transparent User Agent strings rather than blocking them and encouraging use of scrapers masked as human visitors.\n",
    "\n",
    "* I will reach out to the owner of the scraper (thanks to their ethical User Agent string) before blocking permanently. A temporary block is acceptable in the case of site performance or ethical concerns.\n",
    "\n",
    "* I understand that scrapers are a reality of the open web.\n",
    "\n",
    "* I will consider public APIs to provide data as an alternative to scrapers.\"\n",
    "\n",
    "In general, while scraping appears to exist in a legal and ethical grey area, there is a lot of litigation and many arguments that suggest that once information is posted publically on a website, that there is no longer an expectation of privacy, and the data is open for anyone to use. But be careful when you use web scraping! If there IS an expectation of privacy, such as for any website with a password or other restrictions on access, then the legality and ethics of web scraping are much more dubious. If an API is available, it's available for a reason, and it's the correct ethical decision to use the API instead of scraping. Use care and judgment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How Websites Prevent You From Scraping\n",
    "This discussion follows the excellent overview by a Stack Overflow and GitHub contributor with the username JonasCz (I wish I knew this user's real name!) on [how to prevent web scraping](https://github.com/JonasCz/How-To-Prevent-Scraping/blob/master/README.md).\n",
    "\n",
    "To understand the restrictions and challenges you will encounter when scraping data, put yourself in the position of a website's owner:\n",
    "\n",
    "If you own and maintain a website, there are many reasons why you might want to prevent web scraping bots from accessing the data on your website. Maybe the bots will overload the traffic to your site and make it impossible for your website to work as you intend. You might be running a business through this website and sharing the data in mass transfers would undercut your business. For whatever reason, you are now faced with a challenge: how to you prevent automated scraping of the data on your webpage while still allowing individual customers to view your website?\n",
    "\n",
    "Web scraping will require issuing HTTP requests to a particular web address with a tool like `requests`, sometimes many times in a short period. Every HTTP request is logged by the server that receives the request, and these logs contain the IP address of the entity making the request. If too many requests are made by the same IP address, the server can block that IP address. The coding logic to automatically identify and block overactive IP addresses is simple, so many websites include these security measures. Some blocks are temporary, placing a rate limit on these requests to slow down the scrapers, and some blocks reroute scrapers through a CAPTCHA (which stands for \"Completely Automated Test to Tell Computers and Humans Apart\") to prevent robots like a scraper from accessing the website. JonasCz recommends that these security measures look at other factors as well: the speed of actions on the website, the amount of data requested, and other factors that can identify a user when the IP address is masked.\n",
    "\n",
    "Stronger gates, such as making users register for a username and password with email confirmation to use your website, are effective against scraping bots. But they also turn away individuals who wouldn't want to jump through those hoops. Saving all text as images on your server will prevent bots from accessing the text very easily, but it makes the website harder to use and violates regulations that protect people with disabilities.\n",
    "\n",
    "Instead, JonasCz recommends building your website in a way that never reveals the entirety of the data you own, and never reveals the private API endpoints you use to display the data. Also, web scrapers are fragile: they are built to pull data from the specific HTML structure of a particular website. Changing the HTML code frequently or using different versions of the code based on geographic location will break the scrapers that are built for that code. JonasCz also suggests adding \"honeypot\" links to the HTML code that will not be displayed to legitimate users but will be followed by scrapers that recursively follow links, and taking action against the agents that follow these links: block their IP addresses, require a CAPTCHA, or deliver fake data.\n",
    "\n",
    "One important piece of information in a request is the user agent header (which we discuss in more detail [below](#useragent)). JonasCz recommends looking at this information and blocking requests when the user agent is blank or matches information from agents that have previously been identified as malicious bots.\n",
    "\n",
    "Understanding the steps you would take to protect your data from bots if you owned a website, you should have greater insight into why a web scraping endeavor may fail. Your web scraper might not be malicious, but might still violate the rules that the website owner setup to guard against bots. These rules are usually listed explicitly in a file on the server, usually called `robots.txt`. Some tips for reading and understanding a `robots.txt` file are here: https://www.promptcloud.com/blog/how-to-read-and-respect-robots-file/\n",
    "\n",
    "For example, in this document we will be scraping data on the playlist of a radio station from https://spinitron.com/. This website has a `robots.txt` file here: https://spinitron.com/robots.txt, which reads:\n",
    "```\n",
    "User-agent: *\n",
    "Crawl-delay: 10\n",
    "Request-rate: 1/10\n",
    "```\n",
    "The `User-agent: *` line tells us that the next two lines apply to all user agent strings. `Crawl-delay: 10` places a limit on the frequency with which our scraper can make a request from this website. In this case, individual requests must be made 10 second apart. `Request-rate: 1/10` tells us that our scraper is only allowed to access one page every 10 seconds, and that we are not allowed to make requests from more than one page at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `requests` with a User Agent Header\n",
    "As the articles by James Densmore and JonasCz described, requests are much more likely to get blocked by websites if the request does not specify a header that contains a user agent. An HTTP header is a parameter that gets sent along with the HTTP request that contains metadata about the request. A user agent header contains contact and identification information about the person making the request. If there is any issue with your web scraper, you want to give the website owner a chance to contact you directly about that problem. If you do not feel comfortable being contacted by the website's owner, you should reconsider whether you should be scraping that website.\n",
    "\n",
    "Fortunately, it is straightforward to include headers in a GET request using `requests`: just use the `headers` argument. First, we import the relevant libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In module 4 we issued GET requests from the Wikipedia API as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(\"https://en.wikipedia.org/w/api.php\")\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add a user agent string, I use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user-agent': 'Kropko class example (jkropko@virginia.edu)'}\n",
    "r = requests.get(\"https://en.wikipedia.org/w/api.php\", headers = headers)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What information needs to go into a user agent header? Different resources have different information about that. According to [Amazon Web Services](https://docs.developer.amazonservices.com/en_US/dev_guide/DG_UserAgentHeader.html), a user agent should identify your application, its version number, and programming language. So a user agent should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'user-agent': 'Kropko class example version 1.0 (jkropko@virginia.edu) (Language=Python 3.8.2; Platform=Mac OSX 10.15.5)'}\n",
    "r = requests.get(\"https://en.wikipedia.org/w/api.php\", headers = headers)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including a user agent is not hard, and it goes a long way towards alleviating the anxieties that website owners have about dealing with your web scraping code. It is a good practice to cultivate into a habit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `BeautifulSoup()` (Example: WNRN, Charlottesville's Legendary Radio Station)\n",
    "WNRN is a legendary radio station, and it's based right here in Charlottesville at 91.9 FM (and streaming online at www.wnrn.org). It's commercial-free, with only a few interruptions for local nonprofits to tell you about cool things happening in town. They play a mix of new and classic alternative rock and R&B. They emphasize music for bands coming to play at local venues. And they play the Grateful Dead on Saturday mornings. You should be listening to WNRN!\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/en/thumb/0/0e/WNRN-FM_2014.PNG/200px-WNRN-FM_2014.PNG\" width=\"300\" height=\"300\" class=\"center\"></img></center>\n",
    "\n",
    "The playlist of the songs that WNRN has played in the last few hours is here: https://spinitron.com/WNRN/. I want to scrape the data off this website. I also want to scrape the data off of the additional playlists that this website links to, to collect as much data as possible. Our goal in this example is to create a dataframe of each song WNRN has played, the artist, the album, and the time each song was played.\n",
    "\n",
    "The process involves four steps:\n",
    "\n",
    "1. Download the raw text of the HTML code for the website we want to scrape using the `requests` library.\n",
    "\n",
    "2. Use the `BeautifulSoup()` function from the `bs4` library to parse the raw text so that Python can understand, search through, and operate on the HTML tags from string.\n",
    "\n",
    "3. Use methods associated with `BeautifulSoup()` to extract the data we need from the HTML code.\n",
    "\n",
    "4. Place the data into a `pandas` data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading and Understanding Raw HTML\n",
    "For this example, I first download the HTML that exists on https://spinitron.com/WNRN using the `requests.get()` function. To be ethical and to help this website's owners know that I am not a malicious actor, I also specify a user agent string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://spinitron.com/WNRN\"\n",
    "headers = {'user-agent': 'Kropko class example (jkropko@virginia.edu)'}\n",
    "r = requests.get(url, headers=headers)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw HTML code contains a series of text fragments that look like this,\n",
    "```\n",
    "<tag attribute=\"value\"> Navigable string </tag>\n",
    "```\n",
    "where `tag`, `attribute`, `\"value\"`, and `Navigable string` are replaced by specific parameters and data that control the content and presentation of the webpage that gets displayed in a web browser. For example, here are the first 1000 characters of the raw text from WNRN's playlist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<!doctype html><html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"utf-8\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1,maximum-scale=1\">\n",
      "    <title>WNRN – Independent Music Radio</title>\n",
      "    <meta name=\"description\" content=\"A member-supported, independent music radio station broadcasting from the Blue Ridge to the Bay across Virginia—Richmond, Hampton Roads, Roanoke, Charlottesville, Lynchburg, Nelson County, Williamsburg, and The Shenandoah Valley.\">\n",
      "\n",
      "                                    <meta name=\"csrf-param\" content=\"_csrf\">\n",
      "<meta name=\"csrf-token\" content=\"XY-IUzxJJ7gmqsy-G2umwNl1bKjol-wHmMey_ThUMFM1_MIgWxtz9WXwu81WRouftTAI0pGgvGKpkfyxfC1Uag==\">\n",
      "\n",
      "    <meta property=\"og:url\" content=\"/WNRN/\">\n",
      "<meta property=\"og:title\" content=\"WNRN – Independent Music Radio\">\n",
      "<meta property=\"og:description\" content=\"A member-supported, independent music radio station broadcasting from the Blue Ridge to the Bay across Virgi\n"
     ]
    }
   ],
   "source": [
    "print(r.text[0:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tags** specify how the data contained within the page are organized and how the visual elements on this page should look. Tags are designated by opening and closing angle braces, < and >. In the HTML code displayed above, there are tags named \n",
    "\n",
    "* `<html>`, which tells browsers that the following code is written in HTML, \n",
    "* `<meta>`, which defines metadata in the document that help govern how the output shold be displayed in the browser, \n",
    "* `<title>`, which sets the title of the document, and \n",
    "* `<link>`, which pulls data or images from external resources for later use. \n",
    "\n",
    "To see what other HTML tags do, look at the list on https://www.w3schools.com/TAGs/. \n",
    "\n",
    "In some cases the tag operates on the text that immediately follows, and a closing tag `</tag>` frames the text that gets operated on by the tag. The text in between the opening and closing tag is called the **navigable string**. For example, the tag `<title>WNRN – Independent Music Radio</title>` specifies that \"WNRN – Independent Music Radio\", and only this string, is the title.\n",
    "\n",
    "Some tags have **attributes**, which are arguments listed inside an opening tag to modify the behavior of that tag or to attach relevant data to the tag. The first `<html>` tag listed above contains an attribute `lang` with a value `\"en\"` that specifies that this document contains HTML code in English.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Raw HTML Using `BeautifulSoup()`\n",
    "The `requests.get()` function only downloads the raw text of the HTML code, but it does not yet understand the logic and organization of the HTML code. Getting Python to register text as a particular coding standard is called **parsing** the code. We've parsed code into Python before with JSON data. We used `requests.get()` to download the JSON formatted data, but we needed `json.loads()` to parse the data in order to be able to navigate the branches of the JSON tree. \n",
    "\n",
    "There are two widely used Python libraries for parsing HTML data: `bs4` which contains the `BeautifulSoup()` function, and `selenium`. `BeautifulSoup()` works with raw text, but cannot access websites themselves (we use `requests.get()` for that). In order to access the data on a website, the data needs to be visible in the raw HTML that `requests.get()` returns. If there are measures taken by a website to hide that data, possibly by calling server-side Javascript to populate data fields, or by saving data as image files, then we won't be able to access the data with an HTML parser. `selenium` has more features to extract more complicated data and circumvent anti-scraping measures, such as taking a screenshot of the webpage in a browser and using optical character recognition (OCR) to pull data directly from the image. However, `selenium` requires each request to be loaded in a web browser, so it can be quite a bit slower than `BeautifulSoup()`. If you are interested in learning how to use `selenium`, see this guide: https://selenium-python.readthedocs.io/. Here we will be using `BeautifulSoup()`.\n",
    "\n",
    "First I import the `BeautifulSoup()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use it, we pass the `.text` attribute of the `requests.get()` output from https://spinitron.com/WNRN to `BeautifulSoup()` (which I saved as `r.text` above). This function can parse either HTML or XML code, so the second argument should specify HTML:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnrn = BeautifulSoup(r.text, 'html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the https://spinitron.com/WNRN source code is registered as HTML code in Python, we can begin executing commands to navigate the organizational structure of the code and extract data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for HTML Tags and Extracting Data\n",
    "While HTML is a coding language, it does not force coders to follow very strict templates. There's a lot of flexibility and creativity possible for HTML programmers, and as such, there is no one universal method for extracting data from HTML. The best approach is to open a browser window, navigate to the webpage you want to scrape, and \"view page source\". (Different web browsers have different ways to do that. On Mozilla Firefox, right click somewhere on the page other than an active link, and \"view page source\" should be an option.) The source will display the raw HTML code that generates the page. You will need to search through this code to find examples of the data points you intend to collect, possibly using control+F to search for specific values. Once you find the data you need, make note of the tags that surround the data and use the tools we will describe next to extract the data.\n",
    "\n",
    "The parsable HTML `BeautifulSoup()` output, `wnrn`, has important methods and attributes that we will use to extract the data we want. First, we can use the name of a tag as an attribute to extract the first occurrence of that tag. Here we extract the first `<meta>` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<meta charset=\"utf-8\"/>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metatag = wnrn.meta\n",
    "metatag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tag stores its attributes as a list, so we can extract the value of an attribute by calling the name of that attribute as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metatag['charset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a tag has a navigable string, we can extract that with the `.string` attribute of a particular tag. For example, to extract the title, we start with the `<title>` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>WNRN – Independent Music Radio</title>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titletag = wnrn.title\n",
    "titletag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we extract the title as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WNRN – Independent Music Radio'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titletag.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal in this example is to extract the artist, song, album, and time played for every song played on WNRN. I look in the raw HTML source code for the first instance of an artist. These data are contained in the `<span>` tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"artist\">Baby Rose f/ BADBADNOTGOOD</span>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spantag = wnrn.span\n",
    "spantag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling one tag is not especially useful, because we generally want to extract all of the relevant data on a page. For that, we can use the `.find_next()` and `.find_all()` methods, both of which are very literal. The next `<span>` tag in the HTML code contains the song associated with the artist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"song\">Weekness</span>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spantag.find_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the next occurrence of `<span>` contains the album name (under `\"release\"`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"info\"><span class=\"release\">Slow Burn EP</span></div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spantag.find_next().find_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find all occurrences of the `<span>` tag, organized in a list, use `.find_all()` and provide the tag as the argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"artist\">Baby Rose f/ BADBADNOTGOOD</span>,\n",
       " <span class=\"song\">Weekness</span>,\n",
       " <span class=\"release\">Slow Burn EP</span>,\n",
       " <span class=\"artist\">Angie McMahon</span>,\n",
       " <span class=\"song\">Untangling</span>,\n",
       " <span class=\"release\">Light Sides EP</span>,\n",
       " <span class=\"artist\">Willie Nelson and Daniel Lanois</span>,\n",
       " <span class=\"song\">The Maker</span>,\n",
       " <span class=\"release\">Teatro</span>,\n",
       " <span class=\"artist\">Lucy Dacus</span>,\n",
       " <span class=\"song\">Ankles</span>,\n",
       " <span class=\"release\">Forever Is A Feeling</span>,\n",
       " <span class=\"artist\">Brigitte Calls Me Baby</span>,\n",
       " <span class=\"song\">Too Easy</span>,\n",
       " <span class=\"release\">The Future Is Our Way Out</span>,\n",
       " <span class=\"artist\">Kashus Culpepper</span>,\n",
       " <span class=\"song\">After Me?</span>,\n",
       " <span class=\"release\">(Single)</span>,\n",
       " <span class=\"artist\">Deep Sea Diver</span>,\n",
       " <span class=\"song\">Shovel</span>,\n",
       " <span class=\"release\">Billboard Heart</span>,\n",
       " <span class=\"artist\">The Devil Makes Three</span>,\n",
       " <span class=\"song\">Spirits</span>,\n",
       " <span class=\"release\">Spirits</span>,\n",
       " <span class=\"artist\">The Barons</span>,\n",
       " <span class=\"song\">Would You Want It (If You Had It)</span>,\n",
       " <span class=\"release\">(Single)</span>,\n",
       " <span class=\"artist\">Sunflower Bean</span>,\n",
       " <span class=\"song\">Champagne Taste</span>,\n",
       " <span class=\"release\">Mortal Primetime</span>,\n",
       " <span class=\"artist\">Ray LaMontagne</span>,\n",
       " <span class=\"song\">And They Call Her California</span>,\n",
       " <span class=\"release\">Long Way Home</span>,\n",
       " <span class=\"artist\">Spoon</span>,\n",
       " <span class=\"song\">The Underdog</span>,\n",
       " <span class=\"release\">Ga Ga Ga Ga Ga</span>,\n",
       " <span class=\"artist\">Noeline Hofmann</span>,\n",
       " <span class=\"song\">Lightning in July (Prairie Fire)</span>,\n",
       " <span class=\"release\">Purple Gas</span>,\n",
       " <span class=\"artist\">Inhaler</span>,\n",
       " <span class=\"song\">Your House</span>,\n",
       " <span class=\"release\">Open Wide</span>,\n",
       " <span class=\"artist\">John Prine</span>,\n",
       " <span class=\"song\">Lake Marie</span>,\n",
       " <span class=\"release\">Lost Dogs &amp; Mixed Blessings</span>,\n",
       " <span class=\"artist\">49 Winchester</span>,\n",
       " <span class=\"song\">Miles to Go</span>,\n",
       " <span class=\"release\">(Single)</span>,\n",
       " <span class=\"artist\">Ruthie Foster</span>,\n",
       " <span class=\"song\">Rainbow</span>,\n",
       " <span class=\"release\">Mileage</span>,\n",
       " <span class=\"artist\">Joy Oladokun</span>,\n",
       " <span class=\"song\">DUST/DIVINITY</span>,\n",
       " <span class=\"release\">Observations From A Crowded Room</span>,\n",
       " <span class=\"artist\">Death Cab for Cutie</span>,\n",
       " <span class=\"song\">Cath</span>,\n",
       " <span class=\"release\">Narrow Stairs</span>,\n",
       " <span class=\"artist\">Jeremie Albino</span>,\n",
       " <span class=\"song\">Rolling Down the 405</span>,\n",
       " <span class=\"release\">Our Time In The Sun</span>,\n",
       " <span class=\"artist\">Cristina Vane f/ Molly Tuttle</span>,\n",
       " <span class=\"song\">Hear My Call</span>,\n",
       " <span class=\"release\">Hear My Call</span>,\n",
       " <span class=\"artist\">Ziggy Marley &amp; the Melody Makers</span>,\n",
       " <span class=\"song\">Tomorrow People</span>,\n",
       " <span class=\"release\">Conscious Party</span>,\n",
       " <span class=\"artist\">Chuck Prophet</span>,\n",
       " <span class=\"song\">First Came The Thunder</span>,\n",
       " <span class=\"release\">Wake the Dead</span>,\n",
       " <span class=\"artist\">The Vices</span>,\n",
       " <span class=\"song\">Before It Might Be Gone</span>,\n",
       " <span class=\"release\">Before It Might Be Gone</span>,\n",
       " <span class=\"artist\">Jim Lauderdale</span>,\n",
       " <span class=\"song\">Don't Leave Your Light Low</span>,\n",
       " <span class=\"release\">Persimmons</span>,\n",
       " <span class=\"artist\">Humbird</span>,\n",
       " <span class=\"song\">Blueberry Bog</span>,\n",
       " <span class=\"release\">Right On</span>,\n",
       " <span class=\"artist\">ALO</span>,\n",
       " <span class=\"song\">Blank Canvas</span>,\n",
       " <span class=\"release\">Frames</span>,\n",
       " <span class=\"artist\">Tracy Chapman</span>,\n",
       " <span class=\"song\">You're the One</span>,\n",
       " <span class=\"release\">Let It Rain</span>,\n",
       " <span class=\"artist\">The Bamboos</span>,\n",
       " <span class=\"song\">Hard Up</span>,\n",
       " <span class=\"release\">Hard Up</span>,\n",
       " <span class=\"artist\">Oracle Sisters</span>,\n",
       " <span class=\"song\">Alouette</span>,\n",
       " <span class=\"release\">Divinations</span>,\n",
       " <span class=\"artist\">Ruthie Foster</span>,\n",
       " <span class=\"song\">Singing the Blues</span>,\n",
       " <span class=\"release\">Promise of a Brand New Day</span>,\n",
       " <span class=\"artist\">Local The Neighbour</span>,\n",
       " <span class=\"song\">Cruise Control</span>,\n",
       " <span class=\"release\">VALLEY pt. 2</span>,\n",
       " <span class=\"artist\">Kasey Chambers</span>,\n",
       " <span class=\"song\">Broken Cup</span>,\n",
       " <span class=\"release\">Backbone</span>,\n",
       " <span class=\"artist\">Hiss Golden Messenger</span>,\n",
       " <span class=\"song\">Heart like a Levee</span>,\n",
       " <span class=\"release\">Heart Like a Levee</span>,\n",
       " <span class=\"artist\">Daughter of Swords</span>,\n",
       " <span class=\"song\">Alone Together</span>,\n",
       " <span class=\"release\">Cardinals At The Window</span>,\n",
       " <span class=\"artist\">Soccer Mommy</span>,\n",
       " <span class=\"song\">Circle the Drain</span>,\n",
       " <span class=\"release\">Color Theory</span>,\n",
       " <span class=\"artist\">Pug Johnson</span>,\n",
       " <span class=\"song\">Believer</span>,\n",
       " <span class=\"release\">El Cabron</span>,\n",
       " <span class=\"artist\">JD McPherson</span>,\n",
       " <span class=\"song\">I Can't Go Anywhere With You</span>,\n",
       " <span class=\"release\">Nite Owls</span>,\n",
       " <span class=\"artist\">Guster</span>,\n",
       " <span class=\"song\">Amsterdam</span>,\n",
       " <span class=\"release\">Keep It Together</span>,\n",
       " <span class=\"artist\">Jungle</span>,\n",
       " <span class=\"song\">Keep Me Satisfied</span>,\n",
       " <span class=\"release\">(Single)</span>,\n",
       " <span class=\"artist\">Johnny Delaware</span>,\n",
       " <span class=\"song\">Running</span>,\n",
       " <span class=\"release\">Para Llevar</span>,\n",
       " <span class=\"artist\">Nickel Creek</span>,\n",
       " <span class=\"song\">This Side</span>,\n",
       " <span class=\"release\">This Side</span>,\n",
       " <span class=\"artist\">Luke Winslow-King</span>,\n",
       " <span class=\"song\">Flash-A-Magic</span>,\n",
       " <span class=\"release\">Flash-A-Magic</span>,\n",
       " <span class=\"artist\">The English Beat</span>,\n",
       " <span class=\"song\">Best Friend</span>,\n",
       " <span class=\"release\">I Just Can't Stop It</span>,\n",
       " <span class=\"artist\">Bebe Stockwell</span>,\n",
       " <span class=\"song\">Minor Inconveniences</span>,\n",
       " <span class=\"release\">(Single)</span>,\n",
       " <span class=\"artist\">Wallice</span>,\n",
       " <span class=\"song\">I Want You Yesterday</span>,\n",
       " <span class=\"release\">The Jester</span>,\n",
       " <span class=\"artist\">Jesper Lindell</span>,\n",
       " <span class=\"song\">One of These Rainy Days</span>,\n",
       " <span class=\"release\">Before the Sun</span>,\n",
       " <span class=\"artist\">The Smile</span>,\n",
       " <span class=\"song\">No Words</span>,\n",
       " <span class=\"release\">Cutouts</span>,\n",
       " <span class=\"artist\">Mumford &amp; Sons</span>,\n",
       " <span class=\"song\">Rushmere</span>,\n",
       " <span class=\"release\">Rushmere</span>,\n",
       " <span class=\"artist\">Ray Charles</span>,\n",
       " <span class=\"song\">What'd I Say Pts I and II</span>,\n",
       " <span class=\"release\">What'd I Say</span>,\n",
       " <span class=\"artist\">Kat Edmonson</span>,\n",
       " <span class=\"song\">Keep Movin'</span>,\n",
       " <span class=\"release\">Keep Movin'</span>,\n",
       " <span class=\"artist\">The Heavy Heavy</span>,\n",
       " <span class=\"song\">Feel</span>,\n",
       " <span class=\"release\">One of a Kind</span>,\n",
       " <span class=\"artist\">Waxahatchee</span>,\n",
       " <span class=\"song\">Can't Do Much</span>,\n",
       " <span class=\"release\">Saint Cloud</span>,\n",
       " <span class=\"artist\">Johnny Blue Skies</span>,\n",
       " <span class=\"song\">If The Sun Never Rises Again</span>,\n",
       " <span class=\"release\">Passage Du Desir</span>,\n",
       " <span class=\"artist\">Charley Crockett</span>,\n",
       " <span class=\"song\">Lonesome Drifter</span>,\n",
       " <span class=\"release\">Lonesome Drifter</span>,\n",
       " <span class=\"artist\">Morrissey</span>,\n",
       " <span class=\"song\">Suedehead</span>,\n",
       " <span class=\"release\">Viva Hate</span>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spanlist = wnrn.find_all(\"span\")\n",
    "spanlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the HTML source code distinguishes between the three types of datapoint with different `class` values. To limit this list to just the artists, we can specify the `\"artist\"` class as a second argument of `.find_all()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"artist\">Baby Rose f/ BADBADNOTGOOD</span>,\n",
       " <span class=\"artist\">Angie McMahon</span>,\n",
       " <span class=\"artist\">Willie Nelson and Daniel Lanois</span>,\n",
       " <span class=\"artist\">Lucy Dacus</span>,\n",
       " <span class=\"artist\">Brigitte Calls Me Baby</span>,\n",
       " <span class=\"artist\">Kashus Culpepper</span>,\n",
       " <span class=\"artist\">Deep Sea Diver</span>,\n",
       " <span class=\"artist\">The Devil Makes Three</span>,\n",
       " <span class=\"artist\">The Barons</span>,\n",
       " <span class=\"artist\">Sunflower Bean</span>,\n",
       " <span class=\"artist\">Ray LaMontagne</span>,\n",
       " <span class=\"artist\">Spoon</span>,\n",
       " <span class=\"artist\">Noeline Hofmann</span>,\n",
       " <span class=\"artist\">Inhaler</span>,\n",
       " <span class=\"artist\">John Prine</span>,\n",
       " <span class=\"artist\">49 Winchester</span>,\n",
       " <span class=\"artist\">Ruthie Foster</span>,\n",
       " <span class=\"artist\">Joy Oladokun</span>,\n",
       " <span class=\"artist\">Death Cab for Cutie</span>,\n",
       " <span class=\"artist\">Jeremie Albino</span>,\n",
       " <span class=\"artist\">Cristina Vane f/ Molly Tuttle</span>,\n",
       " <span class=\"artist\">Ziggy Marley &amp; the Melody Makers</span>,\n",
       " <span class=\"artist\">Chuck Prophet</span>,\n",
       " <span class=\"artist\">The Vices</span>,\n",
       " <span class=\"artist\">Jim Lauderdale</span>,\n",
       " <span class=\"artist\">Humbird</span>,\n",
       " <span class=\"artist\">ALO</span>,\n",
       " <span class=\"artist\">Tracy Chapman</span>,\n",
       " <span class=\"artist\">The Bamboos</span>,\n",
       " <span class=\"artist\">Oracle Sisters</span>,\n",
       " <span class=\"artist\">Ruthie Foster</span>,\n",
       " <span class=\"artist\">Local The Neighbour</span>,\n",
       " <span class=\"artist\">Kasey Chambers</span>,\n",
       " <span class=\"artist\">Hiss Golden Messenger</span>,\n",
       " <span class=\"artist\">Daughter of Swords</span>,\n",
       " <span class=\"artist\">Soccer Mommy</span>,\n",
       " <span class=\"artist\">Pug Johnson</span>,\n",
       " <span class=\"artist\">JD McPherson</span>,\n",
       " <span class=\"artist\">Guster</span>,\n",
       " <span class=\"artist\">Jungle</span>,\n",
       " <span class=\"artist\">Johnny Delaware</span>,\n",
       " <span class=\"artist\">Nickel Creek</span>,\n",
       " <span class=\"artist\">Luke Winslow-King</span>,\n",
       " <span class=\"artist\">The English Beat</span>,\n",
       " <span class=\"artist\">Bebe Stockwell</span>,\n",
       " <span class=\"artist\">Wallice</span>,\n",
       " <span class=\"artist\">Jesper Lindell</span>,\n",
       " <span class=\"artist\">The Smile</span>,\n",
       " <span class=\"artist\">Mumford &amp; Sons</span>,\n",
       " <span class=\"artist\">Ray Charles</span>,\n",
       " <span class=\"artist\">Kat Edmonson</span>,\n",
       " <span class=\"artist\">The Heavy Heavy</span>,\n",
       " <span class=\"artist\">Waxahatchee</span>,\n",
       " <span class=\"artist\">Johnny Blue Skies</span>,\n",
       " <span class=\"artist\">Charley Crockett</span>,\n",
       " <span class=\"artist\">Morrissey</span>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artistlist = wnrn.find_all(\"span\", \"artist\")\n",
    "artistlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise we can create lists of the songs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"song\">Weekness</span>,\n",
       " <span class=\"song\">Untangling</span>,\n",
       " <span class=\"song\">The Maker</span>,\n",
       " <span class=\"song\">Ankles</span>,\n",
       " <span class=\"song\">Too Easy</span>,\n",
       " <span class=\"song\">After Me?</span>,\n",
       " <span class=\"song\">Shovel</span>,\n",
       " <span class=\"song\">Spirits</span>,\n",
       " <span class=\"song\">Would You Want It (If You Had It)</span>,\n",
       " <span class=\"song\">Champagne Taste</span>,\n",
       " <span class=\"song\">And They Call Her California</span>,\n",
       " <span class=\"song\">The Underdog</span>,\n",
       " <span class=\"song\">Lightning in July (Prairie Fire)</span>,\n",
       " <span class=\"song\">Your House</span>,\n",
       " <span class=\"song\">Lake Marie</span>,\n",
       " <span class=\"song\">Miles to Go</span>,\n",
       " <span class=\"song\">Rainbow</span>,\n",
       " <span class=\"song\">DUST/DIVINITY</span>,\n",
       " <span class=\"song\">Cath</span>,\n",
       " <span class=\"song\">Rolling Down the 405</span>,\n",
       " <span class=\"song\">Hear My Call</span>,\n",
       " <span class=\"song\">Tomorrow People</span>,\n",
       " <span class=\"song\">First Came The Thunder</span>,\n",
       " <span class=\"song\">Before It Might Be Gone</span>,\n",
       " <span class=\"song\">Don't Leave Your Light Low</span>,\n",
       " <span class=\"song\">Blueberry Bog</span>,\n",
       " <span class=\"song\">Blank Canvas</span>,\n",
       " <span class=\"song\">You're the One</span>,\n",
       " <span class=\"song\">Hard Up</span>,\n",
       " <span class=\"song\">Alouette</span>,\n",
       " <span class=\"song\">Singing the Blues</span>,\n",
       " <span class=\"song\">Cruise Control</span>,\n",
       " <span class=\"song\">Broken Cup</span>,\n",
       " <span class=\"song\">Heart like a Levee</span>,\n",
       " <span class=\"song\">Alone Together</span>,\n",
       " <span class=\"song\">Circle the Drain</span>,\n",
       " <span class=\"song\">Believer</span>,\n",
       " <span class=\"song\">I Can't Go Anywhere With You</span>,\n",
       " <span class=\"song\">Amsterdam</span>,\n",
       " <span class=\"song\">Keep Me Satisfied</span>,\n",
       " <span class=\"song\">Running</span>,\n",
       " <span class=\"song\">This Side</span>,\n",
       " <span class=\"song\">Flash-A-Magic</span>,\n",
       " <span class=\"song\">Best Friend</span>,\n",
       " <span class=\"song\">Minor Inconveniences</span>,\n",
       " <span class=\"song\">I Want You Yesterday</span>,\n",
       " <span class=\"song\">One of These Rainy Days</span>,\n",
       " <span class=\"song\">No Words</span>,\n",
       " <span class=\"song\">Rushmere</span>,\n",
       " <span class=\"song\">What'd I Say Pts I and II</span>,\n",
       " <span class=\"song\">Keep Movin'</span>,\n",
       " <span class=\"song\">Feel</span>,\n",
       " <span class=\"song\">Can't Do Much</span>,\n",
       " <span class=\"song\">If The Sun Never Rises Again</span>,\n",
       " <span class=\"song\">Lonesome Drifter</span>,\n",
       " <span class=\"song\">Suedehead</span>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songlist = wnrn.find_all(\"span\", \"song\")\n",
    "songlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a list for the albums:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"release\">Slow Burn EP</span>,\n",
       " <span class=\"release\">Light Sides EP</span>,\n",
       " <span class=\"release\">Teatro</span>,\n",
       " <span class=\"release\">Forever Is A Feeling</span>,\n",
       " <span class=\"release\">The Future Is Our Way Out</span>,\n",
       " <span class=\"release\">(Single)</span>,\n",
       " <span class=\"release\">Billboard Heart</span>,\n",
       " <span class=\"release\">Spirits</span>,\n",
       " <span class=\"release\">(Single)</span>,\n",
       " <span class=\"release\">Mortal Primetime</span>,\n",
       " <span class=\"release\">Long Way Home</span>,\n",
       " <span class=\"release\">Ga Ga Ga Ga Ga</span>,\n",
       " <span class=\"release\">Purple Gas</span>,\n",
       " <span class=\"release\">Open Wide</span>,\n",
       " <span class=\"release\">Lost Dogs &amp; Mixed Blessings</span>,\n",
       " <span class=\"release\">(Single)</span>,\n",
       " <span class=\"release\">Mileage</span>,\n",
       " <span class=\"release\">Observations From A Crowded Room</span>,\n",
       " <span class=\"release\">Narrow Stairs</span>,\n",
       " <span class=\"release\">Our Time In The Sun</span>,\n",
       " <span class=\"release\">Hear My Call</span>,\n",
       " <span class=\"release\">Conscious Party</span>,\n",
       " <span class=\"release\">Wake the Dead</span>,\n",
       " <span class=\"release\">Before It Might Be Gone</span>,\n",
       " <span class=\"release\">Persimmons</span>,\n",
       " <span class=\"release\">Right On</span>,\n",
       " <span class=\"release\">Frames</span>,\n",
       " <span class=\"release\">Let It Rain</span>,\n",
       " <span class=\"release\">Hard Up</span>,\n",
       " <span class=\"release\">Divinations</span>,\n",
       " <span class=\"release\">Promise of a Brand New Day</span>,\n",
       " <span class=\"release\">VALLEY pt. 2</span>,\n",
       " <span class=\"release\">Backbone</span>,\n",
       " <span class=\"release\">Heart Like a Levee</span>,\n",
       " <span class=\"release\">Cardinals At The Window</span>,\n",
       " <span class=\"release\">Color Theory</span>,\n",
       " <span class=\"release\">El Cabron</span>,\n",
       " <span class=\"release\">Nite Owls</span>,\n",
       " <span class=\"release\">Keep It Together</span>,\n",
       " <span class=\"release\">(Single)</span>,\n",
       " <span class=\"release\">Para Llevar</span>,\n",
       " <span class=\"release\">This Side</span>,\n",
       " <span class=\"release\">Flash-A-Magic</span>,\n",
       " <span class=\"release\">I Just Can't Stop It</span>,\n",
       " <span class=\"release\">(Single)</span>,\n",
       " <span class=\"release\">The Jester</span>,\n",
       " <span class=\"release\">Before the Sun</span>,\n",
       " <span class=\"release\">Cutouts</span>,\n",
       " <span class=\"release\">Rushmere</span>,\n",
       " <span class=\"release\">What'd I Say</span>,\n",
       " <span class=\"release\">Keep Movin'</span>,\n",
       " <span class=\"release\">One of a Kind</span>,\n",
       " <span class=\"release\">Saint Cloud</span>,\n",
       " <span class=\"release\">Passage Du Desir</span>,\n",
       " <span class=\"release\">Lonesome Drifter</span>,\n",
       " <span class=\"release\">Viva Hate</span>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "albumlist = wnrn.find_all(\"span\", \"release\")\n",
    "albumlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to also extract the times each song was played. I look at the HTML code and find an example of the play time. These times are stored in the `<td>` tag with `class=\"spin-time\"`. I create a list of these times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404900332\">10:01 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404900043\">9:57 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404899761\">9:52 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404899574\">9:49 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404899290\">9:44 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404899108\">9:41 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404898822\">9:37 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404898449\">9:31 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404898231\">9:27 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404898035\">9:24 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404897743\">9:18 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404897461\">9:14 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404897244\">9:10 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404896934\">9:04 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404896543\">8:59 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404896311\">8:55 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404896139\">8:51 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404895788\">8:45 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404895496\">8:41 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404895300\">8:38 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404894901\">8:31 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404894703\">8:27 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404894280\">8:19 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404894034\">8:15 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404893873\">8:11 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404893736\">8:09 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404893382\">8:03 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404893206\">8:00 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404892835\">7:55 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404892629\">7:52 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404892405\">7:48 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404892087\">7:43 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404891894\">7:39 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404891665\">7:35 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404891511\">7:33 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404890936\">7:22 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404890703\">7:18 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404890440\">7:14 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404890225\">7:10 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404890090\">7:07 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404889741\">7:02 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404889447\">6:58 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404889226\">6:55 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404889050\">6:52 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404888886\">6:49 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404888635\">6:45 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404888433\">6:42 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404888131\">6:37 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404887816\">6:32 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404887419\">6:25 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404887228\">6:22 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404886918\">6:17 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404886706\">6:13 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404886427\">6:09 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404886148\">6:04 AM</a></td>,\n",
       " <td class=\"spin-time\"><a href=\"/WNRN/pl/20207938/WNRN?sp=404885903\">6:00 AM</a></td>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timelist = wnrn.find_all(\"td\", \"spin-time\")\n",
    "timelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes the information we need exists in a particular tag, but only when a specific attribute is present. For example, in the WNRN playlist HTML there are many `<a>` tags, but only some of those tags include a `title` attribute. To extract all of the `<a>` tags with a `title` attribute, specify `title=True` in the call to `.find_all()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"buy-link\" data-vendor=\"apple\" href=\"#\" target=\"_blank\" title='View \"Baby Rose f/ BADBADNOTGOOD - Weekness\" on Apple'><div alt='View \"Baby Rose f/ BADBADNOTGOOD - Weekness\" on Apple' class=\"buy-icon buy-icon-apple\"></div></a>, <a class=\"buy-link\" data-vendor=\"amazon\" href=\"#\" target=\"_blank\" title='View \"Baby Rose f/ BADBADNOTGOOD - Weekness\" on Amazon'><div alt='View \"Baby Rose f/ BADBADNOTGOOD - Weekness\" on Amazon' class=\"buy-icon buy-icon-amazon\"></div></a>, <a class=\"buy-link\" data-vendor=\"spotify\" href=\"#\" target=\"_blank\" title='View \"Baby Rose f/ BADBADNOTGOOD - Weekness\" on Spotify'><div alt='View \"Baby Rose f/ BADBADNOTGOOD - Weekness\" on Spotify' class=\"buy-icon buy-icon-spotify\"></div></a>, <a class=\"buy-link\" data-vendor=\"apple\" href=\"#\" target=\"_blank\" title='View \"Angie McMahon - Untangling\" on Apple'><div alt='View \"Angie McMahon - Untangling\" on Apple' class=\"buy-icon buy-icon-apple\"></div></a>, <a class=\"buy-link\" data-vendor=\"amazon\" href=\"#\" target=\"_blank\" title='View \"Angie McMahon - Untangling\" on Amazon'><div alt='View \"Angie McMahon - Untangling\" on Amazon' class=\"buy-icon buy-icon-amazon\"></div></a>]\n"
     ]
    }
   ],
   "source": [
    "atags_title = wnrn.find_all(\"a\", title=True)\n",
    "print(atags_title[0:5]) # just show the first 6 elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a Data Frame from HTML Data\n",
    "Next we need to place these data into a clean data frame. For that, we will need to keep the valid data while dropping the HTML tags. We stored the tags with the artists, songs, albums, and times in separate lists. Every name is stored as a navigable string in the HTML tags, so to extract these names we need to loop across the elements of the list. The simplest loop for this task is called a **list comprehension**, which has the following syntax:\n",
    "\n",
    "*newlist* `= [` *expression* `for` *item* `in` *oldlist* `if` *condition* `]`\n",
    "\n",
    "In this syntax, we are creating a new list by iteratively performing operations on the elements of an existing list (*oldlist*). *item* is a token that we will use to represent one item of the existing list. *expression* is the same Python code we would use on a single element of the existing list, except we replace the name of the element with the token defined with *item*. Finally *condition* is an optional part of this code which sets a filter by which only certain elements of the old list are transformed and placed into the new list (there's an example of conditioning in a comprehension loop in the section on [spiders](#spider)).\n",
    "\n",
    "For example, to extract the navigable string from every element of `artistlist`, we can set *item* to `a`, *expression* to `a.string`, and *list* to `artistlist`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baby Rose f/ BADBADNOTGOOD',\n",
       " 'Angie McMahon',\n",
       " 'Willie Nelson and Daniel Lanois',\n",
       " 'Lucy Dacus',\n",
       " 'Brigitte Calls Me Baby',\n",
       " 'Kashus Culpepper',\n",
       " 'Deep Sea Diver',\n",
       " 'The Devil Makes Three',\n",
       " 'The Barons',\n",
       " 'Sunflower Bean',\n",
       " 'Ray LaMontagne',\n",
       " 'Spoon',\n",
       " 'Noeline Hofmann',\n",
       " 'Inhaler',\n",
       " 'John Prine',\n",
       " '49 Winchester',\n",
       " 'Ruthie Foster',\n",
       " 'Joy Oladokun',\n",
       " 'Death Cab for Cutie',\n",
       " 'Jeremie Albino',\n",
       " 'Cristina Vane f/ Molly Tuttle',\n",
       " 'Ziggy Marley & the Melody Makers',\n",
       " 'Chuck Prophet',\n",
       " 'The Vices',\n",
       " 'Jim Lauderdale',\n",
       " 'Humbird',\n",
       " 'ALO',\n",
       " 'Tracy Chapman',\n",
       " 'The Bamboos',\n",
       " 'Oracle Sisters',\n",
       " 'Ruthie Foster',\n",
       " 'Local The Neighbour',\n",
       " 'Kasey Chambers',\n",
       " 'Hiss Golden Messenger',\n",
       " 'Daughter of Swords',\n",
       " 'Soccer Mommy',\n",
       " 'Pug Johnson',\n",
       " 'JD McPherson',\n",
       " 'Guster',\n",
       " 'Jungle',\n",
       " 'Johnny Delaware',\n",
       " 'Nickel Creek',\n",
       " 'Luke Winslow-King',\n",
       " 'The English Beat',\n",
       " 'Bebe Stockwell',\n",
       " 'Wallice',\n",
       " 'Jesper Lindell',\n",
       " 'The Smile',\n",
       " 'Mumford & Sons',\n",
       " 'Ray Charles',\n",
       " 'Kat Edmonson',\n",
       " 'The Heavy Heavy',\n",
       " 'Waxahatchee',\n",
       " 'Johnny Blue Skies',\n",
       " 'Charley Crockett',\n",
       " 'Morrissey']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = [a.string for a in artistlist]\n",
    "artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, we extract the navigable strings for the songs, albums, and times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = [a.string for a in songlist]\n",
    "albums = [a.string for a in albumlist]\n",
    "times = [a.string for a in timelist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, to construct a clean data frame, we create a dictionary that combines these lists and passes this dictionary to the `pd.DataFrame()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>album</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10:01 AM</td>\n",
       "      <td>Baby Rose f/ BADBADNOTGOOD</td>\n",
       "      <td>Weekness</td>\n",
       "      <td>Slow Burn EP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9:57 AM</td>\n",
       "      <td>Angie McMahon</td>\n",
       "      <td>Untangling</td>\n",
       "      <td>Light Sides EP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9:52 AM</td>\n",
       "      <td>Willie Nelson and Daniel Lanois</td>\n",
       "      <td>The Maker</td>\n",
       "      <td>Teatro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9:49 AM</td>\n",
       "      <td>Lucy Dacus</td>\n",
       "      <td>Ankles</td>\n",
       "      <td>Forever Is A Feeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9:44 AM</td>\n",
       "      <td>Brigitte Calls Me Baby</td>\n",
       "      <td>Too Easy</td>\n",
       "      <td>The Future Is Our Way Out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9:41 AM</td>\n",
       "      <td>Kashus Culpepper</td>\n",
       "      <td>After Me?</td>\n",
       "      <td>(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9:37 AM</td>\n",
       "      <td>Deep Sea Diver</td>\n",
       "      <td>Shovel</td>\n",
       "      <td>Billboard Heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9:31 AM</td>\n",
       "      <td>The Devil Makes Three</td>\n",
       "      <td>Spirits</td>\n",
       "      <td>Spirits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9:27 AM</td>\n",
       "      <td>The Barons</td>\n",
       "      <td>Would You Want It (If You Had It)</td>\n",
       "      <td>(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9:24 AM</td>\n",
       "      <td>Sunflower Bean</td>\n",
       "      <td>Champagne Taste</td>\n",
       "      <td>Mortal Primetime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9:18 AM</td>\n",
       "      <td>Ray LaMontagne</td>\n",
       "      <td>And They Call Her California</td>\n",
       "      <td>Long Way Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9:14 AM</td>\n",
       "      <td>Spoon</td>\n",
       "      <td>The Underdog</td>\n",
       "      <td>Ga Ga Ga Ga Ga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9:10 AM</td>\n",
       "      <td>Noeline Hofmann</td>\n",
       "      <td>Lightning in July (Prairie Fire)</td>\n",
       "      <td>Purple Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9:04 AM</td>\n",
       "      <td>Inhaler</td>\n",
       "      <td>Your House</td>\n",
       "      <td>Open Wide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8:59 AM</td>\n",
       "      <td>John Prine</td>\n",
       "      <td>Lake Marie</td>\n",
       "      <td>Lost Dogs &amp; Mixed Blessings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8:55 AM</td>\n",
       "      <td>49 Winchester</td>\n",
       "      <td>Miles to Go</td>\n",
       "      <td>(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>8:51 AM</td>\n",
       "      <td>Ruthie Foster</td>\n",
       "      <td>Rainbow</td>\n",
       "      <td>Mileage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8:45 AM</td>\n",
       "      <td>Joy Oladokun</td>\n",
       "      <td>DUST/DIVINITY</td>\n",
       "      <td>Observations From A Crowded Room</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8:41 AM</td>\n",
       "      <td>Death Cab for Cutie</td>\n",
       "      <td>Cath</td>\n",
       "      <td>Narrow Stairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8:38 AM</td>\n",
       "      <td>Jeremie Albino</td>\n",
       "      <td>Rolling Down the 405</td>\n",
       "      <td>Our Time In The Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8:31 AM</td>\n",
       "      <td>Cristina Vane f/ Molly Tuttle</td>\n",
       "      <td>Hear My Call</td>\n",
       "      <td>Hear My Call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8:27 AM</td>\n",
       "      <td>Ziggy Marley &amp; the Melody Makers</td>\n",
       "      <td>Tomorrow People</td>\n",
       "      <td>Conscious Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8:19 AM</td>\n",
       "      <td>Chuck Prophet</td>\n",
       "      <td>First Came The Thunder</td>\n",
       "      <td>Wake the Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8:15 AM</td>\n",
       "      <td>The Vices</td>\n",
       "      <td>Before It Might Be Gone</td>\n",
       "      <td>Before It Might Be Gone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8:11 AM</td>\n",
       "      <td>Jim Lauderdale</td>\n",
       "      <td>Don't Leave Your Light Low</td>\n",
       "      <td>Persimmons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8:09 AM</td>\n",
       "      <td>Humbird</td>\n",
       "      <td>Blueberry Bog</td>\n",
       "      <td>Right On</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8:03 AM</td>\n",
       "      <td>ALO</td>\n",
       "      <td>Blank Canvas</td>\n",
       "      <td>Frames</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8:00 AM</td>\n",
       "      <td>Tracy Chapman</td>\n",
       "      <td>You're the One</td>\n",
       "      <td>Let It Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7:55 AM</td>\n",
       "      <td>The Bamboos</td>\n",
       "      <td>Hard Up</td>\n",
       "      <td>Hard Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7:52 AM</td>\n",
       "      <td>Oracle Sisters</td>\n",
       "      <td>Alouette</td>\n",
       "      <td>Divinations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7:48 AM</td>\n",
       "      <td>Ruthie Foster</td>\n",
       "      <td>Singing the Blues</td>\n",
       "      <td>Promise of a Brand New Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>7:43 AM</td>\n",
       "      <td>Local The Neighbour</td>\n",
       "      <td>Cruise Control</td>\n",
       "      <td>VALLEY pt. 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>7:39 AM</td>\n",
       "      <td>Kasey Chambers</td>\n",
       "      <td>Broken Cup</td>\n",
       "      <td>Backbone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>7:35 AM</td>\n",
       "      <td>Hiss Golden Messenger</td>\n",
       "      <td>Heart like a Levee</td>\n",
       "      <td>Heart Like a Levee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7:33 AM</td>\n",
       "      <td>Daughter of Swords</td>\n",
       "      <td>Alone Together</td>\n",
       "      <td>Cardinals At The Window</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7:22 AM</td>\n",
       "      <td>Soccer Mommy</td>\n",
       "      <td>Circle the Drain</td>\n",
       "      <td>Color Theory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7:18 AM</td>\n",
       "      <td>Pug Johnson</td>\n",
       "      <td>Believer</td>\n",
       "      <td>El Cabron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7:14 AM</td>\n",
       "      <td>JD McPherson</td>\n",
       "      <td>I Can't Go Anywhere With You</td>\n",
       "      <td>Nite Owls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>7:10 AM</td>\n",
       "      <td>Guster</td>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>Keep It Together</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>7:07 AM</td>\n",
       "      <td>Jungle</td>\n",
       "      <td>Keep Me Satisfied</td>\n",
       "      <td>(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7:02 AM</td>\n",
       "      <td>Johnny Delaware</td>\n",
       "      <td>Running</td>\n",
       "      <td>Para Llevar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6:58 AM</td>\n",
       "      <td>Nickel Creek</td>\n",
       "      <td>This Side</td>\n",
       "      <td>This Side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>6:55 AM</td>\n",
       "      <td>Luke Winslow-King</td>\n",
       "      <td>Flash-A-Magic</td>\n",
       "      <td>Flash-A-Magic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6:52 AM</td>\n",
       "      <td>The English Beat</td>\n",
       "      <td>Best Friend</td>\n",
       "      <td>I Just Can't Stop It</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6:49 AM</td>\n",
       "      <td>Bebe Stockwell</td>\n",
       "      <td>Minor Inconveniences</td>\n",
       "      <td>(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>6:45 AM</td>\n",
       "      <td>Wallice</td>\n",
       "      <td>I Want You Yesterday</td>\n",
       "      <td>The Jester</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6:42 AM</td>\n",
       "      <td>Jesper Lindell</td>\n",
       "      <td>One of These Rainy Days</td>\n",
       "      <td>Before the Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6:37 AM</td>\n",
       "      <td>The Smile</td>\n",
       "      <td>No Words</td>\n",
       "      <td>Cutouts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6:32 AM</td>\n",
       "      <td>Mumford &amp; Sons</td>\n",
       "      <td>Rushmere</td>\n",
       "      <td>Rushmere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>6:25 AM</td>\n",
       "      <td>Ray Charles</td>\n",
       "      <td>What'd I Say Pts I and II</td>\n",
       "      <td>What'd I Say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6:22 AM</td>\n",
       "      <td>Kat Edmonson</td>\n",
       "      <td>Keep Movin'</td>\n",
       "      <td>Keep Movin'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6:17 AM</td>\n",
       "      <td>The Heavy Heavy</td>\n",
       "      <td>Feel</td>\n",
       "      <td>One of a Kind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6:13 AM</td>\n",
       "      <td>Waxahatchee</td>\n",
       "      <td>Can't Do Much</td>\n",
       "      <td>Saint Cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6:09 AM</td>\n",
       "      <td>Johnny Blue Skies</td>\n",
       "      <td>If The Sun Never Rises Again</td>\n",
       "      <td>Passage Du Desir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6:04 AM</td>\n",
       "      <td>Charley Crockett</td>\n",
       "      <td>Lonesome Drifter</td>\n",
       "      <td>Lonesome Drifter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6:00 AM</td>\n",
       "      <td>Morrissey</td>\n",
       "      <td>Suedehead</td>\n",
       "      <td>Viva Hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time                            artist  \\\n",
       "0   10:01 AM        Baby Rose f/ BADBADNOTGOOD   \n",
       "1    9:57 AM                     Angie McMahon   \n",
       "2    9:52 AM   Willie Nelson and Daniel Lanois   \n",
       "3    9:49 AM                        Lucy Dacus   \n",
       "4    9:44 AM            Brigitte Calls Me Baby   \n",
       "5    9:41 AM                  Kashus Culpepper   \n",
       "6    9:37 AM                    Deep Sea Diver   \n",
       "7    9:31 AM             The Devil Makes Three   \n",
       "8    9:27 AM                        The Barons   \n",
       "9    9:24 AM                    Sunflower Bean   \n",
       "10   9:18 AM                    Ray LaMontagne   \n",
       "11   9:14 AM                             Spoon   \n",
       "12   9:10 AM                   Noeline Hofmann   \n",
       "13   9:04 AM                           Inhaler   \n",
       "14   8:59 AM                        John Prine   \n",
       "15   8:55 AM                     49 Winchester   \n",
       "16   8:51 AM                     Ruthie Foster   \n",
       "17   8:45 AM                      Joy Oladokun   \n",
       "18   8:41 AM               Death Cab for Cutie   \n",
       "19   8:38 AM                    Jeremie Albino   \n",
       "20   8:31 AM     Cristina Vane f/ Molly Tuttle   \n",
       "21   8:27 AM  Ziggy Marley & the Melody Makers   \n",
       "22   8:19 AM                     Chuck Prophet   \n",
       "23   8:15 AM                         The Vices   \n",
       "24   8:11 AM                    Jim Lauderdale   \n",
       "25   8:09 AM                           Humbird   \n",
       "26   8:03 AM                               ALO   \n",
       "27   8:00 AM                     Tracy Chapman   \n",
       "28   7:55 AM                       The Bamboos   \n",
       "29   7:52 AM                    Oracle Sisters   \n",
       "30   7:48 AM                     Ruthie Foster   \n",
       "31   7:43 AM               Local The Neighbour   \n",
       "32   7:39 AM                    Kasey Chambers   \n",
       "33   7:35 AM             Hiss Golden Messenger   \n",
       "34   7:33 AM                Daughter of Swords   \n",
       "35   7:22 AM                      Soccer Mommy   \n",
       "36   7:18 AM                       Pug Johnson   \n",
       "37   7:14 AM                      JD McPherson   \n",
       "38   7:10 AM                            Guster   \n",
       "39   7:07 AM                            Jungle   \n",
       "40   7:02 AM                   Johnny Delaware   \n",
       "41   6:58 AM                      Nickel Creek   \n",
       "42   6:55 AM                 Luke Winslow-King   \n",
       "43   6:52 AM                  The English Beat   \n",
       "44   6:49 AM                    Bebe Stockwell   \n",
       "45   6:45 AM                           Wallice   \n",
       "46   6:42 AM                    Jesper Lindell   \n",
       "47   6:37 AM                         The Smile   \n",
       "48   6:32 AM                    Mumford & Sons   \n",
       "49   6:25 AM                       Ray Charles   \n",
       "50   6:22 AM                      Kat Edmonson   \n",
       "51   6:17 AM                   The Heavy Heavy   \n",
       "52   6:13 AM                       Waxahatchee   \n",
       "53   6:09 AM                 Johnny Blue Skies   \n",
       "54   6:04 AM                  Charley Crockett   \n",
       "55   6:00 AM                         Morrissey   \n",
       "\n",
       "                                 song                             album  \n",
       "0                            Weekness                      Slow Burn EP  \n",
       "1                          Untangling                    Light Sides EP  \n",
       "2                           The Maker                            Teatro  \n",
       "3                              Ankles              Forever Is A Feeling  \n",
       "4                            Too Easy         The Future Is Our Way Out  \n",
       "5                           After Me?                          (Single)  \n",
       "6                              Shovel                   Billboard Heart  \n",
       "7                             Spirits                           Spirits  \n",
       "8   Would You Want It (If You Had It)                          (Single)  \n",
       "9                     Champagne Taste                  Mortal Primetime  \n",
       "10       And They Call Her California                     Long Way Home  \n",
       "11                       The Underdog                    Ga Ga Ga Ga Ga  \n",
       "12   Lightning in July (Prairie Fire)                        Purple Gas  \n",
       "13                         Your House                         Open Wide  \n",
       "14                         Lake Marie       Lost Dogs & Mixed Blessings  \n",
       "15                        Miles to Go                          (Single)  \n",
       "16                            Rainbow                           Mileage  \n",
       "17                      DUST/DIVINITY  Observations From A Crowded Room  \n",
       "18                               Cath                     Narrow Stairs  \n",
       "19               Rolling Down the 405               Our Time In The Sun  \n",
       "20                       Hear My Call                      Hear My Call  \n",
       "21                    Tomorrow People                   Conscious Party  \n",
       "22             First Came The Thunder                     Wake the Dead  \n",
       "23            Before It Might Be Gone           Before It Might Be Gone  \n",
       "24         Don't Leave Your Light Low                        Persimmons  \n",
       "25                      Blueberry Bog                          Right On  \n",
       "26                       Blank Canvas                            Frames  \n",
       "27                     You're the One                       Let It Rain  \n",
       "28                            Hard Up                           Hard Up  \n",
       "29                           Alouette                       Divinations  \n",
       "30                  Singing the Blues        Promise of a Brand New Day  \n",
       "31                     Cruise Control                      VALLEY pt. 2  \n",
       "32                         Broken Cup                          Backbone  \n",
       "33                 Heart like a Levee                Heart Like a Levee  \n",
       "34                     Alone Together           Cardinals At The Window  \n",
       "35                   Circle the Drain                      Color Theory  \n",
       "36                           Believer                         El Cabron  \n",
       "37       I Can't Go Anywhere With You                         Nite Owls  \n",
       "38                          Amsterdam                  Keep It Together  \n",
       "39                  Keep Me Satisfied                          (Single)  \n",
       "40                            Running                       Para Llevar  \n",
       "41                          This Side                         This Side  \n",
       "42                      Flash-A-Magic                     Flash-A-Magic  \n",
       "43                        Best Friend              I Just Can't Stop It  \n",
       "44               Minor Inconveniences                          (Single)  \n",
       "45               I Want You Yesterday                        The Jester  \n",
       "46            One of These Rainy Days                    Before the Sun  \n",
       "47                           No Words                           Cutouts  \n",
       "48                           Rushmere                          Rushmere  \n",
       "49          What'd I Say Pts I and II                      What'd I Say  \n",
       "50                        Keep Movin'                       Keep Movin'  \n",
       "51                               Feel                     One of a Kind  \n",
       "52                      Can't Do Much                       Saint Cloud  \n",
       "53       If The Sun Never Rises Again                  Passage Du Desir  \n",
       "54                   Lonesome Drifter                  Lonesome Drifter  \n",
       "55                          Suedehead                         Viva Hate  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = {'time':times,\n",
    "          'artist':artists,\n",
    "         'song':songs,\n",
    "         'album':albums}\n",
    "wnrn_df = pd.DataFrame(mydict)\n",
    "wnrn_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Spider\n",
    "At the bottom of the WNRN playlist on https://spinitron.com/WNRN/ there are links to older song playlists. Let's extend our example by building a **spider** to capture the data that exists on these links as well. A spider is a web scraper that follows links on a page automatically and scrapes from those links as well. \n",
    "\n",
    "I look at the page source for these links, and find that they are contained in a `<div class=\"recent-playlists\">` tag. I start by finding this tag. As there's only one occurrence, I can use `.find()` instead of `.find_all()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"recent-playlists\">\n",
       "<h4>Recent</h4>\n",
       "<div class=\"grid-view\" id=\"w2\"><div class=\"summary\"></div>\n",
       "<table class=\"table table-bordered table-narrow\"><tbody>\n",
       "<tr data-key=\"0\"><td class=\"show-time\">5:00 AM</td><td></td><td><strong><a href=\"/WNRN/pl/20207753/WNRN-2-11-25-5-00-AM\">WNRN 2/11/25, 5:00 AM</a></strong> with <a href=\"/WNRN/dj/104061/WNRN\">WNRN</a></td></tr>\n",
       "<tr data-key=\"1\"><td class=\"show-time\">4:00 AM</td><td></td><td><strong><a href=\"/WNRN/pl/20207688/WNRN-2-11-25-4-03-AM\">WNRN 2/11/25, 4:03 AM</a></strong> with <a href=\"/WNRN/dj/104061/WNRN\">WNRN</a></td></tr>\n",
       "<tr data-key=\"2\"><td class=\"show-time\">8:00 PM</td><td></td><td><strong><a href=\"/WNRN/pl/20206023/WNRN\">WNRN</a></strong> (Music)</td></tr>\n",
       "<tr data-key=\"3\"><td class=\"show-time\">6:00 PM</td><td></td><td><strong><a href=\"/WNRN/pl/20205530/World-Caf%C3%A9\">World Café</a></strong> (Music) with <a href=\"/WNRN/dj/179987/Raina-Douris-and-Stephen-Kallao\">Raina Douris and Stephen Kallao</a></td></tr>\n",
       "<tr data-key=\"4\"><td class=\"show-time\">6:00 AM</td><td></td><td><strong><a href=\"/WNRN/pl/20202904/WNRN\">WNRN</a></strong> (Music)</td></tr>\n",
       "</tbody></table>\n",
       "</div></div>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent = wnrn.find(\"div\", \"recent-playlists\")\n",
    "recent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that all of the addresses we need are contained in `<a>` tags. We can extract these `<a>` tags with `.find_all()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/WNRN/pl/20207753/WNRN-2-11-25-5-00-AM\">WNRN 2/11/25, 5:00 AM</a>,\n",
       " <a href=\"/WNRN/dj/104061/WNRN\">WNRN</a>,\n",
       " <a href=\"/WNRN/pl/20207688/WNRN-2-11-25-4-03-AM\">WNRN 2/11/25, 4:03 AM</a>,\n",
       " <a href=\"/WNRN/dj/104061/WNRN\">WNRN</a>,\n",
       " <a href=\"/WNRN/pl/20206023/WNRN\">WNRN</a>,\n",
       " <a href=\"/WNRN/pl/20205530/World-Caf%C3%A9\">World Café</a>,\n",
       " <a href=\"/WNRN/dj/179987/Raina-Douris-and-Stephen-Kallao\">Raina Douris and Stephen Kallao</a>,\n",
       " <a href=\"/WNRN/pl/20202904/WNRN\">WNRN</a>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_atags = recent.find_all(\"a\")\n",
    "recent_atags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting list contains the web endpoints we need, and also some web endpoints we don't need: we want the URLs that contain the string `/pl/` as these are playlists, and we want to exclude the URLs that contain the string `/dj/` as these pages refer to a particular DJ. We need a comprehension loop that loops across these elements, extracts the `href` attribute of the entries that include `/pl/`, and ignore the entries that include `/dj/`. We again use this syntax:\n",
    "\n",
    "*newlist* `= [` *expression* `for` *item* `in` *oldlist* `if` *condition* `]`\n",
    "\n",
    "In this case:\n",
    "\n",
    "* *newlist* is a list containing the URLs we want to direct our spider to. I call it `urls`.\n",
    "* *item* is one element of `recent_atags`, which I will call `pl`.\n",
    "* *expression* is code that extracts the web address from the `href` attribute of the `<a>` tag, so here the code would be `pl['href']`.\n",
    "* Finally, *condition* is a logical statement that should be `True` if the web address contains `/pl/` and `False` if the web address contains `/dj/`. Here, the conditional statement should be `if \"/pl/\" in pl['href']`. This code will look for the string `\"/pl/\"` inside the string called by `pl['href']` and return `True` or `False` depending on whether this string is found.\n",
    "\n",
    "Putting all this syntax together gives us our list of playlist URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/WNRN/pl/20207753/WNRN-2-11-25-5-00-AM',\n",
       " '/WNRN/pl/20207688/WNRN-2-11-25-4-03-AM',\n",
       " '/WNRN/pl/20206023/WNRN',\n",
       " '/WNRN/pl/20205530/World-Caf%C3%A9',\n",
       " '/WNRN/pl/20202904/WNRN']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnrn_url = [pl['href'] for pl in recent_atags if \"/pl/\" in pl['href']]\n",
    "wnrn_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to collect all of the code we created above to extract the artist, song, album, and play times from the HTML code. We define a function that does all of this work. We specify one argument for this function, the URL, so that all the function needs is the URL and it can output a clean dataframe. I name the function `wnrn_spider()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wnrn_spider(url):\n",
    "    \"\"\"Perform web scraping for any WNRN playlist given the available link\"\"\"\n",
    "    \n",
    "    headers = {'user-agent': 'Kropko class example (jkropko@virginia.edu)'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    wnrn = BeautifulSoup(r.text, 'html')\n",
    "    \n",
    "    artistlist = wnrn.find_all(\"span\", \"artist\")\n",
    "    songlist = wnrn.find_all(\"span\", \"song\")\n",
    "    albumlist = wnrn.find_all(\"span\", \"release\")\n",
    "    timelist = wnrn.find_all(\"td\", \"spin-time\")\n",
    "    \n",
    "    artists = [a.string for a in artistlist]\n",
    "    songs = [a.string for a in songlist]\n",
    "    albums = [a.string for a in albumlist]\n",
    "    times = [a.string for a in timelist]\n",
    "    \n",
    "    mydict = {'time':times, 'artist':artists, 'song':songs, 'album':albums}\n",
    "    wnrn_df = pd.DataFrame(mydict)\n",
    "    \n",
    "    return wnrn_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can pass any of the URLs we collected to our function and get the other playlists. We will have to add the domain \"https://spinitron.com\" to the beginning of each of the URLs we collected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>album</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5:00 AM</td>\n",
       "      <td>The Avett Brothers</td>\n",
       "      <td>February Seven</td>\n",
       "      <td>The Carpenter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5:04 AM</td>\n",
       "      <td>Michael Kiwanuka</td>\n",
       "      <td>The Rest Of Me</td>\n",
       "      <td>Small Changes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5:07 AM</td>\n",
       "      <td>Randall Bramblett</td>\n",
       "      <td>Throw My Cane Away</td>\n",
       "      <td>Paradise Breakdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5:10 AM</td>\n",
       "      <td>Michael Franti &amp; Spearhead</td>\n",
       "      <td>Say Hey</td>\n",
       "      <td>All Rebel Rockers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5:15 AM</td>\n",
       "      <td>Becca Mancari</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>The Greatest Part</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5:17 AM</td>\n",
       "      <td>The Lumineers</td>\n",
       "      <td>Same Old Song</td>\n",
       "      <td>Automatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5:20 AM</td>\n",
       "      <td>Circa Waves</td>\n",
       "      <td>Like You Did Before</td>\n",
       "      <td>Death &amp; Love Pt. 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5:23 AM</td>\n",
       "      <td>The Mavericks</td>\n",
       "      <td>Things I Cannot Change</td>\n",
       "      <td>Super Colossal Smash Hits of the 9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5:27 AM</td>\n",
       "      <td>Clairo</td>\n",
       "      <td>Amoeba</td>\n",
       "      <td>Sling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5:31 AM</td>\n",
       "      <td>Olivia Wolf</td>\n",
       "      <td>Cosmic Appalachian Radio</td>\n",
       "      <td>Silver Rounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5:33 AM</td>\n",
       "      <td>flipturn</td>\n",
       "      <td>Rodeo Clown</td>\n",
       "      <td>Burnout Days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5:42 AM</td>\n",
       "      <td>Moby</td>\n",
       "      <td>Porcelain</td>\n",
       "      <td>Play</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5:46 AM</td>\n",
       "      <td>Sofia Valdes</td>\n",
       "      <td>Already Yours</td>\n",
       "      <td>Sofia Valdes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5:50 AM</td>\n",
       "      <td>Kris Delmhorst</td>\n",
       "      <td>I Won't Be Long</td>\n",
       "      <td>Ghosts In the Garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5:53 AM</td>\n",
       "      <td>Julien Baker &amp; TORRES</td>\n",
       "      <td>Sugar In The Tank</td>\n",
       "      <td>Send A Prayer My Way</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5:56 AM</td>\n",
       "      <td>The Shins</td>\n",
       "      <td>New Slang</td>\n",
       "      <td>Oh, Inverted World!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time                      artist                      song  \\\n",
       "0   5:00 AM          The Avett Brothers            February Seven   \n",
       "1   5:04 AM            Michael Kiwanuka            The Rest Of Me   \n",
       "2   5:07 AM           Randall Bramblett        Throw My Cane Away   \n",
       "3   5:10 AM  Michael Franti & Spearhead                   Say Hey   \n",
       "4   5:15 AM               Becca Mancari                    Hunter   \n",
       "5   5:17 AM               The Lumineers             Same Old Song   \n",
       "6   5:20 AM                 Circa Waves       Like You Did Before   \n",
       "7   5:23 AM               The Mavericks    Things I Cannot Change   \n",
       "8   5:27 AM                      Clairo                    Amoeba   \n",
       "9   5:31 AM                 Olivia Wolf  Cosmic Appalachian Radio   \n",
       "10  5:33 AM                    flipturn               Rodeo Clown   \n",
       "11  5:42 AM                        Moby                 Porcelain   \n",
       "12  5:46 AM                Sofia Valdes             Already Yours   \n",
       "13  5:50 AM              Kris Delmhorst           I Won't Be Long   \n",
       "14  5:53 AM       Julien Baker & TORRES         Sugar In The Tank   \n",
       "15  5:56 AM                   The Shins                 New Slang   \n",
       "\n",
       "                                 album  \n",
       "0                        The Carpenter  \n",
       "1                        Small Changes  \n",
       "2                   Paradise Breakdown  \n",
       "3                    All Rebel Rockers  \n",
       "4                    The Greatest Part  \n",
       "5                            Automatic  \n",
       "6                   Death & Love Pt. 1  \n",
       "7   Super Colossal Smash Hits of the 9  \n",
       "8                                Sling  \n",
       "9                        Silver Rounds  \n",
       "10                        Burnout Days  \n",
       "11                                Play  \n",
       "12                        Sofia Valdes  \n",
       "13                Ghosts In the Garden  \n",
       "14                Send A Prayer My Way  \n",
       "15                 Oh, Inverted World!  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnrn2 = wnrn_spider('https://spinitron.com/' + wnrn_url[0])\n",
    "wnrn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal here is to loop across all the URLs we collected, extract the data in a clean data frame, and append these data frames together to construct a longer playlist. To do that, we will use a `for` loop, which has the following syntax:\n",
    "```\n",
    "for index in list:\n",
    "    expressions\n",
    "```\n",
    "This syntax is similar to the syntax we used to build a comprehension loop. `list` is an existing list, and `index` stands in for one element of this list. For each element of the list, we execute the code contained in `expressions`, which can use the `index`.\n",
    "\n",
    "For our spider, we will use the following steps:\n",
    "\n",
    "1. We take the data we already scraped from https://spinitron.com/WNRN (saved as `wnrn_df`) and clone it as a new variable named `wnrn_total_playlist`. It is important that we make a copy, and that we do not overwrite `wnrn_df`. We will be repeatedly saving over `wnrn_total_playlist` within the loop, and if we do not overwrite `wnrn_df`, it gives us a stable data frame to return to as a starting point if we need to rerun this loop. \n",
    "\n",
    "2. We use a `for` loop to loop across all the web addresses inside `wnrn_url`.\n",
    "\n",
    "3. In the `for` loop, we use the `wnrn_spider()` function to extract the playlist data from each of the URLs inside `wnrn_url`.\n",
    "\n",
    "4. In the `for` loop, we use the `pd.concat()` method to attach the new data to the bottom of the existing data, matching corresponding columns.\n",
    "\n",
    "The code is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wnrn_total_playlist = wnrn_df \n",
    "for w in wnrn_url:\n",
    "    moredata = wnrn_spider('https://spinitron.com/' + w) \n",
    "    wnrn_total_playlist = pd.concat([wnrn_total_playlist, moredata], ignore_index=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a data frame that combines all of the playlists on https://spinitron.com/WNRN and on the playlists linked to under \"Recent\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>album</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10:01 AM</td>\n",
       "      <td>Baby Rose f/ BADBADNOTGOOD</td>\n",
       "      <td>Weekness</td>\n",
       "      <td>Slow Burn EP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9:57 AM</td>\n",
       "      <td>Angie McMahon</td>\n",
       "      <td>Untangling</td>\n",
       "      <td>Light Sides EP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9:52 AM</td>\n",
       "      <td>Willie Nelson and Daniel Lanois</td>\n",
       "      <td>The Maker</td>\n",
       "      <td>Teatro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9:49 AM</td>\n",
       "      <td>Lucy Dacus</td>\n",
       "      <td>Ankles</td>\n",
       "      <td>Forever Is A Feeling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9:44 AM</td>\n",
       "      <td>Brigitte Calls Me Baby</td>\n",
       "      <td>Too Easy</td>\n",
       "      <td>The Future Is Our Way Out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>5:38 PM</td>\n",
       "      <td>Electric Guest</td>\n",
       "      <td>This Head I Hold</td>\n",
       "      <td>Mondo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>5:41 PM</td>\n",
       "      <td>Ray LaMontagne</td>\n",
       "      <td>And They Call Her California</td>\n",
       "      <td>Long Way Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>5:47 PM</td>\n",
       "      <td>49 Winchester</td>\n",
       "      <td>Miles to Go</td>\n",
       "      <td>(Single)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>5:51 PM</td>\n",
       "      <td>Hurray for the Riff Raff</td>\n",
       "      <td>Living in the City</td>\n",
       "      <td>The Navigator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>5:55 PM</td>\n",
       "      <td>The B-52s</td>\n",
       "      <td>Rock Lobster</td>\n",
       "      <td>The B-52s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         time                           artist                          song  \\\n",
       "0    10:01 AM       Baby Rose f/ BADBADNOTGOOD                      Weekness   \n",
       "1     9:57 AM                    Angie McMahon                    Untangling   \n",
       "2     9:52 AM  Willie Nelson and Daniel Lanois                     The Maker   \n",
       "3     9:49 AM                       Lucy Dacus                        Ankles   \n",
       "4     9:44 AM           Brigitte Calls Me Baby                      Too Easy   \n",
       "..        ...                              ...                           ...   \n",
       "383   5:38 PM                   Electric Guest              This Head I Hold   \n",
       "384   5:41 PM                   Ray LaMontagne  And They Call Her California   \n",
       "385   5:47 PM                    49 Winchester                   Miles to Go   \n",
       "386   5:51 PM         Hurray for the Riff Raff            Living in the City   \n",
       "387   5:55 PM                        The B-52s                  Rock Lobster   \n",
       "\n",
       "                         album  \n",
       "0                 Slow Burn EP  \n",
       "1               Light Sides EP  \n",
       "2                       Teatro  \n",
       "3         Forever Is A Feeling  \n",
       "4    The Future Is Our Way Out  \n",
       "..                         ...  \n",
       "383                      Mondo  \n",
       "384              Long Way Home  \n",
       "385                   (Single)  \n",
       "386              The Navigator  \n",
       "387                  The B-52s  \n",
       "\n",
       "[388 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnrn_total_playlist"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}