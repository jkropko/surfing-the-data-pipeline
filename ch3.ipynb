{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Loading, Converting, and Writing JSON Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```{contents} Table of Contents\n",
    ":depth: 4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction: Douglas Crockford's JSON Saga\n",
    "[JSON](https://www.json.org/json-en.html) stands for **JavaScript Object Notation**, and it is one of the most frequently used data formats for transferring data over the Internet. If you will be using a web-based data transfer system, such as an API (more on that in the next module), you will be dealing with data in JSON format.\n",
    "\n",
    "The JSON data format is attributed to Douglas Crockford, a Javascript architect at Yahoo!, although in his words: \"I discovered JSON. I do not claim to have invented JSON, because it already existed in nature. What I did was I found it, I named it, I described how it was useful.\" Here's an excellent talk by Douglas Crockford in which he describes the origin of JSON and the early struggles to create a universal and lightweight language for data transference. The talk is about 50 minutes long, but it is worth watching if you have the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://www.youtube.com/embed/-C-JoyNuQJs\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1106bfcf8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src=\"https://www.youtube.com/embed/-C-JoyNuQJs\", width=\"560\", height=\"315\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For what it's worth, Douglas Crockford calls the language \"Jay-Sin\", like the first name, and not \"Jay-Sawn\". Although he says \"I strictly don't care\" about however people choose to pronounce JSON.\n",
    "\n",
    "Crockford and his collaborators developed JSON in 2001 with the objective of creating a language to store, display, and transfer in a way that works on every browser. In other words, the whole point of JSON is to be **universal**, so that the data are readable no matter the browser or environment. JSON is also designed to be as **lightweight** as possible: that is, JSON code is as compact as possible. JSON sacrificies features that expand the functionality of the language, such as comments, processing instructions, or attributes, in order to use the minimal amount of code. The lightweight construction of JSON makes [JSON code much faster than alternative data interchange languages like XML](https://stackoverflow.com/questions/12346349/why-is-json-more-lightweight-than-xml). It also helps achieve the goal of universality: a lightweight language works within existing infrastructures with no additional software or extraneous code because every programming language understands data in some form, and a minimalist data structure works with every language's idea of what data should be. In Crockford's words:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> One of the key design goals behind JSON was minimalism. My idea was that the less we have to agree on in order to inter-operate, the more likely we're going to be able to inter-operate well. If the interfaces are really simple, we can easily connect, and if the interfaces are really complicated, the likelihood that something's going to go wrong goes way, way up. So I endeavored to make JSON as simple as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get to examples of using JSONs in Python, load the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "sys.tracebacklimit = 0 # turn off the long tracebacks on error messages\n",
    "#sys.tracebacklimit = None # use to turn tracebacks back on if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Structure of a JSON File\n",
    "The biggest difference between JSON (and other data interchange formats like XML, PHP, and YAML) and CSV is that JSON accomodates **tree-based** data structures, whereas CSV only handles **tabular** data. Many real-world applications require a tree-based structure for data. For example, here are the first two records from fake data from a business's customer records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"name\": \"Leanne Graham\",\n",
      "    \"username\": \"Bret\",\n",
      "    \"email\": \"Sincere@april.biz\",\n",
      "    \"address\": {\n",
      "      \"street\": \"Kulas Light\",\n",
      "      \"suite\": \"Apt. 556\",\n",
      "      \"city\": \"Gwenborough\",\n",
      "      \"zipcode\": \"92998-3874\",\n",
      "      \"geo\": {\n",
      "        \"lat\": \"-37.3159\",\n",
      "        \"lng\": \"81.1496\"\n",
      "      }\n",
      "    },\n",
      "    \"phone\": \"1-770-736-8031 x56442\",\n",
      "    \"website\": \"hildegard.org\",\n",
      "    \"company\": {\n",
      "      \"name\": \"Romaguera-Crona\",\n",
      "      \"catchPhrase\": \"Multi-layered client-server neural-net\",\n",
      "      \"bs\": \"harness real-time e-markets\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"name\": \"Ervin Howell\",\n",
      "    \"username\": \"Antonette\",\n",
      "    \"email\": \"Shanna@melissa.tv\",\n",
      "    \"address\": {\n",
      "      \"street\": \"Victor Plains\",\n",
      "      \"suite\": \"Suite 879\",\n",
      "      \"city\": \"Wisokyburgh\",\n",
      "      \"zipcode\": \"90566-7771\",\n",
      "      \"geo\": {\n",
      "        \"lat\": \"-43.9509\",\n",
      "        \"lng\": \"-34.4618\"\n",
      "      }\n",
      "    },\n",
      "    \"phone\": \"010-692-6593 x09125\",\n",
      "    \"website\": \"anastasia.net\",\n",
      "    \"company\": {\n",
      "      \"name\": \"Deckow-Crist\",\n",
      "      \"catchPhrase\": \"Proactive didactic contingency\",\n",
      "      \"bs\": \"synergize scalable supply-chains\"\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "users = requests.get(\"https://jsonplaceholder.typicode.com/users\")\n",
    "print(users.text[0:1110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "There are several elements of the JSON format that we need to discuss. \n",
    "\n",
    "### Lists, Sets, and Dictionaries\n",
    "First, notice the opening square brace `[`. This character tells Python to read all the following records as elements of a **list**. In a Python list, the order of the elements matters and elements can be repeated, but are not given names. The first element is denoted with index 0, the second element is denoted with index 1, and so on. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [5,8,-9]\n",
    "my_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Within the JSON syntax, each individual element of the list is a **set**, denoted by curly braces `{` and `}`. A Python set differs from a Python list in that the order of the elements does not matter (it sorts the elements automatically), it doesn't allow repetition, and it allows the elements to be named. For example, in the following code, notice how the repeated 5s are removed and how the elements are sorted from smallest to largest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-9, 5, 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_set = {5,5,5,8,-9}\n",
    "my_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's only possible to use call individual elements of a set if those elements are given distinct names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_set = {'larry':5, 'curly':8, 'moe':-9}\n",
    "my_set['larry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In Python, sets in which elements of a set have names are called **dictionaries**. The names are called **keys**, and the elements themselves are called **values**. So in this case, an element of the dictionary has a key of \"larry\" and a value of 5. Like sets, dictionaries enforce no repetition, but they apply this restriction to the keys only: multiple keys can have the same value, but every value must have a distinct key. In this example, I define the key \"larry\" twice, and only the last \"larry\" entered into the dictionary definition is saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'larry': 10, 'curly': 10, 'moe': -9}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_set = {'larry':15, 'larry':10, 'curly':10, 'moe':-9}\n",
    "my_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That means that JSON notation is the same as a **list in which each element is a dictionary** in Python. Every dictionary represents one record in the data, and when we convert the data to a tabular dataframe, each record will occupy one row in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nested Structures\n",
    "JSON can store data structures that are awkward or impossible for CSV. We can convert JSON formats to tabular formats to store the data in a data frame, but in doing so, we lose information about which features are nested within other fields. \n",
    "\n",
    "Let's return to the example of the customer records stored in JSON format.  In these data, some features are themselves dictionaries that contain additional features, resulting in a nested and tree-like shape to the data. The first record looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"name\": \"Leanne Graham\",\n",
      "    \"username\": \"Bret\",\n",
      "    \"email\": \"Sincere@april.biz\",\n",
      "    \"address\": {\n",
      "      \"street\": \"Kulas Light\",\n",
      "      \"suite\": \"Apt. 556\",\n",
      "      \"city\": \"Gwenborough\",\n",
      "      \"zipcode\": \"92998-3874\",\n",
      "      \"geo\": {\n",
      "        \"lat\": \"-37.3159\",\n",
      "        \"lng\": \"81.1496\"\n",
      "      }\n",
      "    },\n",
      "    \"phone\": \"1-770-736-8031 x56442\",\n",
      "    \"website\": \"hildegard.org\",\n",
      "    \"company\": {\n",
      "      \"name\": \"Romaguera-Crona\",\n",
      "      \"catchPhrase\": \"Multi-layered client-server neural-net\",\n",
      "      \"bs\": \"harness real-time e-markets\"\n",
      "    }\n",
      "  },\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(users.text[0:560])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For this customer, we have the ID number, name, username, and email address. So far we can easily place these values in the same row of a table to store the same information. But the next key, `address`, is set equal to a dictionary, as indicated by the additional set of curly braces. Within the address field, we have data on the customer's street, suite, city, and ZIP code. We also have a field, `geo`, equal to yet another dictionary that contains the latitude and longitude coordinates of the address. The structure then returns to the first level of nesting, providing the phone number and website, before introducing another branch for company with three sub-fields: name, catch phrase, and business slogan. In all, the structure of this JSON data is best described with the following tree:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://github.com/jkropko/DS-6001/raw/master/localimages/jsontree.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This tree can only be placed into a table, as we must do to work with a data frame, if we lose the information about nesting and instead treat the 15 distinct features as 15 columns in the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "In addition to nesting, JSON is an ideal format for placing metadata in the same file as the main data. Metadata is \"[data that provides information about other data](https://en.wikipedia.org/wiki/Metadata)\". Metadata might describe the date the data were last accessed, provide the stable URL for accessing the data, might credit authorship or describe copyright, and so on, prior to displaying information about each of the records in the data. In general, JSON formats with metadata can look like this:\n",
    "\n",
    "<img src=\"https://github.com/jkropko/DS-6001/raw/master/localimages/metadata.png\" width=300>\n",
    "\n",
    "In order to convert JSON data with a metadata format to a tabular data frame, you will have to specify the name of the branch that contains the records. As with nested structures, this procedure involves losing information. In this case, we will lose the metadata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values and Different Data Types\n",
    "After unpacking the nested structure of a JSON data file and removing metadata, there can be differences from record to record in the information stored in the file. It's possible that some records do not have data on the same set of features that other records do. Even if the same feature is present across records, it is possible that its value has one data type in some records and another data type in other records. \n",
    "\n",
    "For example, consider public opinion data in which records are individuals answering questions on a survey and the features include an individual ID number, the individual's rating of the Republican Candidate, the individual's rating of the Democratic candidate, and the individual's birthyear and gender. One possible way a few records can look like in JSON format (and then converted to a data frame) is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"caseid\":1.0,\"ftrep\":\"Awful\",\"ftdem\":\"Pretty good\",\"birthyr\":1960},\n",
      "{\"caseid\":2.0,\"ftrep\":28.0,\"ftdem\":52.0,\"birthyr\":1987,\"gender\":2},\n",
      "{\"caseid\":3.0,\"ftrep\":100.0,\"ftdem\":1.0,\"gender\":1}]\n"
     ]
    }
   ],
   "source": [
    "case1 = '{\"caseid\":1.0,\"ftrep\":\"Awful\",\"ftdem\":\"Pretty good\",\"birthyr\":1960}'\n",
    "case2 = '{\"caseid\":2.0,\"ftrep\":28.0,\"ftdem\":52.0,\"birthyr\":1987,\"gender\":2}'\n",
    "case3 = '{\"caseid\":3.0,\"ftrep\":100.0,\"ftdem\":1.0,\"gender\":1}'\n",
    "case_json = '[' + case1 + ',\\n' + case2 + ',\\n' + case3 + ']'\n",
    "print(case_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>ftrep</th>\n",
       "      <th>ftdem</th>\n",
       "      <th>birthyr</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Awful</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  ftrep        ftdem  birthyr  gender\n",
       "0       1  Awful  Pretty good   1960.0     NaN\n",
       "1       2     28           52   1987.0     2.0\n",
       "2       3    100            1      NaN     1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(case_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to look at the raw JSON formatted data. There are some differences between the three cases. The first case did not record the individual's gender and the third case did not record the individual's birthyear. Note that in the JSON format, these features are simply absent: we do not need to explicitly code these values as missing. When we convert the data to tabular format, the cells for the missing features are filled with `NaN` missing values automatically.\n",
    "\n",
    "Additionally, the first case records the feeling thermometer scores for the Republican and Democrat with strings: this person feels \"Awful\" towards the Republican and \"Pretty good\" towards the Democrat. For the second and third cases these ratings are coded numerically. The JSON format naturally allows the same feature to be populated by data of a different type across records. Tabular data, however, has stricter requirements for data uniformity within a column: specifically all of the data must have the same type in a column. The data frame handles that by coding all of these values with the ambiguous `object` type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caseid       int64\n",
       "ftrep       object\n",
       "ftdem       object\n",
       "birthyr    float64\n",
       "gender     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(case_json).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, while it is straightforward to convert JSON data to tabular format, we can potentially lose a great deal of information in this conversion: nesting, metadata, and varying data type. In addition, tabular data inefficiently require that cells for missing values be filled with a symbol to denote missingness, to preserve the rectangular shape of the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Reading JSON Data in Python\n",
    "JSON, like CSV and ASCII, is a **text-based** system for data storage. When first loading JSON data into Python, the data will be read as a giant block of text. First we need to get Python to understand that the text is actually organized JSON data using the `json` library. Once we can work with the data as JSON, we can search through the JSON data's index path to extract particular datapoints. We can even construct loops to pull out lists of values from across the records.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the `requests.get()`, `json.loads()` and `json.dumps()` Functions \n",
    "There is an important function from the `requests` library and two important functions in the `json` library for us to know when working with JSON data:\n",
    "\n",
    "* `requests.get()` downloads data from a URL and stores it in Python's memory as a giant block of text. It also can include additional parameters to send to the website to provide information on credentials or on specifying the subset of data to collect. \n",
    "\n",
    "* `json.loads()` converts text into an object that Python recognizes as JSON-formatted data.\n",
    "\n",
    "* `json.dumps()` converts JSON data into a block of text.\n",
    "\n",
    "Consider again the JSON data on fake consumer records. The data are stored on a website called [JSON Placeholder](https://jsonplaceholder.typicode.com/), which has several excellent example JSON datasets and has resources for guiding people who are writing their own APIs. The customer data exists here: https://jsonplaceholder.typicode.com/users. Take a moment and click on this link to see how the data appear in your web browser.\n",
    "\n",
    "To download the data, use `requests.get()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = requests.get(\"https://jsonplaceholder.typicode.com/users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the text of this download, use the `.text` attribute. If I want to display only the first record, I have to specify the first and last character numbers of this record, which turns out to be (after a lot of guess-and-checking) the first 560 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"name\": \"Leanne Graham\",\n",
      "    \"username\": \"Bret\",\n",
      "    \"email\": \"Sincere@april.biz\",\n",
      "    \"address\": {\n",
      "      \"street\": \"Kulas Light\",\n",
      "      \"suite\": \"Apt. 556\",\n",
      "      \"city\": \"Gwenborough\",\n",
      "      \"zipcode\": \"92998-3874\",\n",
      "      \"geo\": {\n",
      "        \"lat\": \"-37.3159\",\n",
      "        \"lng\": \"81.1496\"\n",
      "      }\n",
      "    },\n",
      "    \"phone\": \"1-770-736-8031 x56442\",\n",
      "    \"website\": \"hildegard.org\",\n",
      "    \"company\": {\n",
      "      \"name\": \"Romaguera-Crona\",\n",
      "      \"catchPhrase\": \"Multi-layered client-server neural-net\",\n",
      "      \"bs\": \"harness real-time e-markets\"\n",
      "    }\n",
      "  },\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(users.text[0:560])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presently, although the text above looks like it is formatted like a JSON file, Python only understands it as text (with type `str`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get Python to read this text as JSON data, make sure the `json` library is imported (which we did at the top of this notebook), and use the `json.loads()` function. Now, to display the first record, I only have to pass the index 0, representing the first item in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'name': 'Leanne Graham',\n",
       " 'username': 'Bret',\n",
       " 'email': 'Sincere@april.biz',\n",
       " 'address': {'street': 'Kulas Light',\n",
       "  'suite': 'Apt. 556',\n",
       "  'city': 'Gwenborough',\n",
       "  'zipcode': '92998-3874',\n",
       "  'geo': {'lat': '-37.3159', 'lng': '81.1496'}},\n",
       " 'phone': '1-770-736-8031 x56442',\n",
       " 'website': 'hildegard.org',\n",
       " 'company': {'name': 'Romaguera-Crona',\n",
       "  'catchPhrase': 'Multi-layered client-server neural-net',\n",
       "  'bs': 'harness real-time e-markets'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_json = json.loads(users.text)\n",
    "users_json[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of text, Python now recognizes `users_json` as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Along the JSON Index Path\n",
    "After using `json.loads()`, Python understands the JSON data to be a list-of-lists. We can now use indices to extract particular datapoints. The records are numbers, starting with 0, and keys within particular records can be called by name.\n",
    "\n",
    "For example, to extract the email address of the fifth customer (element 4), in the data, I type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lucio_Hettinger@annie.ca'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_json[4]['email']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call fields that contain several nested features, Python returns a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'street': 'Kulas Light',\n",
       " 'suite': 'Apt. 556',\n",
       " 'city': 'Gwenborough',\n",
       " 'zipcode': '92998-3874',\n",
       " 'geo': {'lat': '-37.3159', 'lng': '81.1496'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_json[0]['address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract elements that are several levels of nesting down the JSON tree, specify the keys in order that lead to the desired element. For example, to extract the latitudinal coordinate, we navigate to the `address`, `geo`, and `lat` keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-37.3159'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_json[0]['address']['geo']['lat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it may be necessary at times to covert the JSON back to text, maybe to assist in transfering the data to another platform (although I recommend using the `.to_json()` method, discussed below, for this purpose). To convert JSON back to text, use the `json.dumps()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_text = json.dumps(users_json)\n",
    "type(users_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping Across Records to Extract Datapoints\n",
    "While JSON is a well-organized and flexible data format that preserves a lot of the meaningful context of the data, most analytical tools and statistical models can only operate on tabular data. So a major challenge with JSON data is converting the data to a tabular format to be saved in a data frame. One method is to construct a loop across records to extract desired elements. \n",
    "\n",
    "Before we discuss this method, I do not recommend using this approach in general. Loops are usually slow, and it is much faster to perform these kinds of operations by **vectorizing** code. [Vectorizing](https://stackoverflow.com/questions/1422149/what-is-vectorization#1422181) refers to the ability of a programming language to operate on an entire vector of data and work on several elements simultaneously, rather than on each element one at a time. Vectorization is the specialty of the `numpy` library, and most functions in `pandas` are vectorized as well. I suggest using `pd.read_json()` and `pd.json_normalize()` to convert JSON data to a data frame as they will be several orders of magnitude faster for converting the entire JSON to a data frame. Looping make sense only when we need to extract a small number of features from JSON data with a large feature set, because with the loop we directly call the features we want and we can avoid having to work with features we don't need.\n",
    "\n",
    "To start the loop, choose an index to represent one record. To display all of the email addresses, type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sincere@april.biz\n",
      "Shanna@melissa.tv\n",
      "Nathan@yesenia.net\n",
      "Julianne.OConner@kory.org\n",
      "Lucio_Hettinger@annie.ca\n",
      "Karley_Dach@jasper.info\n",
      "Telly.Hoeger@billy.biz\n",
      "Sherwood@rosamond.me\n",
      "Chaim_McDermott@dana.io\n",
      "Rey.Padberg@karina.biz\n"
     ]
    }
   ],
   "source": [
    "for u in users_json:\n",
    "    print(u['email'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, to place all of the email addresses in a list, you can loop inside of a list like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sincere@april.biz',\n",
       " 'Shanna@melissa.tv',\n",
       " 'Nathan@yesenia.net',\n",
       " 'Julianne.OConner@kory.org',\n",
       " 'Lucio_Hettinger@annie.ca',\n",
       " 'Karley_Dach@jasper.info',\n",
       " 'Telly.Hoeger@billy.biz',\n",
       " 'Sherwood@rosamond.me',\n",
       " 'Chaim_McDermott@dana.io',\n",
       " 'Rey.Padberg@karina.biz']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = [u['email'] for u in users_json]\n",
    "emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick is extracting the data and saving it in a data frame at the same time. We can do this by using the `pd.DataFrame()` function, and using list loops inside this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leanne Graham</td>\n",
       "      <td>Sincere@april.biz</td>\n",
       "      <td>Romaguera-Crona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ervin Howell</td>\n",
       "      <td>Shanna@melissa.tv</td>\n",
       "      <td>Deckow-Crist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clementine Bauch</td>\n",
       "      <td>Nathan@yesenia.net</td>\n",
       "      <td>Romaguera-Jacobson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patricia Lebsack</td>\n",
       "      <td>Julianne.OConner@kory.org</td>\n",
       "      <td>Robel-Corkery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chelsey Dietrich</td>\n",
       "      <td>Lucio_Hettinger@annie.ca</td>\n",
       "      <td>Keebler LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mrs. Dennis Schulist</td>\n",
       "      <td>Karley_Dach@jasper.info</td>\n",
       "      <td>Considine-Lockman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kurtis Weissnat</td>\n",
       "      <td>Telly.Hoeger@billy.biz</td>\n",
       "      <td>Johns Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nicholas Runolfsdottir V</td>\n",
       "      <td>Sherwood@rosamond.me</td>\n",
       "      <td>Abernathy Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glenna Reichert</td>\n",
       "      <td>Chaim_McDermott@dana.io</td>\n",
       "      <td>Yost and Sons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clementina DuBuque</td>\n",
       "      <td>Rey.Padberg@karina.biz</td>\n",
       "      <td>Hoeger LLC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                      email        company_name\n",
       "0             Leanne Graham          Sincere@april.biz     Romaguera-Crona\n",
       "1              Ervin Howell          Shanna@melissa.tv        Deckow-Crist\n",
       "2          Clementine Bauch         Nathan@yesenia.net  Romaguera-Jacobson\n",
       "3          Patricia Lebsack  Julianne.OConner@kory.org       Robel-Corkery\n",
       "4          Chelsey Dietrich   Lucio_Hettinger@annie.ca         Keebler LLC\n",
       "5      Mrs. Dennis Schulist    Karley_Dach@jasper.info   Considine-Lockman\n",
       "6           Kurtis Weissnat     Telly.Hoeger@billy.biz         Johns Group\n",
       "7  Nicholas Runolfsdottir V       Sherwood@rosamond.me     Abernathy Group\n",
       "8           Glenna Reichert    Chaim_McDermott@dana.io       Yost and Sons\n",
       "9        Clementina DuBuque     Rey.Padberg@karina.biz          Hoeger LLC"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = pd.DataFrame(\n",
    "    [u['name'], u['email'], u['company']['name']] for u in users_json\n",
    ")\n",
    "users_df.columns = ['name', 'email', 'company_name']\n",
    "users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, note, there are many many ways to construct a loop to extract JSON elements into a dataframe. If you look on Stack Overflow, for example, you will see many different approaches, and it can be confusing. Find an approach that you understand and feel comfortable using, and go with that. There's not much difference between one loop and the next, as the real improvement comes from vectorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `pd.read_json()` and `pd.json_normalize()` to Store JSON Data in a Data Frame\n",
    "If there aren't too many features in the data, or if you want to keep all of the features in the data anyway, then the fastest and best way to convert JSON data to a tabular data frame depends on **whether or not the JSON data has metadata or a nested structure**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situation 1: No nesting, no metadata\n",
    "\n",
    "If the JSON has no nesting - that is, if every key is associated with a single datapoint, and no key is associated with a dictionary that contains additional features - and also does not include metadata, then use the following steps:\n",
    "\n",
    "1. Use `requests.get()` to download the raw JSON data (unless you have another way of acquiring the raw data)\n",
    "\n",
    "2. Use `pd.read_json()` on the `.text` attribute of the output of `requests.get()`\n",
    "\n",
    "The result will be a dataframe in which the columns have the same names as the keys in the JSON file. For example, JSON Placeholder has an example JSON dataset that contains [random Latin posts to a blog](https://jsonplaceholder.typicode.com/posts). This JSON contains no metadata and no nesting. The best way to acquire this dataset and convert it to a dataframe is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sunt aut facere repellat provident occaecati e...</td>\n",
       "      <td>quia et suscipit\\nsuscipit recusandae consequu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>qui est esse</td>\n",
       "      <td>est rerum tempore vitae\\nsequi sint nihil repr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ea molestias quasi exercitationem repellat qui...</td>\n",
       "      <td>et iusto sed quo iure\\nvoluptatem occaecati om...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>eum et est occaecati</td>\n",
       "      <td>ullam et saepe reiciendis voluptatem adipisci\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>nesciunt quas odio</td>\n",
       "      <td>repudiandae veniam quaerat sunt sed\\nalias aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>quaerat velit veniam amet cupiditate aut numqu...</td>\n",
       "      <td>in non odio excepturi sint eum\\nlabore volupta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10</td>\n",
       "      <td>97</td>\n",
       "      <td>quas fugiat ut perspiciatis vero provident</td>\n",
       "      <td>eum non blanditiis soluta porro quibusdam volu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>laboriosam dolor voluptates</td>\n",
       "      <td>doloremque ex facilis sit sint culpa\\nsoluta a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10</td>\n",
       "      <td>99</td>\n",
       "      <td>temporibus sit alias delectus eligendi possimu...</td>\n",
       "      <td>quo deleniti praesentium dicta non quod\\naut e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>at nam consequatur ea labore ea harum</td>\n",
       "      <td>cupiditate quo est a modi nesciunt soluta\\nips...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId   id                                              title  \\\n",
       "0        1    1  sunt aut facere repellat provident occaecati e...   \n",
       "1        1    2                                       qui est esse   \n",
       "2        1    3  ea molestias quasi exercitationem repellat qui...   \n",
       "3        1    4                               eum et est occaecati   \n",
       "4        1    5                                 nesciunt quas odio   \n",
       "..     ...  ...                                                ...   \n",
       "95      10   96  quaerat velit veniam amet cupiditate aut numqu...   \n",
       "96      10   97         quas fugiat ut perspiciatis vero provident   \n",
       "97      10   98                        laboriosam dolor voluptates   \n",
       "98      10   99  temporibus sit alias delectus eligendi possimu...   \n",
       "99      10  100              at nam consequatur ea labore ea harum   \n",
       "\n",
       "                                                 body  \n",
       "0   quia et suscipit\\nsuscipit recusandae consequu...  \n",
       "1   est rerum tempore vitae\\nsequi sint nihil repr...  \n",
       "2   et iusto sed quo iure\\nvoluptatem occaecati om...  \n",
       "3   ullam et saepe reiciendis voluptatem adipisci\\...  \n",
       "4   repudiandae veniam quaerat sunt sed\\nalias aut...  \n",
       "..                                                ...  \n",
       "95  in non odio excepturi sint eum\\nlabore volupta...  \n",
       "96  eum non blanditiis soluta porro quibusdam volu...  \n",
       "97  doloremque ex facilis sit sint culpa\\nsoluta a...  \n",
       "98  quo deleniti praesentium dicta non quod\\naut e...  \n",
       "99  cupiditate quo est a modi nesciunt soluta\\nips...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = requests.get(\"https://jsonplaceholder.typicode.com/posts\")\n",
    "posts_df = pd.read_json(posts.text)\n",
    "posts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situation 2: Nesting, but no metadata\n",
    "\n",
    "If the JSON file contains nesting, but no metadata, then the best strategy is to\n",
    "\n",
    "1. Use `requests.get()` to download the raw JSON data (unless you have another way of acquiring the raw data)\n",
    "\n",
    "2. Use `json.loads()` on the `.text` attribute of the output from step 1 to register the data as a list in Python\n",
    "\n",
    "3. Use the `pd.json_normalize()` function on the list that is the output of step 2\n",
    "\n",
    "The `pd.json_normalize()` function stores every feature in the data in a separate column, no matter how many levels of nesting it must parse to find the feature. \n",
    "\n",
    "Every column has the same name as the key from which it drew the feature. For features that are nested within other features, `pd.json_normalize()` uses every key on the path to the datapoint to construct the column name, separated by periods. For example, the `users` data that we worked with above contains up to three levels of nesting. So the `lat` data is stored in a column named `address.geo.lat`, since we had to navigate to \"address\", then \"geo\", then \"lat\" in the JSON to find these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>address.street</th>\n",
       "      <th>address.suite</th>\n",
       "      <th>address.city</th>\n",
       "      <th>address.zipcode</th>\n",
       "      <th>address.geo.lat</th>\n",
       "      <th>address.geo.lng</th>\n",
       "      <th>company.name</th>\n",
       "      <th>company.catchPhrase</th>\n",
       "      <th>company.bs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Leanne Graham</td>\n",
       "      <td>Bret</td>\n",
       "      <td>Sincere@april.biz</td>\n",
       "      <td>1-770-736-8031 x56442</td>\n",
       "      <td>hildegard.org</td>\n",
       "      <td>Kulas Light</td>\n",
       "      <td>Apt. 556</td>\n",
       "      <td>Gwenborough</td>\n",
       "      <td>92998-3874</td>\n",
       "      <td>-37.3159</td>\n",
       "      <td>81.1496</td>\n",
       "      <td>Romaguera-Crona</td>\n",
       "      <td>Multi-layered client-server neural-net</td>\n",
       "      <td>harness real-time e-markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ervin Howell</td>\n",
       "      <td>Antonette</td>\n",
       "      <td>Shanna@melissa.tv</td>\n",
       "      <td>010-692-6593 x09125</td>\n",
       "      <td>anastasia.net</td>\n",
       "      <td>Victor Plains</td>\n",
       "      <td>Suite 879</td>\n",
       "      <td>Wisokyburgh</td>\n",
       "      <td>90566-7771</td>\n",
       "      <td>-43.9509</td>\n",
       "      <td>-34.4618</td>\n",
       "      <td>Deckow-Crist</td>\n",
       "      <td>Proactive didactic contingency</td>\n",
       "      <td>synergize scalable supply-chains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Clementine Bauch</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Nathan@yesenia.net</td>\n",
       "      <td>1-463-123-4447</td>\n",
       "      <td>ramiro.info</td>\n",
       "      <td>Douglas Extension</td>\n",
       "      <td>Suite 847</td>\n",
       "      <td>McKenziehaven</td>\n",
       "      <td>59590-4157</td>\n",
       "      <td>-68.6102</td>\n",
       "      <td>-47.0653</td>\n",
       "      <td>Romaguera-Jacobson</td>\n",
       "      <td>Face to face bifurcated interface</td>\n",
       "      <td>e-enable strategic applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Patricia Lebsack</td>\n",
       "      <td>Karianne</td>\n",
       "      <td>Julianne.OConner@kory.org</td>\n",
       "      <td>493-170-9623 x156</td>\n",
       "      <td>kale.biz</td>\n",
       "      <td>Hoeger Mall</td>\n",
       "      <td>Apt. 692</td>\n",
       "      <td>South Elvis</td>\n",
       "      <td>53919-4257</td>\n",
       "      <td>29.4572</td>\n",
       "      <td>-164.2990</td>\n",
       "      <td>Robel-Corkery</td>\n",
       "      <td>Multi-tiered zero tolerance productivity</td>\n",
       "      <td>transition cutting-edge web services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chelsey Dietrich</td>\n",
       "      <td>Kamren</td>\n",
       "      <td>Lucio_Hettinger@annie.ca</td>\n",
       "      <td>(254)954-1289</td>\n",
       "      <td>demarco.info</td>\n",
       "      <td>Skiles Walks</td>\n",
       "      <td>Suite 351</td>\n",
       "      <td>Roscoeview</td>\n",
       "      <td>33263</td>\n",
       "      <td>-31.8129</td>\n",
       "      <td>62.5342</td>\n",
       "      <td>Keebler LLC</td>\n",
       "      <td>User-centric fault-tolerant solution</td>\n",
       "      <td>revolutionize end-to-end systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mrs. Dennis Schulist</td>\n",
       "      <td>Leopoldo_Corkery</td>\n",
       "      <td>Karley_Dach@jasper.info</td>\n",
       "      <td>1-477-935-8478 x6430</td>\n",
       "      <td>ola.org</td>\n",
       "      <td>Norberto Crossing</td>\n",
       "      <td>Apt. 950</td>\n",
       "      <td>South Christy</td>\n",
       "      <td>23505-1337</td>\n",
       "      <td>-71.4197</td>\n",
       "      <td>71.7478</td>\n",
       "      <td>Considine-Lockman</td>\n",
       "      <td>Synchronised bottom-line interface</td>\n",
       "      <td>e-enable innovative applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Kurtis Weissnat</td>\n",
       "      <td>Elwyn.Skiles</td>\n",
       "      <td>Telly.Hoeger@billy.biz</td>\n",
       "      <td>210.067.6132</td>\n",
       "      <td>elvis.io</td>\n",
       "      <td>Rex Trail</td>\n",
       "      <td>Suite 280</td>\n",
       "      <td>Howemouth</td>\n",
       "      <td>58804-1099</td>\n",
       "      <td>24.8918</td>\n",
       "      <td>21.8984</td>\n",
       "      <td>Johns Group</td>\n",
       "      <td>Configurable multimedia task-force</td>\n",
       "      <td>generate enterprise e-tailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Nicholas Runolfsdottir V</td>\n",
       "      <td>Maxime_Nienow</td>\n",
       "      <td>Sherwood@rosamond.me</td>\n",
       "      <td>586.493.6943 x140</td>\n",
       "      <td>jacynthe.com</td>\n",
       "      <td>Ellsworth Summit</td>\n",
       "      <td>Suite 729</td>\n",
       "      <td>Aliyaview</td>\n",
       "      <td>45169</td>\n",
       "      <td>-14.3990</td>\n",
       "      <td>-120.7677</td>\n",
       "      <td>Abernathy Group</td>\n",
       "      <td>Implemented secondary concept</td>\n",
       "      <td>e-enable extensible e-tailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Glenna Reichert</td>\n",
       "      <td>Delphine</td>\n",
       "      <td>Chaim_McDermott@dana.io</td>\n",
       "      <td>(775)976-6794 x41206</td>\n",
       "      <td>conrad.com</td>\n",
       "      <td>Dayna Park</td>\n",
       "      <td>Suite 449</td>\n",
       "      <td>Bartholomebury</td>\n",
       "      <td>76495-3109</td>\n",
       "      <td>24.6463</td>\n",
       "      <td>-168.8889</td>\n",
       "      <td>Yost and Sons</td>\n",
       "      <td>Switchable contextually-based project</td>\n",
       "      <td>aggregate real-time technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Clementina DuBuque</td>\n",
       "      <td>Moriah.Stanton</td>\n",
       "      <td>Rey.Padberg@karina.biz</td>\n",
       "      <td>024-648-3804</td>\n",
       "      <td>ambrose.net</td>\n",
       "      <td>Kattie Turnpike</td>\n",
       "      <td>Suite 198</td>\n",
       "      <td>Lebsackbury</td>\n",
       "      <td>31428-2261</td>\n",
       "      <td>-38.2386</td>\n",
       "      <td>57.2232</td>\n",
       "      <td>Hoeger LLC</td>\n",
       "      <td>Centralized empowering task-force</td>\n",
       "      <td>target end-to-end models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      name          username                      email  \\\n",
       "0   1             Leanne Graham              Bret          Sincere@april.biz   \n",
       "1   2              Ervin Howell         Antonette          Shanna@melissa.tv   \n",
       "2   3          Clementine Bauch          Samantha         Nathan@yesenia.net   \n",
       "3   4          Patricia Lebsack          Karianne  Julianne.OConner@kory.org   \n",
       "4   5          Chelsey Dietrich            Kamren   Lucio_Hettinger@annie.ca   \n",
       "5   6      Mrs. Dennis Schulist  Leopoldo_Corkery    Karley_Dach@jasper.info   \n",
       "6   7           Kurtis Weissnat      Elwyn.Skiles     Telly.Hoeger@billy.biz   \n",
       "7   8  Nicholas Runolfsdottir V     Maxime_Nienow       Sherwood@rosamond.me   \n",
       "8   9           Glenna Reichert          Delphine    Chaim_McDermott@dana.io   \n",
       "9  10        Clementina DuBuque    Moriah.Stanton     Rey.Padberg@karina.biz   \n",
       "\n",
       "                   phone        website     address.street address.suite  \\\n",
       "0  1-770-736-8031 x56442  hildegard.org        Kulas Light      Apt. 556   \n",
       "1    010-692-6593 x09125  anastasia.net      Victor Plains     Suite 879   \n",
       "2         1-463-123-4447    ramiro.info  Douglas Extension     Suite 847   \n",
       "3      493-170-9623 x156       kale.biz        Hoeger Mall      Apt. 692   \n",
       "4          (254)954-1289   demarco.info       Skiles Walks     Suite 351   \n",
       "5   1-477-935-8478 x6430        ola.org  Norberto Crossing      Apt. 950   \n",
       "6           210.067.6132       elvis.io          Rex Trail     Suite 280   \n",
       "7      586.493.6943 x140   jacynthe.com   Ellsworth Summit     Suite 729   \n",
       "8   (775)976-6794 x41206     conrad.com         Dayna Park     Suite 449   \n",
       "9           024-648-3804    ambrose.net    Kattie Turnpike     Suite 198   \n",
       "\n",
       "     address.city address.zipcode address.geo.lat address.geo.lng  \\\n",
       "0     Gwenborough      92998-3874        -37.3159         81.1496   \n",
       "1     Wisokyburgh      90566-7771        -43.9509        -34.4618   \n",
       "2   McKenziehaven      59590-4157        -68.6102        -47.0653   \n",
       "3     South Elvis      53919-4257         29.4572       -164.2990   \n",
       "4      Roscoeview           33263        -31.8129         62.5342   \n",
       "5   South Christy      23505-1337        -71.4197         71.7478   \n",
       "6       Howemouth      58804-1099         24.8918         21.8984   \n",
       "7       Aliyaview           45169        -14.3990       -120.7677   \n",
       "8  Bartholomebury      76495-3109         24.6463       -168.8889   \n",
       "9     Lebsackbury      31428-2261        -38.2386         57.2232   \n",
       "\n",
       "         company.name                       company.catchPhrase  \\\n",
       "0     Romaguera-Crona    Multi-layered client-server neural-net   \n",
       "1        Deckow-Crist            Proactive didactic contingency   \n",
       "2  Romaguera-Jacobson         Face to face bifurcated interface   \n",
       "3       Robel-Corkery  Multi-tiered zero tolerance productivity   \n",
       "4         Keebler LLC      User-centric fault-tolerant solution   \n",
       "5   Considine-Lockman        Synchronised bottom-line interface   \n",
       "6         Johns Group        Configurable multimedia task-force   \n",
       "7     Abernathy Group             Implemented secondary concept   \n",
       "8       Yost and Sons     Switchable contextually-based project   \n",
       "9          Hoeger LLC         Centralized empowering task-force   \n",
       "\n",
       "                             company.bs  \n",
       "0           harness real-time e-markets  \n",
       "1      synergize scalable supply-chains  \n",
       "2       e-enable strategic applications  \n",
       "3  transition cutting-edge web services  \n",
       "4      revolutionize end-to-end systems  \n",
       "5      e-enable innovative applications  \n",
       "6         generate enterprise e-tailers  \n",
       "7         e-enable extensible e-tailers  \n",
       "8      aggregate real-time technologies  \n",
       "9              target end-to-end models  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = requests.get(\"https://jsonplaceholder.typicode.com/users\")\n",
    "users_json = json.loads(users.text)\n",
    "users_df = pd.json_normalize(users_json)\n",
    "users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situation 3: Metadata\n",
    "\n",
    "Finally, if the JSON file contains metadata (regardless of whether or not the records contain nested data), follow these steps:\n",
    "\n",
    "1. Use `requests.get()` to download the raw JSON data (unless you have another way of acquiring the raw data)\n",
    "\n",
    "2. Use `json.loads()` on the `.text` attribute of the output from step 1 to register the data as a list in Python\n",
    "\n",
    "3. Look at the data using a web-browser, or using the text that appears when the JSON object is called in Python, to decide on the path that is necessary to find the records\n",
    "\n",
    "4. Use the `pd.json_normalize()` function on the list that is the output of step 2. But within this function, use the `record_path` parameter and set it equal to a list with the keys, in order, that lead to the record\n",
    "\n",
    "5. Optionally, use the `meta` and `meta_prefix` parameters in `pd.json_normalize()` to store the metadata in the dataframe\n",
    "\n",
    "For example, we can access a JSON file for the top 25 top posts at the moment on [Reddit's r/popular page](https://www.reddit.com/r/popular/) here: http://www.reddit.com/r/popular/top.json. If our goal is to construct a data frame with 25 rows, one for each post, we must find the path that leads to these data. Looking at the web-browser, the top-level has two keys: \"kind\" and \"data\". \"kind\" is simply metadata telling us that this file contains listings, and the data live in \"data\". Within this branch, there are four more metadata branches, \"modhash\", \"dist\", \"before\", and \"after\", and the data we need exist within \"children\". So the path we need is `[\"data\", \"children\"]`. The code to construct the data frame we need is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>data.approved_at_utc</th>\n",
       "      <th>data.subreddit</th>\n",
       "      <th>data.selftext</th>\n",
       "      <th>data.author_fullname</th>\n",
       "      <th>data.saved</th>\n",
       "      <th>data.mod_reason_title</th>\n",
       "      <th>data.gilded</th>\n",
       "      <th>data.clicked</th>\n",
       "      <th>data.title</th>\n",
       "      <th>...</th>\n",
       "      <th>data.media.oembed.author_name</th>\n",
       "      <th>data.media.oembed.height</th>\n",
       "      <th>data.media.oembed.width</th>\n",
       "      <th>data.media.oembed.html</th>\n",
       "      <th>data.media.oembed.thumbnail_width</th>\n",
       "      <th>data.media.oembed.version</th>\n",
       "      <th>data.media.oembed.provider_name</th>\n",
       "      <th>data.media.oembed.thumbnail_url</th>\n",
       "      <th>data.media.oembed.thumbnail_height</th>\n",
       "      <th>data.link_flair_template_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>KidsAreFuckingStupid</td>\n",
       "      <td></td>\n",
       "      <td>t2_jkwyx</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>My girl does a 50 meter run-up to kick a ball</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td></td>\n",
       "      <td>t2_v51f9</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>TIL a Georgia teacher who bought a $400 travel...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>pics</td>\n",
       "      <td></td>\n",
       "      <td>t2_3nkxnuz0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>My painting today, â€œFaith and Fateâ€. Done with...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>memes</td>\n",
       "      <td></td>\n",
       "      <td>t2_47y2qd1c</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Sully boi</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td></td>\n",
       "      <td>t2_9zcsxqk</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Our neighbors pet pig stays on their porch all...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_15d4m3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>We adopted a senior doggo and he loves sleepin...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td></td>\n",
       "      <td>t2_xduj3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Ref saves fighters head from hitting floor</td>\n",
       "      <td>...</td>\n",
       "      <td>Gfycat</td>\n",
       "      <td>337.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>&amp;lt;iframe class=\"embedly-embed\" src=\"https://...</td>\n",
       "      <td>444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gfycat</td>\n",
       "      <td>https://thumbs.gfycat.com/FastValidBlackfish-s...</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>funny</td>\n",
       "      <td></td>\n",
       "      <td>t2_6fpnv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mother-in-law just served me this piece of cak...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_ayyx6</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Ocelot scratches!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>funny</td>\n",
       "      <td></td>\n",
       "      <td>t2_4cf674sy</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Wiener of Shame!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td></td>\n",
       "      <td>t2_3dtthbpp</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>I love watching talent progression!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>memes</td>\n",
       "      <td></td>\n",
       "      <td>t2_4dyr5fo8</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>Do not suggest anything to your boss in a boar...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>interestingasfuck</td>\n",
       "      <td></td>\n",
       "      <td>t2_ar7lvxr</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Divers walking upside-down underneath ice</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td></td>\n",
       "      <td>t2_5e7f3bem</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Doctors of Reddit, what's the biggest case of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>therewasanattempt</td>\n",
       "      <td></td>\n",
       "      <td>t2_r1i19</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>to protect and serve</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>MadeMeSmile</td>\n",
       "      <td></td>\n",
       "      <td>t2_16qd6g</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>I'm a lone dad that's shaved my head all my li...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>wholesomememes</td>\n",
       "      <td></td>\n",
       "      <td>t2_344uuir9</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you mom</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td></td>\n",
       "      <td>t2_17am3d</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>$2.97 Headphone stand</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6bd464aa-c51a-11e3-85ad-12313d163aa0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>WatchPeopleDieInside</td>\n",
       "      <td></td>\n",
       "      <td>t2_1jtr3unj</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Realizing you're about to be guarded by a 7'4\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_552sq4vz</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Bath time</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>comics</td>\n",
       "      <td></td>\n",
       "      <td>t2_4jkot8yv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>[OC] ..dog world problems</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>gifs</td>\n",
       "      <td></td>\n",
       "      <td>t2_ayyx6</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Child is endlessly amused by kissing an orangu...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>oddlysatisfying</td>\n",
       "      <td></td>\n",
       "      <td>t2_3zdo30sv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Picture of the Sky from a plane</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_8w94q</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Synchronized wagging</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>HolUp</td>\n",
       "      <td></td>\n",
       "      <td>t2_3msic3xp</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>hol the fuck up</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows Ã— 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   kind data.approved_at_utc        data.subreddit data.selftext  \\\n",
       "0    t3                 None  KidsAreFuckingStupid                 \n",
       "1    t3                 None         todayilearned                 \n",
       "2    t3                 None                  pics                 \n",
       "3    t3                 None                 memes                 \n",
       "4    t3                 None     mildlyinteresting                 \n",
       "5    t3                 None                   aww                 \n",
       "6    t3                 None      nextfuckinglevel                 \n",
       "7    t3                 None                 funny                 \n",
       "8    t3                 None                   aww                 \n",
       "9    t3                 None                 funny                 \n",
       "10   t3                 None      nextfuckinglevel                 \n",
       "11   t3                 None                 memes                 \n",
       "12   t3                 None     interestingasfuck                 \n",
       "13   t3                 None             AskReddit                 \n",
       "14   t3                 None     therewasanattempt                 \n",
       "15   t3                 None           MadeMeSmile                 \n",
       "16   t3                 None        wholesomememes                 \n",
       "17   t3                 None          pcmasterrace                 \n",
       "18   t3                 None  WatchPeopleDieInside                 \n",
       "19   t3                 None                   aww                 \n",
       "20   t3                 None                comics                 \n",
       "21   t3                 None                  gifs                 \n",
       "22   t3                 None       oddlysatisfying                 \n",
       "23   t3                 None                   aww                 \n",
       "24   t3                 None                 HolUp                 \n",
       "\n",
       "   data.author_fullname  data.saved data.mod_reason_title  data.gilded  \\\n",
       "0              t2_jkwyx       False                  None            1   \n",
       "1              t2_v51f9       False                  None            2   \n",
       "2           t2_3nkxnuz0       False                  None            7   \n",
       "3           t2_47y2qd1c       False                  None            0   \n",
       "4            t2_9zcsxqk       False                  None            0   \n",
       "5             t2_15d4m3       False                  None            2   \n",
       "6              t2_xduj3       False                  None            1   \n",
       "7              t2_6fpnv       False                  None            0   \n",
       "8              t2_ayyx6       False                  None            1   \n",
       "9           t2_4cf674sy       False                  None            1   \n",
       "10          t2_3dtthbpp       False                  None            3   \n",
       "11          t2_4dyr5fo8       False                  None            3   \n",
       "12           t2_ar7lvxr       False                  None            0   \n",
       "13          t2_5e7f3bem       False                  None            4   \n",
       "14             t2_r1i19       False                  None            1   \n",
       "15            t2_16qd6g       False                  None            5   \n",
       "16          t2_344uuir9       False                  None            0   \n",
       "17            t2_17am3d       False                  None            1   \n",
       "18          t2_1jtr3unj       False                  None            0   \n",
       "19          t2_552sq4vz       False                  None            0   \n",
       "20          t2_4jkot8yv       False                  None            3   \n",
       "21             t2_ayyx6       False                  None            1   \n",
       "22          t2_3zdo30sv       False                  None            1   \n",
       "23             t2_8w94q       False                  None            0   \n",
       "24          t2_3msic3xp       False                  None            0   \n",
       "\n",
       "    data.clicked                                         data.title  ...  \\\n",
       "0          False      My girl does a 50 meter run-up to kick a ball  ...   \n",
       "1          False  TIL a Georgia teacher who bought a $400 travel...  ...   \n",
       "2          False  My painting today, â€œFaith and Fateâ€. Done with...  ...   \n",
       "3          False                                          Sully boi  ...   \n",
       "4          False  Our neighbors pet pig stays on their porch all...  ...   \n",
       "5          False  We adopted a senior doggo and he loves sleepin...  ...   \n",
       "6          False         Ref saves fighters head from hitting floor  ...   \n",
       "7          False  Mother-in-law just served me this piece of cak...  ...   \n",
       "8          False                                  Ocelot scratches!  ...   \n",
       "9          False                                   Wiener of Shame!  ...   \n",
       "10         False                I love watching talent progression!  ...   \n",
       "11         False  Do not suggest anything to your boss in a boar...  ...   \n",
       "12         False          Divers walking upside-down underneath ice  ...   \n",
       "13         False  Doctors of Reddit, what's the biggest case of ...  ...   \n",
       "14         False                               to protect and serve  ...   \n",
       "15         False  I'm a lone dad that's shaved my head all my li...  ...   \n",
       "16         False                                      Thank you mom  ...   \n",
       "17         False                              $2.97 Headphone stand  ...   \n",
       "18         False  Realizing you're about to be guarded by a 7'4\"...  ...   \n",
       "19         False                                          Bath time  ...   \n",
       "20         False                          [OC] ..dog world problems  ...   \n",
       "21         False  Child is endlessly amused by kissing an orangu...  ...   \n",
       "22         False                    Picture of the Sky from a plane  ...   \n",
       "23         False                               Synchronized wagging  ...   \n",
       "24         False                                    hol the fuck up  ...   \n",
       "\n",
       "   data.media.oembed.author_name data.media.oembed.height  \\\n",
       "0                            NaN                      NaN   \n",
       "1                            NaN                      NaN   \n",
       "2                            NaN                      NaN   \n",
       "3                            NaN                      NaN   \n",
       "4                            NaN                      NaN   \n",
       "5                            NaN                      NaN   \n",
       "6                         Gfycat                    337.0   \n",
       "7                            NaN                      NaN   \n",
       "8                            NaN                      NaN   \n",
       "9                            NaN                      NaN   \n",
       "10                           NaN                      NaN   \n",
       "11                           NaN                      NaN   \n",
       "12                           NaN                      NaN   \n",
       "13                           NaN                      NaN   \n",
       "14                           NaN                      NaN   \n",
       "15                           NaN                      NaN   \n",
       "16                           NaN                      NaN   \n",
       "17                           NaN                      NaN   \n",
       "18                           NaN                      NaN   \n",
       "19                           NaN                      NaN   \n",
       "20                           NaN                      NaN   \n",
       "21                           NaN                      NaN   \n",
       "22                           NaN                      NaN   \n",
       "23                           NaN                      NaN   \n",
       "24                           NaN                      NaN   \n",
       "\n",
       "    data.media.oembed.width  \\\n",
       "0                       NaN   \n",
       "1                       NaN   \n",
       "2                       NaN   \n",
       "3                       NaN   \n",
       "4                       NaN   \n",
       "5                       NaN   \n",
       "6                     600.0   \n",
       "7                       NaN   \n",
       "8                       NaN   \n",
       "9                       NaN   \n",
       "10                      NaN   \n",
       "11                      NaN   \n",
       "12                      NaN   \n",
       "13                      NaN   \n",
       "14                      NaN   \n",
       "15                      NaN   \n",
       "16                      NaN   \n",
       "17                      NaN   \n",
       "18                      NaN   \n",
       "19                      NaN   \n",
       "20                      NaN   \n",
       "21                      NaN   \n",
       "22                      NaN   \n",
       "23                      NaN   \n",
       "24                      NaN   \n",
       "\n",
       "                               data.media.oembed.html  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6   &lt;iframe class=\"embedly-embed\" src=\"https://...   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "\n",
       "   data.media.oembed.thumbnail_width  data.media.oembed.version  \\\n",
       "0                                NaN                        NaN   \n",
       "1                                NaN                        NaN   \n",
       "2                                NaN                        NaN   \n",
       "3                                NaN                        NaN   \n",
       "4                                NaN                        NaN   \n",
       "5                                NaN                        NaN   \n",
       "6                              444.0                        1.0   \n",
       "7                                NaN                        NaN   \n",
       "8                                NaN                        NaN   \n",
       "9                                NaN                        NaN   \n",
       "10                               NaN                        NaN   \n",
       "11                               NaN                        NaN   \n",
       "12                               NaN                        NaN   \n",
       "13                               NaN                        NaN   \n",
       "14                               NaN                        NaN   \n",
       "15                               NaN                        NaN   \n",
       "16                               NaN                        NaN   \n",
       "17                               NaN                        NaN   \n",
       "18                               NaN                        NaN   \n",
       "19                               NaN                        NaN   \n",
       "20                               NaN                        NaN   \n",
       "21                               NaN                        NaN   \n",
       "22                               NaN                        NaN   \n",
       "23                               NaN                        NaN   \n",
       "24                               NaN                        NaN   \n",
       "\n",
       "    data.media.oembed.provider_name  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "5                               NaN   \n",
       "6                            Gfycat   \n",
       "7                               NaN   \n",
       "8                               NaN   \n",
       "9                               NaN   \n",
       "10                              NaN   \n",
       "11                              NaN   \n",
       "12                              NaN   \n",
       "13                              NaN   \n",
       "14                              NaN   \n",
       "15                              NaN   \n",
       "16                              NaN   \n",
       "17                              NaN   \n",
       "18                              NaN   \n",
       "19                              NaN   \n",
       "20                              NaN   \n",
       "21                              NaN   \n",
       "22                              NaN   \n",
       "23                              NaN   \n",
       "24                              NaN   \n",
       "\n",
       "                      data.media.oembed.thumbnail_url  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6   https://thumbs.gfycat.com/FastValidBlackfish-s...   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "\n",
       "   data.media.oembed.thumbnail_height           data.link_flair_template_id  \n",
       "0                                 NaN                                   NaN  \n",
       "1                                 NaN                                   NaN  \n",
       "2                                 NaN                                   NaN  \n",
       "3                                 NaN                                   NaN  \n",
       "4                                 NaN                                   NaN  \n",
       "5                                 NaN                                   NaN  \n",
       "6                               250.0                                   NaN  \n",
       "7                                 NaN                                   NaN  \n",
       "8                                 NaN                                   NaN  \n",
       "9                                 NaN                                   NaN  \n",
       "10                                NaN                                   NaN  \n",
       "11                                NaN                                   NaN  \n",
       "12                                NaN                                   NaN  \n",
       "13                                NaN                                   NaN  \n",
       "14                                NaN                                   NaN  \n",
       "15                                NaN                                   NaN  \n",
       "16                                NaN                                   NaN  \n",
       "17                                NaN  6bd464aa-c51a-11e3-85ad-12313d163aa0  \n",
       "18                                NaN                                   NaN  \n",
       "19                                NaN                                   NaN  \n",
       "20                                NaN                                   NaN  \n",
       "21                                NaN                                   NaN  \n",
       "22                                NaN                                   NaN  \n",
       "23                                NaN                                   NaN  \n",
       "24                                NaN                                   NaN  \n",
       "\n",
       "[25 rows x 170 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.reddit.com/r/popular/top.json\"\n",
    "reddit = requests.get(url, headers = {'User-agent': 'DS6001'})\n",
    "reddit_json = json.loads(reddit.text)\n",
    "reddit_df = pd.json_normalize(reddit_json, record_path = [\"data\", \"children\"])\n",
    "reddit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note: we added `headers = {'User-agent': 'DS6001'}` to the `requests.get()` function. When we use `requests.get()`, we are accessing an API: a web-based interface for transferring data, usually in the form of JSON files. We will cover APIs in the next module. Most APIs, including Reddit's, include some security to keep any one user from overusing the API and causing it to crash. For Reddit, we only need to provide a unique \"[User-agent](https://www.reddit.com/r/redditdev/comments/3qbll8/429_too_many_requests/)\", which is an ID that Reddit uses to keep track of how much we are using the API. If two people use the same User-agent, both uses are counted against the same limit, so it's better to choose a User-agent that has a unique name. If this block of code results in an error for you (so that `reddit.text` displays as `'{\"message\": \"Too Many Requests\", \"error\": 429}'`), then change `DS6001` to something else, and it should work. \n",
    "\n",
    "To save the metadata in the data frame, use the `meta` parameter, set equal to a list of paths for each metadata feature you wish to store in the dataframe. In this case, to save the \"kind\" feature and the \"after\" feature within the \"data\" branch, I type `meta = ['kind', ['data', 'after']]`. Finally, because there is already a `kind` feature stored within the records, I must distinguish the metadata feature with a prefix. I use `meta_prefix='meta'` to place \"meta\" prior to the column names of the metadata.\n",
    "\n",
    "Because metadata exist outside of the records, they will be constant across the rows in the dataframe. Here's the code to convert the Reddit data to a data frame while storing the metadata. Take a look at the resulting dataframe and scroll all the way to the right to see the two metadata columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>data.approved_at_utc</th>\n",
       "      <th>data.subreddit</th>\n",
       "      <th>data.selftext</th>\n",
       "      <th>data.author_fullname</th>\n",
       "      <th>data.saved</th>\n",
       "      <th>data.mod_reason_title</th>\n",
       "      <th>data.gilded</th>\n",
       "      <th>data.clicked</th>\n",
       "      <th>data.title</th>\n",
       "      <th>...</th>\n",
       "      <th>data.media.oembed.thumbnail_width</th>\n",
       "      <th>data.media.oembed.version</th>\n",
       "      <th>data.media.oembed.provider_name</th>\n",
       "      <th>data.media.oembed.thumbnail_url</th>\n",
       "      <th>data.media.oembed.type</th>\n",
       "      <th>data.media.oembed.thumbnail_height</th>\n",
       "      <th>data.media.type</th>\n",
       "      <th>data.link_flair_template_id</th>\n",
       "      <th>metakind</th>\n",
       "      <th>metadata.after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>KidsAreFuckingStupid</td>\n",
       "      <td></td>\n",
       "      <td>t2_jkwyx</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>My girl does a 50 meter run-up to kick a ball</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td></td>\n",
       "      <td>t2_v51f9</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>TIL a Georgia teacher who bought a $400 travel...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>pics</td>\n",
       "      <td></td>\n",
       "      <td>t2_3nkxnuz0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>My painting today, â€œFaith and Fateâ€. Done with...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>memes</td>\n",
       "      <td></td>\n",
       "      <td>t2_47y2qd1c</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Sully boi</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td></td>\n",
       "      <td>t2_9zcsxqk</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Our neighbors pet pig stays on their porch all...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_15d4m3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>We adopted a senior doggo and he loves sleepin...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td></td>\n",
       "      <td>t2_xduj3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Ref saves fighters head from hitting floor</td>\n",
       "      <td>...</td>\n",
       "      <td>444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gfycat</td>\n",
       "      <td>https://thumbs.gfycat.com/FastValidBlackfish-s...</td>\n",
       "      <td>video</td>\n",
       "      <td>250.0</td>\n",
       "      <td>gfycat.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>funny</td>\n",
       "      <td></td>\n",
       "      <td>t2_6fpnv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mother-in-law just served me this piece of cak...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_ayyx6</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Ocelot scratches!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>funny</td>\n",
       "      <td></td>\n",
       "      <td>t2_4cf674sy</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Wiener of Shame!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td></td>\n",
       "      <td>t2_3dtthbpp</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>I love watching talent progression!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>memes</td>\n",
       "      <td></td>\n",
       "      <td>t2_4dyr5fo8</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>Do not suggest anything to your boss in a boar...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>interestingasfuck</td>\n",
       "      <td></td>\n",
       "      <td>t2_ar7lvxr</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Divers walking upside-down underneath ice</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td></td>\n",
       "      <td>t2_5e7f3bem</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Doctors of Reddit, what's the biggest case of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>therewasanattempt</td>\n",
       "      <td></td>\n",
       "      <td>t2_r1i19</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>to protect and serve</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>MadeMeSmile</td>\n",
       "      <td></td>\n",
       "      <td>t2_16qd6g</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>I'm a lone dad that's shaved my head all my li...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>wholesomememes</td>\n",
       "      <td></td>\n",
       "      <td>t2_344uuir9</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you mom</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td></td>\n",
       "      <td>t2_17am3d</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>$2.97 Headphone stand</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6bd464aa-c51a-11e3-85ad-12313d163aa0</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>WatchPeopleDieInside</td>\n",
       "      <td></td>\n",
       "      <td>t2_1jtr3unj</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Realizing you're about to be guarded by a 7'4\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_552sq4vz</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Bath time</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>comics</td>\n",
       "      <td></td>\n",
       "      <td>t2_4jkot8yv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>[OC] ..dog world problems</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>gifs</td>\n",
       "      <td></td>\n",
       "      <td>t2_ayyx6</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Child is endlessly amused by kissing an orangu...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>oddlysatisfying</td>\n",
       "      <td></td>\n",
       "      <td>t2_3zdo30sv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Picture of the Sky from a plane</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_8w94q</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Synchronized wagging</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>HolUp</td>\n",
       "      <td></td>\n",
       "      <td>t2_3msic3xp</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>hol the fuck up</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows Ã— 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   kind data.approved_at_utc        data.subreddit data.selftext  \\\n",
       "0    t3                 None  KidsAreFuckingStupid                 \n",
       "1    t3                 None         todayilearned                 \n",
       "2    t3                 None                  pics                 \n",
       "3    t3                 None                 memes                 \n",
       "4    t3                 None     mildlyinteresting                 \n",
       "5    t3                 None                   aww                 \n",
       "6    t3                 None      nextfuckinglevel                 \n",
       "7    t3                 None                 funny                 \n",
       "8    t3                 None                   aww                 \n",
       "9    t3                 None                 funny                 \n",
       "10   t3                 None      nextfuckinglevel                 \n",
       "11   t3                 None                 memes                 \n",
       "12   t3                 None     interestingasfuck                 \n",
       "13   t3                 None             AskReddit                 \n",
       "14   t3                 None     therewasanattempt                 \n",
       "15   t3                 None           MadeMeSmile                 \n",
       "16   t3                 None        wholesomememes                 \n",
       "17   t3                 None          pcmasterrace                 \n",
       "18   t3                 None  WatchPeopleDieInside                 \n",
       "19   t3                 None                   aww                 \n",
       "20   t3                 None                comics                 \n",
       "21   t3                 None                  gifs                 \n",
       "22   t3                 None       oddlysatisfying                 \n",
       "23   t3                 None                   aww                 \n",
       "24   t3                 None                 HolUp                 \n",
       "\n",
       "   data.author_fullname  data.saved data.mod_reason_title  data.gilded  \\\n",
       "0              t2_jkwyx       False                  None            1   \n",
       "1              t2_v51f9       False                  None            2   \n",
       "2           t2_3nkxnuz0       False                  None            7   \n",
       "3           t2_47y2qd1c       False                  None            0   \n",
       "4            t2_9zcsxqk       False                  None            0   \n",
       "5             t2_15d4m3       False                  None            2   \n",
       "6              t2_xduj3       False                  None            1   \n",
       "7              t2_6fpnv       False                  None            0   \n",
       "8              t2_ayyx6       False                  None            1   \n",
       "9           t2_4cf674sy       False                  None            1   \n",
       "10          t2_3dtthbpp       False                  None            3   \n",
       "11          t2_4dyr5fo8       False                  None            3   \n",
       "12           t2_ar7lvxr       False                  None            0   \n",
       "13          t2_5e7f3bem       False                  None            4   \n",
       "14             t2_r1i19       False                  None            1   \n",
       "15            t2_16qd6g       False                  None            5   \n",
       "16          t2_344uuir9       False                  None            0   \n",
       "17            t2_17am3d       False                  None            1   \n",
       "18          t2_1jtr3unj       False                  None            0   \n",
       "19          t2_552sq4vz       False                  None            0   \n",
       "20          t2_4jkot8yv       False                  None            3   \n",
       "21             t2_ayyx6       False                  None            1   \n",
       "22          t2_3zdo30sv       False                  None            1   \n",
       "23             t2_8w94q       False                  None            0   \n",
       "24          t2_3msic3xp       False                  None            0   \n",
       "\n",
       "    data.clicked                                         data.title  ...  \\\n",
       "0          False      My girl does a 50 meter run-up to kick a ball  ...   \n",
       "1          False  TIL a Georgia teacher who bought a $400 travel...  ...   \n",
       "2          False  My painting today, â€œFaith and Fateâ€. Done with...  ...   \n",
       "3          False                                          Sully boi  ...   \n",
       "4          False  Our neighbors pet pig stays on their porch all...  ...   \n",
       "5          False  We adopted a senior doggo and he loves sleepin...  ...   \n",
       "6          False         Ref saves fighters head from hitting floor  ...   \n",
       "7          False  Mother-in-law just served me this piece of cak...  ...   \n",
       "8          False                                  Ocelot scratches!  ...   \n",
       "9          False                                   Wiener of Shame!  ...   \n",
       "10         False                I love watching talent progression!  ...   \n",
       "11         False  Do not suggest anything to your boss in a boar...  ...   \n",
       "12         False          Divers walking upside-down underneath ice  ...   \n",
       "13         False  Doctors of Reddit, what's the biggest case of ...  ...   \n",
       "14         False                               to protect and serve  ...   \n",
       "15         False  I'm a lone dad that's shaved my head all my li...  ...   \n",
       "16         False                                      Thank you mom  ...   \n",
       "17         False                              $2.97 Headphone stand  ...   \n",
       "18         False  Realizing you're about to be guarded by a 7'4\"...  ...   \n",
       "19         False                                          Bath time  ...   \n",
       "20         False                          [OC] ..dog world problems  ...   \n",
       "21         False  Child is endlessly amused by kissing an orangu...  ...   \n",
       "22         False                    Picture of the Sky from a plane  ...   \n",
       "23         False                               Synchronized wagging  ...   \n",
       "24         False                                    hol the fuck up  ...   \n",
       "\n",
       "   data.media.oembed.thumbnail_width data.media.oembed.version  \\\n",
       "0                                NaN                       NaN   \n",
       "1                                NaN                       NaN   \n",
       "2                                NaN                       NaN   \n",
       "3                                NaN                       NaN   \n",
       "4                                NaN                       NaN   \n",
       "5                                NaN                       NaN   \n",
       "6                              444.0                       1.0   \n",
       "7                                NaN                       NaN   \n",
       "8                                NaN                       NaN   \n",
       "9                                NaN                       NaN   \n",
       "10                               NaN                       NaN   \n",
       "11                               NaN                       NaN   \n",
       "12                               NaN                       NaN   \n",
       "13                               NaN                       NaN   \n",
       "14                               NaN                       NaN   \n",
       "15                               NaN                       NaN   \n",
       "16                               NaN                       NaN   \n",
       "17                               NaN                       NaN   \n",
       "18                               NaN                       NaN   \n",
       "19                               NaN                       NaN   \n",
       "20                               NaN                       NaN   \n",
       "21                               NaN                       NaN   \n",
       "22                               NaN                       NaN   \n",
       "23                               NaN                       NaN   \n",
       "24                               NaN                       NaN   \n",
       "\n",
       "    data.media.oembed.provider_name  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "5                               NaN   \n",
       "6                            Gfycat   \n",
       "7                               NaN   \n",
       "8                               NaN   \n",
       "9                               NaN   \n",
       "10                              NaN   \n",
       "11                              NaN   \n",
       "12                              NaN   \n",
       "13                              NaN   \n",
       "14                              NaN   \n",
       "15                              NaN   \n",
       "16                              NaN   \n",
       "17                              NaN   \n",
       "18                              NaN   \n",
       "19                              NaN   \n",
       "20                              NaN   \n",
       "21                              NaN   \n",
       "22                              NaN   \n",
       "23                              NaN   \n",
       "24                              NaN   \n",
       "\n",
       "                      data.media.oembed.thumbnail_url data.media.oembed.type  \\\n",
       "0                                                 NaN                    NaN   \n",
       "1                                                 NaN                    NaN   \n",
       "2                                                 NaN                    NaN   \n",
       "3                                                 NaN                    NaN   \n",
       "4                                                 NaN                    NaN   \n",
       "5                                                 NaN                    NaN   \n",
       "6   https://thumbs.gfycat.com/FastValidBlackfish-s...                  video   \n",
       "7                                                 NaN                    NaN   \n",
       "8                                                 NaN                    NaN   \n",
       "9                                                 NaN                    NaN   \n",
       "10                                                NaN                    NaN   \n",
       "11                                                NaN                    NaN   \n",
       "12                                                NaN                    NaN   \n",
       "13                                                NaN                    NaN   \n",
       "14                                                NaN                    NaN   \n",
       "15                                                NaN                    NaN   \n",
       "16                                                NaN                    NaN   \n",
       "17                                                NaN                    NaN   \n",
       "18                                                NaN                    NaN   \n",
       "19                                                NaN                    NaN   \n",
       "20                                                NaN                    NaN   \n",
       "21                                                NaN                    NaN   \n",
       "22                                                NaN                    NaN   \n",
       "23                                                NaN                    NaN   \n",
       "24                                                NaN                    NaN   \n",
       "\n",
       "    data.media.oembed.thumbnail_height  data.media.type  \\\n",
       "0                                  NaN              NaN   \n",
       "1                                  NaN              NaN   \n",
       "2                                  NaN              NaN   \n",
       "3                                  NaN              NaN   \n",
       "4                                  NaN              NaN   \n",
       "5                                  NaN              NaN   \n",
       "6                                250.0       gfycat.com   \n",
       "7                                  NaN              NaN   \n",
       "8                                  NaN              NaN   \n",
       "9                                  NaN              NaN   \n",
       "10                                 NaN              NaN   \n",
       "11                                 NaN              NaN   \n",
       "12                                 NaN              NaN   \n",
       "13                                 NaN              NaN   \n",
       "14                                 NaN              NaN   \n",
       "15                                 NaN              NaN   \n",
       "16                                 NaN              NaN   \n",
       "17                                 NaN              NaN   \n",
       "18                                 NaN              NaN   \n",
       "19                                 NaN              NaN   \n",
       "20                                 NaN              NaN   \n",
       "21                                 NaN              NaN   \n",
       "22                                 NaN              NaN   \n",
       "23                                 NaN              NaN   \n",
       "24                                 NaN              NaN   \n",
       "\n",
       "             data.link_flair_template_id metakind  metadata.after  \n",
       "0                                    NaN  Listing       t3_f4t7mb  \n",
       "1                                    NaN  Listing       t3_f4t7mb  \n",
       "2                                    NaN  Listing       t3_f4t7mb  \n",
       "3                                    NaN  Listing       t3_f4t7mb  \n",
       "4                                    NaN  Listing       t3_f4t7mb  \n",
       "5                                    NaN  Listing       t3_f4t7mb  \n",
       "6                                    NaN  Listing       t3_f4t7mb  \n",
       "7                                    NaN  Listing       t3_f4t7mb  \n",
       "8                                    NaN  Listing       t3_f4t7mb  \n",
       "9                                    NaN  Listing       t3_f4t7mb  \n",
       "10                                   NaN  Listing       t3_f4t7mb  \n",
       "11                                   NaN  Listing       t3_f4t7mb  \n",
       "12                                   NaN  Listing       t3_f4t7mb  \n",
       "13                                   NaN  Listing       t3_f4t7mb  \n",
       "14                                   NaN  Listing       t3_f4t7mb  \n",
       "15                                   NaN  Listing       t3_f4t7mb  \n",
       "16                                   NaN  Listing       t3_f4t7mb  \n",
       "17  6bd464aa-c51a-11e3-85ad-12313d163aa0  Listing       t3_f4t7mb  \n",
       "18                                   NaN  Listing       t3_f4t7mb  \n",
       "19                                   NaN  Listing       t3_f4t7mb  \n",
       "20                                   NaN  Listing       t3_f4t7mb  \n",
       "21                                   NaN  Listing       t3_f4t7mb  \n",
       "22                                   NaN  Listing       t3_f4t7mb  \n",
       "23                                   NaN  Listing       t3_f4t7mb  \n",
       "24                                   NaN  Listing       t3_f4t7mb  \n",
       "\n",
       "[25 rows x 172 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.reddit.com/r/popular/top.json\"\n",
    "reddit = requests.get(url, headers = {'User-agent': 'DS6001'})\n",
    "reddit_json = json.loads(reddit.text)\n",
    "reddit_df = pd.json_normalize(reddit_json, \n",
    "                              record_path = [\"data\", \"children\"], \n",
    "                              meta = ['kind', ['data', 'after']], \n",
    "                              meta_prefix = \"meta\")\n",
    "reddit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving JSON Files and Converting Data Frames to JSON\n",
    "It is possible to save a JSON file to your local disk space, or to convert a dataframe to JSON and, if you want to, save that JSON to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Existing JSON Files to Disk\n",
    "Once we've used the `json.loads()` function to register data as JSON in Python, we can save that JSON to our local disk space by using `open()` to create a new file, and `json.dump()` (note: not `json.dumps()`) to save the JSON to that file.\n",
    "\n",
    "For example, we registered the customer data as JSON in Python with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = requests.get(\"https://jsonplaceholder.typicode.com/users\")\n",
    "users_json = json.loads(users.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save this JSON file to my harddrive, I first use `os.chdir()` to set the working directory to the folder where I want to save my JSON file. (I omit that code here because it won't work on other people's computers.) Then I type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('users.json', 'w') as outfile:\n",
    "     json.dump(users_json, outfile, sort_keys = True, indent = 4,\n",
    "               ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use a file extension such as `.txt` instead of `.json` to save the JSON formatted data in a plain text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Tabular DataFrames to JSON\n",
    "Any dataframe can be turned into a JSON file by applying the `.to_json()` method to the dataframe that is saved in Python's memory. The trick is specifying a good organization for this file. Recall that JSON structures are much more flexible than dataframes. It is not possible to go from a dataframe to a nested, complicated JSON structure because the information about nesting simply does not exist for dataframes. That said, there are several choices for organizing the data:\n",
    "\n",
    "* `orient=\"records\"` works with JSON files organized as a list-of-sets, where each set is an entire record (or a row in flat data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'name': 'Leanne Graham',\n",
       " 'username': 'Bret',\n",
       " 'email': 'Sincere@april.biz',\n",
       " 'phone': '1-770-736-8031 x56442',\n",
       " 'website': 'hildegard.org',\n",
       " 'address.street': 'Kulas Light',\n",
       " 'address.suite': 'Apt. 556',\n",
       " 'address.city': 'Gwenborough',\n",
       " 'address.zipcode': '92998-3874',\n",
       " 'address.geo.lat': '-37.3159',\n",
       " 'address.geo.lng': '81.1496',\n",
       " 'company.name': 'Romaguera-Crona',\n",
       " 'company.catchPhrase': 'Multi-layered client-server neural-net',\n",
       " 'company.bs': 'harness real-time e-markets'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = users_df.loc[0:2,] # just keeping the first 3 records, for display purposes\n",
    "new_json = users_df.to_json(orient=\"records\")\n",
    "json.loads(new_json)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `orient=\"columns\"` works with JSON files organized as a list-of-dictionaries, where each dictionary is an entire column (the names are the row-names in the tabular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': {'0': 1, '1': 2, '2': 3},\n",
       " 'name': {'0': 'Leanne Graham', '1': 'Ervin Howell', '2': 'Clementine Bauch'},\n",
       " 'username': {'0': 'Bret', '1': 'Antonette', '2': 'Samantha'},\n",
       " 'email': {'0': 'Sincere@april.biz',\n",
       "  '1': 'Shanna@melissa.tv',\n",
       "  '2': 'Nathan@yesenia.net'},\n",
       " 'phone': {'0': '1-770-736-8031 x56442',\n",
       "  '1': '010-692-6593 x09125',\n",
       "  '2': '1-463-123-4447'},\n",
       " 'website': {'0': 'hildegard.org', '1': 'anastasia.net', '2': 'ramiro.info'},\n",
       " 'address.street': {'0': 'Kulas Light',\n",
       "  '1': 'Victor Plains',\n",
       "  '2': 'Douglas Extension'},\n",
       " 'address.suite': {'0': 'Apt. 556', '1': 'Suite 879', '2': 'Suite 847'},\n",
       " 'address.city': {'0': 'Gwenborough',\n",
       "  '1': 'Wisokyburgh',\n",
       "  '2': 'McKenziehaven'},\n",
       " 'address.zipcode': {'0': '92998-3874', '1': '90566-7771', '2': '59590-4157'},\n",
       " 'address.geo.lat': {'0': '-37.3159', '1': '-43.9509', '2': '-68.6102'},\n",
       " 'address.geo.lng': {'0': '81.1496', '1': '-34.4618', '2': '-47.0653'},\n",
       " 'company.name': {'0': 'Romaguera-Crona',\n",
       "  '1': 'Deckow-Crist',\n",
       "  '2': 'Romaguera-Jacobson'},\n",
       " 'company.catchPhrase': {'0': 'Multi-layered client-server neural-net',\n",
       "  '1': 'Proactive didactic contingency',\n",
       "  '2': 'Face to face bifurcated interface'},\n",
       " 'company.bs': {'0': 'harness real-time e-markets',\n",
       "  '1': 'synergize scalable supply-chains',\n",
       "  '2': 'e-enable strategic applications'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json = users_df.to_json(orient=\"columns\")\n",
    "json.loads(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `orient=\"split\"` works with JSON files organized as dictionary with three lists: `columns` lists the column names, `index` lists the row names, and `data` is a list-of-lists of data points, one list for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': ['id',\n",
       "  'name',\n",
       "  'username',\n",
       "  'email',\n",
       "  'phone',\n",
       "  'website',\n",
       "  'address.street',\n",
       "  'address.suite',\n",
       "  'address.city',\n",
       "  'address.zipcode',\n",
       "  'address.geo.lat',\n",
       "  'address.geo.lng',\n",
       "  'company.name',\n",
       "  'company.catchPhrase',\n",
       "  'company.bs'],\n",
       " 'index': [0, 1, 2],\n",
       " 'data': [[1,\n",
       "   'Leanne Graham',\n",
       "   'Bret',\n",
       "   'Sincere@april.biz',\n",
       "   '1-770-736-8031 x56442',\n",
       "   'hildegard.org',\n",
       "   'Kulas Light',\n",
       "   'Apt. 556',\n",
       "   'Gwenborough',\n",
       "   '92998-3874',\n",
       "   '-37.3159',\n",
       "   '81.1496',\n",
       "   'Romaguera-Crona',\n",
       "   'Multi-layered client-server neural-net',\n",
       "   'harness real-time e-markets'],\n",
       "  [2,\n",
       "   'Ervin Howell',\n",
       "   'Antonette',\n",
       "   'Shanna@melissa.tv',\n",
       "   '010-692-6593 x09125',\n",
       "   'anastasia.net',\n",
       "   'Victor Plains',\n",
       "   'Suite 879',\n",
       "   'Wisokyburgh',\n",
       "   '90566-7771',\n",
       "   '-43.9509',\n",
       "   '-34.4618',\n",
       "   'Deckow-Crist',\n",
       "   'Proactive didactic contingency',\n",
       "   'synergize scalable supply-chains'],\n",
       "  [3,\n",
       "   'Clementine Bauch',\n",
       "   'Samantha',\n",
       "   'Nathan@yesenia.net',\n",
       "   '1-463-123-4447',\n",
       "   'ramiro.info',\n",
       "   'Douglas Extension',\n",
       "   'Suite 847',\n",
       "   'McKenziehaven',\n",
       "   '59590-4157',\n",
       "   '-68.6102',\n",
       "   '-47.0653',\n",
       "   'Romaguera-Jacobson',\n",
       "   'Face to face bifurcated interface',\n",
       "   'e-enable strategic applications']]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json = users_df.to_json(orient=\"split\")\n",
    "json.loads(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `orient=\"index\"` is like `orient=\"records\"` but includes the name of each row in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'id': 1,\n",
       "  'name': 'Leanne Graham',\n",
       "  'username': 'Bret',\n",
       "  'email': 'Sincere@april.biz',\n",
       "  'phone': '1-770-736-8031 x56442',\n",
       "  'website': 'hildegard.org',\n",
       "  'address.street': 'Kulas Light',\n",
       "  'address.suite': 'Apt. 556',\n",
       "  'address.city': 'Gwenborough',\n",
       "  'address.zipcode': '92998-3874',\n",
       "  'address.geo.lat': '-37.3159',\n",
       "  'address.geo.lng': '81.1496',\n",
       "  'company.name': 'Romaguera-Crona',\n",
       "  'company.catchPhrase': 'Multi-layered client-server neural-net',\n",
       "  'company.bs': 'harness real-time e-markets'},\n",
       " '1': {'id': 2,\n",
       "  'name': 'Ervin Howell',\n",
       "  'username': 'Antonette',\n",
       "  'email': 'Shanna@melissa.tv',\n",
       "  'phone': '010-692-6593 x09125',\n",
       "  'website': 'anastasia.net',\n",
       "  'address.street': 'Victor Plains',\n",
       "  'address.suite': 'Suite 879',\n",
       "  'address.city': 'Wisokyburgh',\n",
       "  'address.zipcode': '90566-7771',\n",
       "  'address.geo.lat': '-43.9509',\n",
       "  'address.geo.lng': '-34.4618',\n",
       "  'company.name': 'Deckow-Crist',\n",
       "  'company.catchPhrase': 'Proactive didactic contingency',\n",
       "  'company.bs': 'synergize scalable supply-chains'},\n",
       " '2': {'id': 3,\n",
       "  'name': 'Clementine Bauch',\n",
       "  'username': 'Samantha',\n",
       "  'email': 'Nathan@yesenia.net',\n",
       "  'phone': '1-463-123-4447',\n",
       "  'website': 'ramiro.info',\n",
       "  'address.street': 'Douglas Extension',\n",
       "  'address.suite': 'Suite 847',\n",
       "  'address.city': 'McKenziehaven',\n",
       "  'address.zipcode': '59590-4157',\n",
       "  'address.geo.lat': '-68.6102',\n",
       "  'address.geo.lng': '-47.0653',\n",
       "  'company.name': 'Romaguera-Jacobson',\n",
       "  'company.catchPhrase': 'Face to face bifurcated interface',\n",
       "  'company.bs': 'e-enable strategic applications'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json = users_df.to_json(orient=\"index\")\n",
    "json.loads(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `orient=\"values\"` only contains the datapoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  'Leanne Graham',\n",
       "  'Bret',\n",
       "  'Sincere@april.biz',\n",
       "  '1-770-736-8031 x56442',\n",
       "  'hildegard.org',\n",
       "  'Kulas Light',\n",
       "  'Apt. 556',\n",
       "  'Gwenborough',\n",
       "  '92998-3874',\n",
       "  '-37.3159',\n",
       "  '81.1496',\n",
       "  'Romaguera-Crona',\n",
       "  'Multi-layered client-server neural-net',\n",
       "  'harness real-time e-markets'],\n",
       " [2,\n",
       "  'Ervin Howell',\n",
       "  'Antonette',\n",
       "  'Shanna@melissa.tv',\n",
       "  '010-692-6593 x09125',\n",
       "  'anastasia.net',\n",
       "  'Victor Plains',\n",
       "  'Suite 879',\n",
       "  'Wisokyburgh',\n",
       "  '90566-7771',\n",
       "  '-43.9509',\n",
       "  '-34.4618',\n",
       "  'Deckow-Crist',\n",
       "  'Proactive didactic contingency',\n",
       "  'synergize scalable supply-chains'],\n",
       " [3,\n",
       "  'Clementine Bauch',\n",
       "  'Samantha',\n",
       "  'Nathan@yesenia.net',\n",
       "  '1-463-123-4447',\n",
       "  'ramiro.info',\n",
       "  'Douglas Extension',\n",
       "  'Suite 847',\n",
       "  'McKenziehaven',\n",
       "  '59590-4157',\n",
       "  '-68.6102',\n",
       "  '-47.0653',\n",
       "  'Romaguera-Jacobson',\n",
       "  'Face to face bifurcated interface',\n",
       "  'e-enable strategic applications']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json = users_df.to_json(orient=\"values\")\n",
    "json.loads(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save these files to disk, specify a filename (using the `os.chdir()` function to change the working directory to the folder in which you save to save this file), or a filename and path, for the first parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.to_json(\"myjson.json\", orient=\"values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
