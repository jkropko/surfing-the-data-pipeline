
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>&lt;no title&gt; &#8212; Surfing the Data Pipeline with Python</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      <img src="_static/surf.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Surfing the Data Pipeline with Python</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="intro.html">
   Surfing the Data Pipeline with Python
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Get Started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ch1.html">
   Getting Yourself Unstuck
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Get Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ch2.html">
   Loading Data from Electronic Data Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch3.html">
   Loading, Converting, and Writing JSON Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch4.html">
   Acquiring Data from APIs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch5.html">
   Web Scraping Using
   <code class="docutils literal notranslate">
    <span class="pre">
     BeautifulSoup
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch6.html">
   Creating and Connecting to Databases
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Wrangle Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ch7.html">
   Database Queries
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch8.html">
   Data Wrangling with
   <code class="docutils literal notranslate">
    <span class="pre">
     pandas
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch9.html">
   Reshaping and Merging Data and Working with Strings, Dates, and Times
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Explore and Communicate Data
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="ch10.html">
   Exploratory Data Analysis
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch11.html">
   Static Data Visualizations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ch12.html">
   Interactive Data Visualizations and Dashboards
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="_sources/Untitled4.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/Untitled4.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav">
                <ul class="simple visible nav section-nav flex-column">
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/jkropko/DS-6001/master/localdata/anes_example_toplines.csv&quot;</span>
<span class="n">anes</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;x&#39;</span><span class="p">:[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">]})</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">anes</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index([&#39;x&#39;], dtype=&#39;object&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">help</span><span class="p">(</span><span class="n">anes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Help on DataFrame in module pandas.core.frame object:

class DataFrame(pandas.core.generic.NDFrame, pandas.core.arraylike.OpsMixin)
 |  DataFrame(data=None, index: &#39;Axes | None&#39; = None, columns: &#39;Axes | None&#39; = None, dtype: &#39;Dtype | None&#39; = None, copy: &#39;bool | None&#39; = None)
 |  
 |  Two-dimensional, size-mutable, potentially heterogeneous tabular data.
 |  
 |  Data structure also contains labeled axes (rows and columns).
 |  Arithmetic operations align on both row and column labels. Can be
 |  thought of as a dict-like container for Series objects. The primary
 |  pandas data structure.
 |  
 |  Parameters
 |  ----------
 |  data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame
 |      Dict can contain Series, arrays, constants, dataclass or list-like objects. If
 |      data is a dict, column order follows insertion-order.
 |  
 |      .. versionchanged:: 0.25.0
 |         If data is a list of dicts, column order follows insertion-order.
 |  
 |  index : Index or array-like
 |      Index to use for resulting frame. Will default to RangeIndex if
 |      no indexing information part of input data and no index provided.
 |  columns : Index or array-like
 |      Column labels to use for resulting frame when data does not have them,
 |      defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,
 |      will perform column selection instead.
 |  dtype : dtype, default None
 |      Data type to force. Only a single dtype is allowed. If None, infer.
 |  copy : bool or None, default None
 |      Copy data from inputs.
 |      For dict data, the default of None behaves like ``copy=True``.  For DataFrame
 |      or 2d ndarray input, the default of None behaves like ``copy=False``.
 |  
 |      .. versionchanged:: 1.3.0
 |  
 |  See Also
 |  --------
 |  DataFrame.from_records : Constructor from tuples, also record arrays.
 |  DataFrame.from_dict : From dicts of Series, arrays, or dicts.
 |  read_csv : Read a comma-separated values (csv) file into DataFrame.
 |  read_table : Read general delimited file into DataFrame.
 |  read_clipboard : Read text from clipboard into DataFrame.
 |  
 |  Examples
 |  --------
 |  Constructing DataFrame from a dictionary.
 |  
 |  &gt;&gt;&gt; d = {&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]}
 |  &gt;&gt;&gt; df = pd.DataFrame(data=d)
 |  &gt;&gt;&gt; df
 |     col1  col2
 |  0     1     3
 |  1     2     4
 |  
 |  Notice that the inferred dtype is int64.
 |  
 |  &gt;&gt;&gt; df.dtypes
 |  col1    int64
 |  col2    int64
 |  dtype: object
 |  
 |  To enforce a single dtype:
 |  
 |  &gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)
 |  &gt;&gt;&gt; df.dtypes
 |  col1    int8
 |  col2    int8
 |  dtype: object
 |  
 |  Constructing DataFrame from numpy ndarray:
 |  
 |  &gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),
 |  ...                    columns=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])
 |  &gt;&gt;&gt; df2
 |     a  b  c
 |  0  1  2  3
 |  1  4  5  6
 |  2  7  8  9
 |  
 |  Constructing DataFrame from a numpy ndarray that has labeled columns:
 |  
 |  &gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],
 |  ...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])
 |  &gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#39;c&#39;, &#39;a&#39;])
 |  ...
 |  &gt;&gt;&gt; df3
 |     c  a
 |  0  3  1
 |  1  6  4
 |  2  9  7
 |  
 |  Constructing DataFrame from dataclass:
 |  
 |  &gt;&gt;&gt; from dataclasses import make_dataclass
 |  &gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])
 |  &gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])
 |     x  y
 |  0  0  0
 |  1  0  3
 |  2  2  3
 |  
 |  Method resolution order:
 |      DataFrame
 |      pandas.core.generic.NDFrame
 |      pandas.core.base.PandasObject
 |      pandas.core.accessor.DirNamesMixin
 |      pandas.core.indexing.IndexingMixin
 |      pandas.core.arraylike.OpsMixin
 |      builtins.object
 |  
 |  Methods defined here:
 |  
 |  __divmod__(self, other) -&gt; &#39;tuple[DataFrame, DataFrame]&#39;
 |  
 |  __getitem__(self, key)
 |  
 |  __init__(self, data=None, index: &#39;Axes | None&#39; = None, columns: &#39;Axes | None&#39; = None, dtype: &#39;Dtype | None&#39; = None, copy: &#39;bool | None&#39; = None)
 |      Initialize self.  See help(type(self)) for accurate signature.
 |  
 |  __len__(self) -&gt; &#39;int&#39;
 |      Returns length of info axis, but here we use the index.
 |  
 |  __matmul__(self, other: &#39;AnyArrayLike | FrameOrSeriesUnion&#39;) -&gt; &#39;FrameOrSeriesUnion&#39;
 |      Matrix multiplication using binary `@` operator in Python&gt;=3.5.
 |  
 |  __rdivmod__(self, other) -&gt; &#39;tuple[DataFrame, DataFrame]&#39;
 |  
 |  __repr__(self) -&gt; &#39;str&#39;
 |      Return a string representation for a particular DataFrame.
 |  
 |  __rmatmul__(self, other)
 |      Matrix multiplication using binary `@` operator in Python&gt;=3.5.
 |  
 |  __setitem__(self, key, value)
 |  
 |  add(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Addition of dataframe and other, element-wise (binary operator `add`).
 |      
 |      Equivalent to ``dataframe + other``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `radd`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  agg = aggregate(self, func=None, axis: &#39;Axis&#39; = 0, *args, **kwargs)
 |  
 |  aggregate(self, func=None, axis: &#39;Axis&#39; = 0, *args, **kwargs)
 |      Aggregate using one or more operations over the specified axis.
 |      
 |      Parameters
 |      ----------
 |      func : function, str, list or dict
 |          Function to use for aggregating the data. If a function, must either
 |          work when passed a DataFrame or when passed to DataFrame.apply.
 |      
 |          Accepted combinations are:
 |      
 |          - function
 |          - string function name
 |          - list of functions and/or function names, e.g. ``[np.sum, &#39;mean&#39;]``
 |          - dict of axis labels -&gt; functions, function names or list of such.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |              If 0 or &#39;index&#39;: apply function to each column.
 |              If 1 or &#39;columns&#39;: apply function to each row.
 |      *args
 |          Positional arguments to pass to `func`.
 |      **kwargs
 |          Keyword arguments to pass to `func`.
 |      
 |      Returns
 |      -------
 |      scalar, Series or DataFrame
 |      
 |          The return can be:
 |      
 |          * scalar : when Series.agg is called with single function
 |          * Series : when DataFrame.agg is called with a single function
 |          * DataFrame : when DataFrame.agg is called with several functions
 |      
 |          Return scalar, Series or DataFrame.
 |      
 |      The aggregation operations are always performed over an axis, either the
 |      index (default) or the column axis. This behavior is different from
 |      `numpy` aggregation functions (`mean`, `median`, `prod`, `sum`, `std`,
 |      `var`), where the default is to compute the aggregation of the flattened
 |      array, e.g., ``numpy.mean(arr_2d)`` as opposed to
 |      ``numpy.mean(arr_2d, axis=0)``.
 |      
 |      `agg` is an alias for `aggregate`. Use the alias.
 |      
 |      See Also
 |      --------
 |      DataFrame.apply : Perform any type of operations.
 |      DataFrame.transform : Perform transformation type operations.
 |      core.groupby.GroupBy : Perform operations over groups.
 |      core.resample.Resampler : Perform operations over resampled bins.
 |      core.window.Rolling : Perform operations over rolling window.
 |      core.window.Expanding : Perform operations over expanding window.
 |      core.window.ExponentialMovingWindow : Perform operation over exponential weighted
 |          window.
 |      
 |      Notes
 |      -----
 |      `agg` is an alias for `aggregate`. Use the alias.
 |      
 |      Functions that mutate the passed object can produce unexpected
 |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`
 |      for more details.
 |      
 |      A passed user-defined-function will be passed a Series for evaluation.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2, 3],
 |      ...                    [4, 5, 6],
 |      ...                    [7, 8, 9],
 |      ...                    [np.nan, np.nan, np.nan]],
 |      ...                   columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      
 |      Aggregate these functions over the rows.
 |      
 |      &gt;&gt;&gt; df.agg([&#39;sum&#39;, &#39;min&#39;])
 |              A     B     C
 |      sum  12.0  15.0  18.0
 |      min   1.0   2.0   3.0
 |      
 |      Different aggregations per column.
 |      
 |      &gt;&gt;&gt; df.agg({&#39;A&#39; : [&#39;sum&#39;, &#39;min&#39;], &#39;B&#39; : [&#39;min&#39;, &#39;max&#39;]})
 |              A    B
 |      sum  12.0  NaN
 |      min   1.0  2.0
 |      max   NaN  8.0
 |      
 |      Aggregate different functions over the columns and rename the index of the resulting
 |      DataFrame.
 |      
 |      &gt;&gt;&gt; df.agg(x=(&#39;A&#39;, max), y=(&#39;B&#39;, &#39;min&#39;), z=(&#39;C&#39;, np.mean))
 |           A    B    C
 |      x  7.0  NaN  NaN
 |      y  NaN  2.0  NaN
 |      z  NaN  NaN  6.0
 |      
 |      Aggregate over the columns.
 |      
 |      &gt;&gt;&gt; df.agg(&quot;mean&quot;, axis=&quot;columns&quot;)
 |      0    2.0
 |      1    5.0
 |      2    8.0
 |      3    NaN
 |      dtype: float64
 |  
 |  align(self, other, join: &#39;str&#39; = &#39;outer&#39;, axis: &#39;Axis | None&#39; = None, level: &#39;Level | None&#39; = None, copy: &#39;bool&#39; = True, fill_value=None, method: &#39;str | None&#39; = None, limit=None, fill_axis: &#39;Axis&#39; = 0, broadcast_axis: &#39;Axis | None&#39; = None) -&gt; &#39;DataFrame&#39;
 |      Align two objects on their axes with the specified join method.
 |      
 |      Join method is specified for each axis Index.
 |      
 |      Parameters
 |      ----------
 |      other : DataFrame or Series
 |      join : {&#39;outer&#39;, &#39;inner&#39;, &#39;left&#39;, &#39;right&#39;}, default &#39;outer&#39;
 |      axis : allowed axis of the other object, default None
 |          Align on index (0), columns (1), or both (None).
 |      level : int or level name, default None
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      copy : bool, default True
 |          Always returns new objects. If copy=False and no reindexing is
 |          required then original objects are returned.
 |      fill_value : scalar, default np.NaN
 |          Value to use for missing values. Defaults to NaN, but can be any
 |          &quot;compatible&quot; value.
 |      method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}, default None
 |          Method to use for filling holes in reindexed Series:
 |      
 |          - pad / ffill: propagate last valid observation forward to next valid.
 |          - backfill / bfill: use NEXT valid observation to fill gap.
 |      
 |      limit : int, default None
 |          If method is specified, this is the maximum number of consecutive
 |          NaN values to forward/backward fill. In other words, if there is
 |          a gap with more than this number of consecutive NaNs, it will only
 |          be partially filled. If method is not specified, this is the
 |          maximum number of entries along the entire axis where NaNs will be
 |          filled. Must be greater than 0 if not None.
 |      fill_axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Filling axis, method and limit.
 |      broadcast_axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default None
 |          Broadcast values along this axis, if aligning two objects of
 |          different dimensions.
 |      
 |      Returns
 |      -------
 |      (left, right) : (DataFrame, type of other)
 |          Aligned objects.
 |  
 |  all(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)
 |      Return whether all elements are True, potentially over an axis.
 |      
 |      Returns True unless there at least one element within a series or
 |      along a Dataframe axis that is False or equivalent (e.g. zero or
 |      empty).
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}, default 0
 |          Indicate which axis or axes should be reduced.
 |      
 |          * 0 / &#39;index&#39; : reduce the index, return a Series whose index is the
 |            original column labels.
 |          * 1 / &#39;columns&#39; : reduce the columns, return a Series whose index is the
 |            original index.
 |          * None : reduce all axes, return a scalar.
 |      
 |      bool_only : bool, default None
 |          Include only boolean columns. If None, will attempt to use everything,
 |          then use only boolean data. Not implemented for Series.
 |      skipna : bool, default True
 |          Exclude NA/null values. If the entire row/column is NA and skipna is
 |          True, then the result will be True, as for an empty row/column.
 |          If skipna is False, then NA are treated as True, because these are not
 |          equal to zero.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      **kwargs : any, default None
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          If level is specified, then, DataFrame is returned; otherwise, Series
 |          is returned.
 |      
 |      See Also
 |      --------
 |      Series.all : Return True if all elements are True.
 |      DataFrame.any : Return True if one (or more) elements are True.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; pd.Series([True, True]).all()
 |      True
 |      &gt;&gt;&gt; pd.Series([True, False]).all()
 |      False
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).all()
 |      True
 |      &gt;&gt;&gt; pd.Series([np.nan]).all()
 |      True
 |      &gt;&gt;&gt; pd.Series([np.nan]).all(skipna=False)
 |      True
 |      
 |      **DataFrames**
 |      
 |      Create a dataframe from a dictionary.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;col1&#39;: [True, True], &#39;col2&#39;: [True, False]})
 |      &gt;&gt;&gt; df
 |         col1   col2
 |      0  True   True
 |      1  True  False
 |      
 |      Default behaviour checks if column-wise values all return True.
 |      
 |      &gt;&gt;&gt; df.all()
 |      col1     True
 |      col2    False
 |      dtype: bool
 |      
 |      Specify ``axis=&#39;columns&#39;`` to check if row-wise values all return True.
 |      
 |      &gt;&gt;&gt; df.all(axis=&#39;columns&#39;)
 |      0     True
 |      1    False
 |      dtype: bool
 |      
 |      Or ``axis=None`` for whether every value is True.
 |      
 |      &gt;&gt;&gt; df.all(axis=None)
 |      False
 |  
 |  any(self, axis=0, bool_only=None, skipna=True, level=None, **kwargs)
 |      Return whether any element is True, potentially over an axis.
 |      
 |      Returns False unless there is at least one element within a series or
 |      along a Dataframe axis that is True or equivalent (e.g. non-zero or
 |      non-empty).
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}, default 0
 |          Indicate which axis or axes should be reduced.
 |      
 |          * 0 / &#39;index&#39; : reduce the index, return a Series whose index is the
 |            original column labels.
 |          * 1 / &#39;columns&#39; : reduce the columns, return a Series whose index is the
 |            original index.
 |          * None : reduce all axes, return a scalar.
 |      
 |      bool_only : bool, default None
 |          Include only boolean columns. If None, will attempt to use everything,
 |          then use only boolean data. Not implemented for Series.
 |      skipna : bool, default True
 |          Exclude NA/null values. If the entire row/column is NA and skipna is
 |          True, then the result will be False, as for an empty row/column.
 |          If skipna is False, then NA are treated as True, because these are not
 |          equal to zero.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      **kwargs : any, default None
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          If level is specified, then, DataFrame is returned; otherwise, Series
 |          is returned.
 |      
 |      See Also
 |      --------
 |      numpy.any : Numpy version of this method.
 |      Series.any : Return whether any element is True.
 |      Series.all : Return whether all elements are True.
 |      DataFrame.any : Return whether any element is True over requested axis.
 |      DataFrame.all : Return whether all elements are True over requested axis.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      For Series input, the output is a scalar indicating whether any element
 |      is True.
 |      
 |      &gt;&gt;&gt; pd.Series([False, False]).any()
 |      False
 |      &gt;&gt;&gt; pd.Series([True, False]).any()
 |      True
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).any()
 |      False
 |      &gt;&gt;&gt; pd.Series([np.nan]).any()
 |      False
 |      &gt;&gt;&gt; pd.Series([np.nan]).any(skipna=False)
 |      True
 |      
 |      **DataFrame**
 |      
 |      Whether each column contains at least one True element (the default).
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2], &quot;B&quot;: [0, 2], &quot;C&quot;: [0, 0]})
 |      &gt;&gt;&gt; df
 |         A  B  C
 |      0  1  0  0
 |      1  2  2  0
 |      
 |      &gt;&gt;&gt; df.any()
 |      A     True
 |      B     True
 |      C    False
 |      dtype: bool
 |      
 |      Aggregating over the columns.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [True, False], &quot;B&quot;: [1, 2]})
 |      &gt;&gt;&gt; df
 |             A  B
 |      0   True  1
 |      1  False  2
 |      
 |      &gt;&gt;&gt; df.any(axis=&#39;columns&#39;)
 |      0    True
 |      1    True
 |      dtype: bool
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [True, False], &quot;B&quot;: [1, 0]})
 |      &gt;&gt;&gt; df
 |             A  B
 |      0   True  1
 |      1  False  0
 |      
 |      &gt;&gt;&gt; df.any(axis=&#39;columns&#39;)
 |      0    True
 |      1    False
 |      dtype: bool
 |      
 |      Aggregating over the entire DataFrame with ``axis=None``.
 |      
 |      &gt;&gt;&gt; df.any(axis=None)
 |      True
 |      
 |      `any` for an empty DataFrame is an empty Series.
 |      
 |      &gt;&gt;&gt; pd.DataFrame([]).any()
 |      Series([], dtype: bool)
 |  
 |  append(self, other, ignore_index: &#39;bool&#39; = False, verify_integrity: &#39;bool&#39; = False, sort: &#39;bool&#39; = False) -&gt; &#39;DataFrame&#39;
 |      Append rows of `other` to the end of caller, returning a new object.
 |      
 |      Columns in `other` that are not in the caller are added as new columns.
 |      
 |      Parameters
 |      ----------
 |      other : DataFrame or Series/dict-like object, or list of these
 |          The data to append.
 |      ignore_index : bool, default False
 |          If True, the resulting axis will be labeled 0, 1, …, n - 1.
 |      verify_integrity : bool, default False
 |          If True, raise ValueError on creating index with duplicates.
 |      sort : bool, default False
 |          Sort columns if the columns of `self` and `other` are not aligned.
 |      
 |          .. versionchanged:: 1.0.0
 |      
 |              Changed to not sort by default.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          A new DataFrame consisting of the rows of caller and the rows of `other`.
 |      
 |      See Also
 |      --------
 |      concat : General function to concatenate DataFrame or Series objects.
 |      
 |      Notes
 |      -----
 |      If a list of dict/series is passed and the keys are all contained in
 |      the DataFrame&#39;s index, the order of the columns in the resulting
 |      DataFrame will be unchanged.
 |      
 |      Iteratively appending rows to a DataFrame can be more computationally
 |      intensive than a single concatenate. A better solution is to append
 |      those rows to a list and then concatenate the list with the original
 |      DataFrame all at once.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [3, 4]], columns=list(&#39;AB&#39;), index=[&#39;x&#39;, &#39;y&#39;])
 |      &gt;&gt;&gt; df
 |         A  B
 |      x  1  2
 |      y  3  4
 |      &gt;&gt;&gt; df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list(&#39;AB&#39;), index=[&#39;x&#39;, &#39;y&#39;])
 |      &gt;&gt;&gt; df.append(df2)
 |         A  B
 |      x  1  2
 |      y  3  4
 |      x  5  6
 |      y  7  8
 |      
 |      With `ignore_index` set to True:
 |      
 |      &gt;&gt;&gt; df.append(df2, ignore_index=True)
 |         A  B
 |      0  1  2
 |      1  3  4
 |      2  5  6
 |      3  7  8
 |      
 |      The following, while not recommended methods for generating DataFrames,
 |      show two ways to generate a DataFrame from multiple data sources.
 |      
 |      Less efficient:
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(columns=[&#39;A&#39;])
 |      &gt;&gt;&gt; for i in range(5):
 |      ...     df = df.append({&#39;A&#39;: i}, ignore_index=True)
 |      &gt;&gt;&gt; df
 |         A
 |      0  0
 |      1  1
 |      2  2
 |      3  3
 |      4  4
 |      
 |      More efficient:
 |      
 |      &gt;&gt;&gt; pd.concat([pd.DataFrame([i], columns=[&#39;A&#39;]) for i in range(5)],
 |      ...           ignore_index=True)
 |         A
 |      0  0
 |      1  1
 |      2  2
 |      3  3
 |      4  4
 |  
 |  apply(self, func: &#39;AggFuncType&#39;, axis: &#39;Axis&#39; = 0, raw: &#39;bool&#39; = False, result_type=None, args=(), **kwargs)
 |      Apply a function along an axis of the DataFrame.
 |      
 |      Objects passed to the function are Series objects whose index is
 |      either the DataFrame&#39;s index (``axis=0``) or the DataFrame&#39;s columns
 |      (``axis=1``). By default (``result_type=None``), the final return type
 |      is inferred from the return type of the applied function. Otherwise,
 |      it depends on the `result_type` argument.
 |      
 |      Parameters
 |      ----------
 |      func : function
 |          Function to apply to each column or row.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Axis along which the function is applied:
 |      
 |          * 0 or &#39;index&#39;: apply function to each column.
 |          * 1 or &#39;columns&#39;: apply function to each row.
 |      
 |      raw : bool, default False
 |          Determines if row or column is passed as a Series or ndarray object:
 |      
 |          * ``False`` : passes each row or column as a Series to the
 |            function.
 |          * ``True`` : the passed function will receive ndarray objects
 |            instead.
 |            If you are just applying a NumPy reduction function this will
 |            achieve much better performance.
 |      
 |      result_type : {&#39;expand&#39;, &#39;reduce&#39;, &#39;broadcast&#39;, None}, default None
 |          These only act when ``axis=1`` (columns):
 |      
 |          * &#39;expand&#39; : list-like results will be turned into columns.
 |          * &#39;reduce&#39; : returns a Series if possible rather than expanding
 |            list-like results. This is the opposite of &#39;expand&#39;.
 |          * &#39;broadcast&#39; : results will be broadcast to the original shape
 |            of the DataFrame, the original index and columns will be
 |            retained.
 |      
 |          The default behaviour (None) depends on the return value of the
 |          applied function: list-like results will be returned as a Series
 |          of those. However if the apply function returns a Series these
 |          are expanded to columns.
 |      args : tuple
 |          Positional arguments to pass to `func` in addition to the
 |          array/series.
 |      **kwargs
 |          Additional keyword arguments to pass as keywords arguments to
 |          `func`.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Result of applying ``func`` along the given axis of the
 |          DataFrame.
 |      
 |      See Also
 |      --------
 |      DataFrame.applymap: For elementwise operations.
 |      DataFrame.aggregate: Only perform aggregating type operations.
 |      DataFrame.transform: Only perform transforming type operations.
 |      
 |      Notes
 |      -----
 |      Functions that mutate the passed object can produce unexpected
 |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`
 |      for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([[4, 9]] * 3, columns=[&#39;A&#39;, &#39;B&#39;])
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  4  9
 |      1  4  9
 |      2  4  9
 |      
 |      Using a numpy universal function (in this case the same as
 |      ``np.sqrt(df)``):
 |      
 |      &gt;&gt;&gt; df.apply(np.sqrt)
 |           A    B
 |      0  2.0  3.0
 |      1  2.0  3.0
 |      2  2.0  3.0
 |      
 |      Using a reducing function on either axis
 |      
 |      &gt;&gt;&gt; df.apply(np.sum, axis=0)
 |      A    12
 |      B    27
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df.apply(np.sum, axis=1)
 |      0    13
 |      1    13
 |      2    13
 |      dtype: int64
 |      
 |      Returning a list-like will result in a Series
 |      
 |      &gt;&gt;&gt; df.apply(lambda x: [1, 2], axis=1)
 |      0    [1, 2]
 |      1    [1, 2]
 |      2    [1, 2]
 |      dtype: object
 |      
 |      Passing ``result_type=&#39;expand&#39;`` will expand list-like results
 |      to columns of a Dataframe
 |      
 |      &gt;&gt;&gt; df.apply(lambda x: [1, 2], axis=1, result_type=&#39;expand&#39;)
 |         0  1
 |      0  1  2
 |      1  1  2
 |      2  1  2
 |      
 |      Returning a Series inside the function is similar to passing
 |      ``result_type=&#39;expand&#39;``. The resulting column names
 |      will be the Series index.
 |      
 |      &gt;&gt;&gt; df.apply(lambda x: pd.Series([1, 2], index=[&#39;foo&#39;, &#39;bar&#39;]), axis=1)
 |         foo  bar
 |      0    1    2
 |      1    1    2
 |      2    1    2
 |      
 |      Passing ``result_type=&#39;broadcast&#39;`` will ensure the same shape
 |      result, whether list-like or scalar is returned by the function,
 |      and broadcast it along the axis. The resulting column names will
 |      be the originals.
 |      
 |      &gt;&gt;&gt; df.apply(lambda x: [1, 2], axis=1, result_type=&#39;broadcast&#39;)
 |         A  B
 |      0  1  2
 |      1  1  2
 |      2  1  2
 |  
 |  applymap(self, func: &#39;PythonFuncType&#39;, na_action: &#39;str | None&#39; = None, **kwargs) -&gt; &#39;DataFrame&#39;
 |      Apply a function to a Dataframe elementwise.
 |      
 |      This method applies a function that accepts and returns a scalar
 |      to every element of a DataFrame.
 |      
 |      Parameters
 |      ----------
 |      func : callable
 |          Python function, returns a single value from a single value.
 |      na_action : {None, &#39;ignore&#39;}, default None
 |          If ‘ignore’, propagate NaN values, without passing them to func.
 |      
 |          .. versionadded:: 1.2
 |      
 |      **kwargs
 |          Additional keyword arguments to pass as keywords arguments to
 |          `func`.
 |      
 |          .. versionadded:: 1.3.0
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Transformed DataFrame.
 |      
 |      See Also
 |      --------
 |      DataFrame.apply : Apply a function along input axis of DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2.12], [3.356, 4.567]])
 |      &gt;&gt;&gt; df
 |             0      1
 |      0  1.000  2.120
 |      1  3.356  4.567
 |      
 |      &gt;&gt;&gt; df.applymap(lambda x: len(str(x)))
 |         0  1
 |      0  3  4
 |      1  5  5
 |      
 |      Like Series.map, NA values can be ignored:
 |      
 |      &gt;&gt;&gt; df_copy = df.copy()
 |      &gt;&gt;&gt; df_copy.iloc[0, 0] = pd.NA
 |      &gt;&gt;&gt; df_copy.applymap(lambda x: len(str(x)), na_action=&#39;ignore&#39;)
 |            0  1
 |      0  &lt;NA&gt;  4
 |      1     5  5
 |      
 |      Note that a vectorized version of `func` often exists, which will
 |      be much faster. You could square each number elementwise.
 |      
 |      &gt;&gt;&gt; df.applymap(lambda x: x**2)
 |                 0          1
 |      0   1.000000   4.494400
 |      1  11.262736  20.857489
 |      
 |      But it&#39;s better to avoid applymap in that case.
 |      
 |      &gt;&gt;&gt; df ** 2
 |                 0          1
 |      0   1.000000   4.494400
 |      1  11.262736  20.857489
 |  
 |  asfreq(self, freq: &#39;Frequency&#39;, method=None, how: &#39;str | None&#39; = None, normalize: &#39;bool&#39; = False, fill_value=None) -&gt; &#39;DataFrame&#39;
 |      Convert time series to specified frequency.
 |      
 |      Returns the original data conformed to a new index with the specified
 |      frequency.
 |      
 |      If the index of this DataFrame is a :class:`~pandas.PeriodIndex`, the new index
 |      is the result of transforming the original index with
 |      :meth:`PeriodIndex.asfreq &lt;pandas.PeriodIndex.asfreq&gt;` (so the original index
 |      will map one-to-one to the new index).
 |      
 |      Otherwise, the new index will be equivalent to ``pd.date_range(start, end,
 |      freq=freq)`` where ``start`` and ``end`` are, respectively, the first and
 |      last entries in the original index (see :func:`pandas.date_range`). The
 |      values corresponding to any timesteps in the new index which were not present
 |      in the original index will be null (``NaN``), unless a method for filling
 |      such unknowns is provided (see the ``method`` parameter below).
 |      
 |      The :meth:`resample` method is more appropriate if an operation on each group of
 |      timesteps (such as an aggregate) is necessary to represent the data at the new
 |      frequency.
 |      
 |      Parameters
 |      ----------
 |      freq : DateOffset or str
 |          Frequency DateOffset or string.
 |      method : {&#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;}, default None
 |          Method to use for filling holes in reindexed Series (note this
 |          does not fill NaNs that already were present):
 |      
 |          * &#39;pad&#39; / &#39;ffill&#39;: propagate last valid observation forward to next
 |            valid
 |          * &#39;backfill&#39; / &#39;bfill&#39;: use NEXT valid observation to fill.
 |      how : {&#39;start&#39;, &#39;end&#39;}, default end
 |          For PeriodIndex only (see PeriodIndex.asfreq).
 |      normalize : bool, default False
 |          Whether to reset output index to midnight.
 |      fill_value : scalar, optional
 |          Value to use for missing values, applied during upsampling (note
 |          this does not fill NaNs that already were present).
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          DataFrame object reindexed to the specified frequency.
 |      
 |      See Also
 |      --------
 |      reindex : Conform DataFrame to new index with optional filling logic.
 |      
 |      Notes
 |      -----
 |      To learn more about the frequency strings, please see `this link
 |      &lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases&gt;`__.
 |      
 |      Examples
 |      --------
 |      Start by creating a series with 4 one minute timestamps.
 |      
 |      &gt;&gt;&gt; index = pd.date_range(&#39;1/1/2000&#39;, periods=4, freq=&#39;T&#39;)
 |      &gt;&gt;&gt; series = pd.Series([0.0, None, 2.0, 3.0], index=index)
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;s&#39;: series})
 |      &gt;&gt;&gt; df
 |                             s
 |      2000-01-01 00:00:00    0.0
 |      2000-01-01 00:01:00    NaN
 |      2000-01-01 00:02:00    2.0
 |      2000-01-01 00:03:00    3.0
 |      
 |      Upsample the series into 30 second bins.
 |      
 |      &gt;&gt;&gt; df.asfreq(freq=&#39;30S&#39;)
 |                             s
 |      2000-01-01 00:00:00    0.0
 |      2000-01-01 00:00:30    NaN
 |      2000-01-01 00:01:00    NaN
 |      2000-01-01 00:01:30    NaN
 |      2000-01-01 00:02:00    2.0
 |      2000-01-01 00:02:30    NaN
 |      2000-01-01 00:03:00    3.0
 |      
 |      Upsample again, providing a ``fill value``.
 |      
 |      &gt;&gt;&gt; df.asfreq(freq=&#39;30S&#39;, fill_value=9.0)
 |                             s
 |      2000-01-01 00:00:00    0.0
 |      2000-01-01 00:00:30    9.0
 |      2000-01-01 00:01:00    NaN
 |      2000-01-01 00:01:30    9.0
 |      2000-01-01 00:02:00    2.0
 |      2000-01-01 00:02:30    9.0
 |      2000-01-01 00:03:00    3.0
 |      
 |      Upsample again, providing a ``method``.
 |      
 |      &gt;&gt;&gt; df.asfreq(freq=&#39;30S&#39;, method=&#39;bfill&#39;)
 |                             s
 |      2000-01-01 00:00:00    0.0
 |      2000-01-01 00:00:30    NaN
 |      2000-01-01 00:01:00    NaN
 |      2000-01-01 00:01:30    2.0
 |      2000-01-01 00:02:00    2.0
 |      2000-01-01 00:02:30    3.0
 |      2000-01-01 00:03:00    3.0
 |  
 |  assign(self, **kwargs) -&gt; &#39;DataFrame&#39;
 |      Assign new columns to a DataFrame.
 |      
 |      Returns a new object with all original columns in addition to new ones.
 |      Existing columns that are re-assigned will be overwritten.
 |      
 |      Parameters
 |      ----------
 |      **kwargs : dict of {str: callable or Series}
 |          The column names are keywords. If the values are
 |          callable, they are computed on the DataFrame and
 |          assigned to the new columns. The callable must not
 |          change input DataFrame (though pandas doesn&#39;t check it).
 |          If the values are not callable, (e.g. a Series, scalar, or array),
 |          they are simply assigned.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          A new DataFrame with the new columns in addition to
 |          all the existing columns.
 |      
 |      Notes
 |      -----
 |      Assigning multiple columns within the same ``assign`` is possible.
 |      Later items in &#39;\*\*kwargs&#39; may refer to newly created or modified
 |      columns in &#39;df&#39;; items are computed and assigned into &#39;df&#39; in order.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;temp_c&#39;: [17.0, 25.0]},
 |      ...                   index=[&#39;Portland&#39;, &#39;Berkeley&#39;])
 |      &gt;&gt;&gt; df
 |                temp_c
 |      Portland    17.0
 |      Berkeley    25.0
 |      
 |      Where the value is a callable, evaluated on `df`:
 |      
 |      &gt;&gt;&gt; df.assign(temp_f=lambda x: x.temp_c * 9 / 5 + 32)
 |                temp_c  temp_f
 |      Portland    17.0    62.6
 |      Berkeley    25.0    77.0
 |      
 |      Alternatively, the same behavior can be achieved by directly
 |      referencing an existing Series or sequence:
 |      
 |      &gt;&gt;&gt; df.assign(temp_f=df[&#39;temp_c&#39;] * 9 / 5 + 32)
 |                temp_c  temp_f
 |      Portland    17.0    62.6
 |      Berkeley    25.0    77.0
 |      
 |      You can create multiple columns within the same assign where one
 |      of the columns depends on another one defined within the same assign:
 |      
 |      &gt;&gt;&gt; df.assign(temp_f=lambda x: x[&#39;temp_c&#39;] * 9 / 5 + 32,
 |      ...           temp_k=lambda x: (x[&#39;temp_f&#39;] +  459.67) * 5 / 9)
 |                temp_c  temp_f  temp_k
 |      Portland    17.0    62.6  290.15
 |      Berkeley    25.0    77.0  298.15
 |  
 |  bfill(self: &#39;DataFrame&#39;, axis: &#39;None | Axis&#39; = None, inplace: &#39;bool&#39; = False, limit: &#39;None | int&#39; = None, downcast=None) -&gt; &#39;DataFrame | None&#39;
 |      Synonym for :meth:`DataFrame.fillna` with ``method=&#39;bfill&#39;``.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame or None
 |          Object with missing values filled or None if ``inplace=True``.
 |  
 |  boxplot = boxplot_frame(self, column=None, by=None, ax=None, fontsize=None, rot=0, grid=True, figsize=None, layout=None, return_type=None, backend=None, **kwargs)
 |      Make a box plot from DataFrame columns.
 |      
 |      Make a box-and-whisker plot from DataFrame columns, optionally grouped
 |      by some other columns. A box plot is a method for graphically depicting
 |      groups of numerical data through their quartiles.
 |      The box extends from the Q1 to Q3 quartile values of the data,
 |      with a line at the median (Q2). The whiskers extend from the edges
 |      of box to show the range of the data. By default, they extend no more than
 |      `1.5 * IQR (IQR = Q3 - Q1)` from the edges of the box, ending at the farthest
 |      data point within that interval. Outliers are plotted as separate dots.
 |      
 |      For further details see
 |      Wikipedia&#39;s entry for `boxplot &lt;https://en.wikipedia.org/wiki/Box_plot&gt;`_.
 |      
 |      Parameters
 |      ----------
 |      column : str or list of str, optional
 |          Column name or list of names, or vector.
 |          Can be any valid input to :meth:`pandas.DataFrame.groupby`.
 |      by : str or array-like, optional
 |          Column in the DataFrame to :meth:`pandas.DataFrame.groupby`.
 |          One box-plot will be done per value of columns in `by`.
 |      ax : object of class matplotlib.axes.Axes, optional
 |          The matplotlib axes to be used by boxplot.
 |      fontsize : float or str
 |          Tick label font size in points or as a string (e.g., `large`).
 |      rot : int or float, default 0
 |          The rotation angle of labels (in degrees)
 |          with respect to the screen coordinate system.
 |      grid : bool, default True
 |          Setting this to True will show the grid.
 |      figsize : A tuple (width, height) in inches
 |          The size of the figure to create in matplotlib.
 |      layout : tuple (rows, columns), optional
 |          For example, (3, 5) will display the subplots
 |          using 3 columns and 5 rows, starting from the top-left.
 |      return_type : {&#39;axes&#39;, &#39;dict&#39;, &#39;both&#39;} or None, default &#39;axes&#39;
 |          The kind of object to return. The default is ``axes``.
 |      
 |          * &#39;axes&#39; returns the matplotlib axes the boxplot is drawn on.
 |          * &#39;dict&#39; returns a dictionary whose values are the matplotlib
 |            Lines of the boxplot.
 |          * &#39;both&#39; returns a namedtuple with the axes and dict.
 |          * when grouping with ``by``, a Series mapping columns to
 |            ``return_type`` is returned.
 |      
 |            If ``return_type`` is `None`, a NumPy array
 |            of axes with the same shape as ``layout`` is returned.
 |      backend : str, default None
 |          Backend to use instead of the backend specified in the option
 |          ``plotting.backend``. For instance, &#39;matplotlib&#39;. Alternatively, to
 |          specify the ``plotting.backend`` for the whole session, set
 |          ``pd.options.plotting.backend``.
 |      
 |          .. versionadded:: 1.0.0
 |      
 |      **kwargs
 |          All other plotting keyword arguments to be passed to
 |          :func:`matplotlib.pyplot.boxplot`.
 |      
 |      Returns
 |      -------
 |      result
 |          See Notes.
 |      
 |      See Also
 |      --------
 |      Series.plot.hist: Make a histogram.
 |      matplotlib.pyplot.boxplot : Matplotlib equivalent plot.
 |      
 |      Notes
 |      -----
 |      The return type depends on the `return_type` parameter:
 |      
 |      * &#39;axes&#39; : object of class matplotlib.axes.Axes
 |      * &#39;dict&#39; : dict of matplotlib.lines.Line2D objects
 |      * &#39;both&#39; : a namedtuple with structure (ax, lines)
 |      
 |      For data grouped with ``by``, return a Series of the above or a numpy
 |      array:
 |      
 |      * :class:`~pandas.Series`
 |      * :class:`~numpy.array` (for ``return_type = None``)
 |      
 |      Use ``return_type=&#39;dict&#39;`` when you want to tweak the appearance
 |      of the lines after plotting. In this case a dict containing the Lines
 |      making up the boxes, caps, fliers, medians, and whiskers is returned.
 |      
 |      Examples
 |      --------
 |      
 |      Boxplots can be created for every column in the dataframe
 |      by ``df.boxplot()`` or indicating the columns to be used:
 |      
 |      .. plot::
 |          :context: close-figs
 |      
 |          &gt;&gt;&gt; np.random.seed(1234)
 |          &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(10, 4),
 |          ...                   columns=[&#39;Col1&#39;, &#39;Col2&#39;, &#39;Col3&#39;, &#39;Col4&#39;])
 |          &gt;&gt;&gt; boxplot = df.boxplot(column=[&#39;Col1&#39;, &#39;Col2&#39;, &#39;Col3&#39;])
 |      
 |      Boxplots of variables distributions grouped by the values of a third
 |      variable can be created using the option ``by``. For instance:
 |      
 |      .. plot::
 |          :context: close-figs
 |      
 |          &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(10, 2),
 |          ...                   columns=[&#39;Col1&#39;, &#39;Col2&#39;])
 |          &gt;&gt;&gt; df[&#39;X&#39;] = pd.Series([&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;A&#39;,
 |          ...                      &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;])
 |          &gt;&gt;&gt; boxplot = df.boxplot(by=&#39;X&#39;)
 |      
 |      A list of strings (i.e. ``[&#39;X&#39;, &#39;Y&#39;]``) can be passed to boxplot
 |      in order to group the data by combination of the variables in the x-axis:
 |      
 |      .. plot::
 |          :context: close-figs
 |      
 |          &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(10, 3),
 |          ...                   columns=[&#39;Col1&#39;, &#39;Col2&#39;, &#39;Col3&#39;])
 |          &gt;&gt;&gt; df[&#39;X&#39;] = pd.Series([&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;A&#39;,
 |          ...                      &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;])
 |          &gt;&gt;&gt; df[&#39;Y&#39;] = pd.Series([&#39;A&#39;, &#39;B&#39;, &#39;A&#39;, &#39;B&#39;, &#39;A&#39;,
 |          ...                      &#39;B&#39;, &#39;A&#39;, &#39;B&#39;, &#39;A&#39;, &#39;B&#39;])
 |          &gt;&gt;&gt; boxplot = df.boxplot(column=[&#39;Col1&#39;, &#39;Col2&#39;], by=[&#39;X&#39;, &#39;Y&#39;])
 |      
 |      The layout of boxplot can be adjusted giving a tuple to ``layout``:
 |      
 |      .. plot::
 |          :context: close-figs
 |      
 |          &gt;&gt;&gt; boxplot = df.boxplot(column=[&#39;Col1&#39;, &#39;Col2&#39;], by=&#39;X&#39;,
 |          ...                      layout=(2, 1))
 |      
 |      Additional formatting can be done to the boxplot, like suppressing the grid
 |      (``grid=False``), rotating the labels in the x-axis (i.e. ``rot=45``)
 |      or changing the fontsize (i.e. ``fontsize=15``):
 |      
 |      .. plot::
 |          :context: close-figs
 |      
 |          &gt;&gt;&gt; boxplot = df.boxplot(grid=False, rot=45, fontsize=15)
 |      
 |      The parameter ``return_type`` can be used to select the type of element
 |      returned by `boxplot`.  When ``return_type=&#39;axes&#39;`` is selected,
 |      the matplotlib axes on which the boxplot is drawn are returned:
 |      
 |          &gt;&gt;&gt; boxplot = df.boxplot(column=[&#39;Col1&#39;, &#39;Col2&#39;], return_type=&#39;axes&#39;)
 |          &gt;&gt;&gt; type(boxplot)
 |          &lt;class &#39;matplotlib.axes._subplots.AxesSubplot&#39;&gt;
 |      
 |      When grouping with ``by``, a Series mapping columns to ``return_type``
 |      is returned:
 |      
 |          &gt;&gt;&gt; boxplot = df.boxplot(column=[&#39;Col1&#39;, &#39;Col2&#39;], by=&#39;X&#39;,
 |          ...                      return_type=&#39;axes&#39;)
 |          &gt;&gt;&gt; type(boxplot)
 |          &lt;class &#39;pandas.core.series.Series&#39;&gt;
 |      
 |      If ``return_type`` is `None`, a NumPy array of axes with the same shape
 |      as ``layout`` is returned:
 |      
 |          &gt;&gt;&gt; boxplot = df.boxplot(column=[&#39;Col1&#39;, &#39;Col2&#39;], by=&#39;X&#39;,
 |          ...                      return_type=None)
 |          &gt;&gt;&gt; type(boxplot)
 |          &lt;class &#39;numpy.ndarray&#39;&gt;
 |  
 |  clip(self: &#39;DataFrame&#39;, lower=None, upper=None, axis: &#39;Axis | None&#39; = None, inplace: &#39;bool&#39; = False, *args, **kwargs) -&gt; &#39;DataFrame | None&#39;
 |      Trim values at input threshold(s).
 |      
 |      Assigns values outside boundary to boundary values. Thresholds
 |      can be singular values or array like, and in the latter case
 |      the clipping is performed element-wise in the specified axis.
 |      
 |      Parameters
 |      ----------
 |      lower : float or array-like, default None
 |          Minimum threshold value. All values below this
 |          threshold will be set to it. A missing
 |          threshold (e.g `NA`) will not clip the value.
 |      upper : float or array-like, default None
 |          Maximum threshold value. All values above this
 |          threshold will be set to it. A missing
 |          threshold (e.g `NA`) will not clip the value.
 |      axis : int or str axis name, optional
 |          Align object with lower and upper along the given axis.
 |      inplace : bool, default False
 |          Whether to perform the operation in place on the data.
 |      *args, **kwargs
 |          Additional keywords have no effect but might be accepted
 |          for compatibility with numpy.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame or None
 |          Same type as calling object with the values outside the
 |          clip boundaries replaced or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      Series.clip : Trim values at input threshold in series.
 |      DataFrame.clip : Trim values at input threshold in dataframe.
 |      numpy.clip : Clip (limit) the values in an array.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; data = {&#39;col_0&#39;: [9, -3, 0, -1, 5], &#39;col_1&#39;: [-2, -7, 6, 8, -5]}
 |      &gt;&gt;&gt; df = pd.DataFrame(data)
 |      &gt;&gt;&gt; df
 |         col_0  col_1
 |      0      9     -2
 |      1     -3     -7
 |      2      0      6
 |      3     -1      8
 |      4      5     -5
 |      
 |      Clips per column using lower and upper thresholds:
 |      
 |      &gt;&gt;&gt; df.clip(-4, 6)
 |         col_0  col_1
 |      0      6     -2
 |      1     -3     -4
 |      2      0      6
 |      3     -1      6
 |      4      5     -4
 |      
 |      Clips using specific lower and upper thresholds per column element:
 |      
 |      &gt;&gt;&gt; t = pd.Series([2, -4, -1, 6, 3])
 |      &gt;&gt;&gt; t
 |      0    2
 |      1   -4
 |      2   -1
 |      3    6
 |      4    3
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df.clip(t, t + 4, axis=0)
 |         col_0  col_1
 |      0      6      2
 |      1     -3     -4
 |      2      0      3
 |      3      6      8
 |      4      5      3
 |      
 |      Clips using specific lower threshold per column element, with missing values:
 |      
 |      &gt;&gt;&gt; t = pd.Series([2, -4, np.NaN, 6, 3])
 |      &gt;&gt;&gt; t
 |      0    2.0
 |      1   -4.0
 |      2    NaN
 |      3    6.0
 |      4    3.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; df.clip(t, axis=0)
 |      col_0  col_1
 |      0      9      2
 |      1     -3     -4
 |      2      0      6
 |      3      6      8
 |      4      5      3
 |  
 |  combine(self, other: &#39;DataFrame&#39;, func, fill_value=None, overwrite: &#39;bool&#39; = True) -&gt; &#39;DataFrame&#39;
 |      Perform column-wise combine with another DataFrame.
 |      
 |      Combines a DataFrame with `other` DataFrame using `func`
 |      to element-wise combine columns. The row and column indexes of the
 |      resulting DataFrame will be the union of the two.
 |      
 |      Parameters
 |      ----------
 |      other : DataFrame
 |          The DataFrame to merge column-wise.
 |      func : function
 |          Function that takes two series as inputs and return a Series or a
 |          scalar. Used to merge the two dataframes column by columns.
 |      fill_value : scalar value, default None
 |          The value to fill NaNs with prior to passing any column to the
 |          merge func.
 |      overwrite : bool, default True
 |          If True, columns in `self` that do not exist in `other` will be
 |          overwritten with NaNs.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Combination of the provided DataFrames.
 |      
 |      See Also
 |      --------
 |      DataFrame.combine_first : Combine two DataFrame objects and default to
 |          non-null values in frame calling the method.
 |      
 |      Examples
 |      --------
 |      Combine using a simple function that chooses the smaller column.
 |      
 |      &gt;&gt;&gt; df1 = pd.DataFrame({&#39;A&#39;: [0, 0], &#39;B&#39;: [4, 4]})
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;A&#39;: [1, 1], &#39;B&#39;: [3, 3]})
 |      &gt;&gt;&gt; take_smaller = lambda s1, s2: s1 if s1.sum() &lt; s2.sum() else s2
 |      &gt;&gt;&gt; df1.combine(df2, take_smaller)
 |         A  B
 |      0  0  3
 |      1  0  3
 |      
 |      Example using a true element-wise combine function.
 |      
 |      &gt;&gt;&gt; df1 = pd.DataFrame({&#39;A&#39;: [5, 0], &#39;B&#39;: [2, 4]})
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;A&#39;: [1, 1], &#39;B&#39;: [3, 3]})
 |      &gt;&gt;&gt; df1.combine(df2, np.minimum)
 |         A  B
 |      0  1  2
 |      1  0  3
 |      
 |      Using `fill_value` fills Nones prior to passing the column to the
 |      merge function.
 |      
 |      &gt;&gt;&gt; df1 = pd.DataFrame({&#39;A&#39;: [0, 0], &#39;B&#39;: [None, 4]})
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;A&#39;: [1, 1], &#39;B&#39;: [3, 3]})
 |      &gt;&gt;&gt; df1.combine(df2, take_smaller, fill_value=-5)
 |         A    B
 |      0  0 -5.0
 |      1  0  4.0
 |      
 |      However, if the same element in both dataframes is None, that None
 |      is preserved
 |      
 |      &gt;&gt;&gt; df1 = pd.DataFrame({&#39;A&#39;: [0, 0], &#39;B&#39;: [None, 4]})
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;A&#39;: [1, 1], &#39;B&#39;: [None, 3]})
 |      &gt;&gt;&gt; df1.combine(df2, take_smaller, fill_value=-5)
 |          A    B
 |      0  0 -5.0
 |      1  0  3.0
 |      
 |      Example that demonstrates the use of `overwrite` and behavior when
 |      the axis differ between the dataframes.
 |      
 |      &gt;&gt;&gt; df1 = pd.DataFrame({&#39;A&#39;: [0, 0], &#39;B&#39;: [4, 4]})
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;B&#39;: [3, 3], &#39;C&#39;: [-10, 1], }, index=[1, 2])
 |      &gt;&gt;&gt; df1.combine(df2, take_smaller)
 |           A    B     C
 |      0  NaN  NaN   NaN
 |      1  NaN  3.0 -10.0
 |      2  NaN  3.0   1.0
 |      
 |      &gt;&gt;&gt; df1.combine(df2, take_smaller, overwrite=False)
 |           A    B     C
 |      0  0.0  NaN   NaN
 |      1  0.0  3.0 -10.0
 |      2  NaN  3.0   1.0
 |      
 |      Demonstrating the preference of the passed in dataframe.
 |      
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;B&#39;: [3, 3], &#39;C&#39;: [1, 1], }, index=[1, 2])
 |      &gt;&gt;&gt; df2.combine(df1, take_smaller)
 |         A    B   C
 |      0  0.0  NaN NaN
 |      1  0.0  3.0 NaN
 |      2  NaN  3.0 NaN
 |      
 |      &gt;&gt;&gt; df2.combine(df1, take_smaller, overwrite=False)
 |           A    B   C
 |      0  0.0  NaN NaN
 |      1  0.0  3.0 1.0
 |      2  NaN  3.0 1.0
 |  
 |  combine_first(self, other: &#39;DataFrame&#39;) -&gt; &#39;DataFrame&#39;
 |      Update null elements with value in the same location in `other`.
 |      
 |      Combine two DataFrame objects by filling null values in one DataFrame
 |      with non-null values from other DataFrame. The row and column indexes
 |      of the resulting DataFrame will be the union of the two.
 |      
 |      Parameters
 |      ----------
 |      other : DataFrame
 |          Provided DataFrame to use to fill null values.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          The result of combining the provided DataFrame with the other object.
 |      
 |      See Also
 |      --------
 |      DataFrame.combine : Perform series-wise operation on two DataFrames
 |          using a given function.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df1 = pd.DataFrame({&#39;A&#39;: [None, 0], &#39;B&#39;: [None, 4]})
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;A&#39;: [1, 1], &#39;B&#39;: [3, 3]})
 |      &gt;&gt;&gt; df1.combine_first(df2)
 |           A    B
 |      0  1.0  3.0
 |      1  0.0  4.0
 |      
 |      Null values still persist if the location of that null value
 |      does not exist in `other`
 |      
 |      &gt;&gt;&gt; df1 = pd.DataFrame({&#39;A&#39;: [None, 0], &#39;B&#39;: [4, None]})
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;B&#39;: [3, 3], &#39;C&#39;: [1, 1]}, index=[1, 2])
 |      &gt;&gt;&gt; df1.combine_first(df2)
 |           A    B    C
 |      0  NaN  4.0  NaN
 |      1  0.0  3.0  1.0
 |      2  NaN  3.0  1.0
 |  
 |  compare(self, other: &#39;DataFrame&#39;, align_axis: &#39;Axis&#39; = 1, keep_shape: &#39;bool&#39; = False, keep_equal: &#39;bool&#39; = False) -&gt; &#39;DataFrame&#39;
 |      Compare to another DataFrame and show the differences.
 |      
 |      .. versionadded:: 1.1.0
 |      
 |      Parameters
 |      ----------
 |      other : DataFrame
 |          Object to compare with.
 |      
 |      align_axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 1
 |          Determine which axis to align the comparison on.
 |      
 |          * 0, or &#39;index&#39; : Resulting differences are stacked vertically
 |              with rows drawn alternately from self and other.
 |          * 1, or &#39;columns&#39; : Resulting differences are aligned horizontally
 |              with columns drawn alternately from self and other.
 |      
 |      keep_shape : bool, default False
 |          If true, all rows and columns are kept.
 |          Otherwise, only the ones with different values are kept.
 |      
 |      keep_equal : bool, default False
 |          If true, the result keeps values that are equal.
 |          Otherwise, equal values are shown as NaNs.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          DataFrame that shows the differences stacked side by side.
 |      
 |          The resulting index will be a MultiIndex with &#39;self&#39; and &#39;other&#39;
 |          stacked alternately at the inner level.
 |      
 |      Raises
 |      ------
 |      ValueError
 |          When the two DataFrames don&#39;t have identical labels or shape.
 |      
 |      See Also
 |      --------
 |      Series.compare : Compare with another Series and show differences.
 |      DataFrame.equals : Test whether two objects contain the same elements.
 |      
 |      Notes
 |      -----
 |      Matching NaNs will not appear as a difference.
 |      
 |      Can only compare identically-labeled
 |      (i.e. same shape, identical row and column labels) DataFrames
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(
 |      ...     {
 |      ...         &quot;col1&quot;: [&quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;],
 |      ...         &quot;col2&quot;: [1.0, 2.0, 3.0, np.nan, 5.0],
 |      ...         &quot;col3&quot;: [1.0, 2.0, 3.0, 4.0, 5.0]
 |      ...     },
 |      ...     columns=[&quot;col1&quot;, &quot;col2&quot;, &quot;col3&quot;],
 |      ... )
 |      &gt;&gt;&gt; df
 |        col1  col2  col3
 |      0    a   1.0   1.0
 |      1    a   2.0   2.0
 |      2    b   3.0   3.0
 |      3    b   NaN   4.0
 |      4    a   5.0   5.0
 |      
 |      &gt;&gt;&gt; df2 = df.copy()
 |      &gt;&gt;&gt; df2.loc[0, &#39;col1&#39;] = &#39;c&#39;
 |      &gt;&gt;&gt; df2.loc[2, &#39;col3&#39;] = 4.0
 |      &gt;&gt;&gt; df2
 |        col1  col2  col3
 |      0    c   1.0   1.0
 |      1    a   2.0   2.0
 |      2    b   3.0   4.0
 |      3    b   NaN   4.0
 |      4    a   5.0   5.0
 |      
 |      Align the differences on columns
 |      
 |      &gt;&gt;&gt; df.compare(df2)
 |        col1       col3
 |        self other self other
 |      0    a     c  NaN   NaN
 |      2  NaN   NaN  3.0   4.0
 |      
 |      Stack the differences on rows
 |      
 |      &gt;&gt;&gt; df.compare(df2, align_axis=0)
 |              col1  col3
 |      0 self     a   NaN
 |        other    c   NaN
 |      2 self   NaN   3.0
 |        other  NaN   4.0
 |      
 |      Keep the equal values
 |      
 |      &gt;&gt;&gt; df.compare(df2, keep_equal=True)
 |        col1       col3
 |        self other self other
 |      0    a     c  1.0   1.0
 |      2    b     b  3.0   4.0
 |      
 |      Keep all original rows and columns
 |      
 |      &gt;&gt;&gt; df.compare(df2, keep_shape=True)
 |        col1       col2       col3
 |        self other self other self other
 |      0    a     c  NaN   NaN  NaN   NaN
 |      1  NaN   NaN  NaN   NaN  NaN   NaN
 |      2  NaN   NaN  NaN   NaN  3.0   4.0
 |      3  NaN   NaN  NaN   NaN  NaN   NaN
 |      4  NaN   NaN  NaN   NaN  NaN   NaN
 |      
 |      Keep all original rows and columns and also all original values
 |      
 |      &gt;&gt;&gt; df.compare(df2, keep_shape=True, keep_equal=True)
 |        col1       col2       col3
 |        self other self other self other
 |      0    a     c  1.0   1.0  1.0   1.0
 |      1    a     a  2.0   2.0  2.0   2.0
 |      2    b     b  3.0   3.0  3.0   4.0
 |      3    b     b  NaN   NaN  4.0   4.0
 |      4    a     a  5.0   5.0  5.0   5.0
 |  
 |  corr(self, method: &#39;str | Callable[[np.ndarray, np.ndarray], float]&#39; = &#39;pearson&#39;, min_periods: &#39;int&#39; = 1) -&gt; &#39;DataFrame&#39;
 |      Compute pairwise correlation of columns, excluding NA/null values.
 |      
 |      Parameters
 |      ----------
 |      method : {&#39;pearson&#39;, &#39;kendall&#39;, &#39;spearman&#39;} or callable
 |          Method of correlation:
 |      
 |          * pearson : standard correlation coefficient
 |          * kendall : Kendall Tau correlation coefficient
 |          * spearman : Spearman rank correlation
 |          * callable: callable with input two 1d ndarrays
 |              and returning a float. Note that the returned matrix from corr
 |              will have 1 along the diagonals and will be symmetric
 |              regardless of the callable&#39;s behavior.
 |      min_periods : int, optional
 |          Minimum number of observations required per pair of columns
 |          to have a valid result.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Correlation matrix.
 |      
 |      See Also
 |      --------
 |      DataFrame.corrwith : Compute pairwise correlation with another
 |          DataFrame or Series.
 |      Series.corr : Compute the correlation between two Series.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; def histogram_intersection(a, b):
 |      ...     v = np.minimum(a, b).sum().round(decimals=1)
 |      ...     return v
 |      &gt;&gt;&gt; df = pd.DataFrame([(.2, .3), (.0, .6), (.6, .0), (.2, .1)],
 |      ...                   columns=[&#39;dogs&#39;, &#39;cats&#39;])
 |      &gt;&gt;&gt; df.corr(method=histogram_intersection)
 |            dogs  cats
 |      dogs   1.0   0.3
 |      cats   0.3   1.0
 |  
 |  corrwith(self, other, axis: &#39;Axis&#39; = 0, drop=False, method=&#39;pearson&#39;) -&gt; &#39;Series&#39;
 |      Compute pairwise correlation.
 |      
 |      Pairwise correlation is computed between rows or columns of
 |      DataFrame with rows or columns of Series or DataFrame. DataFrames
 |      are first aligned along both axes before computing the
 |      correlations.
 |      
 |      Parameters
 |      ----------
 |      other : DataFrame, Series
 |          Object with which to compute correlations.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to use. 0 or &#39;index&#39; to compute column-wise, 1 or &#39;columns&#39; for
 |          row-wise.
 |      drop : bool, default False
 |          Drop missing indices from result.
 |      method : {&#39;pearson&#39;, &#39;kendall&#39;, &#39;spearman&#39;} or callable
 |          Method of correlation:
 |      
 |          * pearson : standard correlation coefficient
 |          * kendall : Kendall Tau correlation coefficient
 |          * spearman : Spearman rank correlation
 |          * callable: callable with input two 1d ndarrays
 |              and returning a float.
 |      
 |      Returns
 |      -------
 |      Series
 |          Pairwise correlations.
 |      
 |      See Also
 |      --------
 |      DataFrame.corr : Compute pairwise correlation of columns.
 |  
 |  count(self, axis: &#39;Axis&#39; = 0, level: &#39;Level | None&#39; = None, numeric_only: &#39;bool&#39; = False)
 |      Count non-NA cells for each column or row.
 |      
 |      The values `None`, `NaN`, `NaT`, and optionally `numpy.inf` (depending
 |      on `pandas.options.mode.use_inf_as_na`) are considered NA.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          If 0 or &#39;index&#39; counts are generated for each column.
 |          If 1 or &#39;columns&#39; counts are generated for each row.
 |      level : int or str, optional
 |          If the axis is a `MultiIndex` (hierarchical), count along a
 |          particular `level`, collapsing into a `DataFrame`.
 |          A `str` specifies the level name.
 |      numeric_only : bool, default False
 |          Include only `float`, `int` or `boolean` data.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          For each column/row the number of non-NA/null entries.
 |          If `level` is specified returns a `DataFrame`.
 |      
 |      See Also
 |      --------
 |      Series.count: Number of non-NA elements in a Series.
 |      DataFrame.value_counts: Count unique combinations of columns.
 |      DataFrame.shape: Number of DataFrame rows and columns (including NA
 |          elements).
 |      DataFrame.isna: Boolean same-sized DataFrame showing places of NA
 |          elements.
 |      
 |      Examples
 |      --------
 |      Constructing DataFrame from a dictionary:
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;Person&quot;:
 |      ...                    [&quot;John&quot;, &quot;Myla&quot;, &quot;Lewis&quot;, &quot;John&quot;, &quot;Myla&quot;],
 |      ...                    &quot;Age&quot;: [24., np.nan, 21., 33, 26],
 |      ...                    &quot;Single&quot;: [False, True, True, True, False]})
 |      &gt;&gt;&gt; df
 |         Person   Age  Single
 |      0    John  24.0   False
 |      1    Myla   NaN    True
 |      2   Lewis  21.0    True
 |      3    John  33.0    True
 |      4    Myla  26.0   False
 |      
 |      Notice the uncounted NA values:
 |      
 |      &gt;&gt;&gt; df.count()
 |      Person    5
 |      Age       4
 |      Single    5
 |      dtype: int64
 |      
 |      Counts for each **row**:
 |      
 |      &gt;&gt;&gt; df.count(axis=&#39;columns&#39;)
 |      0    3
 |      1    2
 |      2    3
 |      3    3
 |      4    3
 |      dtype: int64
 |  
 |  cov(self, min_periods: &#39;int | None&#39; = None, ddof: &#39;int | None&#39; = 1) -&gt; &#39;DataFrame&#39;
 |      Compute pairwise covariance of columns, excluding NA/null values.
 |      
 |      Compute the pairwise covariance among the series of a DataFrame.
 |      The returned data frame is the `covariance matrix
 |      &lt;https://en.wikipedia.org/wiki/Covariance_matrix&gt;`__ of the columns
 |      of the DataFrame.
 |      
 |      Both NA and null values are automatically excluded from the
 |      calculation. (See the note below about bias from missing values.)
 |      A threshold can be set for the minimum number of
 |      observations for each value created. Comparisons with observations
 |      below this threshold will be returned as ``NaN``.
 |      
 |      This method is generally used for the analysis of time series data to
 |      understand the relationship between different measures
 |      across time.
 |      
 |      Parameters
 |      ----------
 |      min_periods : int, optional
 |          Minimum number of observations required per pair of columns
 |          to have a valid result.
 |      
 |      ddof : int, default 1
 |          Delta degrees of freedom.  The divisor used in calculations
 |          is ``N - ddof``, where ``N`` represents the number of elements.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          The covariance matrix of the series of the DataFrame.
 |      
 |      See Also
 |      --------
 |      Series.cov : Compute covariance with another Series.
 |      core.window.ExponentialMovingWindow.cov: Exponential weighted sample covariance.
 |      core.window.Expanding.cov : Expanding sample covariance.
 |      core.window.Rolling.cov : Rolling sample covariance.
 |      
 |      Notes
 |      -----
 |      Returns the covariance matrix of the DataFrame&#39;s time series.
 |      The covariance is normalized by N-ddof.
 |      
 |      For DataFrames that have Series that are missing data (assuming that
 |      data is `missing at random
 |      &lt;https://en.wikipedia.org/wiki/Missing_data#Missing_at_random&gt;`__)
 |      the returned covariance matrix will be an unbiased estimate
 |      of the variance and covariance between the member Series.
 |      
 |      However, for many applications this estimate may not be acceptable
 |      because the estimate covariance matrix is not guaranteed to be positive
 |      semi-definite. This could lead to estimate correlations having
 |      absolute values which are greater than one, and/or a non-invertible
 |      covariance matrix. See `Estimation of covariance matrices
 |      &lt;https://en.wikipedia.org/w/index.php?title=Estimation_of_covariance_
 |      matrices&gt;`__ for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([(1, 2), (0, 3), (2, 0), (1, 1)],
 |      ...                   columns=[&#39;dogs&#39;, &#39;cats&#39;])
 |      &gt;&gt;&gt; df.cov()
 |                dogs      cats
 |      dogs  0.666667 -1.000000
 |      cats -1.000000  1.666667
 |      
 |      &gt;&gt;&gt; np.random.seed(42)
 |      &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(1000, 5),
 |      ...                   columns=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;])
 |      &gt;&gt;&gt; df.cov()
 |                a         b         c         d         e
 |      a  0.998438 -0.020161  0.059277 -0.008943  0.014144
 |      b -0.020161  1.059352 -0.008543 -0.024738  0.009826
 |      c  0.059277 -0.008543  1.010670 -0.001486 -0.000271
 |      d -0.008943 -0.024738 -0.001486  0.921297 -0.013692
 |      e  0.014144  0.009826 -0.000271 -0.013692  0.977795
 |      
 |      **Minimum number of periods**
 |      
 |      This method also supports an optional ``min_periods`` keyword
 |      that specifies the required minimum number of non-NA observations for
 |      each column pair in order to have a valid result:
 |      
 |      &gt;&gt;&gt; np.random.seed(42)
 |      &gt;&gt;&gt; df = pd.DataFrame(np.random.randn(20, 3),
 |      ...                   columns=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])
 |      &gt;&gt;&gt; df.loc[df.index[:5], &#39;a&#39;] = np.nan
 |      &gt;&gt;&gt; df.loc[df.index[5:10], &#39;b&#39;] = np.nan
 |      &gt;&gt;&gt; df.cov(min_periods=12)
 |                a         b         c
 |      a  0.316741       NaN -0.150812
 |      b       NaN  1.248003  0.191417
 |      c -0.150812  0.191417  0.895202
 |  
 |  cummax(self, axis=None, skipna=True, *args, **kwargs)
 |      Return cumulative maximum over a DataFrame or Series axis.
 |      
 |      Returns a DataFrame or Series of the same size containing the cumulative
 |      maximum.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The index or the name of the axis. 0 is equivalent to None or &#39;index&#39;.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      *args, **kwargs
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Return cumulative maximum of Series or DataFrame.
 |      
 |      See Also
 |      --------
 |      core.window.Expanding.max : Similar functionality
 |          but ignores ``NaN`` values.
 |      DataFrame.max : Return the maximum over
 |          DataFrame axis.
 |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.
 |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.
 |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.
 |      DataFrame.cumprod : Return cumulative product over DataFrame axis.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([2, np.nan, 5, -1, 0])
 |      &gt;&gt;&gt; s
 |      0    2.0
 |      1    NaN
 |      2    5.0
 |      3   -1.0
 |      4    0.0
 |      dtype: float64
 |      
 |      By default, NA values are ignored.
 |      
 |      &gt;&gt;&gt; s.cummax()
 |      0    2.0
 |      1    NaN
 |      2    5.0
 |      3    5.0
 |      4    5.0
 |      dtype: float64
 |      
 |      To include NA values in the operation, use ``skipna=False``
 |      
 |      &gt;&gt;&gt; s.cummax(skipna=False)
 |      0    2.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      **DataFrame**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[2.0, 1.0],
 |      ...                    [3.0, np.nan],
 |      ...                    [1.0, 0.0]],
 |      ...                    columns=list(&#39;AB&#39;))
 |      &gt;&gt;&gt; df
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |      
 |      By default, iterates over rows and finds the maximum
 |      in each column. This is equivalent to ``axis=None`` or ``axis=&#39;index&#39;``.
 |      
 |      &gt;&gt;&gt; df.cummax()
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  3.0  1.0
 |      
 |      To iterate over columns and find the maximum in each row,
 |      use ``axis=1``
 |      
 |      &gt;&gt;&gt; df.cummax(axis=1)
 |           A    B
 |      0  2.0  2.0
 |      1  3.0  NaN
 |      2  1.0  1.0
 |  
 |  cummin(self, axis=None, skipna=True, *args, **kwargs)
 |      Return cumulative minimum over a DataFrame or Series axis.
 |      
 |      Returns a DataFrame or Series of the same size containing the cumulative
 |      minimum.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The index or the name of the axis. 0 is equivalent to None or &#39;index&#39;.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      *args, **kwargs
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Return cumulative minimum of Series or DataFrame.
 |      
 |      See Also
 |      --------
 |      core.window.Expanding.min : Similar functionality
 |          but ignores ``NaN`` values.
 |      DataFrame.min : Return the minimum over
 |          DataFrame axis.
 |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.
 |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.
 |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.
 |      DataFrame.cumprod : Return cumulative product over DataFrame axis.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([2, np.nan, 5, -1, 0])
 |      &gt;&gt;&gt; s
 |      0    2.0
 |      1    NaN
 |      2    5.0
 |      3   -1.0
 |      4    0.0
 |      dtype: float64
 |      
 |      By default, NA values are ignored.
 |      
 |      &gt;&gt;&gt; s.cummin()
 |      0    2.0
 |      1    NaN
 |      2    2.0
 |      3   -1.0
 |      4   -1.0
 |      dtype: float64
 |      
 |      To include NA values in the operation, use ``skipna=False``
 |      
 |      &gt;&gt;&gt; s.cummin(skipna=False)
 |      0    2.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      **DataFrame**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[2.0, 1.0],
 |      ...                    [3.0, np.nan],
 |      ...                    [1.0, 0.0]],
 |      ...                    columns=list(&#39;AB&#39;))
 |      &gt;&gt;&gt; df
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |      
 |      By default, iterates over rows and finds the minimum
 |      in each column. This is equivalent to ``axis=None`` or ``axis=&#39;index&#39;``.
 |      
 |      &gt;&gt;&gt; df.cummin()
 |           A    B
 |      0  2.0  1.0
 |      1  2.0  NaN
 |      2  1.0  0.0
 |      
 |      To iterate over columns and find the minimum in each row,
 |      use ``axis=1``
 |      
 |      &gt;&gt;&gt; df.cummin(axis=1)
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |  
 |  cumprod(self, axis=None, skipna=True, *args, **kwargs)
 |      Return cumulative product over a DataFrame or Series axis.
 |      
 |      Returns a DataFrame or Series of the same size containing the cumulative
 |      product.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The index or the name of the axis. 0 is equivalent to None or &#39;index&#39;.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      *args, **kwargs
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Return cumulative product of Series or DataFrame.
 |      
 |      See Also
 |      --------
 |      core.window.Expanding.prod : Similar functionality
 |          but ignores ``NaN`` values.
 |      DataFrame.prod : Return the product over
 |          DataFrame axis.
 |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.
 |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.
 |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.
 |      DataFrame.cumprod : Return cumulative product over DataFrame axis.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([2, np.nan, 5, -1, 0])
 |      &gt;&gt;&gt; s
 |      0    2.0
 |      1    NaN
 |      2    5.0
 |      3   -1.0
 |      4    0.0
 |      dtype: float64
 |      
 |      By default, NA values are ignored.
 |      
 |      &gt;&gt;&gt; s.cumprod()
 |      0     2.0
 |      1     NaN
 |      2    10.0
 |      3   -10.0
 |      4    -0.0
 |      dtype: float64
 |      
 |      To include NA values in the operation, use ``skipna=False``
 |      
 |      &gt;&gt;&gt; s.cumprod(skipna=False)
 |      0    2.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      **DataFrame**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[2.0, 1.0],
 |      ...                    [3.0, np.nan],
 |      ...                    [1.0, 0.0]],
 |      ...                    columns=list(&#39;AB&#39;))
 |      &gt;&gt;&gt; df
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |      
 |      By default, iterates over rows and finds the product
 |      in each column. This is equivalent to ``axis=None`` or ``axis=&#39;index&#39;``.
 |      
 |      &gt;&gt;&gt; df.cumprod()
 |           A    B
 |      0  2.0  1.0
 |      1  6.0  NaN
 |      2  6.0  0.0
 |      
 |      To iterate over columns and find the product in each row,
 |      use ``axis=1``
 |      
 |      &gt;&gt;&gt; df.cumprod(axis=1)
 |           A    B
 |      0  2.0  2.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |  
 |  cumsum(self, axis=None, skipna=True, *args, **kwargs)
 |      Return cumulative sum over a DataFrame or Series axis.
 |      
 |      Returns a DataFrame or Series of the same size containing the cumulative
 |      sum.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The index or the name of the axis. 0 is equivalent to None or &#39;index&#39;.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      *args, **kwargs
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with NumPy.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Return cumulative sum of Series or DataFrame.
 |      
 |      See Also
 |      --------
 |      core.window.Expanding.sum : Similar functionality
 |          but ignores ``NaN`` values.
 |      DataFrame.sum : Return the sum over
 |          DataFrame axis.
 |      DataFrame.cummax : Return cumulative maximum over DataFrame axis.
 |      DataFrame.cummin : Return cumulative minimum over DataFrame axis.
 |      DataFrame.cumsum : Return cumulative sum over DataFrame axis.
 |      DataFrame.cumprod : Return cumulative product over DataFrame axis.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([2, np.nan, 5, -1, 0])
 |      &gt;&gt;&gt; s
 |      0    2.0
 |      1    NaN
 |      2    5.0
 |      3   -1.0
 |      4    0.0
 |      dtype: float64
 |      
 |      By default, NA values are ignored.
 |      
 |      &gt;&gt;&gt; s.cumsum()
 |      0    2.0
 |      1    NaN
 |      2    7.0
 |      3    6.0
 |      4    6.0
 |      dtype: float64
 |      
 |      To include NA values in the operation, use ``skipna=False``
 |      
 |      &gt;&gt;&gt; s.cumsum(skipna=False)
 |      0    2.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      **DataFrame**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[2.0, 1.0],
 |      ...                    [3.0, np.nan],
 |      ...                    [1.0, 0.0]],
 |      ...                    columns=list(&#39;AB&#39;))
 |      &gt;&gt;&gt; df
 |           A    B
 |      0  2.0  1.0
 |      1  3.0  NaN
 |      2  1.0  0.0
 |      
 |      By default, iterates over rows and finds the sum
 |      in each column. This is equivalent to ``axis=None`` or ``axis=&#39;index&#39;``.
 |      
 |      &gt;&gt;&gt; df.cumsum()
 |           A    B
 |      0  2.0  1.0
 |      1  5.0  NaN
 |      2  6.0  1.0
 |      
 |      To iterate over columns and find the sum in each row,
 |      use ``axis=1``
 |      
 |      &gt;&gt;&gt; df.cumsum(axis=1)
 |           A    B
 |      0  2.0  3.0
 |      1  3.0  NaN
 |      2  1.0  1.0
 |  
 |  diff(self, periods: &#39;int&#39; = 1, axis: &#39;Axis&#39; = 0) -&gt; &#39;DataFrame&#39;
 |      First discrete difference of element.
 |      
 |      Calculates the difference of a Dataframe element compared with another
 |      element in the Dataframe (default is element in previous row).
 |      
 |      Parameters
 |      ----------
 |      periods : int, default 1
 |          Periods to shift for calculating difference, accepts negative
 |          values.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Take difference over rows (0) or columns (1).
 |      
 |      Returns
 |      -------
 |      Dataframe
 |          First differences of the Series.
 |      
 |      See Also
 |      --------
 |      Dataframe.pct_change: Percent change over given number of periods.
 |      Dataframe.shift: Shift index by desired number of periods with an
 |          optional time freq.
 |      Series.diff: First discrete difference of object.
 |      
 |      Notes
 |      -----
 |      For boolean dtypes, this uses :meth:`operator.xor` rather than
 |      :meth:`operator.sub`.
 |      The result is calculated according to current dtype in Dataframe,
 |      however dtype of the result is always float64.
 |      
 |      Examples
 |      --------
 |      
 |      Difference with previous row
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;a&#39;: [1, 2, 3, 4, 5, 6],
 |      ...                    &#39;b&#39;: [1, 1, 2, 3, 5, 8],
 |      ...                    &#39;c&#39;: [1, 4, 9, 16, 25, 36]})
 |      &gt;&gt;&gt; df
 |         a  b   c
 |      0  1  1   1
 |      1  2  1   4
 |      2  3  2   9
 |      3  4  3  16
 |      4  5  5  25
 |      5  6  8  36
 |      
 |      &gt;&gt;&gt; df.diff()
 |           a    b     c
 |      0  NaN  NaN   NaN
 |      1  1.0  0.0   3.0
 |      2  1.0  1.0   5.0
 |      3  1.0  1.0   7.0
 |      4  1.0  2.0   9.0
 |      5  1.0  3.0  11.0
 |      
 |      Difference with previous column
 |      
 |      &gt;&gt;&gt; df.diff(axis=1)
 |          a  b   c
 |      0 NaN  0   0
 |      1 NaN -1   3
 |      2 NaN -1   7
 |      3 NaN -1  13
 |      4 NaN  0  20
 |      5 NaN  2  28
 |      
 |      Difference with 3rd previous row
 |      
 |      &gt;&gt;&gt; df.diff(periods=3)
 |           a    b     c
 |      0  NaN  NaN   NaN
 |      1  NaN  NaN   NaN
 |      2  NaN  NaN   NaN
 |      3  3.0  2.0  15.0
 |      4  3.0  4.0  21.0
 |      5  3.0  6.0  27.0
 |      
 |      Difference with following row
 |      
 |      &gt;&gt;&gt; df.diff(periods=-1)
 |           a    b     c
 |      0 -1.0  0.0  -3.0
 |      1 -1.0 -1.0  -5.0
 |      2 -1.0 -1.0  -7.0
 |      3 -1.0 -2.0  -9.0
 |      4 -1.0 -3.0 -11.0
 |      5  NaN  NaN   NaN
 |      
 |      Overflow in input dtype
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;a&#39;: [1, 0]}, dtype=np.uint8)
 |      &gt;&gt;&gt; df.diff()
 |             a
 |      0    NaN
 |      1  255.0
 |  
 |  div = truediv(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |  
 |  divide = truediv(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |  
 |  dot(self, other: &#39;AnyArrayLike | FrameOrSeriesUnion&#39;) -&gt; &#39;FrameOrSeriesUnion&#39;
 |      Compute the matrix multiplication between the DataFrame and other.
 |      
 |      This method computes the matrix product between the DataFrame and the
 |      values of an other Series, DataFrame or a numpy array.
 |      
 |      It can also be called using ``self @ other`` in Python &gt;= 3.5.
 |      
 |      Parameters
 |      ----------
 |      other : Series, DataFrame or array-like
 |          The other object to compute the matrix product with.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          If other is a Series, return the matrix product between self and
 |          other as a Series. If other is a DataFrame or a numpy.array, return
 |          the matrix product of self and other in a DataFrame of a np.array.
 |      
 |      See Also
 |      --------
 |      Series.dot: Similar method for Series.
 |      
 |      Notes
 |      -----
 |      The dimensions of DataFrame and other must be compatible in order to
 |      compute the matrix multiplication. In addition, the column names of
 |      DataFrame and the index of other must contain the same values, as they
 |      will be aligned prior to the multiplication.
 |      
 |      The dot method for Series computes the inner product, instead of the
 |      matrix product here.
 |      
 |      Examples
 |      --------
 |      Here we multiply a DataFrame with a Series.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[0, 1, -2, -1], [1, 1, 1, 1]])
 |      &gt;&gt;&gt; s = pd.Series([1, 1, 2, 1])
 |      &gt;&gt;&gt; df.dot(s)
 |      0    -4
 |      1     5
 |      dtype: int64
 |      
 |      Here we multiply a DataFrame with another DataFrame.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame([[0, 1], [1, 2], [-1, -1], [2, 0]])
 |      &gt;&gt;&gt; df.dot(other)
 |          0   1
 |      0   1   4
 |      1   2   2
 |      
 |      Note that the dot method give the same result as @
 |      
 |      &gt;&gt;&gt; df @ other
 |          0   1
 |      0   1   4
 |      1   2   2
 |      
 |      The dot method works also if other is an np.array.
 |      
 |      &gt;&gt;&gt; arr = np.array([[0, 1], [1, 2], [-1, -1], [2, 0]])
 |      &gt;&gt;&gt; df.dot(arr)
 |          0   1
 |      0   1   4
 |      1   2   2
 |      
 |      Note how shuffling of the objects does not change the result.
 |      
 |      &gt;&gt;&gt; s2 = s.reindex([1, 0, 2, 3])
 |      &gt;&gt;&gt; df.dot(s2)
 |      0    -4
 |      1     5
 |      dtype: int64
 |  
 |  drop(self, labels=None, axis: &#39;Axis&#39; = 0, index=None, columns=None, level: &#39;Level | None&#39; = None, inplace: &#39;bool&#39; = False, errors: &#39;str&#39; = &#39;raise&#39;)
 |      Drop specified labels from rows or columns.
 |      
 |      Remove rows or columns by specifying label names and corresponding
 |      axis, or by specifying directly index or column names. When using a
 |      multi-index, labels on different levels can be removed by specifying
 |      the level. See the `user guide &lt;advanced.shown_levels&gt;`
 |      for more information about the now unused levels.
 |      
 |      Parameters
 |      ----------
 |      labels : single label or list-like
 |          Index or column labels to drop.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Whether to drop labels from the index (0 or &#39;index&#39;) or
 |          columns (1 or &#39;columns&#39;).
 |      index : single label or list-like
 |          Alternative to specifying axis (``labels, axis=0``
 |          is equivalent to ``index=labels``).
 |      columns : single label or list-like
 |          Alternative to specifying axis (``labels, axis=1``
 |          is equivalent to ``columns=labels``).
 |      level : int or level name, optional
 |          For MultiIndex, level from which the labels will be removed.
 |      inplace : bool, default False
 |          If False, return a copy. Otherwise, do operation
 |          inplace and return None.
 |      errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;raise&#39;
 |          If &#39;ignore&#39;, suppress error and only existing labels are
 |          dropped.
 |      
 |      Returns
 |      -------
 |      DataFrame or None
 |          DataFrame without the removed index or column labels or
 |          None if ``inplace=True``.
 |      
 |      Raises
 |      ------
 |      KeyError
 |          If any of the labels is not found in the selected axis.
 |      
 |      See Also
 |      --------
 |      DataFrame.loc : Label-location based indexer for selection by label.
 |      DataFrame.dropna : Return DataFrame with labels on given axis omitted
 |          where (all or any) data are missing.
 |      DataFrame.drop_duplicates : Return DataFrame with duplicate rows
 |          removed, optionally only considering certain columns.
 |      Series.drop : Return Series with specified index labels removed.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(np.arange(12).reshape(3, 4),
 |      ...                   columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
 |      &gt;&gt;&gt; df
 |         A  B   C   D
 |      0  0  1   2   3
 |      1  4  5   6   7
 |      2  8  9  10  11
 |      
 |      Drop columns
 |      
 |      &gt;&gt;&gt; df.drop([&#39;B&#39;, &#39;C&#39;], axis=1)
 |         A   D
 |      0  0   3
 |      1  4   7
 |      2  8  11
 |      
 |      &gt;&gt;&gt; df.drop(columns=[&#39;B&#39;, &#39;C&#39;])
 |         A   D
 |      0  0   3
 |      1  4   7
 |      2  8  11
 |      
 |      Drop a row by index
 |      
 |      &gt;&gt;&gt; df.drop([0, 1])
 |         A  B   C   D
 |      2  8  9  10  11
 |      
 |      Drop columns and/or rows of MultiIndex DataFrame
 |      
 |      &gt;&gt;&gt; midx = pd.MultiIndex(levels=[[&#39;lama&#39;, &#39;cow&#39;, &#39;falcon&#39;],
 |      ...                              [&#39;speed&#39;, &#39;weight&#39;, &#39;length&#39;]],
 |      ...                      codes=[[0, 0, 0, 1, 1, 1, 2, 2, 2],
 |      ...                             [0, 1, 2, 0, 1, 2, 0, 1, 2]])
 |      &gt;&gt;&gt; df = pd.DataFrame(index=midx, columns=[&#39;big&#39;, &#39;small&#39;],
 |      ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],
 |      ...                         [250, 150], [1.5, 0.8], [320, 250],
 |      ...                         [1, 0.8], [0.3, 0.2]])
 |      &gt;&gt;&gt; df
 |                      big     small
 |      lama    speed   45.0    30.0
 |              weight  200.0   100.0
 |              length  1.5     1.0
 |      cow     speed   30.0    20.0
 |              weight  250.0   150.0
 |              length  1.5     0.8
 |      falcon  speed   320.0   250.0
 |              weight  1.0     0.8
 |              length  0.3     0.2
 |      
 |      &gt;&gt;&gt; df.drop(index=&#39;cow&#39;, columns=&#39;small&#39;)
 |                      big
 |      lama    speed   45.0
 |              weight  200.0
 |              length  1.5
 |      falcon  speed   320.0
 |              weight  1.0
 |              length  0.3
 |      
 |      &gt;&gt;&gt; df.drop(index=&#39;length&#39;, level=1)
 |                      big     small
 |      lama    speed   45.0    30.0
 |              weight  200.0   100.0
 |      cow     speed   30.0    20.0
 |              weight  250.0   150.0
 |      falcon  speed   320.0   250.0
 |              weight  1.0     0.8
 |  
 |  drop_duplicates(self, subset: &#39;Hashable | Sequence[Hashable] | None&#39; = None, keep: &quot;Literal[&#39;first&#39;] | Literal[&#39;last&#39;] | Literal[False]&quot; = &#39;first&#39;, inplace: &#39;bool&#39; = False, ignore_index: &#39;bool&#39; = False) -&gt; &#39;DataFrame | None&#39;
 |      Return DataFrame with duplicate rows removed.
 |      
 |      Considering certain columns is optional. Indexes, including time indexes
 |      are ignored.
 |      
 |      Parameters
 |      ----------
 |      subset : column label or sequence of labels, optional
 |          Only consider certain columns for identifying duplicates, by
 |          default use all of the columns.
 |      keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
 |          Determines which duplicates (if any) to keep.
 |          - ``first`` : Drop duplicates except for the first occurrence.
 |          - ``last`` : Drop duplicates except for the last occurrence.
 |          - False : Drop all duplicates.
 |      inplace : bool, default False
 |          Whether to drop duplicates in place or to return a copy.
 |      ignore_index : bool, default False
 |          If True, the resulting axis will be labeled 0, 1, …, n - 1.
 |      
 |          .. versionadded:: 1.0.0
 |      
 |      Returns
 |      -------
 |      DataFrame or None
 |          DataFrame with duplicates removed or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      DataFrame.value_counts: Count unique combinations of columns.
 |      
 |      Examples
 |      --------
 |      Consider dataset containing ramen rating.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;brand&#39;: [&#39;Yum Yum&#39;, &#39;Yum Yum&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;],
 |      ...     &#39;style&#39;: [&#39;cup&#39;, &#39;cup&#39;, &#39;cup&#39;, &#39;pack&#39;, &#39;pack&#39;],
 |      ...     &#39;rating&#39;: [4, 4, 3.5, 15, 5]
 |      ... })
 |      &gt;&gt;&gt; df
 |          brand style  rating
 |      0  Yum Yum   cup     4.0
 |      1  Yum Yum   cup     4.0
 |      2  Indomie   cup     3.5
 |      3  Indomie  pack    15.0
 |      4  Indomie  pack     5.0
 |      
 |      By default, it removes duplicate rows based on all columns.
 |      
 |      &gt;&gt;&gt; df.drop_duplicates()
 |          brand style  rating
 |      0  Yum Yum   cup     4.0
 |      2  Indomie   cup     3.5
 |      3  Indomie  pack    15.0
 |      4  Indomie  pack     5.0
 |      
 |      To remove duplicates on specific column(s), use ``subset``.
 |      
 |      &gt;&gt;&gt; df.drop_duplicates(subset=[&#39;brand&#39;])
 |          brand style  rating
 |      0  Yum Yum   cup     4.0
 |      2  Indomie   cup     3.5
 |      
 |      To remove duplicates and keep last occurrences, use ``keep``.
 |      
 |      &gt;&gt;&gt; df.drop_duplicates(subset=[&#39;brand&#39;, &#39;style&#39;], keep=&#39;last&#39;)
 |          brand style  rating
 |      1  Yum Yum   cup     4.0
 |      2  Indomie   cup     3.5
 |      4  Indomie  pack     5.0
 |  
 |  dropna(self, axis: &#39;Axis&#39; = 0, how: &#39;str&#39; = &#39;any&#39;, thresh=None, subset=None, inplace: &#39;bool&#39; = False)
 |      Remove missing values.
 |      
 |      See the :ref:`User Guide &lt;missing_data&gt;` for more on which values are
 |      considered missing, and how to work with missing data.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Determine if rows or columns which contain missing values are
 |          removed.
 |      
 |          * 0, or &#39;index&#39; : Drop rows which contain missing values.
 |          * 1, or &#39;columns&#39; : Drop columns which contain missing value.
 |      
 |          .. versionchanged:: 1.0.0
 |      
 |             Pass tuple or list to drop on multiple axes.
 |             Only a single axis is allowed.
 |      
 |      how : {&#39;any&#39;, &#39;all&#39;}, default &#39;any&#39;
 |          Determine if row or column is removed from DataFrame, when we have
 |          at least one NA or all NA.
 |      
 |          * &#39;any&#39; : If any NA values are present, drop that row or column.
 |          * &#39;all&#39; : If all values are NA, drop that row or column.
 |      
 |      thresh : int, optional
 |          Require that many non-NA values.
 |      subset : array-like, optional
 |          Labels along other axis to consider, e.g. if you are dropping rows
 |          these would be a list of columns to include.
 |      inplace : bool, default False
 |          If True, do operation inplace and return None.
 |      
 |      Returns
 |      -------
 |      DataFrame or None
 |          DataFrame with NA entries dropped from it or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      DataFrame.isna: Indicate missing values.
 |      DataFrame.notna : Indicate existing (non-missing) values.
 |      DataFrame.fillna : Replace missing values.
 |      Series.dropna : Drop missing values.
 |      Index.dropna : Drop missing indices.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;name&quot;: [&#39;Alfred&#39;, &#39;Batman&#39;, &#39;Catwoman&#39;],
 |      ...                    &quot;toy&quot;: [np.nan, &#39;Batmobile&#39;, &#39;Bullwhip&#39;],
 |      ...                    &quot;born&quot;: [pd.NaT, pd.Timestamp(&quot;1940-04-25&quot;),
 |      ...                             pd.NaT]})
 |      &gt;&gt;&gt; df
 |             name        toy       born
 |      0    Alfred        NaN        NaT
 |      1    Batman  Batmobile 1940-04-25
 |      2  Catwoman   Bullwhip        NaT
 |      
 |      Drop the rows where at least one element is missing.
 |      
 |      &gt;&gt;&gt; df.dropna()
 |           name        toy       born
 |      1  Batman  Batmobile 1940-04-25
 |      
 |      Drop the columns where at least one element is missing.
 |      
 |      &gt;&gt;&gt; df.dropna(axis=&#39;columns&#39;)
 |             name
 |      0    Alfred
 |      1    Batman
 |      2  Catwoman
 |      
 |      Drop the rows where all elements are missing.
 |      
 |      &gt;&gt;&gt; df.dropna(how=&#39;all&#39;)
 |             name        toy       born
 |      0    Alfred        NaN        NaT
 |      1    Batman  Batmobile 1940-04-25
 |      2  Catwoman   Bullwhip        NaT
 |      
 |      Keep only the rows with at least 2 non-NA values.
 |      
 |      &gt;&gt;&gt; df.dropna(thresh=2)
 |             name        toy       born
 |      1    Batman  Batmobile 1940-04-25
 |      2  Catwoman   Bullwhip        NaT
 |      
 |      Define in which columns to look for missing values.
 |      
 |      &gt;&gt;&gt; df.dropna(subset=[&#39;name&#39;, &#39;toy&#39;])
 |             name        toy       born
 |      1    Batman  Batmobile 1940-04-25
 |      2  Catwoman   Bullwhip        NaT
 |      
 |      Keep the DataFrame with valid entries in the same variable.
 |      
 |      &gt;&gt;&gt; df.dropna(inplace=True)
 |      &gt;&gt;&gt; df
 |           name        toy       born
 |      1  Batman  Batmobile 1940-04-25
 |  
 |  duplicated(self, subset: &#39;Hashable | Sequence[Hashable] | None&#39; = None, keep: &quot;Literal[&#39;first&#39;] | Literal[&#39;last&#39;] | Literal[False]&quot; = &#39;first&#39;) -&gt; &#39;Series&#39;
 |      Return boolean Series denoting duplicate rows.
 |      
 |      Considering certain columns is optional.
 |      
 |      Parameters
 |      ----------
 |      subset : column label or sequence of labels, optional
 |          Only consider certain columns for identifying duplicates, by
 |          default use all of the columns.
 |      keep : {&#39;first&#39;, &#39;last&#39;, False}, default &#39;first&#39;
 |          Determines which duplicates (if any) to mark.
 |      
 |          - ``first`` : Mark duplicates as ``True`` except for the first occurrence.
 |          - ``last`` : Mark duplicates as ``True`` except for the last occurrence.
 |          - False : Mark all duplicates as ``True``.
 |      
 |      Returns
 |      -------
 |      Series
 |          Boolean series for each duplicated rows.
 |      
 |      See Also
 |      --------
 |      Index.duplicated : Equivalent method on index.
 |      Series.duplicated : Equivalent method on Series.
 |      Series.drop_duplicates : Remove duplicate values from Series.
 |      DataFrame.drop_duplicates : Remove duplicate values from DataFrame.
 |      
 |      Examples
 |      --------
 |      Consider dataset containing ramen rating.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;brand&#39;: [&#39;Yum Yum&#39;, &#39;Yum Yum&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;, &#39;Indomie&#39;],
 |      ...     &#39;style&#39;: [&#39;cup&#39;, &#39;cup&#39;, &#39;cup&#39;, &#39;pack&#39;, &#39;pack&#39;],
 |      ...     &#39;rating&#39;: [4, 4, 3.5, 15, 5]
 |      ... })
 |      &gt;&gt;&gt; df
 |          brand style  rating
 |      0  Yum Yum   cup     4.0
 |      1  Yum Yum   cup     4.0
 |      2  Indomie   cup     3.5
 |      3  Indomie  pack    15.0
 |      4  Indomie  pack     5.0
 |      
 |      By default, for each set of duplicated values, the first occurrence
 |      is set on False and all others on True.
 |      
 |      &gt;&gt;&gt; df.duplicated()
 |      0    False
 |      1     True
 |      2    False
 |      3    False
 |      4    False
 |      dtype: bool
 |      
 |      By using &#39;last&#39;, the last occurrence of each set of duplicated values
 |      is set on False and all others on True.
 |      
 |      &gt;&gt;&gt; df.duplicated(keep=&#39;last&#39;)
 |      0     True
 |      1    False
 |      2    False
 |      3    False
 |      4    False
 |      dtype: bool
 |      
 |      By setting ``keep`` on False, all duplicates are True.
 |      
 |      &gt;&gt;&gt; df.duplicated(keep=False)
 |      0     True
 |      1     True
 |      2    False
 |      3    False
 |      4    False
 |      dtype: bool
 |      
 |      To find duplicates on specific column(s), use ``subset``.
 |      
 |      &gt;&gt;&gt; df.duplicated(subset=[&#39;brand&#39;])
 |      0    False
 |      1     True
 |      2    False
 |      3     True
 |      4     True
 |      dtype: bool
 |  
 |  eq(self, other, axis=&#39;columns&#39;, level=None)
 |      Get Equal to of dataframe and other, element-wise (binary operator `eq`).
 |      
 |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison
 |      operators.
 |      
 |      Equivalent to `==`, `!=`, `&lt;=`, `&lt;`, `&gt;=`, `&gt;` with support to choose axis
 |      (rows or columns) and level for comparison.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default &#39;columns&#39;
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;).
 |      level : int or label
 |          Broadcast across a level, matching Index values on the passed
 |          MultiIndex level.
 |      
 |      Returns
 |      -------
 |      DataFrame of bool
 |          Result of the comparison.
 |      
 |      See Also
 |      --------
 |      DataFrame.eq : Compare DataFrames for equality elementwise.
 |      DataFrame.ne : Compare DataFrames for inequality elementwise.
 |      DataFrame.le : Compare DataFrames for less than inequality
 |          or equality elementwise.
 |      DataFrame.lt : Compare DataFrames for strictly less than
 |          inequality elementwise.
 |      DataFrame.ge : Compare DataFrames for greater than inequality
 |          or equality elementwise.
 |      DataFrame.gt : Compare DataFrames for strictly greater than
 |          inequality elementwise.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      `NaN` values are considered different (i.e. `NaN` != `NaN`).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;cost&#39;: [250, 150, 100],
 |      ...                    &#39;revenue&#39;: [100, 250, 300]},
 |      ...                   index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; df
 |         cost  revenue
 |      A   250      100
 |      B   150      250
 |      C   100      300
 |      
 |      Comparison with a scalar, using either the operator or method:
 |      
 |      &gt;&gt;&gt; df == 100
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      &gt;&gt;&gt; df.eq(100)
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned
 |      with the index of `other` and broadcast:
 |      
 |      &gt;&gt;&gt; df != pd.Series([100, 250], index=[&quot;cost&quot;, &quot;revenue&quot;])
 |          cost  revenue
 |      A   True     True
 |      B   True    False
 |      C  False     True
 |      
 |      Use the method to control the broadcast axis:
 |      
 |      &gt;&gt;&gt; df.ne(pd.Series([100, 300], index=[&quot;A&quot;, &quot;D&quot;]), axis=&#39;index&#39;)
 |         cost  revenue
 |      A  True    False
 |      B  True     True
 |      C  True     True
 |      D  True     True
 |      
 |      When comparing to an arbitrary sequence, the number of columns must
 |      match the number elements in `other`:
 |      
 |      &gt;&gt;&gt; df == [250, 100]
 |          cost  revenue
 |      A   True     True
 |      B  False    False
 |      C  False    False
 |      
 |      Use the method to control the axis:
 |      
 |      &gt;&gt;&gt; df.eq([250, 250, 100], axis=&#39;index&#39;)
 |          cost  revenue
 |      A   True    False
 |      B  False     True
 |      C   True    False
 |      
 |      Compare to a DataFrame of different shape.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;revenue&#39;: [300, 250, 100, 150]},
 |      ...                      index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
 |      &gt;&gt;&gt; other
 |         revenue
 |      A      300
 |      B      250
 |      C      100
 |      D      150
 |      
 |      &gt;&gt;&gt; df.gt(other)
 |          cost  revenue
 |      A  False    False
 |      B  False    False
 |      C  False     True
 |      D  False    False
 |      
 |      Compare to a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;cost&#39;: [250, 150, 100, 150, 300, 220],
 |      ...                              &#39;revenue&#39;: [100, 250, 300, 200, 175, 225]},
 |      ...                             index=[[&#39;Q1&#39;, &#39;Q1&#39;, &#39;Q1&#39;, &#39;Q2&#39;, &#39;Q2&#39;, &#39;Q2&#39;],
 |      ...                                    [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |            cost  revenue
 |      Q1 A   250      100
 |         B   150      250
 |         C   100      300
 |      Q2 A   150      200
 |         B   300      175
 |         C   220      225
 |      
 |      &gt;&gt;&gt; df.le(df_multindex, level=1)
 |             cost  revenue
 |      Q1 A   True     True
 |         B   True     True
 |         C   True     True
 |      Q2 A  False     True
 |         B   True    False
 |         C   True    False
 |  
 |  eval(self, expr: &#39;str&#39;, inplace: &#39;bool&#39; = False, **kwargs)
 |      Evaluate a string describing operations on DataFrame columns.
 |      
 |      Operates on columns only, not specific rows or elements.  This allows
 |      `eval` to run arbitrary code, which can make you vulnerable to code
 |      injection if you pass user input to this function.
 |      
 |      Parameters
 |      ----------
 |      expr : str
 |          The expression string to evaluate.
 |      inplace : bool, default False
 |          If the expression contains an assignment, whether to perform the
 |          operation inplace and mutate the existing DataFrame. Otherwise,
 |          a new DataFrame is returned.
 |      **kwargs
 |          See the documentation for :func:`eval` for complete details
 |          on the keyword arguments accepted by
 |          :meth:`~pandas.DataFrame.query`.
 |      
 |      Returns
 |      -------
 |      ndarray, scalar, pandas object, or None
 |          The result of the evaluation or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      DataFrame.query : Evaluates a boolean expression to query the columns
 |          of a frame.
 |      DataFrame.assign : Can evaluate an expression or function to create new
 |          values for a column.
 |      eval : Evaluate a Python expression as a string using various
 |          backends.
 |      
 |      Notes
 |      -----
 |      For more details see the API documentation for :func:`~eval`.
 |      For detailed examples see :ref:`enhancing performance with eval
 |      &lt;enhancingperf.eval&gt;`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: range(1, 6), &#39;B&#39;: range(10, 0, -2)})
 |      &gt;&gt;&gt; df
 |         A   B
 |      0  1  10
 |      1  2   8
 |      2  3   6
 |      3  4   4
 |      4  5   2
 |      &gt;&gt;&gt; df.eval(&#39;A + B&#39;)
 |      0    11
 |      1    10
 |      2     9
 |      3     8
 |      4     7
 |      dtype: int64
 |      
 |      Assignment is allowed though by default the original DataFrame is not
 |      modified.
 |      
 |      &gt;&gt;&gt; df.eval(&#39;C = A + B&#39;)
 |         A   B   C
 |      0  1  10  11
 |      1  2   8  10
 |      2  3   6   9
 |      3  4   4   8
 |      4  5   2   7
 |      &gt;&gt;&gt; df
 |         A   B
 |      0  1  10
 |      1  2   8
 |      2  3   6
 |      3  4   4
 |      4  5   2
 |      
 |      Use ``inplace=True`` to modify the original DataFrame.
 |      
 |      &gt;&gt;&gt; df.eval(&#39;C = A + B&#39;, inplace=True)
 |      &gt;&gt;&gt; df
 |         A   B   C
 |      0  1  10  11
 |      1  2   8  10
 |      2  3   6   9
 |      3  4   4   8
 |      4  5   2   7
 |      
 |      Multiple columns can be assigned to using multi-line expressions:
 |      
 |      &gt;&gt;&gt; df.eval(
 |      ...     &#39;&#39;&#39;
 |      ... C = A + B
 |      ... D = A - B
 |      ... &#39;&#39;&#39;
 |      ... )
 |         A   B   C  D
 |      0  1  10  11 -9
 |      1  2   8  10 -6
 |      2  3   6   9 -3
 |      3  4   4   8  0
 |      4  5   2   7  3
 |  
 |  explode(self, column: &#39;str | tuple | list[str | tuple]&#39;, ignore_index: &#39;bool&#39; = False) -&gt; &#39;DataFrame&#39;
 |      Transform each element of a list-like to a row, replicating index values.
 |      
 |      .. versionadded:: 0.25.0
 |      
 |      Parameters
 |      ----------
 |      column : str or tuple or list thereof
 |          Column(s) to explode.
 |          For multiple columns, specify a non-empty list with each element
 |          be str or tuple, and all specified columns their list-like data
 |          on same row of the frame must have matching length.
 |      
 |          .. versionadded:: 1.3.0
 |              Multi-column explode
 |      
 |      ignore_index : bool, default False
 |          If True, the resulting index will be labeled 0, 1, …, n - 1.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Exploded lists to rows of the subset columns;
 |          index will be duplicated for these rows.
 |      
 |      Raises
 |      ------
 |      ValueError :
 |          * If columns of the frame are not unique.
 |          * If specified columns to explode is empty list.
 |          * If specified columns to explode have not matching count of
 |            elements rowwise in the frame.
 |      
 |      See Also
 |      --------
 |      DataFrame.unstack : Pivot a level of the (necessarily hierarchical)
 |          index labels.
 |      DataFrame.melt : Unpivot a DataFrame from wide format to long format.
 |      Series.explode : Explode a DataFrame from list-like columns to long format.
 |      
 |      Notes
 |      -----
 |      This routine will explode list-likes including lists, tuples, sets,
 |      Series, and np.ndarray. The result dtype of the subset rows will
 |      be object. Scalars will be returned unchanged, and empty list-likes will
 |      result in a np.nan for that row. In addition, the ordering of rows in the
 |      output will be non-deterministic when exploding sets.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [[0, 1, 2], &#39;foo&#39;, [], [3, 4]],
 |      ...                    &#39;B&#39;: 1,
 |      ...                    &#39;C&#39;: [[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], np.nan, [], [&#39;d&#39;, &#39;e&#39;]]})
 |      &gt;&gt;&gt; df
 |                 A  B          C
 |      0  [0, 1, 2]  1  [a, b, c]
 |      1        foo  1        NaN
 |      2         []  1         []
 |      3     [3, 4]  1     [d, e]
 |      
 |      Single-column explode.
 |      
 |      &gt;&gt;&gt; df.explode(&#39;A&#39;)
 |           A  B          C
 |      0    0  1  [a, b, c]
 |      0    1  1  [a, b, c]
 |      0    2  1  [a, b, c]
 |      1  foo  1        NaN
 |      2  NaN  1         []
 |      3    3  1     [d, e]
 |      3    4  1     [d, e]
 |      
 |      Multi-column explode.
 |      
 |      &gt;&gt;&gt; df.explode(list(&#39;AC&#39;))
 |           A  B    C
 |      0    0  1    a
 |      0    1  1    b
 |      0    2  1    c
 |      1  foo  1  NaN
 |      2  NaN  1  NaN
 |      3    3  1    d
 |      3    4  1    e
 |  
 |  ffill(self: &#39;DataFrame&#39;, axis: &#39;None | Axis&#39; = None, inplace: &#39;bool&#39; = False, limit: &#39;None | int&#39; = None, downcast=None) -&gt; &#39;DataFrame | None&#39;
 |      Synonym for :meth:`DataFrame.fillna` with ``method=&#39;ffill&#39;``.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame or None
 |          Object with missing values filled or None if ``inplace=True``.
 |  
 |  fillna(self, value: &#39;object | ArrayLike | None&#39; = None, method: &#39;FillnaOptions | None&#39; = None, axis: &#39;Axis | None&#39; = None, inplace: &#39;bool&#39; = False, limit=None, downcast=None) -&gt; &#39;DataFrame | None&#39;
 |      Fill NA/NaN values using the specified method.
 |      
 |      Parameters
 |      ----------
 |      value : scalar, dict, Series, or DataFrame
 |          Value to use to fill holes (e.g. 0), alternately a
 |          dict/Series/DataFrame of values specifying which value to use for
 |          each index (for a Series) or column (for a DataFrame).  Values not
 |          in the dict/Series/DataFrame will not be filled. This value cannot
 |          be a list.
 |      method : {&#39;backfill&#39;, &#39;bfill&#39;, &#39;pad&#39;, &#39;ffill&#39;, None}, default None
 |          Method to use for filling holes in reindexed Series
 |          pad / ffill: propagate last valid observation forward to next valid
 |          backfill / bfill: use next valid observation to fill gap.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Axis along which to fill missing values.
 |      inplace : bool, default False
 |          If True, fill in-place. Note: this will modify any
 |          other views on this object (e.g., a no-copy slice for a column in a
 |          DataFrame).
 |      limit : int, default None
 |          If method is specified, this is the maximum number of consecutive
 |          NaN values to forward/backward fill. In other words, if there is
 |          a gap with more than this number of consecutive NaNs, it will only
 |          be partially filled. If method is not specified, this is the
 |          maximum number of entries along the entire axis where NaNs will be
 |          filled. Must be greater than 0 if not None.
 |      downcast : dict, default is None
 |          A dict of item-&gt;dtype of what to downcast if possible,
 |          or the string &#39;infer&#39; which will try to downcast to an appropriate
 |          equal type (e.g. float64 to int64 if possible).
 |      
 |      Returns
 |      -------
 |      DataFrame or None
 |          Object with missing values filled or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      interpolate : Fill NaN values using interpolation.
 |      reindex : Conform object to new index.
 |      asfreq : Convert TimeSeries to specified frequency.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([[np.nan, 2, np.nan, 0],
 |      ...                    [3, 4, np.nan, 1],
 |      ...                    [np.nan, np.nan, np.nan, 5],
 |      ...                    [np.nan, 3, np.nan, 4]],
 |      ...                   columns=list(&quot;ABCD&quot;))
 |      &gt;&gt;&gt; df
 |           A    B   C  D
 |      0  NaN  2.0 NaN  0
 |      1  3.0  4.0 NaN  1
 |      2  NaN  NaN NaN  5
 |      3  NaN  3.0 NaN  4
 |      
 |      Replace all NaN elements with 0s.
 |      
 |      &gt;&gt;&gt; df.fillna(0)
 |          A   B   C   D
 |      0   0.0 2.0 0.0 0
 |      1   3.0 4.0 0.0 1
 |      2   0.0 0.0 0.0 5
 |      3   0.0 3.0 0.0 4
 |      
 |      We can also propagate non-null values forward or backward.
 |      
 |      &gt;&gt;&gt; df.fillna(method=&quot;ffill&quot;)
 |          A   B   C   D
 |      0   NaN 2.0 NaN 0
 |      1   3.0 4.0 NaN 1
 |      2   3.0 4.0 NaN 5
 |      3   3.0 3.0 NaN 4
 |      
 |      Replace all NaN elements in column &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, and &#39;D&#39;, with 0, 1,
 |      2, and 3 respectively.
 |      
 |      &gt;&gt;&gt; values = {&quot;A&quot;: 0, &quot;B&quot;: 1, &quot;C&quot;: 2, &quot;D&quot;: 3}
 |      &gt;&gt;&gt; df.fillna(value=values)
 |          A   B   C   D
 |      0   0.0 2.0 2.0 0
 |      1   3.0 4.0 2.0 1
 |      2   0.0 1.0 2.0 5
 |      3   0.0 3.0 2.0 4
 |      
 |      Only replace the first NaN element.
 |      
 |      &gt;&gt;&gt; df.fillna(value=values, limit=1)
 |          A   B   C   D
 |      0   0.0 2.0 2.0 0
 |      1   3.0 4.0 NaN 1
 |      2   NaN 1.0 NaN 5
 |      3   NaN 3.0 NaN 4
 |      
 |      When filling using a DataFrame, replacement happens along
 |      the same column names and same indices
 |      
 |      &gt;&gt;&gt; df2 = pd.DataFrame(np.zeros((4, 4)), columns=list(&quot;ABCE&quot;))
 |      &gt;&gt;&gt; df.fillna(df2)
 |          A   B   C   D
 |      0   0.0 2.0 0.0 0
 |      1   3.0 4.0 0.0 1
 |      2   0.0 0.0 0.0 5
 |      3   0.0 3.0 0.0 4
 |  
 |  floordiv(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Integer division of dataframe and other, element-wise (binary operator `floordiv`).
 |      
 |      Equivalent to ``dataframe // other``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `rfloordiv`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  ge(self, other, axis=&#39;columns&#39;, level=None)
 |      Get Greater than or equal to of dataframe and other, element-wise (binary operator `ge`).
 |      
 |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison
 |      operators.
 |      
 |      Equivalent to `==`, `!=`, `&lt;=`, `&lt;`, `&gt;=`, `&gt;` with support to choose axis
 |      (rows or columns) and level for comparison.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default &#39;columns&#39;
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;).
 |      level : int or label
 |          Broadcast across a level, matching Index values on the passed
 |          MultiIndex level.
 |      
 |      Returns
 |      -------
 |      DataFrame of bool
 |          Result of the comparison.
 |      
 |      See Also
 |      --------
 |      DataFrame.eq : Compare DataFrames for equality elementwise.
 |      DataFrame.ne : Compare DataFrames for inequality elementwise.
 |      DataFrame.le : Compare DataFrames for less than inequality
 |          or equality elementwise.
 |      DataFrame.lt : Compare DataFrames for strictly less than
 |          inequality elementwise.
 |      DataFrame.ge : Compare DataFrames for greater than inequality
 |          or equality elementwise.
 |      DataFrame.gt : Compare DataFrames for strictly greater than
 |          inequality elementwise.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      `NaN` values are considered different (i.e. `NaN` != `NaN`).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;cost&#39;: [250, 150, 100],
 |      ...                    &#39;revenue&#39;: [100, 250, 300]},
 |      ...                   index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; df
 |         cost  revenue
 |      A   250      100
 |      B   150      250
 |      C   100      300
 |      
 |      Comparison with a scalar, using either the operator or method:
 |      
 |      &gt;&gt;&gt; df == 100
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      &gt;&gt;&gt; df.eq(100)
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned
 |      with the index of `other` and broadcast:
 |      
 |      &gt;&gt;&gt; df != pd.Series([100, 250], index=[&quot;cost&quot;, &quot;revenue&quot;])
 |          cost  revenue
 |      A   True     True
 |      B   True    False
 |      C  False     True
 |      
 |      Use the method to control the broadcast axis:
 |      
 |      &gt;&gt;&gt; df.ne(pd.Series([100, 300], index=[&quot;A&quot;, &quot;D&quot;]), axis=&#39;index&#39;)
 |         cost  revenue
 |      A  True    False
 |      B  True     True
 |      C  True     True
 |      D  True     True
 |      
 |      When comparing to an arbitrary sequence, the number of columns must
 |      match the number elements in `other`:
 |      
 |      &gt;&gt;&gt; df == [250, 100]
 |          cost  revenue
 |      A   True     True
 |      B  False    False
 |      C  False    False
 |      
 |      Use the method to control the axis:
 |      
 |      &gt;&gt;&gt; df.eq([250, 250, 100], axis=&#39;index&#39;)
 |          cost  revenue
 |      A   True    False
 |      B  False     True
 |      C   True    False
 |      
 |      Compare to a DataFrame of different shape.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;revenue&#39;: [300, 250, 100, 150]},
 |      ...                      index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
 |      &gt;&gt;&gt; other
 |         revenue
 |      A      300
 |      B      250
 |      C      100
 |      D      150
 |      
 |      &gt;&gt;&gt; df.gt(other)
 |          cost  revenue
 |      A  False    False
 |      B  False    False
 |      C  False     True
 |      D  False    False
 |      
 |      Compare to a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;cost&#39;: [250, 150, 100, 150, 300, 220],
 |      ...                              &#39;revenue&#39;: [100, 250, 300, 200, 175, 225]},
 |      ...                             index=[[&#39;Q1&#39;, &#39;Q1&#39;, &#39;Q1&#39;, &#39;Q2&#39;, &#39;Q2&#39;, &#39;Q2&#39;],
 |      ...                                    [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |            cost  revenue
 |      Q1 A   250      100
 |         B   150      250
 |         C   100      300
 |      Q2 A   150      200
 |         B   300      175
 |         C   220      225
 |      
 |      &gt;&gt;&gt; df.le(df_multindex, level=1)
 |             cost  revenue
 |      Q1 A   True     True
 |         B   True     True
 |         C   True     True
 |      Q2 A  False     True
 |         B   True    False
 |         C   True    False
 |  
 |  groupby(self, by=None, axis: &#39;Axis&#39; = 0, level: &#39;Level | None&#39; = None, as_index: &#39;bool&#39; = True, sort: &#39;bool&#39; = True, group_keys: &#39;bool&#39; = True, squeeze: &#39;bool | lib.NoDefault&#39; = &lt;no_default&gt;, observed: &#39;bool&#39; = False, dropna: &#39;bool&#39; = True) -&gt; &#39;DataFrameGroupBy&#39;
 |      Group DataFrame using a mapper or by a Series of columns.
 |      
 |      A groupby operation involves some combination of splitting the
 |      object, applying a function, and combining the results. This can be
 |      used to group large amounts of data and compute operations on these
 |      groups.
 |      
 |      Parameters
 |      ----------
 |      by : mapping, function, label, or list of labels
 |          Used to determine the groups for the groupby.
 |          If ``by`` is a function, it&#39;s called on each value of the object&#39;s
 |          index. If a dict or Series is passed, the Series or dict VALUES
 |          will be used to determine the groups (the Series&#39; values are first
 |          aligned; see ``.align()`` method). If an ndarray is passed, the
 |          values are used as-is to determine the groups. A label or list of
 |          labels may be passed to group by the columns in ``self``. Notice
 |          that a tuple is interpreted as a (single) key.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Split along rows (0) or columns (1).
 |      level : int, level name, or sequence of such, default None
 |          If the axis is a MultiIndex (hierarchical), group by a particular
 |          level or levels.
 |      as_index : bool, default True
 |          For aggregated output, return object with group labels as the
 |          index. Only relevant for DataFrame input. as_index=False is
 |          effectively &quot;SQL-style&quot; grouped output.
 |      sort : bool, default True
 |          Sort group keys. Get better performance by turning this off.
 |          Note this does not influence the order of observations within each
 |          group. Groupby preserves the order of rows within each group.
 |      group_keys : bool, default True
 |          When calling apply, add group keys to index to identify pieces.
 |      squeeze : bool, default False
 |          Reduce the dimensionality of the return type if possible,
 |          otherwise return a consistent type.
 |      
 |          .. deprecated:: 1.1.0
 |      
 |      observed : bool, default False
 |          This only applies if any of the groupers are Categoricals.
 |          If True: only show observed values for categorical groupers.
 |          If False: show all values for categorical groupers.
 |      dropna : bool, default True
 |          If True, and if group keys contain NA values, NA values together
 |          with row/column will be dropped.
 |          If False, NA values will also be treated as the key in groups
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      DataFrameGroupBy
 |          Returns a groupby object that contains information about the groups.
 |      
 |      See Also
 |      --------
 |      resample : Convenience method for frequency conversion and resampling
 |          of time series.
 |      
 |      Notes
 |      -----
 |      See the `user guide
 |      &lt;https://pandas.pydata.org/pandas-docs/stable/groupby.html&gt;`__ for more.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;Animal&#39;: [&#39;Falcon&#39;, &#39;Falcon&#39;,
 |      ...                               &#39;Parrot&#39;, &#39;Parrot&#39;],
 |      ...                    &#39;Max Speed&#39;: [380., 370., 24., 26.]})
 |      &gt;&gt;&gt; df
 |         Animal  Max Speed
 |      0  Falcon      380.0
 |      1  Falcon      370.0
 |      2  Parrot       24.0
 |      3  Parrot       26.0
 |      &gt;&gt;&gt; df.groupby([&#39;Animal&#39;]).mean()
 |              Max Speed
 |      Animal
 |      Falcon      375.0
 |      Parrot       25.0
 |      
 |      **Hierarchical Indexes**
 |      
 |      We can groupby different levels of a hierarchical index
 |      using the `level` parameter:
 |      
 |      &gt;&gt;&gt; arrays = [[&#39;Falcon&#39;, &#39;Falcon&#39;, &#39;Parrot&#39;, &#39;Parrot&#39;],
 |      ...           [&#39;Captive&#39;, &#39;Wild&#39;, &#39;Captive&#39;, &#39;Wild&#39;]]
 |      &gt;&gt;&gt; index = pd.MultiIndex.from_arrays(arrays, names=(&#39;Animal&#39;, &#39;Type&#39;))
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;Max Speed&#39;: [390., 350., 30., 20.]},
 |      ...                   index=index)
 |      &gt;&gt;&gt; df
 |                      Max Speed
 |      Animal Type
 |      Falcon Captive      390.0
 |             Wild         350.0
 |      Parrot Captive       30.0
 |             Wild          20.0
 |      &gt;&gt;&gt; df.groupby(level=0).mean()
 |              Max Speed
 |      Animal
 |      Falcon      370.0
 |      Parrot       25.0
 |      &gt;&gt;&gt; df.groupby(level=&quot;Type&quot;).mean()
 |               Max Speed
 |      Type
 |      Captive      210.0
 |      Wild         185.0
 |      
 |      We can also choose to include NA in group keys or not by setting
 |      `dropna` parameter, the default setting is `True`:
 |      
 |      &gt;&gt;&gt; l = [[1, 2, 3], [1, None, 4], [2, 1, 3], [1, 2, 2]]
 |      &gt;&gt;&gt; df = pd.DataFrame(l, columns=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])
 |      
 |      &gt;&gt;&gt; df.groupby(by=[&quot;b&quot;]).sum()
 |          a   c
 |      b
 |      1.0 2   3
 |      2.0 2   5
 |      
 |      &gt;&gt;&gt; df.groupby(by=[&quot;b&quot;], dropna=False).sum()
 |          a   c
 |      b
 |      1.0 2   3
 |      2.0 2   5
 |      NaN 1   4
 |      
 |      &gt;&gt;&gt; l = [[&quot;a&quot;, 12, 12], [None, 12.3, 33.], [&quot;b&quot;, 12.3, 123], [&quot;a&quot;, 1, 1]]
 |      &gt;&gt;&gt; df = pd.DataFrame(l, columns=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])
 |      
 |      &gt;&gt;&gt; df.groupby(by=&quot;a&quot;).sum()
 |          b     c
 |      a
 |      a   13.0   13.0
 |      b   12.3  123.0
 |      
 |      &gt;&gt;&gt; df.groupby(by=&quot;a&quot;, dropna=False).sum()
 |          b     c
 |      a
 |      a   13.0   13.0
 |      b   12.3  123.0
 |      NaN 12.3   33.0
 |  
 |  gt(self, other, axis=&#39;columns&#39;, level=None)
 |      Get Greater than of dataframe and other, element-wise (binary operator `gt`).
 |      
 |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison
 |      operators.
 |      
 |      Equivalent to `==`, `!=`, `&lt;=`, `&lt;`, `&gt;=`, `&gt;` with support to choose axis
 |      (rows or columns) and level for comparison.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default &#39;columns&#39;
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;).
 |      level : int or label
 |          Broadcast across a level, matching Index values on the passed
 |          MultiIndex level.
 |      
 |      Returns
 |      -------
 |      DataFrame of bool
 |          Result of the comparison.
 |      
 |      See Also
 |      --------
 |      DataFrame.eq : Compare DataFrames for equality elementwise.
 |      DataFrame.ne : Compare DataFrames for inequality elementwise.
 |      DataFrame.le : Compare DataFrames for less than inequality
 |          or equality elementwise.
 |      DataFrame.lt : Compare DataFrames for strictly less than
 |          inequality elementwise.
 |      DataFrame.ge : Compare DataFrames for greater than inequality
 |          or equality elementwise.
 |      DataFrame.gt : Compare DataFrames for strictly greater than
 |          inequality elementwise.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      `NaN` values are considered different (i.e. `NaN` != `NaN`).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;cost&#39;: [250, 150, 100],
 |      ...                    &#39;revenue&#39;: [100, 250, 300]},
 |      ...                   index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; df
 |         cost  revenue
 |      A   250      100
 |      B   150      250
 |      C   100      300
 |      
 |      Comparison with a scalar, using either the operator or method:
 |      
 |      &gt;&gt;&gt; df == 100
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      &gt;&gt;&gt; df.eq(100)
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned
 |      with the index of `other` and broadcast:
 |      
 |      &gt;&gt;&gt; df != pd.Series([100, 250], index=[&quot;cost&quot;, &quot;revenue&quot;])
 |          cost  revenue
 |      A   True     True
 |      B   True    False
 |      C  False     True
 |      
 |      Use the method to control the broadcast axis:
 |      
 |      &gt;&gt;&gt; df.ne(pd.Series([100, 300], index=[&quot;A&quot;, &quot;D&quot;]), axis=&#39;index&#39;)
 |         cost  revenue
 |      A  True    False
 |      B  True     True
 |      C  True     True
 |      D  True     True
 |      
 |      When comparing to an arbitrary sequence, the number of columns must
 |      match the number elements in `other`:
 |      
 |      &gt;&gt;&gt; df == [250, 100]
 |          cost  revenue
 |      A   True     True
 |      B  False    False
 |      C  False    False
 |      
 |      Use the method to control the axis:
 |      
 |      &gt;&gt;&gt; df.eq([250, 250, 100], axis=&#39;index&#39;)
 |          cost  revenue
 |      A   True    False
 |      B  False     True
 |      C   True    False
 |      
 |      Compare to a DataFrame of different shape.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;revenue&#39;: [300, 250, 100, 150]},
 |      ...                      index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
 |      &gt;&gt;&gt; other
 |         revenue
 |      A      300
 |      B      250
 |      C      100
 |      D      150
 |      
 |      &gt;&gt;&gt; df.gt(other)
 |          cost  revenue
 |      A  False    False
 |      B  False    False
 |      C  False     True
 |      D  False    False
 |      
 |      Compare to a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;cost&#39;: [250, 150, 100, 150, 300, 220],
 |      ...                              &#39;revenue&#39;: [100, 250, 300, 200, 175, 225]},
 |      ...                             index=[[&#39;Q1&#39;, &#39;Q1&#39;, &#39;Q1&#39;, &#39;Q2&#39;, &#39;Q2&#39;, &#39;Q2&#39;],
 |      ...                                    [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |            cost  revenue
 |      Q1 A   250      100
 |         B   150      250
 |         C   100      300
 |      Q2 A   150      200
 |         B   300      175
 |         C   220      225
 |      
 |      &gt;&gt;&gt; df.le(df_multindex, level=1)
 |             cost  revenue
 |      Q1 A   True     True
 |         B   True     True
 |         C   True     True
 |      Q2 A  False     True
 |         B   True    False
 |         C   True    False
 |  
 |  hist = hist_frame(data: &#39;DataFrame&#39;, column: &#39;IndexLabel&#39; = None, by=None, grid: &#39;bool&#39; = True, xlabelsize: &#39;int | None&#39; = None, xrot: &#39;float | None&#39; = None, ylabelsize: &#39;int | None&#39; = None, yrot: &#39;float | None&#39; = None, ax=None, sharex: &#39;bool&#39; = False, sharey: &#39;bool&#39; = False, figsize: &#39;tuple[int, int] | None&#39; = None, layout: &#39;tuple[int, int] | None&#39; = None, bins: &#39;int | Sequence[int]&#39; = 10, backend: &#39;str | None&#39; = None, legend: &#39;bool&#39; = False, **kwargs)
 |      Make a histogram of the DataFrame&#39;s columns.
 |      
 |      A `histogram`_ is a representation of the distribution of data.
 |      This function calls :meth:`matplotlib.pyplot.hist`, on each series in
 |      the DataFrame, resulting in one histogram per column.
 |      
 |      .. _histogram: https://en.wikipedia.org/wiki/Histogram
 |      
 |      Parameters
 |      ----------
 |      data : DataFrame
 |          The pandas object holding the data.
 |      column : str or sequence, optional
 |          If passed, will be used to limit data to a subset of columns.
 |      by : object, optional
 |          If passed, then used to form histograms for separate groups.
 |      grid : bool, default True
 |          Whether to show axis grid lines.
 |      xlabelsize : int, default None
 |          If specified changes the x-axis label size.
 |      xrot : float, default None
 |          Rotation of x axis labels. For example, a value of 90 displays the
 |          x labels rotated 90 degrees clockwise.
 |      ylabelsize : int, default None
 |          If specified changes the y-axis label size.
 |      yrot : float, default None
 |          Rotation of y axis labels. For example, a value of 90 displays the
 |          y labels rotated 90 degrees clockwise.
 |      ax : Matplotlib axes object, default None
 |          The axes to plot the histogram on.
 |      sharex : bool, default True if ax is None else False
 |          In case subplots=True, share x axis and set some x axis labels to
 |          invisible; defaults to True if ax is None otherwise False if an ax
 |          is passed in.
 |          Note that passing in both an ax and sharex=True will alter all x axis
 |          labels for all subplots in a figure.
 |      sharey : bool, default False
 |          In case subplots=True, share y axis and set some y axis labels to
 |          invisible.
 |      figsize : tuple, optional
 |          The size in inches of the figure to create. Uses the value in
 |          `matplotlib.rcParams` by default.
 |      layout : tuple, optional
 |          Tuple of (rows, columns) for the layout of the histograms.
 |      bins : int or sequence, default 10
 |          Number of histogram bins to be used. If an integer is given, bins + 1
 |          bin edges are calculated and returned. If bins is a sequence, gives
 |          bin edges, including left edge of first bin and right edge of last
 |          bin. In this case, bins is returned unmodified.
 |      
 |      backend : str, default None
 |          Backend to use instead of the backend specified in the option
 |          ``plotting.backend``. For instance, &#39;matplotlib&#39;. Alternatively, to
 |          specify the ``plotting.backend`` for the whole session, set
 |          ``pd.options.plotting.backend``.
 |      
 |          .. versionadded:: 1.0.0
 |      
 |      legend : bool, default False
 |          Whether to show the legend.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      **kwargs
 |          All other plotting keyword arguments to be passed to
 |          :meth:`matplotlib.pyplot.hist`.
 |      
 |      Returns
 |      -------
 |      matplotlib.AxesSubplot or numpy.ndarray of them
 |      
 |      See Also
 |      --------
 |      matplotlib.pyplot.hist : Plot a histogram using matplotlib.
 |      
 |      Examples
 |      --------
 |      This example draws a histogram based on the length and width of
 |      some animals, displayed in three bins
 |      
 |      .. plot::
 |          :context: close-figs
 |      
 |          &gt;&gt;&gt; df = pd.DataFrame({
 |          ...     &#39;length&#39;: [1.5, 0.5, 1.2, 0.9, 3],
 |          ...     &#39;width&#39;: [0.7, 0.2, 0.15, 0.2, 1.1]
 |          ...     }, index=[&#39;pig&#39;, &#39;rabbit&#39;, &#39;duck&#39;, &#39;chicken&#39;, &#39;horse&#39;])
 |          &gt;&gt;&gt; hist = df.hist(bins=3)
 |  
 |  idxmax(self, axis: &#39;Axis&#39; = 0, skipna: &#39;bool&#39; = True) -&gt; &#39;Series&#39;
 |      Return index of first occurrence of maximum over requested axis.
 |      
 |      NA/null values are excluded.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to use. 0 or &#39;index&#39; for row-wise, 1 or &#39;columns&#39; for column-wise.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      
 |      Returns
 |      -------
 |      Series
 |          Indexes of maxima along the specified axis.
 |      
 |      Raises
 |      ------
 |      ValueError
 |          * If the row/column is empty
 |      
 |      See Also
 |      --------
 |      Series.idxmax : Return index of the maximum element.
 |      
 |      Notes
 |      -----
 |      This method is the DataFrame version of ``ndarray.argmax``.
 |      
 |      Examples
 |      --------
 |      Consider a dataset containing food consumption in Argentina.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;consumption&#39;: [10.51, 103.11, 55.48],
 |      ...                    &#39;co2_emissions&#39;: [37.2, 19.66, 1712]},
 |      ...                    index=[&#39;Pork&#39;, &#39;Wheat Products&#39;, &#39;Beef&#39;])
 |      
 |      &gt;&gt;&gt; df
 |                      consumption  co2_emissions
 |      Pork                  10.51         37.20
 |      Wheat Products       103.11         19.66
 |      Beef                  55.48       1712.00
 |      
 |      By default, it returns the index for the maximum value in each column.
 |      
 |      &gt;&gt;&gt; df.idxmax()
 |      consumption     Wheat Products
 |      co2_emissions             Beef
 |      dtype: object
 |      
 |      To return the index for the maximum value in each row, use ``axis=&quot;columns&quot;``.
 |      
 |      &gt;&gt;&gt; df.idxmax(axis=&quot;columns&quot;)
 |      Pork              co2_emissions
 |      Wheat Products     consumption
 |      Beef              co2_emissions
 |      dtype: object
 |  
 |  idxmin(self, axis: &#39;Axis&#39; = 0, skipna: &#39;bool&#39; = True) -&gt; &#39;Series&#39;
 |      Return index of first occurrence of minimum over requested axis.
 |      
 |      NA/null values are excluded.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to use. 0 or &#39;index&#39; for row-wise, 1 or &#39;columns&#39; for column-wise.
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      
 |      Returns
 |      -------
 |      Series
 |          Indexes of minima along the specified axis.
 |      
 |      Raises
 |      ------
 |      ValueError
 |          * If the row/column is empty
 |      
 |      See Also
 |      --------
 |      Series.idxmin : Return index of the minimum element.
 |      
 |      Notes
 |      -----
 |      This method is the DataFrame version of ``ndarray.argmin``.
 |      
 |      Examples
 |      --------
 |      Consider a dataset containing food consumption in Argentina.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;consumption&#39;: [10.51, 103.11, 55.48],
 |      ...                    &#39;co2_emissions&#39;: [37.2, 19.66, 1712]},
 |      ...                    index=[&#39;Pork&#39;, &#39;Wheat Products&#39;, &#39;Beef&#39;])
 |      
 |      &gt;&gt;&gt; df
 |                      consumption  co2_emissions
 |      Pork                  10.51         37.20
 |      Wheat Products       103.11         19.66
 |      Beef                  55.48       1712.00
 |      
 |      By default, it returns the index for the minimum value in each column.
 |      
 |      &gt;&gt;&gt; df.idxmin()
 |      consumption                Pork
 |      co2_emissions    Wheat Products
 |      dtype: object
 |      
 |      To return the index for the minimum value in each row, use ``axis=&quot;columns&quot;``.
 |      
 |      &gt;&gt;&gt; df.idxmin(axis=&quot;columns&quot;)
 |      Pork                consumption
 |      Wheat Products    co2_emissions
 |      Beef                consumption
 |      dtype: object
 |  
 |  info(self, verbose: &#39;bool | None&#39; = None, buf: &#39;IO[str] | None&#39; = None, max_cols: &#39;int | None&#39; = None, memory_usage: &#39;bool | str | None&#39; = None, show_counts: &#39;bool | None&#39; = None, null_counts: &#39;bool | None&#39; = None) -&gt; &#39;None&#39;
 |      Print a concise summary of a DataFrame.
 |      
 |      This method prints information about a DataFrame including
 |      the index dtype and columns, non-null values and memory usage.
 |      
 |      Parameters
 |      ----------
 |      data : DataFrame
 |          DataFrame to print information about.
 |      verbose : bool, optional
 |          Whether to print the full summary. By default, the setting in
 |          ``pandas.options.display.max_info_columns`` is followed.
 |      buf : writable buffer, defaults to sys.stdout
 |          Where to send the output. By default, the output is printed to
 |          sys.stdout. Pass a writable buffer if you need to further process
 |          the output.
 |      max_cols : int, optional
 |          When to switch from the verbose to the truncated output. If the
 |          DataFrame has more than `max_cols` columns, the truncated output
 |          is used. By default, the setting in
 |          ``pandas.options.display.max_info_columns`` is used.
 |      memory_usage : bool, str, optional
 |          Specifies whether total memory usage of the DataFrame
 |          elements (including the index) should be displayed. By default,
 |          this follows the ``pandas.options.display.memory_usage`` setting.
 |      
 |          True always show memory usage. False never shows memory usage.
 |          A value of &#39;deep&#39; is equivalent to &quot;True with deep introspection&quot;.
 |          Memory usage is shown in human-readable units (base-2
 |          representation). Without deep introspection a memory estimation is
 |          made based in column dtype and number of rows assuming values
 |          consume the same memory amount for corresponding dtypes. With deep
 |          memory introspection, a real memory usage calculation is performed
 |          at the cost of computational resources.
 |      show_counts : bool, optional
 |          Whether to show the non-null counts. By default, this is shown
 |          only if the DataFrame is smaller than
 |          ``pandas.options.display.max_info_rows`` and
 |          ``pandas.options.display.max_info_columns``. A value of True always
 |          shows the counts, and False never shows the counts.
 |      null_counts : bool, optional
 |          .. deprecated:: 1.2.0
 |              Use show_counts instead.
 |      
 |      Returns
 |      -------
 |      None
 |          This method prints a summary of a DataFrame and returns None.
 |      
 |      See Also
 |      --------
 |      DataFrame.describe: Generate descriptive statistics of DataFrame
 |          columns.
 |      DataFrame.memory_usage: Memory usage of DataFrame columns.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; int_values = [1, 2, 3, 4, 5]
 |      &gt;&gt;&gt; text_values = [&#39;alpha&#39;, &#39;beta&#39;, &#39;gamma&#39;, &#39;delta&#39;, &#39;epsilon&#39;]
 |      &gt;&gt;&gt; float_values = [0.0, 0.25, 0.5, 0.75, 1.0]
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;int_col&quot;: int_values, &quot;text_col&quot;: text_values,
 |      ...                   &quot;float_col&quot;: float_values})
 |      &gt;&gt;&gt; df
 |          int_col text_col  float_col
 |      0        1    alpha       0.00
 |      1        2     beta       0.25
 |      2        3    gamma       0.50
 |      3        4    delta       0.75
 |      4        5  epsilon       1.00
 |      
 |      Prints information of all columns:
 |      
 |      &gt;&gt;&gt; df.info(verbose=True)
 |      &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
 |      RangeIndex: 5 entries, 0 to 4
 |      Data columns (total 3 columns):
 |       #   Column     Non-Null Count  Dtype
 |      ---  ------     --------------  -----
 |       0   int_col    5 non-null      int64
 |       1   text_col   5 non-null      object
 |       2   float_col  5 non-null      float64
 |      dtypes: float64(1), int64(1), object(1)
 |      memory usage: 248.0+ bytes
 |      
 |      Prints a summary of columns count and its dtypes but not per column
 |      information:
 |      
 |      &gt;&gt;&gt; df.info(verbose=False)
 |      &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
 |      RangeIndex: 5 entries, 0 to 4
 |      Columns: 3 entries, int_col to float_col
 |      dtypes: float64(1), int64(1), object(1)
 |      memory usage: 248.0+ bytes
 |      
 |      Pipe output of DataFrame.info to buffer instead of sys.stdout, get
 |      buffer content and writes to a text file:
 |      
 |      &gt;&gt;&gt; import io
 |      &gt;&gt;&gt; buffer = io.StringIO()
 |      &gt;&gt;&gt; df.info(buf=buffer)
 |      &gt;&gt;&gt; s = buffer.getvalue()
 |      &gt;&gt;&gt; with open(&quot;df_info.txt&quot;, &quot;w&quot;,
 |      ...           encoding=&quot;utf-8&quot;) as f:  # doctest: +SKIP
 |      ...     f.write(s)
 |      260
 |      
 |      The `memory_usage` parameter allows deep introspection mode, specially
 |      useful for big DataFrames and fine-tune memory optimization:
 |      
 |      &gt;&gt;&gt; random_strings_array = np.random.choice([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], 10 ** 6)
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;column_1&#39;: np.random.choice([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], 10 ** 6),
 |      ...     &#39;column_2&#39;: np.random.choice([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], 10 ** 6),
 |      ...     &#39;column_3&#39;: np.random.choice([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], 10 ** 6)
 |      ... })
 |      &gt;&gt;&gt; df.info()
 |      &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
 |      RangeIndex: 1000000 entries, 0 to 999999
 |      Data columns (total 3 columns):
 |       #   Column    Non-Null Count    Dtype
 |      ---  ------    --------------    -----
 |       0   column_1  1000000 non-null  object
 |       1   column_2  1000000 non-null  object
 |       2   column_3  1000000 non-null  object
 |      dtypes: object(3)
 |      memory usage: 22.9+ MB
 |      
 |      &gt;&gt;&gt; df.info(memory_usage=&#39;deep&#39;)
 |      &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
 |      RangeIndex: 1000000 entries, 0 to 999999
 |      Data columns (total 3 columns):
 |       #   Column    Non-Null Count    Dtype
 |      ---  ------    --------------    -----
 |       0   column_1  1000000 non-null  object
 |       1   column_2  1000000 non-null  object
 |       2   column_3  1000000 non-null  object
 |      dtypes: object(3)
 |      memory usage: 165.9 MB
 |  
 |  insert(self, loc, column, value, allow_duplicates: &#39;bool&#39; = False) -&gt; &#39;None&#39;
 |      Insert column into DataFrame at specified location.
 |      
 |      Raises a ValueError if `column` is already contained in the DataFrame,
 |      unless `allow_duplicates` is set to True.
 |      
 |      Parameters
 |      ----------
 |      loc : int
 |          Insertion index. Must verify 0 &lt;= loc &lt;= len(columns).
 |      column : str, number, or hashable object
 |          Label of the inserted column.
 |      value : int, Series, or array-like
 |      allow_duplicates : bool, optional
 |      
 |      See Also
 |      --------
 |      Index.insert : Insert new item by index.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]})
 |      &gt;&gt;&gt; df
 |         col1  col2
 |      0     1     3
 |      1     2     4
 |      &gt;&gt;&gt; df.insert(1, &quot;newcol&quot;, [99, 99])
 |      &gt;&gt;&gt; df
 |         col1  newcol  col2
 |      0     1      99     3
 |      1     2      99     4
 |      &gt;&gt;&gt; df.insert(0, &quot;col1&quot;, [100, 100], allow_duplicates=True)
 |      &gt;&gt;&gt; df
 |         col1  col1  newcol  col2
 |      0   100     1      99     3
 |      1   100     2      99     4
 |      
 |      Notice that pandas uses index alignment in case of `value` from type `Series`:
 |      
 |      &gt;&gt;&gt; df.insert(0, &quot;col0&quot;, pd.Series([5, 6], index=[1, 2]))
 |      &gt;&gt;&gt; df
 |         col0  col1  col1  newcol  col2
 |      0   NaN   100     1      99     3
 |      1   5.0   100     2      99     4
 |  
 |  interpolate(self: &#39;DataFrame&#39;, method: &#39;str&#39; = &#39;linear&#39;, axis: &#39;Axis&#39; = 0, limit: &#39;int | None&#39; = None, inplace: &#39;bool&#39; = False, limit_direction: &#39;str | None&#39; = None, limit_area: &#39;str | None&#39; = None, downcast: &#39;str | None&#39; = None, **kwargs) -&gt; &#39;DataFrame | None&#39;
 |      Fill NaN values using an interpolation method.
 |      
 |      Please note that only ``method=&#39;linear&#39;`` is supported for
 |      DataFrame/Series with a MultiIndex.
 |      
 |      Parameters
 |      ----------
 |      method : str, default &#39;linear&#39;
 |          Interpolation technique to use. One of:
 |      
 |          * &#39;linear&#39;: Ignore the index and treat the values as equally
 |            spaced. This is the only method supported on MultiIndexes.
 |          * &#39;time&#39;: Works on daily and higher resolution data to interpolate
 |            given length of interval.
 |          * &#39;index&#39;, &#39;values&#39;: use the actual numerical values of the index.
 |          * &#39;pad&#39;: Fill in NaNs using existing values.
 |          * &#39;nearest&#39;, &#39;zero&#39;, &#39;slinear&#39;, &#39;quadratic&#39;, &#39;cubic&#39;, &#39;spline&#39;,
 |            &#39;barycentric&#39;, &#39;polynomial&#39;: Passed to
 |            `scipy.interpolate.interp1d`. These methods use the numerical
 |            values of the index.  Both &#39;polynomial&#39; and &#39;spline&#39; require that
 |            you also specify an `order` (int), e.g.
 |            ``df.interpolate(method=&#39;polynomial&#39;, order=5)``.
 |          * &#39;krogh&#39;, &#39;piecewise_polynomial&#39;, &#39;spline&#39;, &#39;pchip&#39;, &#39;akima&#39;,
 |            &#39;cubicspline&#39;: Wrappers around the SciPy interpolation methods of
 |            similar names. See `Notes`.
 |          * &#39;from_derivatives&#39;: Refers to
 |            `scipy.interpolate.BPoly.from_derivatives` which
 |            replaces &#39;piecewise_polynomial&#39; interpolation method in
 |            scipy 0.18.
 |      
 |      axis : {{0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}}, default None
 |          Axis to interpolate along.
 |      limit : int, optional
 |          Maximum number of consecutive NaNs to fill. Must be greater than
 |          0.
 |      inplace : bool, default False
 |          Update the data in place if possible.
 |      limit_direction : {{&#39;forward&#39;, &#39;backward&#39;, &#39;both&#39;}}, Optional
 |          Consecutive NaNs will be filled in this direction.
 |      
 |          If limit is specified:
 |              * If &#39;method&#39; is &#39;pad&#39; or &#39;ffill&#39;, &#39;limit_direction&#39; must be &#39;forward&#39;.
 |              * If &#39;method&#39; is &#39;backfill&#39; or &#39;bfill&#39;, &#39;limit_direction&#39; must be
 |                &#39;backwards&#39;.
 |      
 |          If &#39;limit&#39; is not specified:
 |              * If &#39;method&#39; is &#39;backfill&#39; or &#39;bfill&#39;, the default is &#39;backward&#39;
 |              * else the default is &#39;forward&#39;
 |      
 |          .. versionchanged:: 1.1.0
 |              raises ValueError if `limit_direction` is &#39;forward&#39; or &#39;both&#39; and
 |                  method is &#39;backfill&#39; or &#39;bfill&#39;.
 |              raises ValueError if `limit_direction` is &#39;backward&#39; or &#39;both&#39; and
 |                  method is &#39;pad&#39; or &#39;ffill&#39;.
 |      
 |      limit_area : {{`None`, &#39;inside&#39;, &#39;outside&#39;}}, default None
 |          If limit is specified, consecutive NaNs will be filled with this
 |          restriction.
 |      
 |          * ``None``: No fill restriction.
 |          * &#39;inside&#39;: Only fill NaNs surrounded by valid values
 |            (interpolate).
 |          * &#39;outside&#39;: Only fill NaNs outside valid values (extrapolate).
 |      
 |      downcast : optional, &#39;infer&#39; or None, defaults to None
 |          Downcast dtypes if possible.
 |      ``**kwargs`` : optional
 |          Keyword arguments to pass on to the interpolating function.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame or None
 |          Returns the same object type as the caller, interpolated at
 |          some or all ``NaN`` values or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      fillna : Fill missing values using different methods.
 |      scipy.interpolate.Akima1DInterpolator : Piecewise cubic polynomials
 |          (Akima interpolator).
 |      scipy.interpolate.BPoly.from_derivatives : Piecewise polynomial in the
 |          Bernstein basis.
 |      scipy.interpolate.interp1d : Interpolate a 1-D function.
 |      scipy.interpolate.KroghInterpolator : Interpolate polynomial (Krogh
 |          interpolator).
 |      scipy.interpolate.PchipInterpolator : PCHIP 1-d monotonic cubic
 |          interpolation.
 |      scipy.interpolate.CubicSpline : Cubic spline data interpolator.
 |      
 |      Notes
 |      -----
 |      The &#39;krogh&#39;, &#39;piecewise_polynomial&#39;, &#39;spline&#39;, &#39;pchip&#39; and &#39;akima&#39;
 |      methods are wrappers around the respective SciPy implementations of
 |      similar names. These use the actual numerical values of the index.
 |      For more information on their behavior, see the
 |      `SciPy documentation
 |      &lt;https://docs.scipy.org/doc/scipy/reference/interpolate.html#univariate-interpolation&gt;`__
 |      and `SciPy tutorial
 |      &lt;https://docs.scipy.org/doc/scipy/reference/tutorial/interpolate.html&gt;`__.
 |      
 |      Examples
 |      --------
 |      Filling in ``NaN`` in a :class:`~pandas.Series` via linear
 |      interpolation.
 |      
 |      &gt;&gt;&gt; s = pd.Series([0, 1, np.nan, 3])
 |      &gt;&gt;&gt; s
 |      0    0.0
 |      1    1.0
 |      2    NaN
 |      3    3.0
 |      dtype: float64
 |      &gt;&gt;&gt; s.interpolate()
 |      0    0.0
 |      1    1.0
 |      2    2.0
 |      3    3.0
 |      dtype: float64
 |      
 |      Filling in ``NaN`` in a Series by padding, but filling at most two
 |      consecutive ``NaN`` at a time.
 |      
 |      &gt;&gt;&gt; s = pd.Series([np.nan, &quot;single_one&quot;, np.nan,
 |      ...                &quot;fill_two_more&quot;, np.nan, np.nan, np.nan,
 |      ...                4.71, np.nan])
 |      &gt;&gt;&gt; s
 |      0              NaN
 |      1       single_one
 |      2              NaN
 |      3    fill_two_more
 |      4              NaN
 |      5              NaN
 |      6              NaN
 |      7             4.71
 |      8              NaN
 |      dtype: object
 |      &gt;&gt;&gt; s.interpolate(method=&#39;pad&#39;, limit=2)
 |      0              NaN
 |      1       single_one
 |      2       single_one
 |      3    fill_two_more
 |      4    fill_two_more
 |      5    fill_two_more
 |      6              NaN
 |      7             4.71
 |      8             4.71
 |      dtype: object
 |      
 |      Filling in ``NaN`` in a Series via polynomial interpolation or splines:
 |      Both &#39;polynomial&#39; and &#39;spline&#39; methods require that you also specify
 |      an ``order`` (int).
 |      
 |      &gt;&gt;&gt; s = pd.Series([0, 2, np.nan, 8])
 |      &gt;&gt;&gt; s.interpolate(method=&#39;polynomial&#39;, order=2)
 |      0    0.000000
 |      1    2.000000
 |      2    4.666667
 |      3    8.000000
 |      dtype: float64
 |      
 |      Fill the DataFrame forward (that is, going down) along each column
 |      using linear interpolation.
 |      
 |      Note how the last entry in column &#39;a&#39; is interpolated differently,
 |      because there is no entry after it to use for interpolation.
 |      Note how the first entry in column &#39;b&#39; remains ``NaN``, because there
 |      is no entry before it to use for interpolation.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([(0.0, np.nan, -1.0, 1.0),
 |      ...                    (np.nan, 2.0, np.nan, np.nan),
 |      ...                    (2.0, 3.0, np.nan, 9.0),
 |      ...                    (np.nan, 4.0, -4.0, 16.0)],
 |      ...                   columns=list(&#39;abcd&#39;))
 |      &gt;&gt;&gt; df
 |           a    b    c     d
 |      0  0.0  NaN -1.0   1.0
 |      1  NaN  2.0  NaN   NaN
 |      2  2.0  3.0  NaN   9.0
 |      3  NaN  4.0 -4.0  16.0
 |      &gt;&gt;&gt; df.interpolate(method=&#39;linear&#39;, limit_direction=&#39;forward&#39;, axis=0)
 |           a    b    c     d
 |      0  0.0  NaN -1.0   1.0
 |      1  1.0  2.0 -2.0   5.0
 |      2  2.0  3.0 -3.0   9.0
 |      3  2.0  4.0 -4.0  16.0
 |      
 |      Using polynomial interpolation.
 |      
 |      &gt;&gt;&gt; df[&#39;d&#39;].interpolate(method=&#39;polynomial&#39;, order=2)
 |      0     1.0
 |      1     4.0
 |      2     9.0
 |      3    16.0
 |      Name: d, dtype: float64
 |  
 |  isin(self, values) -&gt; &#39;DataFrame&#39;
 |      Whether each element in the DataFrame is contained in values.
 |      
 |      Parameters
 |      ----------
 |      values : iterable, Series, DataFrame or dict
 |          The result will only be true at a location if all the
 |          labels match. If `values` is a Series, that&#39;s the index. If
 |          `values` is a dict, the keys must be the column names,
 |          which must match. If `values` is a DataFrame,
 |          then both the index and column labels must match.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          DataFrame of booleans showing whether each element in the DataFrame
 |          is contained in values.
 |      
 |      See Also
 |      --------
 |      DataFrame.eq: Equality test for DataFrame.
 |      Series.isin: Equivalent method on Series.
 |      Series.str.contains: Test if pattern or regex is contained within a
 |          string of a Series or Index.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;num_legs&#39;: [2, 4], &#39;num_wings&#39;: [2, 0]},
 |      ...                   index=[&#39;falcon&#39;, &#39;dog&#39;])
 |      &gt;&gt;&gt; df
 |              num_legs  num_wings
 |      falcon         2          2
 |      dog            4          0
 |      
 |      When ``values`` is a list check whether every value in the DataFrame
 |      is present in the list (which animals have 0 or 2 legs or wings)
 |      
 |      &gt;&gt;&gt; df.isin([0, 2])
 |              num_legs  num_wings
 |      falcon      True       True
 |      dog        False       True
 |      
 |      When ``values`` is a dict, we can pass values to check for each
 |      column separately:
 |      
 |      &gt;&gt;&gt; df.isin({&#39;num_wings&#39;: [0, 3]})
 |              num_legs  num_wings
 |      falcon     False      False
 |      dog        False       True
 |      
 |      When ``values`` is a Series or DataFrame the index and column must
 |      match. Note that &#39;falcon&#39; does not match based on the number of legs
 |      in df2.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;num_legs&#39;: [8, 2], &#39;num_wings&#39;: [0, 2]},
 |      ...                      index=[&#39;spider&#39;, &#39;falcon&#39;])
 |      &gt;&gt;&gt; df.isin(other)
 |              num_legs  num_wings
 |      falcon      True       True
 |      dog        False      False
 |  
 |  isna(self) -&gt; &#39;DataFrame&#39;
 |      Detect missing values.
 |      
 |      Return a boolean same-sized object indicating if the values are NA.
 |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True
 |      values.
 |      Everything else gets mapped to False values. Characters such as empty
 |      strings ``&#39;&#39;`` or :attr:`numpy.inf` are not considered NA values
 |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Mask of bool values for each element in DataFrame that
 |          indicates whether an element is an NA value.
 |      
 |      See Also
 |      --------
 |      DataFrame.isnull : Alias of isna.
 |      DataFrame.notna : Boolean inverse of isna.
 |      DataFrame.dropna : Omit axes labels with missing values.
 |      isna : Top-level isna.
 |      
 |      Examples
 |      --------
 |      Show which entries in a DataFrame are NA.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(dict(age=[5, 6, np.NaN],
 |      ...                    born=[pd.NaT, pd.Timestamp(&#39;1939-05-27&#39;),
 |      ...                          pd.Timestamp(&#39;1940-04-25&#39;)],
 |      ...                    name=[&#39;Alfred&#39;, &#39;Batman&#39;, &#39;&#39;],
 |      ...                    toy=[None, &#39;Batmobile&#39;, &#39;Joker&#39;]))
 |      &gt;&gt;&gt; df
 |         age       born    name        toy
 |      0  5.0        NaT  Alfred       None
 |      1  6.0 1939-05-27  Batman  Batmobile
 |      2  NaN 1940-04-25              Joker
 |      
 |      &gt;&gt;&gt; df.isna()
 |           age   born   name    toy
 |      0  False   True  False   True
 |      1  False  False  False  False
 |      2   True  False  False  False
 |      
 |      Show which entries in a Series are NA.
 |      
 |      &gt;&gt;&gt; ser = pd.Series([5, 6, np.NaN])
 |      &gt;&gt;&gt; ser
 |      0    5.0
 |      1    6.0
 |      2    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; ser.isna()
 |      0    False
 |      1    False
 |      2     True
 |      dtype: bool
 |  
 |  isnull(self) -&gt; &#39;DataFrame&#39;
 |      Detect missing values.
 |      
 |      Return a boolean same-sized object indicating if the values are NA.
 |      NA values, such as None or :attr:`numpy.NaN`, gets mapped to True
 |      values.
 |      Everything else gets mapped to False values. Characters such as empty
 |      strings ``&#39;&#39;`` or :attr:`numpy.inf` are not considered NA values
 |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Mask of bool values for each element in DataFrame that
 |          indicates whether an element is an NA value.
 |      
 |      See Also
 |      --------
 |      DataFrame.isnull : Alias of isna.
 |      DataFrame.notna : Boolean inverse of isna.
 |      DataFrame.dropna : Omit axes labels with missing values.
 |      isna : Top-level isna.
 |      
 |      Examples
 |      --------
 |      Show which entries in a DataFrame are NA.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(dict(age=[5, 6, np.NaN],
 |      ...                    born=[pd.NaT, pd.Timestamp(&#39;1939-05-27&#39;),
 |      ...                          pd.Timestamp(&#39;1940-04-25&#39;)],
 |      ...                    name=[&#39;Alfred&#39;, &#39;Batman&#39;, &#39;&#39;],
 |      ...                    toy=[None, &#39;Batmobile&#39;, &#39;Joker&#39;]))
 |      &gt;&gt;&gt; df
 |         age       born    name        toy
 |      0  5.0        NaT  Alfred       None
 |      1  6.0 1939-05-27  Batman  Batmobile
 |      2  NaN 1940-04-25              Joker
 |      
 |      &gt;&gt;&gt; df.isna()
 |           age   born   name    toy
 |      0  False   True  False   True
 |      1  False  False  False  False
 |      2   True  False  False  False
 |      
 |      Show which entries in a Series are NA.
 |      
 |      &gt;&gt;&gt; ser = pd.Series([5, 6, np.NaN])
 |      &gt;&gt;&gt; ser
 |      0    5.0
 |      1    6.0
 |      2    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; ser.isna()
 |      0    False
 |      1    False
 |      2     True
 |      dtype: bool
 |  
 |  items(self) -&gt; &#39;Iterable[tuple[Hashable, Series]]&#39;
 |      Iterate over (column name, Series) pairs.
 |      
 |      Iterates over the DataFrame columns, returning a tuple with
 |      the column name and the content as a Series.
 |      
 |      Yields
 |      ------
 |      label : object
 |          The column names for the DataFrame being iterated over.
 |      content : Series
 |          The column entries belonging to each label, as a Series.
 |      
 |      See Also
 |      --------
 |      DataFrame.iterrows : Iterate over DataFrame rows as
 |          (index, Series) pairs.
 |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples
 |          of the values.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;species&#39;: [&#39;bear&#39;, &#39;bear&#39;, &#39;marsupial&#39;],
 |      ...                   &#39;population&#39;: [1864, 22000, 80000]},
 |      ...                   index=[&#39;panda&#39;, &#39;polar&#39;, &#39;koala&#39;])
 |      &gt;&gt;&gt; df
 |              species   population
 |      panda   bear      1864
 |      polar   bear      22000
 |      koala   marsupial 80000
 |      &gt;&gt;&gt; for label, content in df.items():
 |      ...     print(f&#39;label: {label}&#39;)
 |      ...     print(f&#39;content: {content}&#39;, sep=&#39;\n&#39;)
 |      ...
 |      label: species
 |      content:
 |      panda         bear
 |      polar         bear
 |      koala    marsupial
 |      Name: species, dtype: object
 |      label: population
 |      content:
 |      panda     1864
 |      polar    22000
 |      koala    80000
 |      Name: population, dtype: int64
 |  
 |  iteritems(self) -&gt; &#39;Iterable[tuple[Hashable, Series]]&#39;
 |      Iterate over (column name, Series) pairs.
 |      
 |      Iterates over the DataFrame columns, returning a tuple with
 |      the column name and the content as a Series.
 |      
 |      Yields
 |      ------
 |      label : object
 |          The column names for the DataFrame being iterated over.
 |      content : Series
 |          The column entries belonging to each label, as a Series.
 |      
 |      See Also
 |      --------
 |      DataFrame.iterrows : Iterate over DataFrame rows as
 |          (index, Series) pairs.
 |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples
 |          of the values.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;species&#39;: [&#39;bear&#39;, &#39;bear&#39;, &#39;marsupial&#39;],
 |      ...                   &#39;population&#39;: [1864, 22000, 80000]},
 |      ...                   index=[&#39;panda&#39;, &#39;polar&#39;, &#39;koala&#39;])
 |      &gt;&gt;&gt; df
 |              species   population
 |      panda   bear      1864
 |      polar   bear      22000
 |      koala   marsupial 80000
 |      &gt;&gt;&gt; for label, content in df.items():
 |      ...     print(f&#39;label: {label}&#39;)
 |      ...     print(f&#39;content: {content}&#39;, sep=&#39;\n&#39;)
 |      ...
 |      label: species
 |      content:
 |      panda         bear
 |      polar         bear
 |      koala    marsupial
 |      Name: species, dtype: object
 |      label: population
 |      content:
 |      panda     1864
 |      polar    22000
 |      koala    80000
 |      Name: population, dtype: int64
 |  
 |  iterrows(self) -&gt; &#39;Iterable[tuple[Hashable, Series]]&#39;
 |      Iterate over DataFrame rows as (index, Series) pairs.
 |      
 |      Yields
 |      ------
 |      index : label or tuple of label
 |          The index of the row. A tuple for a `MultiIndex`.
 |      data : Series
 |          The data of the row as a Series.
 |      
 |      See Also
 |      --------
 |      DataFrame.itertuples : Iterate over DataFrame rows as namedtuples of the values.
 |      DataFrame.items : Iterate over (column name, Series) pairs.
 |      
 |      Notes
 |      -----
 |      1. Because ``iterrows`` returns a Series for each row,
 |         it does **not** preserve dtypes across the rows (dtypes are
 |         preserved across columns for DataFrames). For example,
 |      
 |         &gt;&gt;&gt; df = pd.DataFrame([[1, 1.5]], columns=[&#39;int&#39;, &#39;float&#39;])
 |         &gt;&gt;&gt; row = next(df.iterrows())[1]
 |         &gt;&gt;&gt; row
 |         int      1.0
 |         float    1.5
 |         Name: 0, dtype: float64
 |         &gt;&gt;&gt; print(row[&#39;int&#39;].dtype)
 |         float64
 |         &gt;&gt;&gt; print(df[&#39;int&#39;].dtype)
 |         int64
 |      
 |         To preserve dtypes while iterating over the rows, it is better
 |         to use :meth:`itertuples` which returns namedtuples of the values
 |         and which is generally faster than ``iterrows``.
 |      
 |      2. You should **never modify** something you are iterating over.
 |         This is not guaranteed to work in all cases. Depending on the
 |         data types, the iterator returns a copy and not a view, and writing
 |         to it will have no effect.
 |  
 |  itertuples(self, index: &#39;bool&#39; = True, name: &#39;str | None&#39; = &#39;Pandas&#39;) -&gt; &#39;Iterable[tuple[Any, ...]]&#39;
 |      Iterate over DataFrame rows as namedtuples.
 |      
 |      Parameters
 |      ----------
 |      index : bool, default True
 |          If True, return the index as the first element of the tuple.
 |      name : str or None, default &quot;Pandas&quot;
 |          The name of the returned namedtuples or None to return regular
 |          tuples.
 |      
 |      Returns
 |      -------
 |      iterator
 |          An object to iterate over namedtuples for each row in the
 |          DataFrame with the first field possibly being the index and
 |          following fields being the column values.
 |      
 |      See Also
 |      --------
 |      DataFrame.iterrows : Iterate over DataFrame rows as (index, Series)
 |          pairs.
 |      DataFrame.items : Iterate over (column name, Series) pairs.
 |      
 |      Notes
 |      -----
 |      The column names will be renamed to positional names if they are
 |      invalid Python identifiers, repeated, or start with an underscore.
 |      On python versions &lt; 3.7 regular tuples are returned for DataFrames
 |      with a large number of columns (&gt;254).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;num_legs&#39;: [4, 2], &#39;num_wings&#39;: [0, 2]},
 |      ...                   index=[&#39;dog&#39;, &#39;hawk&#39;])
 |      &gt;&gt;&gt; df
 |            num_legs  num_wings
 |      dog          4          0
 |      hawk         2          2
 |      &gt;&gt;&gt; for row in df.itertuples():
 |      ...     print(row)
 |      ...
 |      Pandas(Index=&#39;dog&#39;, num_legs=4, num_wings=0)
 |      Pandas(Index=&#39;hawk&#39;, num_legs=2, num_wings=2)
 |      
 |      By setting the `index` parameter to False we can remove the index
 |      as the first element of the tuple:
 |      
 |      &gt;&gt;&gt; for row in df.itertuples(index=False):
 |      ...     print(row)
 |      ...
 |      Pandas(num_legs=4, num_wings=0)
 |      Pandas(num_legs=2, num_wings=2)
 |      
 |      With the `name` parameter set we set a custom name for the yielded
 |      namedtuples:
 |      
 |      &gt;&gt;&gt; for row in df.itertuples(name=&#39;Animal&#39;):
 |      ...     print(row)
 |      ...
 |      Animal(Index=&#39;dog&#39;, num_legs=4, num_wings=0)
 |      Animal(Index=&#39;hawk&#39;, num_legs=2, num_wings=2)
 |  
 |  join(self, other: &#39;FrameOrSeriesUnion&#39;, on: &#39;IndexLabel | None&#39; = None, how: &#39;str&#39; = &#39;left&#39;, lsuffix: &#39;str&#39; = &#39;&#39;, rsuffix: &#39;str&#39; = &#39;&#39;, sort: &#39;bool&#39; = False) -&gt; &#39;DataFrame&#39;
 |      Join columns of another DataFrame.
 |      
 |      Join columns with `other` DataFrame either on index or on a key
 |      column. Efficiently join multiple DataFrame objects by index at once by
 |      passing a list.
 |      
 |      Parameters
 |      ----------
 |      other : DataFrame, Series, or list of DataFrame
 |          Index should be similar to one of the columns in this one. If a
 |          Series is passed, its name attribute must be set, and that will be
 |          used as the column name in the resulting joined DataFrame.
 |      on : str, list of str, or array-like, optional
 |          Column or index level name(s) in the caller to join on the index
 |          in `other`, otherwise joins index-on-index. If multiple
 |          values given, the `other` DataFrame must have a MultiIndex. Can
 |          pass an array as the join key if it is not already contained in
 |          the calling DataFrame. Like an Excel VLOOKUP operation.
 |      how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;}, default &#39;left&#39;
 |          How to handle the operation of the two objects.
 |      
 |          * left: use calling frame&#39;s index (or column if on is specified)
 |          * right: use `other`&#39;s index.
 |          * outer: form union of calling frame&#39;s index (or column if on is
 |            specified) with `other`&#39;s index, and sort it.
 |            lexicographically.
 |          * inner: form intersection of calling frame&#39;s index (or column if
 |            on is specified) with `other`&#39;s index, preserving the order
 |            of the calling&#39;s one.
 |      lsuffix : str, default &#39;&#39;
 |          Suffix to use from left frame&#39;s overlapping columns.
 |      rsuffix : str, default &#39;&#39;
 |          Suffix to use from right frame&#39;s overlapping columns.
 |      sort : bool, default False
 |          Order result DataFrame lexicographically by the join key. If False,
 |          the order of the join key depends on the join type (how keyword).
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          A dataframe containing columns from both the caller and `other`.
 |      
 |      See Also
 |      --------
 |      DataFrame.merge : For column(s)-on-column(s) operations.
 |      
 |      Notes
 |      -----
 |      Parameters `on`, `lsuffix`, and `rsuffix` are not supported when
 |      passing a list of `DataFrame` objects.
 |      
 |      Support for specifying index levels as the `on` parameter was added
 |      in version 0.23.0.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;key&#39;: [&#39;K0&#39;, &#39;K1&#39;, &#39;K2&#39;, &#39;K3&#39;, &#39;K4&#39;, &#39;K5&#39;],
 |      ...                    &#39;A&#39;: [&#39;A0&#39;, &#39;A1&#39;, &#39;A2&#39;, &#39;A3&#39;, &#39;A4&#39;, &#39;A5&#39;]})
 |      
 |      &gt;&gt;&gt; df
 |        key   A
 |      0  K0  A0
 |      1  K1  A1
 |      2  K2  A2
 |      3  K3  A3
 |      4  K4  A4
 |      5  K5  A5
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;key&#39;: [&#39;K0&#39;, &#39;K1&#39;, &#39;K2&#39;],
 |      ...                       &#39;B&#39;: [&#39;B0&#39;, &#39;B1&#39;, &#39;B2&#39;]})
 |      
 |      &gt;&gt;&gt; other
 |        key   B
 |      0  K0  B0
 |      1  K1  B1
 |      2  K2  B2
 |      
 |      Join DataFrames using their indexes.
 |      
 |      &gt;&gt;&gt; df.join(other, lsuffix=&#39;_caller&#39;, rsuffix=&#39;_other&#39;)
 |        key_caller   A key_other    B
 |      0         K0  A0        K0   B0
 |      1         K1  A1        K1   B1
 |      2         K2  A2        K2   B2
 |      3         K3  A3       NaN  NaN
 |      4         K4  A4       NaN  NaN
 |      5         K5  A5       NaN  NaN
 |      
 |      If we want to join using the key columns, we need to set key to be
 |      the index in both `df` and `other`. The joined DataFrame will have
 |      key as its index.
 |      
 |      &gt;&gt;&gt; df.set_index(&#39;key&#39;).join(other.set_index(&#39;key&#39;))
 |            A    B
 |      key
 |      K0   A0   B0
 |      K1   A1   B1
 |      K2   A2   B2
 |      K3   A3  NaN
 |      K4   A4  NaN
 |      K5   A5  NaN
 |      
 |      Another option to join using the key columns is to use the `on`
 |      parameter. DataFrame.join always uses `other`&#39;s index but we can use
 |      any column in `df`. This method preserves the original DataFrame&#39;s
 |      index in the result.
 |      
 |      &gt;&gt;&gt; df.join(other.set_index(&#39;key&#39;), on=&#39;key&#39;)
 |        key   A    B
 |      0  K0  A0   B0
 |      1  K1  A1   B1
 |      2  K2  A2   B2
 |      3  K3  A3  NaN
 |      4  K4  A4  NaN
 |      5  K5  A5  NaN
 |  
 |  kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
 |      Return unbiased kurtosis over requested axis.
 |      
 |      Kurtosis obtained using Fisher&#39;s definition of
 |      kurtosis (kurtosis of normal == 0.0). Normalized by N-1.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |          Axis for the function to be applied on.
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |  
 |  kurtosis = kurt(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
 |  
 |  le(self, other, axis=&#39;columns&#39;, level=None)
 |      Get Less than or equal to of dataframe and other, element-wise (binary operator `le`).
 |      
 |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison
 |      operators.
 |      
 |      Equivalent to `==`, `!=`, `&lt;=`, `&lt;`, `&gt;=`, `&gt;` with support to choose axis
 |      (rows or columns) and level for comparison.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default &#39;columns&#39;
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;).
 |      level : int or label
 |          Broadcast across a level, matching Index values on the passed
 |          MultiIndex level.
 |      
 |      Returns
 |      -------
 |      DataFrame of bool
 |          Result of the comparison.
 |      
 |      See Also
 |      --------
 |      DataFrame.eq : Compare DataFrames for equality elementwise.
 |      DataFrame.ne : Compare DataFrames for inequality elementwise.
 |      DataFrame.le : Compare DataFrames for less than inequality
 |          or equality elementwise.
 |      DataFrame.lt : Compare DataFrames for strictly less than
 |          inequality elementwise.
 |      DataFrame.ge : Compare DataFrames for greater than inequality
 |          or equality elementwise.
 |      DataFrame.gt : Compare DataFrames for strictly greater than
 |          inequality elementwise.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      `NaN` values are considered different (i.e. `NaN` != `NaN`).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;cost&#39;: [250, 150, 100],
 |      ...                    &#39;revenue&#39;: [100, 250, 300]},
 |      ...                   index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; df
 |         cost  revenue
 |      A   250      100
 |      B   150      250
 |      C   100      300
 |      
 |      Comparison with a scalar, using either the operator or method:
 |      
 |      &gt;&gt;&gt; df == 100
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      &gt;&gt;&gt; df.eq(100)
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned
 |      with the index of `other` and broadcast:
 |      
 |      &gt;&gt;&gt; df != pd.Series([100, 250], index=[&quot;cost&quot;, &quot;revenue&quot;])
 |          cost  revenue
 |      A   True     True
 |      B   True    False
 |      C  False     True
 |      
 |      Use the method to control the broadcast axis:
 |      
 |      &gt;&gt;&gt; df.ne(pd.Series([100, 300], index=[&quot;A&quot;, &quot;D&quot;]), axis=&#39;index&#39;)
 |         cost  revenue
 |      A  True    False
 |      B  True     True
 |      C  True     True
 |      D  True     True
 |      
 |      When comparing to an arbitrary sequence, the number of columns must
 |      match the number elements in `other`:
 |      
 |      &gt;&gt;&gt; df == [250, 100]
 |          cost  revenue
 |      A   True     True
 |      B  False    False
 |      C  False    False
 |      
 |      Use the method to control the axis:
 |      
 |      &gt;&gt;&gt; df.eq([250, 250, 100], axis=&#39;index&#39;)
 |          cost  revenue
 |      A   True    False
 |      B  False     True
 |      C   True    False
 |      
 |      Compare to a DataFrame of different shape.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;revenue&#39;: [300, 250, 100, 150]},
 |      ...                      index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
 |      &gt;&gt;&gt; other
 |         revenue
 |      A      300
 |      B      250
 |      C      100
 |      D      150
 |      
 |      &gt;&gt;&gt; df.gt(other)
 |          cost  revenue
 |      A  False    False
 |      B  False    False
 |      C  False     True
 |      D  False    False
 |      
 |      Compare to a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;cost&#39;: [250, 150, 100, 150, 300, 220],
 |      ...                              &#39;revenue&#39;: [100, 250, 300, 200, 175, 225]},
 |      ...                             index=[[&#39;Q1&#39;, &#39;Q1&#39;, &#39;Q1&#39;, &#39;Q2&#39;, &#39;Q2&#39;, &#39;Q2&#39;],
 |      ...                                    [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |            cost  revenue
 |      Q1 A   250      100
 |         B   150      250
 |         C   100      300
 |      Q2 A   150      200
 |         B   300      175
 |         C   220      225
 |      
 |      &gt;&gt;&gt; df.le(df_multindex, level=1)
 |             cost  revenue
 |      Q1 A   True     True
 |         B   True     True
 |         C   True     True
 |      Q2 A  False     True
 |         B   True    False
 |         C   True    False
 |  
 |  lookup(self, row_labels: &#39;Sequence[IndexLabel]&#39;, col_labels: &#39;Sequence[IndexLabel]&#39;) -&gt; &#39;np.ndarray&#39;
 |      Label-based &quot;fancy indexing&quot; function for DataFrame.
 |      Given equal-length arrays of row and column labels, return an
 |      array of the values corresponding to each (row, col) pair.
 |      
 |      .. deprecated:: 1.2.0
 |          DataFrame.lookup is deprecated,
 |          use DataFrame.melt and DataFrame.loc instead.
 |          For further details see
 |          :ref:`Looking up values by index/column labels &lt;indexing.lookup&gt;`.
 |      
 |      Parameters
 |      ----------
 |      row_labels : sequence
 |          The row labels to use for lookup.
 |      col_labels : sequence
 |          The column labels to use for lookup.
 |      
 |      Returns
 |      -------
 |      numpy.ndarray
 |          The found values.
 |  
 |  lt(self, other, axis=&#39;columns&#39;, level=None)
 |      Get Less than of dataframe and other, element-wise (binary operator `lt`).
 |      
 |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison
 |      operators.
 |      
 |      Equivalent to `==`, `!=`, `&lt;=`, `&lt;`, `&gt;=`, `&gt;` with support to choose axis
 |      (rows or columns) and level for comparison.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default &#39;columns&#39;
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;).
 |      level : int or label
 |          Broadcast across a level, matching Index values on the passed
 |          MultiIndex level.
 |      
 |      Returns
 |      -------
 |      DataFrame of bool
 |          Result of the comparison.
 |      
 |      See Also
 |      --------
 |      DataFrame.eq : Compare DataFrames for equality elementwise.
 |      DataFrame.ne : Compare DataFrames for inequality elementwise.
 |      DataFrame.le : Compare DataFrames for less than inequality
 |          or equality elementwise.
 |      DataFrame.lt : Compare DataFrames for strictly less than
 |          inequality elementwise.
 |      DataFrame.ge : Compare DataFrames for greater than inequality
 |          or equality elementwise.
 |      DataFrame.gt : Compare DataFrames for strictly greater than
 |          inequality elementwise.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      `NaN` values are considered different (i.e. `NaN` != `NaN`).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;cost&#39;: [250, 150, 100],
 |      ...                    &#39;revenue&#39;: [100, 250, 300]},
 |      ...                   index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; df
 |         cost  revenue
 |      A   250      100
 |      B   150      250
 |      C   100      300
 |      
 |      Comparison with a scalar, using either the operator or method:
 |      
 |      &gt;&gt;&gt; df == 100
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      &gt;&gt;&gt; df.eq(100)
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned
 |      with the index of `other` and broadcast:
 |      
 |      &gt;&gt;&gt; df != pd.Series([100, 250], index=[&quot;cost&quot;, &quot;revenue&quot;])
 |          cost  revenue
 |      A   True     True
 |      B   True    False
 |      C  False     True
 |      
 |      Use the method to control the broadcast axis:
 |      
 |      &gt;&gt;&gt; df.ne(pd.Series([100, 300], index=[&quot;A&quot;, &quot;D&quot;]), axis=&#39;index&#39;)
 |         cost  revenue
 |      A  True    False
 |      B  True     True
 |      C  True     True
 |      D  True     True
 |      
 |      When comparing to an arbitrary sequence, the number of columns must
 |      match the number elements in `other`:
 |      
 |      &gt;&gt;&gt; df == [250, 100]
 |          cost  revenue
 |      A   True     True
 |      B  False    False
 |      C  False    False
 |      
 |      Use the method to control the axis:
 |      
 |      &gt;&gt;&gt; df.eq([250, 250, 100], axis=&#39;index&#39;)
 |          cost  revenue
 |      A   True    False
 |      B  False     True
 |      C   True    False
 |      
 |      Compare to a DataFrame of different shape.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;revenue&#39;: [300, 250, 100, 150]},
 |      ...                      index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
 |      &gt;&gt;&gt; other
 |         revenue
 |      A      300
 |      B      250
 |      C      100
 |      D      150
 |      
 |      &gt;&gt;&gt; df.gt(other)
 |          cost  revenue
 |      A  False    False
 |      B  False    False
 |      C  False     True
 |      D  False    False
 |      
 |      Compare to a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;cost&#39;: [250, 150, 100, 150, 300, 220],
 |      ...                              &#39;revenue&#39;: [100, 250, 300, 200, 175, 225]},
 |      ...                             index=[[&#39;Q1&#39;, &#39;Q1&#39;, &#39;Q1&#39;, &#39;Q2&#39;, &#39;Q2&#39;, &#39;Q2&#39;],
 |      ...                                    [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |            cost  revenue
 |      Q1 A   250      100
 |         B   150      250
 |         C   100      300
 |      Q2 A   150      200
 |         B   300      175
 |         C   220      225
 |      
 |      &gt;&gt;&gt; df.le(df_multindex, level=1)
 |             cost  revenue
 |      Q1 A   True     True
 |         B   True     True
 |         C   True     True
 |      Q2 A  False     True
 |         B   True    False
 |         C   True    False
 |  
 |  mad(self, axis=None, skipna=None, level=None)
 |      Return the mean absolute deviation of the values over the requested axis.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |          Axis for the function to be applied on.
 |      skipna : bool, default None
 |          Exclude NA/null values when computing the result.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |  
 |  mask(self, cond, other=nan, inplace=False, axis=None, level=None, errors=&#39;raise&#39;, try_cast=&lt;no_default&gt;)
 |      Replace values where the condition is True.
 |      
 |      Parameters
 |      ----------
 |      cond : bool Series/DataFrame, array-like, or callable
 |          Where `cond` is False, keep the original value. Where
 |          True, replace with corresponding value from `other`.
 |          If `cond` is callable, it is computed on the Series/DataFrame and
 |          should return boolean Series/DataFrame or array. The callable must
 |          not change input Series/DataFrame (though pandas doesn&#39;t check it).
 |      other : scalar, Series/DataFrame, or callable
 |          Entries where `cond` is True are replaced with
 |          corresponding value from `other`.
 |          If other is callable, it is computed on the Series/DataFrame and
 |          should return scalar or Series/DataFrame. The callable must not
 |          change input Series/DataFrame (though pandas doesn&#39;t check it).
 |      inplace : bool, default False
 |          Whether to perform the operation in place on the data.
 |      axis : int, default None
 |          Alignment axis if needed.
 |      level : int, default None
 |          Alignment level if needed.
 |      errors : str, {&#39;raise&#39;, &#39;ignore&#39;}, default &#39;raise&#39;
 |          Note that currently this parameter won&#39;t affect
 |          the results and will always coerce to a suitable dtype.
 |      
 |          - &#39;raise&#39; : allow exceptions to be raised.
 |          - &#39;ignore&#39; : suppress exceptions. On error return original object.
 |      
 |      try_cast : bool, default None
 |          Try to cast the result back to the input type (if possible).
 |      
 |          .. deprecated:: 1.3.0
 |              Manually cast back if necessary.
 |      
 |      Returns
 |      -------
 |      Same type as caller or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      :func:`DataFrame.where` : Return an object of same shape as
 |          self.
 |      
 |      Notes
 |      -----
 |      The mask method is an application of the if-then idiom. For each
 |      element in the calling DataFrame, if ``cond`` is ``False`` the
 |      element is used; otherwise the corresponding element from the DataFrame
 |      ``other`` is used.
 |      
 |      The signature for :func:`DataFrame.where` differs from
 |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to
 |      ``np.where(m, df1, df2)``.
 |      
 |      For further details and examples see the ``mask`` documentation in
 |      :ref:`indexing &lt;indexing.where_mask&gt;`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series(range(5))
 |      &gt;&gt;&gt; s.where(s &gt; 0)
 |      0    NaN
 |      1    1.0
 |      2    2.0
 |      3    3.0
 |      4    4.0
 |      dtype: float64
 |      &gt;&gt;&gt; s.mask(s &gt; 0)
 |      0    0.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.where(s &gt; 1, 10)
 |      0    10
 |      1    10
 |      2    2
 |      3    3
 |      4    4
 |      dtype: int64
 |      &gt;&gt;&gt; s.mask(s &gt; 1, 10)
 |      0     0
 |      1     1
 |      2    10
 |      3    10
 |      4    10
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=[&#39;A&#39;, &#39;B&#39;])
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  0  1
 |      1  2  3
 |      2  4  5
 |      3  6  7
 |      4  8  9
 |      &gt;&gt;&gt; m = df % 3 == 0
 |      &gt;&gt;&gt; df.where(m, -df)
 |         A  B
 |      0  0 -1
 |      1 -2  3
 |      2 -4 -5
 |      3  6 -7
 |      4 -8  9
 |      &gt;&gt;&gt; df.where(m, -df) == np.where(m, df, -df)
 |            A     B
 |      0  True  True
 |      1  True  True
 |      2  True  True
 |      3  True  True
 |      4  True  True
 |      &gt;&gt;&gt; df.where(m, -df) == df.mask(~m, -df)
 |            A     B
 |      0  True  True
 |      1  True  True
 |      2  True  True
 |      3  True  True
 |      4  True  True
 |  
 |  max(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
 |      Return the maximum of the values over the requested axis.
 |      
 |      If you want the *index* of the maximum, use ``idxmax``. This is the equivalent of the ``numpy.ndarray`` method ``argmax``.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |          Axis for the function to be applied on.
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |      
 |      See Also
 |      --------
 |      Series.sum : Return the sum.
 |      Series.min : Return the minimum.
 |      Series.max : Return the maximum.
 |      Series.idxmin : Return the index of the minimum.
 |      Series.idxmax : Return the index of the maximum.
 |      DataFrame.sum : Return the sum over the requested axis.
 |      DataFrame.min : Return the minimum over the requested axis.
 |      DataFrame.max : Return the maximum over the requested axis.
 |      DataFrame.idxmin : Return the index of the minimum over the requested axis.
 |      DataFrame.idxmax : Return the index of the maximum over the requested axis.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; idx = pd.MultiIndex.from_arrays([
 |      ...     [&#39;warm&#39;, &#39;warm&#39;, &#39;cold&#39;, &#39;cold&#39;],
 |      ...     [&#39;dog&#39;, &#39;falcon&#39;, &#39;fish&#39;, &#39;spider&#39;]],
 |      ...     names=[&#39;blooded&#39;, &#39;animal&#39;])
 |      &gt;&gt;&gt; s = pd.Series([4, 2, 0, 8], name=&#39;legs&#39;, index=idx)
 |      &gt;&gt;&gt; s
 |      blooded  animal
 |      warm     dog       4
 |               falcon    2
 |      cold     fish      0
 |               spider    8
 |      Name: legs, dtype: int64
 |      
 |      &gt;&gt;&gt; s.max()
 |      8
 |  
 |  mean(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
 |      Return the mean of the values over the requested axis.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |          Axis for the function to be applied on.
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |  
 |  median(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
 |      Return the median of the values over the requested axis.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |          Axis for the function to be applied on.
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |  
 |  melt(self, id_vars=None, value_vars=None, var_name=None, value_name=&#39;value&#39;, col_level: &#39;Level | None&#39; = None, ignore_index: &#39;bool&#39; = True) -&gt; &#39;DataFrame&#39;
 |      Unpivot a DataFrame from wide to long format, optionally leaving identifiers set.
 |      
 |      This function is useful to massage a DataFrame into a format where one
 |      or more columns are identifier variables (`id_vars`), while all other
 |      columns, considered measured variables (`value_vars`), are &quot;unpivoted&quot; to
 |      the row axis, leaving just two non-identifier columns, &#39;variable&#39; and
 |      &#39;value&#39;.
 |      
 |      Parameters
 |      ----------
 |      id_vars : tuple, list, or ndarray, optional
 |          Column(s) to use as identifier variables.
 |      value_vars : tuple, list, or ndarray, optional
 |          Column(s) to unpivot. If not specified, uses all columns that
 |          are not set as `id_vars`.
 |      var_name : scalar
 |          Name to use for the &#39;variable&#39; column. If None it uses
 |          ``frame.columns.name`` or &#39;variable&#39;.
 |      value_name : scalar, default &#39;value&#39;
 |          Name to use for the &#39;value&#39; column.
 |      col_level : int or str, optional
 |          If columns are a MultiIndex then use this level to melt.
 |      ignore_index : bool, default True
 |          If True, original index is ignored. If False, the original index is retained.
 |          Index labels will be repeated as necessary.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Unpivoted DataFrame.
 |      
 |      See Also
 |      --------
 |      melt : Identical method.
 |      pivot_table : Create a spreadsheet-style pivot table as a DataFrame.
 |      DataFrame.pivot : Return reshaped DataFrame organized
 |          by given index / column values.
 |      DataFrame.explode : Explode a DataFrame from list-like
 |              columns to long format.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: {0: &#39;a&#39;, 1: &#39;b&#39;, 2: &#39;c&#39;},
 |      ...                    &#39;B&#39;: {0: 1, 1: 3, 2: 5},
 |      ...                    &#39;C&#39;: {0: 2, 1: 4, 2: 6}})
 |      &gt;&gt;&gt; df
 |         A  B  C
 |      0  a  1  2
 |      1  b  3  4
 |      2  c  5  6
 |      
 |      &gt;&gt;&gt; df.melt(id_vars=[&#39;A&#39;], value_vars=[&#39;B&#39;])
 |         A variable  value
 |      0  a        B      1
 |      1  b        B      3
 |      2  c        B      5
 |      
 |      &gt;&gt;&gt; df.melt(id_vars=[&#39;A&#39;], value_vars=[&#39;B&#39;, &#39;C&#39;])
 |         A variable  value
 |      0  a        B      1
 |      1  b        B      3
 |      2  c        B      5
 |      3  a        C      2
 |      4  b        C      4
 |      5  c        C      6
 |      
 |      The names of &#39;variable&#39; and &#39;value&#39; columns can be customized:
 |      
 |      &gt;&gt;&gt; df.melt(id_vars=[&#39;A&#39;], value_vars=[&#39;B&#39;],
 |      ...         var_name=&#39;myVarname&#39;, value_name=&#39;myValname&#39;)
 |         A myVarname  myValname
 |      0  a         B          1
 |      1  b         B          3
 |      2  c         B          5
 |      
 |      Original index values can be kept around:
 |      
 |      &gt;&gt;&gt; df.melt(id_vars=[&#39;A&#39;], value_vars=[&#39;B&#39;, &#39;C&#39;], ignore_index=False)
 |         A variable  value
 |      0  a        B      1
 |      1  b        B      3
 |      2  c        B      5
 |      0  a        C      2
 |      1  b        C      4
 |      2  c        C      6
 |      
 |      If you have multi-index columns:
 |      
 |      &gt;&gt;&gt; df.columns = [list(&#39;ABC&#39;), list(&#39;DEF&#39;)]
 |      &gt;&gt;&gt; df
 |         A  B  C
 |         D  E  F
 |      0  a  1  2
 |      1  b  3  4
 |      2  c  5  6
 |      
 |      &gt;&gt;&gt; df.melt(col_level=0, id_vars=[&#39;A&#39;], value_vars=[&#39;B&#39;])
 |         A variable  value
 |      0  a        B      1
 |      1  b        B      3
 |      2  c        B      5
 |      
 |      &gt;&gt;&gt; df.melt(id_vars=[(&#39;A&#39;, &#39;D&#39;)], value_vars=[(&#39;B&#39;, &#39;E&#39;)])
 |        (A, D) variable_0 variable_1  value
 |      0      a          B          E      1
 |      1      b          B          E      3
 |      2      c          B          E      5
 |  
 |  memory_usage(self, index: &#39;bool&#39; = True, deep: &#39;bool&#39; = False) -&gt; &#39;Series&#39;
 |      Return the memory usage of each column in bytes.
 |      
 |      The memory usage can optionally include the contribution of
 |      the index and elements of `object` dtype.
 |      
 |      This value is displayed in `DataFrame.info` by default. This can be
 |      suppressed by setting ``pandas.options.display.memory_usage`` to False.
 |      
 |      Parameters
 |      ----------
 |      index : bool, default True
 |          Specifies whether to include the memory usage of the DataFrame&#39;s
 |          index in returned Series. If ``index=True``, the memory usage of
 |          the index is the first item in the output.
 |      deep : bool, default False
 |          If True, introspect the data deeply by interrogating
 |          `object` dtypes for system-level memory consumption, and include
 |          it in the returned values.
 |      
 |      Returns
 |      -------
 |      Series
 |          A Series whose index is the original column names and whose values
 |          is the memory usage of each column in bytes.
 |      
 |      See Also
 |      --------
 |      numpy.ndarray.nbytes : Total bytes consumed by the elements of an
 |          ndarray.
 |      Series.memory_usage : Bytes consumed by a Series.
 |      Categorical : Memory-efficient array for string values with
 |          many repeated values.
 |      DataFrame.info : Concise summary of a DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; dtypes = [&#39;int64&#39;, &#39;float64&#39;, &#39;complex128&#39;, &#39;object&#39;, &#39;bool&#39;]
 |      &gt;&gt;&gt; data = dict([(t, np.ones(shape=5000, dtype=int).astype(t))
 |      ...              for t in dtypes])
 |      &gt;&gt;&gt; df = pd.DataFrame(data)
 |      &gt;&gt;&gt; df.head()
 |         int64  float64            complex128  object  bool
 |      0      1      1.0              1.0+0.0j       1  True
 |      1      1      1.0              1.0+0.0j       1  True
 |      2      1      1.0              1.0+0.0j       1  True
 |      3      1      1.0              1.0+0.0j       1  True
 |      4      1      1.0              1.0+0.0j       1  True
 |      
 |      &gt;&gt;&gt; df.memory_usage()
 |      Index           128
 |      int64         40000
 |      float64       40000
 |      complex128    80000
 |      object        40000
 |      bool           5000
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df.memory_usage(index=False)
 |      int64         40000
 |      float64       40000
 |      complex128    80000
 |      object        40000
 |      bool           5000
 |      dtype: int64
 |      
 |      The memory footprint of `object` dtype columns is ignored by default:
 |      
 |      &gt;&gt;&gt; df.memory_usage(deep=True)
 |      Index            128
 |      int64          40000
 |      float64        40000
 |      complex128     80000
 |      object        180000
 |      bool            5000
 |      dtype: int64
 |      
 |      Use a Categorical for efficient storage of an object-dtype column with
 |      many repeated values.
 |      
 |      &gt;&gt;&gt; df[&#39;object&#39;].astype(&#39;category&#39;).memory_usage(deep=True)
 |      5244
 |  
 |  merge(self, right: &#39;FrameOrSeriesUnion&#39;, how: &#39;str&#39; = &#39;inner&#39;, on: &#39;IndexLabel | None&#39; = None, left_on: &#39;IndexLabel | None&#39; = None, right_on: &#39;IndexLabel | None&#39; = None, left_index: &#39;bool&#39; = False, right_index: &#39;bool&#39; = False, sort: &#39;bool&#39; = False, suffixes: &#39;Suffixes&#39; = (&#39;_x&#39;, &#39;_y&#39;), copy: &#39;bool&#39; = True, indicator: &#39;bool&#39; = False, validate: &#39;str | None&#39; = None) -&gt; &#39;DataFrame&#39;
 |      Merge DataFrame or named Series objects with a database-style join.
 |      
 |      A named Series object is treated as a DataFrame with a single named column.
 |      
 |      The join is done on columns or indexes. If joining columns on
 |      columns, the DataFrame indexes *will be ignored*. Otherwise if joining indexes
 |      on indexes or indexes on a column or columns, the index will be passed on.
 |      When performing a cross merge, no column specifications to merge on are
 |      allowed.
 |      
 |      Parameters
 |      ----------
 |      right : DataFrame or named Series
 |          Object to merge with.
 |      how : {&#39;left&#39;, &#39;right&#39;, &#39;outer&#39;, &#39;inner&#39;, &#39;cross&#39;}, default &#39;inner&#39;
 |          Type of merge to be performed.
 |      
 |          * left: use only keys from left frame, similar to a SQL left outer join;
 |            preserve key order.
 |          * right: use only keys from right frame, similar to a SQL right outer join;
 |            preserve key order.
 |          * outer: use union of keys from both frames, similar to a SQL full outer
 |            join; sort keys lexicographically.
 |          * inner: use intersection of keys from both frames, similar to a SQL inner
 |            join; preserve the order of the left keys.
 |          * cross: creates the cartesian product from both frames, preserves the order
 |            of the left keys.
 |      
 |            .. versionadded:: 1.2.0
 |      
 |      on : label or list
 |          Column or index level names to join on. These must be found in both
 |          DataFrames. If `on` is None and not merging on indexes then this defaults
 |          to the intersection of the columns in both DataFrames.
 |      left_on : label or list, or array-like
 |          Column or index level names to join on in the left DataFrame. Can also
 |          be an array or list of arrays of the length of the left DataFrame.
 |          These arrays are treated as if they are columns.
 |      right_on : label or list, or array-like
 |          Column or index level names to join on in the right DataFrame. Can also
 |          be an array or list of arrays of the length of the right DataFrame.
 |          These arrays are treated as if they are columns.
 |      left_index : bool, default False
 |          Use the index from the left DataFrame as the join key(s). If it is a
 |          MultiIndex, the number of keys in the other DataFrame (either the index
 |          or a number of columns) must match the number of levels.
 |      right_index : bool, default False
 |          Use the index from the right DataFrame as the join key. Same caveats as
 |          left_index.
 |      sort : bool, default False
 |          Sort the join keys lexicographically in the result DataFrame. If False,
 |          the order of the join keys depends on the join type (how keyword).
 |      suffixes : list-like, default is (&quot;_x&quot;, &quot;_y&quot;)
 |          A length-2 sequence where each element is optionally a string
 |          indicating the suffix to add to overlapping column names in
 |          `left` and `right` respectively. Pass a value of `None` instead
 |          of a string to indicate that the column name from `left` or
 |          `right` should be left as-is, with no suffix. At least one of the
 |          values must not be None.
 |      copy : bool, default True
 |          If False, avoid copy if possible.
 |      indicator : bool or str, default False
 |          If True, adds a column to the output DataFrame called &quot;_merge&quot; with
 |          information on the source of each row. The column can be given a different
 |          name by providing a string argument. The column will have a Categorical
 |          type with the value of &quot;left_only&quot; for observations whose merge key only
 |          appears in the left DataFrame, &quot;right_only&quot; for observations
 |          whose merge key only appears in the right DataFrame, and &quot;both&quot;
 |          if the observation&#39;s merge key is found in both DataFrames.
 |      
 |      validate : str, optional
 |          If specified, checks if merge is of specified type.
 |      
 |          * &quot;one_to_one&quot; or &quot;1:1&quot;: check if merge keys are unique in both
 |            left and right datasets.
 |          * &quot;one_to_many&quot; or &quot;1:m&quot;: check if merge keys are unique in left
 |            dataset.
 |          * &quot;many_to_one&quot; or &quot;m:1&quot;: check if merge keys are unique in right
 |            dataset.
 |          * &quot;many_to_many&quot; or &quot;m:m&quot;: allowed, but does not result in checks.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          A DataFrame of the two merged objects.
 |      
 |      See Also
 |      --------
 |      merge_ordered : Merge with optional filling/interpolation.
 |      merge_asof : Merge on nearest keys.
 |      DataFrame.join : Similar method using indices.
 |      
 |      Notes
 |      -----
 |      Support for specifying index levels as the `on`, `left_on`, and
 |      `right_on` parameters was added in version 0.23.0
 |      Support for merging named Series objects was added in version 0.24.0
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df1 = pd.DataFrame({&#39;lkey&#39;: [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;],
 |      ...                     &#39;value&#39;: [1, 2, 3, 5]})
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;rkey&#39;: [&#39;foo&#39;, &#39;bar&#39;, &#39;baz&#39;, &#39;foo&#39;],
 |      ...                     &#39;value&#39;: [5, 6, 7, 8]})
 |      &gt;&gt;&gt; df1
 |          lkey value
 |      0   foo      1
 |      1   bar      2
 |      2   baz      3
 |      3   foo      5
 |      &gt;&gt;&gt; df2
 |          rkey value
 |      0   foo      5
 |      1   bar      6
 |      2   baz      7
 |      3   foo      8
 |      
 |      Merge df1 and df2 on the lkey and rkey columns. The value columns have
 |      the default suffixes, _x and _y, appended.
 |      
 |      &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;)
 |        lkey  value_x rkey  value_y
 |      0  foo        1  foo        5
 |      1  foo        1  foo        8
 |      2  foo        5  foo        5
 |      3  foo        5  foo        8
 |      4  bar        2  bar        6
 |      5  baz        3  baz        7
 |      
 |      Merge DataFrames df1 and df2 with specified left and right suffixes
 |      appended to any overlapping columns.
 |      
 |      &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;,
 |      ...           suffixes=(&#39;_left&#39;, &#39;_right&#39;))
 |        lkey  value_left rkey  value_right
 |      0  foo           1  foo            5
 |      1  foo           1  foo            8
 |      2  foo           5  foo            5
 |      3  foo           5  foo            8
 |      4  bar           2  bar            6
 |      5  baz           3  baz            7
 |      
 |      Merge DataFrames df1 and df2, but raise an exception if the DataFrames have
 |      any overlapping columns.
 |      
 |      &gt;&gt;&gt; df1.merge(df2, left_on=&#39;lkey&#39;, right_on=&#39;rkey&#39;, suffixes=(False, False))
 |      Traceback (most recent call last):
 |      ...
 |      ValueError: columns overlap but no suffix specified:
 |          Index([&#39;value&#39;], dtype=&#39;object&#39;)
 |      
 |      &gt;&gt;&gt; df1 = pd.DataFrame({&#39;a&#39;: [&#39;foo&#39;, &#39;bar&#39;], &#39;b&#39;: [1, 2]})
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;a&#39;: [&#39;foo&#39;, &#39;baz&#39;], &#39;c&#39;: [3, 4]})
 |      &gt;&gt;&gt; df1
 |            a  b
 |      0   foo  1
 |      1   bar  2
 |      &gt;&gt;&gt; df2
 |            a  c
 |      0   foo  3
 |      1   baz  4
 |      
 |      &gt;&gt;&gt; df1.merge(df2, how=&#39;inner&#39;, on=&#39;a&#39;)
 |            a  b  c
 |      0   foo  1  3
 |      
 |      &gt;&gt;&gt; df1.merge(df2, how=&#39;left&#39;, on=&#39;a&#39;)
 |            a  b  c
 |      0   foo  1  3.0
 |      1   bar  2  NaN
 |      
 |      &gt;&gt;&gt; df1 = pd.DataFrame({&#39;left&#39;: [&#39;foo&#39;, &#39;bar&#39;]})
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;right&#39;: [7, 8]})
 |      &gt;&gt;&gt; df1
 |          left
 |      0   foo
 |      1   bar
 |      &gt;&gt;&gt; df2
 |          right
 |      0   7
 |      1   8
 |      
 |      &gt;&gt;&gt; df1.merge(df2, how=&#39;cross&#39;)
 |         left  right
 |      0   foo      7
 |      1   foo      8
 |      2   bar      7
 |      3   bar      8
 |  
 |  min(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
 |      Return the minimum of the values over the requested axis.
 |      
 |      If you want the *index* of the minimum, use ``idxmin``. This is the equivalent of the ``numpy.ndarray`` method ``argmin``.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |          Axis for the function to be applied on.
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |      
 |      See Also
 |      --------
 |      Series.sum : Return the sum.
 |      Series.min : Return the minimum.
 |      Series.max : Return the maximum.
 |      Series.idxmin : Return the index of the minimum.
 |      Series.idxmax : Return the index of the maximum.
 |      DataFrame.sum : Return the sum over the requested axis.
 |      DataFrame.min : Return the minimum over the requested axis.
 |      DataFrame.max : Return the maximum over the requested axis.
 |      DataFrame.idxmin : Return the index of the minimum over the requested axis.
 |      DataFrame.idxmax : Return the index of the maximum over the requested axis.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; idx = pd.MultiIndex.from_arrays([
 |      ...     [&#39;warm&#39;, &#39;warm&#39;, &#39;cold&#39;, &#39;cold&#39;],
 |      ...     [&#39;dog&#39;, &#39;falcon&#39;, &#39;fish&#39;, &#39;spider&#39;]],
 |      ...     names=[&#39;blooded&#39;, &#39;animal&#39;])
 |      &gt;&gt;&gt; s = pd.Series([4, 2, 0, 8], name=&#39;legs&#39;, index=idx)
 |      &gt;&gt;&gt; s
 |      blooded  animal
 |      warm     dog       4
 |               falcon    2
 |      cold     fish      0
 |               spider    8
 |      Name: legs, dtype: int64
 |      
 |      &gt;&gt;&gt; s.min()
 |      0
 |  
 |  mod(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Modulo of dataframe and other, element-wise (binary operator `mod`).
 |      
 |      Equivalent to ``dataframe % other``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `rmod`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  mode(self, axis: &#39;Axis&#39; = 0, numeric_only: &#39;bool&#39; = False, dropna: &#39;bool&#39; = True) -&gt; &#39;DataFrame&#39;
 |      Get the mode(s) of each element along the selected axis.
 |      
 |      The mode of a set of values is the value that appears most often.
 |      It can be multiple values.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to iterate over while searching for the mode:
 |      
 |          * 0 or &#39;index&#39; : get mode of each column
 |          * 1 or &#39;columns&#39; : get mode of each row.
 |      
 |      numeric_only : bool, default False
 |          If True, only apply to numeric columns.
 |      dropna : bool, default True
 |          Don&#39;t consider counts of NaN/NaT.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          The modes of each column or row.
 |      
 |      See Also
 |      --------
 |      Series.mode : Return the highest frequency value in a Series.
 |      Series.value_counts : Return the counts of values in a Series.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([(&#39;bird&#39;, 2, 2),
 |      ...                    (&#39;mammal&#39;, 4, np.nan),
 |      ...                    (&#39;arthropod&#39;, 8, 0),
 |      ...                    (&#39;bird&#39;, 2, np.nan)],
 |      ...                   index=(&#39;falcon&#39;, &#39;horse&#39;, &#39;spider&#39;, &#39;ostrich&#39;),
 |      ...                   columns=(&#39;species&#39;, &#39;legs&#39;, &#39;wings&#39;))
 |      &gt;&gt;&gt; df
 |                 species  legs  wings
 |      falcon        bird     2    2.0
 |      horse       mammal     4    NaN
 |      spider   arthropod     8    0.0
 |      ostrich       bird     2    NaN
 |      
 |      By default, missing values are not considered, and the mode of wings
 |      are both 0 and 2. Because the resulting DataFrame has two rows,
 |      the second row of ``species`` and ``legs`` contains ``NaN``.
 |      
 |      &gt;&gt;&gt; df.mode()
 |        species  legs  wings
 |      0    bird   2.0    0.0
 |      1     NaN   NaN    2.0
 |      
 |      Setting ``dropna=False`` ``NaN`` values are considered and they can be
 |      the mode (like for wings).
 |      
 |      &gt;&gt;&gt; df.mode(dropna=False)
 |        species  legs  wings
 |      0    bird     2    NaN
 |      
 |      Setting ``numeric_only=True``, only the mode of numeric columns is
 |      computed, and columns of other types are ignored.
 |      
 |      &gt;&gt;&gt; df.mode(numeric_only=True)
 |         legs  wings
 |      0   2.0    0.0
 |      1   NaN    2.0
 |      
 |      To compute the mode over columns and not rows, use the axis parameter:
 |      
 |      &gt;&gt;&gt; df.mode(axis=&#39;columns&#39;, numeric_only=True)
 |                 0    1
 |      falcon   2.0  NaN
 |      horse    4.0  NaN
 |      spider   0.0  8.0
 |      ostrich  2.0  NaN
 |  
 |  mul(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Multiplication of dataframe and other, element-wise (binary operator `mul`).
 |      
 |      Equivalent to ``dataframe * other``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `rmul`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  multiply = mul(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |  
 |  ne(self, other, axis=&#39;columns&#39;, level=None)
 |      Get Not equal to of dataframe and other, element-wise (binary operator `ne`).
 |      
 |      Among flexible wrappers (`eq`, `ne`, `le`, `lt`, `ge`, `gt`) to comparison
 |      operators.
 |      
 |      Equivalent to `==`, `!=`, `&lt;=`, `&lt;`, `&gt;=`, `&gt;` with support to choose axis
 |      (rows or columns) and level for comparison.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default &#39;columns&#39;
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;).
 |      level : int or label
 |          Broadcast across a level, matching Index values on the passed
 |          MultiIndex level.
 |      
 |      Returns
 |      -------
 |      DataFrame of bool
 |          Result of the comparison.
 |      
 |      See Also
 |      --------
 |      DataFrame.eq : Compare DataFrames for equality elementwise.
 |      DataFrame.ne : Compare DataFrames for inequality elementwise.
 |      DataFrame.le : Compare DataFrames for less than inequality
 |          or equality elementwise.
 |      DataFrame.lt : Compare DataFrames for strictly less than
 |          inequality elementwise.
 |      DataFrame.ge : Compare DataFrames for greater than inequality
 |          or equality elementwise.
 |      DataFrame.gt : Compare DataFrames for strictly greater than
 |          inequality elementwise.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      `NaN` values are considered different (i.e. `NaN` != `NaN`).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;cost&#39;: [250, 150, 100],
 |      ...                    &#39;revenue&#39;: [100, 250, 300]},
 |      ...                   index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; df
 |         cost  revenue
 |      A   250      100
 |      B   150      250
 |      C   100      300
 |      
 |      Comparison with a scalar, using either the operator or method:
 |      
 |      &gt;&gt;&gt; df == 100
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      &gt;&gt;&gt; df.eq(100)
 |          cost  revenue
 |      A  False     True
 |      B  False    False
 |      C   True    False
 |      
 |      When `other` is a :class:`Series`, the columns of a DataFrame are aligned
 |      with the index of `other` and broadcast:
 |      
 |      &gt;&gt;&gt; df != pd.Series([100, 250], index=[&quot;cost&quot;, &quot;revenue&quot;])
 |          cost  revenue
 |      A   True     True
 |      B   True    False
 |      C  False     True
 |      
 |      Use the method to control the broadcast axis:
 |      
 |      &gt;&gt;&gt; df.ne(pd.Series([100, 300], index=[&quot;A&quot;, &quot;D&quot;]), axis=&#39;index&#39;)
 |         cost  revenue
 |      A  True    False
 |      B  True     True
 |      C  True     True
 |      D  True     True
 |      
 |      When comparing to an arbitrary sequence, the number of columns must
 |      match the number elements in `other`:
 |      
 |      &gt;&gt;&gt; df == [250, 100]
 |          cost  revenue
 |      A   True     True
 |      B  False    False
 |      C  False    False
 |      
 |      Use the method to control the axis:
 |      
 |      &gt;&gt;&gt; df.eq([250, 250, 100], axis=&#39;index&#39;)
 |          cost  revenue
 |      A   True    False
 |      B  False     True
 |      C   True    False
 |      
 |      Compare to a DataFrame of different shape.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;revenue&#39;: [300, 250, 100, 150]},
 |      ...                      index=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
 |      &gt;&gt;&gt; other
 |         revenue
 |      A      300
 |      B      250
 |      C      100
 |      D      150
 |      
 |      &gt;&gt;&gt; df.gt(other)
 |          cost  revenue
 |      A  False    False
 |      B  False    False
 |      C  False     True
 |      D  False    False
 |      
 |      Compare to a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;cost&#39;: [250, 150, 100, 150, 300, 220],
 |      ...                              &#39;revenue&#39;: [100, 250, 300, 200, 175, 225]},
 |      ...                             index=[[&#39;Q1&#39;, &#39;Q1&#39;, &#39;Q1&#39;, &#39;Q2&#39;, &#39;Q2&#39;, &#39;Q2&#39;],
 |      ...                                    [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |            cost  revenue
 |      Q1 A   250      100
 |         B   150      250
 |         C   100      300
 |      Q2 A   150      200
 |         B   300      175
 |         C   220      225
 |      
 |      &gt;&gt;&gt; df.le(df_multindex, level=1)
 |             cost  revenue
 |      Q1 A   True     True
 |         B   True     True
 |         C   True     True
 |      Q2 A  False     True
 |         B   True    False
 |         C   True    False
 |  
 |  nlargest(self, n, columns, keep: &#39;str&#39; = &#39;first&#39;) -&gt; &#39;DataFrame&#39;
 |      Return the first `n` rows ordered by `columns` in descending order.
 |      
 |      Return the first `n` rows with the largest values in `columns`, in
 |      descending order. The columns that are not specified are returned as
 |      well, but not used for ordering.
 |      
 |      This method is equivalent to
 |      ``df.sort_values(columns, ascending=False).head(n)``, but more
 |      performant.
 |      
 |      Parameters
 |      ----------
 |      n : int
 |          Number of rows to return.
 |      columns : label or list of labels
 |          Column label(s) to order by.
 |      keep : {&#39;first&#39;, &#39;last&#39;, &#39;all&#39;}, default &#39;first&#39;
 |          Where there are duplicate values:
 |      
 |          - `first` : prioritize the first occurrence(s)
 |          - `last` : prioritize the last occurrence(s)
 |          - ``all`` : do not drop any duplicates, even it means
 |                      selecting more than `n` items.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          The first `n` rows ordered by the given columns in descending
 |          order.
 |      
 |      See Also
 |      --------
 |      DataFrame.nsmallest : Return the first `n` rows ordered by `columns` in
 |          ascending order.
 |      DataFrame.sort_values : Sort DataFrame by the values.
 |      DataFrame.head : Return the first `n` rows without re-ordering.
 |      
 |      Notes
 |      -----
 |      This function cannot be used with all column types. For example, when
 |      specifying columns with `object` or `category` dtypes, ``TypeError`` is
 |      raised.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;population&#39;: [59000000, 65000000, 434000,
 |      ...                                   434000, 434000, 337000, 11300,
 |      ...                                   11300, 11300],
 |      ...                    &#39;GDP&#39;: [1937894, 2583560 , 12011, 4520, 12128,
 |      ...                            17036, 182, 38, 311],
 |      ...                    &#39;alpha-2&#39;: [&quot;IT&quot;, &quot;FR&quot;, &quot;MT&quot;, &quot;MV&quot;, &quot;BN&quot;,
 |      ...                                &quot;IS&quot;, &quot;NR&quot;, &quot;TV&quot;, &quot;AI&quot;]},
 |      ...                   index=[&quot;Italy&quot;, &quot;France&quot;, &quot;Malta&quot;,
 |      ...                          &quot;Maldives&quot;, &quot;Brunei&quot;, &quot;Iceland&quot;,
 |      ...                          &quot;Nauru&quot;, &quot;Tuvalu&quot;, &quot;Anguilla&quot;])
 |      &gt;&gt;&gt; df
 |                population      GDP alpha-2
 |      Italy       59000000  1937894      IT
 |      France      65000000  2583560      FR
 |      Malta         434000    12011      MT
 |      Maldives      434000     4520      MV
 |      Brunei        434000    12128      BN
 |      Iceland       337000    17036      IS
 |      Nauru          11300      182      NR
 |      Tuvalu         11300       38      TV
 |      Anguilla       11300      311      AI
 |      
 |      In the following example, we will use ``nlargest`` to select the three
 |      rows having the largest values in column &quot;population&quot;.
 |      
 |      &gt;&gt;&gt; df.nlargest(3, &#39;population&#39;)
 |              population      GDP alpha-2
 |      France    65000000  2583560      FR
 |      Italy     59000000  1937894      IT
 |      Malta       434000    12011      MT
 |      
 |      When using ``keep=&#39;last&#39;``, ties are resolved in reverse order:
 |      
 |      &gt;&gt;&gt; df.nlargest(3, &#39;population&#39;, keep=&#39;last&#39;)
 |              population      GDP alpha-2
 |      France    65000000  2583560      FR
 |      Italy     59000000  1937894      IT
 |      Brunei      434000    12128      BN
 |      
 |      When using ``keep=&#39;all&#39;``, all duplicate items are maintained:
 |      
 |      &gt;&gt;&gt; df.nlargest(3, &#39;population&#39;, keep=&#39;all&#39;)
 |                population      GDP alpha-2
 |      France      65000000  2583560      FR
 |      Italy       59000000  1937894      IT
 |      Malta         434000    12011      MT
 |      Maldives      434000     4520      MV
 |      Brunei        434000    12128      BN
 |      
 |      To order by the largest values in column &quot;population&quot; and then &quot;GDP&quot;,
 |      we can specify multiple columns like in the next example.
 |      
 |      &gt;&gt;&gt; df.nlargest(3, [&#39;population&#39;, &#39;GDP&#39;])
 |              population      GDP alpha-2
 |      France    65000000  2583560      FR
 |      Italy     59000000  1937894      IT
 |      Brunei      434000    12128      BN
 |  
 |  notna(self) -&gt; &#39;DataFrame&#39;
 |      Detect existing (non-missing) values.
 |      
 |      Return a boolean same-sized object indicating if the values are not NA.
 |      Non-missing values get mapped to True. Characters such as empty
 |      strings ``&#39;&#39;`` or :attr:`numpy.inf` are not considered NA values
 |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).
 |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False
 |      values.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Mask of bool values for each element in DataFrame that
 |          indicates whether an element is not an NA value.
 |      
 |      See Also
 |      --------
 |      DataFrame.notnull : Alias of notna.
 |      DataFrame.isna : Boolean inverse of notna.
 |      DataFrame.dropna : Omit axes labels with missing values.
 |      notna : Top-level notna.
 |      
 |      Examples
 |      --------
 |      Show which entries in a DataFrame are not NA.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(dict(age=[5, 6, np.NaN],
 |      ...                    born=[pd.NaT, pd.Timestamp(&#39;1939-05-27&#39;),
 |      ...                          pd.Timestamp(&#39;1940-04-25&#39;)],
 |      ...                    name=[&#39;Alfred&#39;, &#39;Batman&#39;, &#39;&#39;],
 |      ...                    toy=[None, &#39;Batmobile&#39;, &#39;Joker&#39;]))
 |      &gt;&gt;&gt; df
 |         age       born    name        toy
 |      0  5.0        NaT  Alfred       None
 |      1  6.0 1939-05-27  Batman  Batmobile
 |      2  NaN 1940-04-25              Joker
 |      
 |      &gt;&gt;&gt; df.notna()
 |           age   born  name    toy
 |      0   True  False  True  False
 |      1   True   True  True   True
 |      2  False   True  True   True
 |      
 |      Show which entries in a Series are not NA.
 |      
 |      &gt;&gt;&gt; ser = pd.Series([5, 6, np.NaN])
 |      &gt;&gt;&gt; ser
 |      0    5.0
 |      1    6.0
 |      2    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; ser.notna()
 |      0     True
 |      1     True
 |      2    False
 |      dtype: bool
 |  
 |  notnull(self) -&gt; &#39;DataFrame&#39;
 |      Detect existing (non-missing) values.
 |      
 |      Return a boolean same-sized object indicating if the values are not NA.
 |      Non-missing values get mapped to True. Characters such as empty
 |      strings ``&#39;&#39;`` or :attr:`numpy.inf` are not considered NA values
 |      (unless you set ``pandas.options.mode.use_inf_as_na = True``).
 |      NA values, such as None or :attr:`numpy.NaN`, get mapped to False
 |      values.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Mask of bool values for each element in DataFrame that
 |          indicates whether an element is not an NA value.
 |      
 |      See Also
 |      --------
 |      DataFrame.notnull : Alias of notna.
 |      DataFrame.isna : Boolean inverse of notna.
 |      DataFrame.dropna : Omit axes labels with missing values.
 |      notna : Top-level notna.
 |      
 |      Examples
 |      --------
 |      Show which entries in a DataFrame are not NA.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(dict(age=[5, 6, np.NaN],
 |      ...                    born=[pd.NaT, pd.Timestamp(&#39;1939-05-27&#39;),
 |      ...                          pd.Timestamp(&#39;1940-04-25&#39;)],
 |      ...                    name=[&#39;Alfred&#39;, &#39;Batman&#39;, &#39;&#39;],
 |      ...                    toy=[None, &#39;Batmobile&#39;, &#39;Joker&#39;]))
 |      &gt;&gt;&gt; df
 |         age       born    name        toy
 |      0  5.0        NaT  Alfred       None
 |      1  6.0 1939-05-27  Batman  Batmobile
 |      2  NaN 1940-04-25              Joker
 |      
 |      &gt;&gt;&gt; df.notna()
 |           age   born  name    toy
 |      0   True  False  True  False
 |      1   True   True  True   True
 |      2  False   True  True   True
 |      
 |      Show which entries in a Series are not NA.
 |      
 |      &gt;&gt;&gt; ser = pd.Series([5, 6, np.NaN])
 |      &gt;&gt;&gt; ser
 |      0    5.0
 |      1    6.0
 |      2    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; ser.notna()
 |      0     True
 |      1     True
 |      2    False
 |      dtype: bool
 |  
 |  nsmallest(self, n, columns, keep: &#39;str&#39; = &#39;first&#39;) -&gt; &#39;DataFrame&#39;
 |      Return the first `n` rows ordered by `columns` in ascending order.
 |      
 |      Return the first `n` rows with the smallest values in `columns`, in
 |      ascending order. The columns that are not specified are returned as
 |      well, but not used for ordering.
 |      
 |      This method is equivalent to
 |      ``df.sort_values(columns, ascending=True).head(n)``, but more
 |      performant.
 |      
 |      Parameters
 |      ----------
 |      n : int
 |          Number of items to retrieve.
 |      columns : list or str
 |          Column name or names to order by.
 |      keep : {&#39;first&#39;, &#39;last&#39;, &#39;all&#39;}, default &#39;first&#39;
 |          Where there are duplicate values:
 |      
 |          - ``first`` : take the first occurrence.
 |          - ``last`` : take the last occurrence.
 |          - ``all`` : do not drop any duplicates, even it means
 |            selecting more than `n` items.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |      
 |      See Also
 |      --------
 |      DataFrame.nlargest : Return the first `n` rows ordered by `columns` in
 |          descending order.
 |      DataFrame.sort_values : Sort DataFrame by the values.
 |      DataFrame.head : Return the first `n` rows without re-ordering.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;population&#39;: [59000000, 65000000, 434000,
 |      ...                                   434000, 434000, 337000, 337000,
 |      ...                                   11300, 11300],
 |      ...                    &#39;GDP&#39;: [1937894, 2583560 , 12011, 4520, 12128,
 |      ...                            17036, 182, 38, 311],
 |      ...                    &#39;alpha-2&#39;: [&quot;IT&quot;, &quot;FR&quot;, &quot;MT&quot;, &quot;MV&quot;, &quot;BN&quot;,
 |      ...                                &quot;IS&quot;, &quot;NR&quot;, &quot;TV&quot;, &quot;AI&quot;]},
 |      ...                   index=[&quot;Italy&quot;, &quot;France&quot;, &quot;Malta&quot;,
 |      ...                          &quot;Maldives&quot;, &quot;Brunei&quot;, &quot;Iceland&quot;,
 |      ...                          &quot;Nauru&quot;, &quot;Tuvalu&quot;, &quot;Anguilla&quot;])
 |      &gt;&gt;&gt; df
 |                population      GDP alpha-2
 |      Italy       59000000  1937894      IT
 |      France      65000000  2583560      FR
 |      Malta         434000    12011      MT
 |      Maldives      434000     4520      MV
 |      Brunei        434000    12128      BN
 |      Iceland       337000    17036      IS
 |      Nauru         337000      182      NR
 |      Tuvalu         11300       38      TV
 |      Anguilla       11300      311      AI
 |      
 |      In the following example, we will use ``nsmallest`` to select the
 |      three rows having the smallest values in column &quot;population&quot;.
 |      
 |      &gt;&gt;&gt; df.nsmallest(3, &#39;population&#39;)
 |                population    GDP alpha-2
 |      Tuvalu         11300     38      TV
 |      Anguilla       11300    311      AI
 |      Iceland       337000  17036      IS
 |      
 |      When using ``keep=&#39;last&#39;``, ties are resolved in reverse order:
 |      
 |      &gt;&gt;&gt; df.nsmallest(3, &#39;population&#39;, keep=&#39;last&#39;)
 |                population  GDP alpha-2
 |      Anguilla       11300  311      AI
 |      Tuvalu         11300   38      TV
 |      Nauru         337000  182      NR
 |      
 |      When using ``keep=&#39;all&#39;``, all duplicate items are maintained:
 |      
 |      &gt;&gt;&gt; df.nsmallest(3, &#39;population&#39;, keep=&#39;all&#39;)
 |                population    GDP alpha-2
 |      Tuvalu         11300     38      TV
 |      Anguilla       11300    311      AI
 |      Iceland       337000  17036      IS
 |      Nauru         337000    182      NR
 |      
 |      To order by the smallest values in column &quot;population&quot; and then &quot;GDP&quot;, we can
 |      specify multiple columns like in the next example.
 |      
 |      &gt;&gt;&gt; df.nsmallest(3, [&#39;population&#39;, &#39;GDP&#39;])
 |                population  GDP alpha-2
 |      Tuvalu         11300   38      TV
 |      Anguilla       11300  311      AI
 |      Nauru         337000  182      NR
 |  
 |  nunique(self, axis: &#39;Axis&#39; = 0, dropna: &#39;bool&#39; = True) -&gt; &#39;Series&#39;
 |      Count number of distinct elements in specified axis.
 |      
 |      Return Series with number of distinct elements. Can ignore NaN
 |      values.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to use. 0 or &#39;index&#39; for row-wise, 1 or &#39;columns&#39; for
 |          column-wise.
 |      dropna : bool, default True
 |          Don&#39;t include NaN in the counts.
 |      
 |      Returns
 |      -------
 |      Series
 |      
 |      See Also
 |      --------
 |      Series.nunique: Method nunique for Series.
 |      DataFrame.count: Count non-NA cells for each column or row.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [4, 5, 6], &#39;B&#39;: [4, 1, 1]})
 |      &gt;&gt;&gt; df.nunique()
 |      A    3
 |      B    2
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df.nunique(axis=1)
 |      0    1
 |      1    2
 |      2    2
 |      dtype: int64
 |  
 |  pivot(self, index=None, columns=None, values=None) -&gt; &#39;DataFrame&#39;
 |      Return reshaped DataFrame organized by given index / column values.
 |      
 |      Reshape data (produce a &quot;pivot&quot; table) based on column values. Uses
 |      unique values from specified `index` / `columns` to form axes of the
 |      resulting DataFrame. This function does not support data
 |      aggregation, multiple values will result in a MultiIndex in the
 |      columns. See the :ref:`User Guide &lt;reshaping&gt;` for more on reshaping.
 |      
 |      Parameters
 |      ----------
 |      index : str or object or a list of str, optional
 |          Column to use to make new frame&#39;s index. If None, uses
 |          existing index.
 |      
 |          .. versionchanged:: 1.1.0
 |             Also accept list of index names.
 |      
 |      columns : str or object or a list of str
 |          Column to use to make new frame&#39;s columns.
 |      
 |          .. versionchanged:: 1.1.0
 |             Also accept list of columns names.
 |      
 |      values : str, object or a list of the previous, optional
 |          Column(s) to use for populating new frame&#39;s values. If not
 |          specified, all remaining columns will be used and the result will
 |          have hierarchically indexed columns.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Returns reshaped DataFrame.
 |      
 |      Raises
 |      ------
 |      ValueError:
 |          When there are any `index`, `columns` combinations with multiple
 |          values. `DataFrame.pivot_table` when you need to aggregate.
 |      
 |      See Also
 |      --------
 |      DataFrame.pivot_table : Generalization of pivot that can handle
 |          duplicate values for one index/column pair.
 |      DataFrame.unstack : Pivot based on the index values instead of a
 |          column.
 |      wide_to_long : Wide panel to long format. Less flexible but more
 |          user-friendly than melt.
 |      
 |      Notes
 |      -----
 |      For finer-tuned control, see hierarchical indexing documentation along
 |      with the related stack/unstack methods.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;foo&#39;: [&#39;one&#39;, &#39;one&#39;, &#39;one&#39;, &#39;two&#39;, &#39;two&#39;,
 |      ...                            &#39;two&#39;],
 |      ...                    &#39;bar&#39;: [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;],
 |      ...                    &#39;baz&#39;: [1, 2, 3, 4, 5, 6],
 |      ...                    &#39;zoo&#39;: [&#39;x&#39;, &#39;y&#39;, &#39;z&#39;, &#39;q&#39;, &#39;w&#39;, &#39;t&#39;]})
 |      &gt;&gt;&gt; df
 |          foo   bar  baz  zoo
 |      0   one   A    1    x
 |      1   one   B    2    y
 |      2   one   C    3    z
 |      3   two   A    4    q
 |      4   two   B    5    w
 |      5   two   C    6    t
 |      
 |      &gt;&gt;&gt; df.pivot(index=&#39;foo&#39;, columns=&#39;bar&#39;, values=&#39;baz&#39;)
 |      bar  A   B   C
 |      foo
 |      one  1   2   3
 |      two  4   5   6
 |      
 |      &gt;&gt;&gt; df.pivot(index=&#39;foo&#39;, columns=&#39;bar&#39;)[&#39;baz&#39;]
 |      bar  A   B   C
 |      foo
 |      one  1   2   3
 |      two  4   5   6
 |      
 |      &gt;&gt;&gt; df.pivot(index=&#39;foo&#39;, columns=&#39;bar&#39;, values=[&#39;baz&#39;, &#39;zoo&#39;])
 |            baz       zoo
 |      bar   A  B  C   A  B  C
 |      foo
 |      one   1  2  3   x  y  z
 |      two   4  5  6   q  w  t
 |      
 |      You could also assign a list of column names or a list of index names.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...        &quot;lev1&quot;: [1, 1, 1, 2, 2, 2],
 |      ...        &quot;lev2&quot;: [1, 1, 2, 1, 1, 2],
 |      ...        &quot;lev3&quot;: [1, 2, 1, 2, 1, 2],
 |      ...        &quot;lev4&quot;: [1, 2, 3, 4, 5, 6],
 |      ...        &quot;values&quot;: [0, 1, 2, 3, 4, 5]})
 |      &gt;&gt;&gt; df
 |          lev1 lev2 lev3 lev4 values
 |      0   1    1    1    1    0
 |      1   1    1    2    2    1
 |      2   1    2    1    3    2
 |      3   2    1    2    4    3
 |      4   2    1    1    5    4
 |      5   2    2    2    6    5
 |      
 |      &gt;&gt;&gt; df.pivot(index=&quot;lev1&quot;, columns=[&quot;lev2&quot;, &quot;lev3&quot;],values=&quot;values&quot;)
 |      lev2    1         2
 |      lev3    1    2    1    2
 |      lev1
 |      1     0.0  1.0  2.0  NaN
 |      2     4.0  3.0  NaN  5.0
 |      
 |      &gt;&gt;&gt; df.pivot(index=[&quot;lev1&quot;, &quot;lev2&quot;], columns=[&quot;lev3&quot;],values=&quot;values&quot;)
 |            lev3    1    2
 |      lev1  lev2
 |         1     1  0.0  1.0
 |               2  2.0  NaN
 |         2     1  4.0  3.0
 |               2  NaN  5.0
 |      
 |      A ValueError is raised if there are any duplicates.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;foo&quot;: [&#39;one&#39;, &#39;one&#39;, &#39;two&#39;, &#39;two&#39;],
 |      ...                    &quot;bar&quot;: [&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;C&#39;],
 |      ...                    &quot;baz&quot;: [1, 2, 3, 4]})
 |      &gt;&gt;&gt; df
 |         foo bar  baz
 |      0  one   A    1
 |      1  one   A    2
 |      2  two   B    3
 |      3  two   C    4
 |      
 |      Notice that the first two rows are the same for our `index`
 |      and `columns` arguments.
 |      
 |      &gt;&gt;&gt; df.pivot(index=&#39;foo&#39;, columns=&#39;bar&#39;, values=&#39;baz&#39;)
 |      Traceback (most recent call last):
 |         ...
 |      ValueError: Index contains duplicate entries, cannot reshape
 |  
 |  pivot_table(self, values=None, index=None, columns=None, aggfunc=&#39;mean&#39;, fill_value=None, margins=False, dropna=True, margins_name=&#39;All&#39;, observed=False, sort=True) -&gt; &#39;DataFrame&#39;
 |      Create a spreadsheet-style pivot table as a DataFrame.
 |      
 |      The levels in the pivot table will be stored in MultiIndex objects
 |      (hierarchical indexes) on the index and columns of the result DataFrame.
 |      
 |      Parameters
 |      ----------
 |      values : column to aggregate, optional
 |      index : column, Grouper, array, or list of the previous
 |          If an array is passed, it must be the same length as the data. The
 |          list can contain any of the other types (except list).
 |          Keys to group by on the pivot table index.  If an array is passed,
 |          it is being used as the same manner as column values.
 |      columns : column, Grouper, array, or list of the previous
 |          If an array is passed, it must be the same length as the data. The
 |          list can contain any of the other types (except list).
 |          Keys to group by on the pivot table column.  If an array is passed,
 |          it is being used as the same manner as column values.
 |      aggfunc : function, list of functions, dict, default numpy.mean
 |          If list of functions passed, the resulting pivot table will have
 |          hierarchical columns whose top level are the function names
 |          (inferred from the function objects themselves)
 |          If dict is passed, the key is column to aggregate and value
 |          is function or list of functions.
 |      fill_value : scalar, default None
 |          Value to replace missing values with (in the resulting pivot table,
 |          after aggregation).
 |      margins : bool, default False
 |          Add all row / columns (e.g. for subtotal / grand totals).
 |      dropna : bool, default True
 |          Do not include columns whose entries are all NaN.
 |      margins_name : str, default &#39;All&#39;
 |          Name of the row / column that will contain the totals
 |          when margins is True.
 |      observed : bool, default False
 |          This only applies if any of the groupers are Categoricals.
 |          If True: only show observed values for categorical groupers.
 |          If False: show all values for categorical groupers.
 |      
 |          .. versionchanged:: 0.25.0
 |      
 |      sort : bool, default True
 |          Specifies if the result should be sorted.
 |      
 |          .. versionadded:: 1.3.0
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          An Excel style pivot table.
 |      
 |      See Also
 |      --------
 |      DataFrame.pivot : Pivot without aggregation that can handle
 |          non-numeric data.
 |      DataFrame.melt: Unpivot a DataFrame from wide to long format,
 |          optionally leaving identifiers set.
 |      wide_to_long : Wide panel to long format. Less flexible but more
 |          user-friendly than melt.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [&quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;,
 |      ...                          &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;],
 |      ...                    &quot;B&quot;: [&quot;one&quot;, &quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;two&quot;,
 |      ...                          &quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;two&quot;],
 |      ...                    &quot;C&quot;: [&quot;small&quot;, &quot;large&quot;, &quot;large&quot;, &quot;small&quot;,
 |      ...                          &quot;small&quot;, &quot;large&quot;, &quot;small&quot;, &quot;small&quot;,
 |      ...                          &quot;large&quot;],
 |      ...                    &quot;D&quot;: [1, 2, 2, 3, 3, 4, 5, 6, 7],
 |      ...                    &quot;E&quot;: [2, 4, 5, 5, 6, 6, 8, 9, 9]})
 |      &gt;&gt;&gt; df
 |           A    B      C  D  E
 |      0  foo  one  small  1  2
 |      1  foo  one  large  2  4
 |      2  foo  one  large  2  5
 |      3  foo  two  small  3  5
 |      4  foo  two  small  3  6
 |      5  bar  one  large  4  6
 |      6  bar  one  small  5  8
 |      7  bar  two  small  6  9
 |      8  bar  two  large  7  9
 |      
 |      This first example aggregates values by taking the sum.
 |      
 |      &gt;&gt;&gt; table = pd.pivot_table(df, values=&#39;D&#39;, index=[&#39;A&#39;, &#39;B&#39;],
 |      ...                     columns=[&#39;C&#39;], aggfunc=np.sum)
 |      &gt;&gt;&gt; table
 |      C        large  small
 |      A   B
 |      bar one    4.0    5.0
 |          two    7.0    6.0
 |      foo one    4.0    1.0
 |          two    NaN    6.0
 |      
 |      We can also fill missing values using the `fill_value` parameter.
 |      
 |      &gt;&gt;&gt; table = pd.pivot_table(df, values=&#39;D&#39;, index=[&#39;A&#39;, &#39;B&#39;],
 |      ...                     columns=[&#39;C&#39;], aggfunc=np.sum, fill_value=0)
 |      &gt;&gt;&gt; table
 |      C        large  small
 |      A   B
 |      bar one      4      5
 |          two      7      6
 |      foo one      4      1
 |          two      0      6
 |      
 |      The next example aggregates by taking the mean across multiple columns.
 |      
 |      &gt;&gt;&gt; table = pd.pivot_table(df, values=[&#39;D&#39;, &#39;E&#39;], index=[&#39;A&#39;, &#39;C&#39;],
 |      ...                     aggfunc={&#39;D&#39;: np.mean,
 |      ...                              &#39;E&#39;: np.mean})
 |      &gt;&gt;&gt; table
 |                      D         E
 |      A   C
 |      bar large  5.500000  7.500000
 |          small  5.500000  8.500000
 |      foo large  2.000000  4.500000
 |          small  2.333333  4.333333
 |      
 |      We can also calculate multiple types of aggregations for any given
 |      value column.
 |      
 |      &gt;&gt;&gt; table = pd.pivot_table(df, values=[&#39;D&#39;, &#39;E&#39;], index=[&#39;A&#39;, &#39;C&#39;],
 |      ...                     aggfunc={&#39;D&#39;: np.mean,
 |      ...                              &#39;E&#39;: [min, max, np.mean]})
 |      &gt;&gt;&gt; table
 |                      D    E
 |                  mean  max      mean  min
 |      A   C
 |      bar large  5.500000  9.0  7.500000  6.0
 |          small  5.500000  9.0  8.500000  8.0
 |      foo large  2.000000  5.0  4.500000  4.0
 |          small  2.333333  6.0  4.333333  2.0
 |  
 |  pop(self, item: &#39;Hashable&#39;) -&gt; &#39;Series&#39;
 |      Return item and drop from frame. Raise KeyError if not found.
 |      
 |      Parameters
 |      ----------
 |      item : label
 |          Label of column to be popped.
 |      
 |      Returns
 |      -------
 |      Series
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([(&#39;falcon&#39;, &#39;bird&#39;, 389.0),
 |      ...                    (&#39;parrot&#39;, &#39;bird&#39;, 24.0),
 |      ...                    (&#39;lion&#39;, &#39;mammal&#39;, 80.5),
 |      ...                    (&#39;monkey&#39;, &#39;mammal&#39;, np.nan)],
 |      ...                   columns=(&#39;name&#39;, &#39;class&#39;, &#39;max_speed&#39;))
 |      &gt;&gt;&gt; df
 |           name   class  max_speed
 |      0  falcon    bird      389.0
 |      1  parrot    bird       24.0
 |      2    lion  mammal       80.5
 |      3  monkey  mammal        NaN
 |      
 |      &gt;&gt;&gt; df.pop(&#39;class&#39;)
 |      0      bird
 |      1      bird
 |      2    mammal
 |      3    mammal
 |      Name: class, dtype: object
 |      
 |      &gt;&gt;&gt; df
 |           name  max_speed
 |      0  falcon      389.0
 |      1  parrot       24.0
 |      2    lion       80.5
 |      3  monkey        NaN
 |  
 |  pow(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Exponential power of dataframe and other, element-wise (binary operator `pow`).
 |      
 |      Equivalent to ``dataframe ** other``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `rpow`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)
 |      Return the product of the values over the requested axis.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |          Axis for the function to be applied on.
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      min_count : int, default 0
 |          The required number of valid values to perform the operation. If fewer than
 |          ``min_count`` non-NA values are present the result will be NA.
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |      
 |      See Also
 |      --------
 |      Series.sum : Return the sum.
 |      Series.min : Return the minimum.
 |      Series.max : Return the maximum.
 |      Series.idxmin : Return the index of the minimum.
 |      Series.idxmax : Return the index of the maximum.
 |      DataFrame.sum : Return the sum over the requested axis.
 |      DataFrame.min : Return the minimum over the requested axis.
 |      DataFrame.max : Return the maximum over the requested axis.
 |      DataFrame.idxmin : Return the index of the minimum over the requested axis.
 |      DataFrame.idxmax : Return the index of the maximum over the requested axis.
 |      
 |      Examples
 |      --------
 |      By default, the product of an empty or all-NA Series is ``1``
 |      
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).prod()
 |      1.0
 |      
 |      This can be controlled with the ``min_count`` parameter
 |      
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).prod(min_count=1)
 |      nan
 |      
 |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and
 |      empty series identically.
 |      
 |      &gt;&gt;&gt; pd.Series([np.nan]).prod()
 |      1.0
 |      
 |      &gt;&gt;&gt; pd.Series([np.nan]).prod(min_count=1)
 |      nan
 |  
 |  product = prod(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)
 |  
 |  quantile(self, q=0.5, axis: &#39;Axis&#39; = 0, numeric_only: &#39;bool&#39; = True, interpolation: &#39;str&#39; = &#39;linear&#39;)
 |      Return values at the given quantile over requested axis.
 |      
 |      Parameters
 |      ----------
 |      q : float or array-like, default 0.5 (50% quantile)
 |          Value between 0 &lt;= q &lt;= 1, the quantile(s) to compute.
 |      axis : {0, 1, &#39;index&#39;, &#39;columns&#39;}, default 0
 |          Equals 0 or &#39;index&#39; for row-wise, 1 or &#39;columns&#39; for column-wise.
 |      numeric_only : bool, default True
 |          If False, the quantile of datetime and timedelta data will be
 |          computed as well.
 |      interpolation : {&#39;linear&#39;, &#39;lower&#39;, &#39;higher&#39;, &#39;midpoint&#39;, &#39;nearest&#39;}
 |          This optional parameter specifies the interpolation method to use,
 |          when the desired quantile lies between two data points `i` and `j`:
 |      
 |          * linear: `i + (j - i) * fraction`, where `fraction` is the
 |            fractional part of the index surrounded by `i` and `j`.
 |          * lower: `i`.
 |          * higher: `j`.
 |          * nearest: `i` or `j` whichever is nearest.
 |          * midpoint: (`i` + `j`) / 2.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |      
 |          If ``q`` is an array, a DataFrame will be returned where the
 |            index is ``q``, the columns are the columns of self, and the
 |            values are the quantiles.
 |          If ``q`` is a float, a Series will be returned where the
 |            index is the columns of self and the values are the quantiles.
 |      
 |      See Also
 |      --------
 |      core.window.Rolling.quantile: Rolling quantile.
 |      numpy.percentile: Numpy function to compute the percentile.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(np.array([[1, 1], [2, 10], [3, 100], [4, 100]]),
 |      ...                   columns=[&#39;a&#39;, &#39;b&#39;])
 |      &gt;&gt;&gt; df.quantile(.1)
 |      a    1.3
 |      b    3.7
 |      Name: 0.1, dtype: float64
 |      &gt;&gt;&gt; df.quantile([.1, .5])
 |             a     b
 |      0.1  1.3   3.7
 |      0.5  2.5  55.0
 |      
 |      Specifying `numeric_only=False` will also compute the quantile of
 |      datetime and timedelta data.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [1, 2],
 |      ...                    &#39;B&#39;: [pd.Timestamp(&#39;2010&#39;),
 |      ...                          pd.Timestamp(&#39;2011&#39;)],
 |      ...                    &#39;C&#39;: [pd.Timedelta(&#39;1 days&#39;),
 |      ...                          pd.Timedelta(&#39;2 days&#39;)]})
 |      &gt;&gt;&gt; df.quantile(0.5, numeric_only=False)
 |      A                    1.5
 |      B    2010-07-02 12:00:00
 |      C        1 days 12:00:00
 |      Name: 0.5, dtype: object
 |  
 |  query(self, expr: &#39;str&#39;, inplace: &#39;bool&#39; = False, **kwargs)
 |      Query the columns of a DataFrame with a boolean expression.
 |      
 |      Parameters
 |      ----------
 |      expr : str
 |          The query string to evaluate.
 |      
 |          You can refer to variables
 |          in the environment by prefixing them with an &#39;@&#39; character like
 |          ``@a + b``.
 |      
 |          You can refer to column names that are not valid Python variable names
 |          by surrounding them in backticks. Thus, column names containing spaces
 |          or punctuations (besides underscores) or starting with digits must be
 |          surrounded by backticks. (For example, a column named &quot;Area (cm^2)&quot; would
 |          be referenced as ```Area (cm^2)```). Column names which are Python keywords
 |          (like &quot;list&quot;, &quot;for&quot;, &quot;import&quot;, etc) cannot be used.
 |      
 |          For example, if one of your columns is called ``a a`` and you want
 |          to sum it with ``b``, your query should be ```a a` + b``.
 |      
 |          .. versionadded:: 0.25.0
 |              Backtick quoting introduced.
 |      
 |          .. versionadded:: 1.0.0
 |              Expanding functionality of backtick quoting for more than only spaces.
 |      
 |      inplace : bool
 |          Whether the query should modify the data in place or return
 |          a modified copy.
 |      **kwargs
 |          See the documentation for :func:`eval` for complete details
 |          on the keyword arguments accepted by :meth:`DataFrame.query`.
 |      
 |      Returns
 |      -------
 |      DataFrame or None
 |          DataFrame resulting from the provided query expression or
 |          None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      eval : Evaluate a string describing operations on
 |          DataFrame columns.
 |      DataFrame.eval : Evaluate a string describing operations on
 |          DataFrame columns.
 |      
 |      Notes
 |      -----
 |      The result of the evaluation of this expression is first passed to
 |      :attr:`DataFrame.loc` and if that fails because of a
 |      multidimensional key (e.g., a DataFrame) then the result will be passed
 |      to :meth:`DataFrame.__getitem__`.
 |      
 |      This method uses the top-level :func:`eval` function to
 |      evaluate the passed query.
 |      
 |      The :meth:`~pandas.DataFrame.query` method uses a slightly
 |      modified Python syntax by default. For example, the ``&amp;`` and ``|``
 |      (bitwise) operators have the precedence of their boolean cousins,
 |      :keyword:`and` and :keyword:`or`. This *is* syntactically valid Python,
 |      however the semantics are different.
 |      
 |      You can change the semantics of the expression by passing the keyword
 |      argument ``parser=&#39;python&#39;``. This enforces the same semantics as
 |      evaluation in Python space. Likewise, you can pass ``engine=&#39;python&#39;``
 |      to evaluate an expression using Python itself as a backend. This is not
 |      recommended as it is inefficient compared to using ``numexpr`` as the
 |      engine.
 |      
 |      The :attr:`DataFrame.index` and
 |      :attr:`DataFrame.columns` attributes of the
 |      :class:`~pandas.DataFrame` instance are placed in the query namespace
 |      by default, which allows you to treat both the index and columns of the
 |      frame as a column in the frame.
 |      The identifier ``index`` is used for the frame index; you can also
 |      use the name of the index to identify it in a query. Please note that
 |      Python keywords may not be used as identifiers.
 |      
 |      For further details and examples see the ``query`` documentation in
 |      :ref:`indexing &lt;indexing.query&gt;`.
 |      
 |      *Backtick quoted variables*
 |      
 |      Backtick quoted variables are parsed as literal Python code and
 |      are converted internally to a Python valid identifier.
 |      This can lead to the following problems.
 |      
 |      During parsing a number of disallowed characters inside the backtick
 |      quoted string are replaced by strings that are allowed as a Python identifier.
 |      These characters include all operators in Python, the space character, the
 |      question mark, the exclamation mark, the dollar sign, and the euro sign.
 |      For other characters that fall outside the ASCII range (U+0001..U+007F)
 |      and those that are not further specified in PEP 3131,
 |      the query parser will raise an error.
 |      This excludes whitespace different than the space character,
 |      but also the hashtag (as it is used for comments) and the backtick
 |      itself (backtick can also not be escaped).
 |      
 |      In a special case, quotes that make a pair around a backtick can
 |      confuse the parser.
 |      For example, ```it&#39;s` &gt; `that&#39;s``` will raise an error,
 |      as it forms a quoted string (``&#39;s &gt; `that&#39;``) with a backtick inside.
 |      
 |      See also the Python documentation about lexical analysis
 |      (https://docs.python.org/3/reference/lexical_analysis.html)
 |      in combination with the source code in :mod:`pandas.core.computation.parsing`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: range(1, 6),
 |      ...                    &#39;B&#39;: range(10, 0, -2),
 |      ...                    &#39;C C&#39;: range(10, 5, -1)})
 |      &gt;&gt;&gt; df
 |         A   B  C C
 |      0  1  10   10
 |      1  2   8    9
 |      2  3   6    8
 |      3  4   4    7
 |      4  5   2    6
 |      &gt;&gt;&gt; df.query(&#39;A &gt; B&#39;)
 |         A  B  C C
 |      4  5  2    6
 |      
 |      The previous expression is equivalent to
 |      
 |      &gt;&gt;&gt; df[df.A &gt; df.B]
 |         A  B  C C
 |      4  5  2    6
 |      
 |      For columns with spaces in their name, you can use backtick quoting.
 |      
 |      &gt;&gt;&gt; df.query(&#39;B == `C C`&#39;)
 |         A   B  C C
 |      0  1  10   10
 |      
 |      The previous expression is equivalent to
 |      
 |      &gt;&gt;&gt; df[df.B == df[&#39;C C&#39;]]
 |         A   B  C C
 |      0  1  10   10
 |  
 |  radd(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Addition of dataframe and other, element-wise (binary operator `radd`).
 |      
 |      Equivalent to ``other + dataframe``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `add`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  rdiv = rtruediv(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |  
 |  reindex(self, labels=None, index=None, columns=None, axis=None, method=None, copy=True, level=None, fill_value=nan, limit=None, tolerance=None)
 |      Conform Series/DataFrame to new index with optional filling logic.
 |      
 |      Places NA/NaN in locations having no value in the previous index. A new object
 |      is produced unless the new index is equivalent to the current one and
 |      ``copy=False``.
 |      
 |      Parameters
 |      ----------
 |      
 |      keywords for axes : array-like, optional
 |          New labels / index to conform to, should be specified using
 |          keywords. Preferably an Index object to avoid duplicating data.
 |      
 |      method : {None, &#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;, &#39;nearest&#39;}
 |          Method to use for filling holes in reindexed DataFrame.
 |          Please note: this is only applicable to DataFrames/Series with a
 |          monotonically increasing/decreasing index.
 |      
 |          * None (default): don&#39;t fill gaps
 |          * pad / ffill: Propagate last valid observation forward to next
 |            valid.
 |          * backfill / bfill: Use next valid observation to fill gap.
 |          * nearest: Use nearest valid observations to fill gap.
 |      
 |      copy : bool, default True
 |          Return a new object, even if the passed indexes are the same.
 |      level : int or name
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : scalar, default np.NaN
 |          Value to use for missing values. Defaults to NaN, but can be any
 |          &quot;compatible&quot; value.
 |      limit : int, default None
 |          Maximum number of consecutive elements to forward or backward fill.
 |      tolerance : optional
 |          Maximum distance between original and new labels for inexact
 |          matches. The values of the index at the matching locations most
 |          satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
 |      
 |          Tolerance may be a scalar value, which applies the same tolerance
 |          to all values, or list-like, which applies variable tolerance per
 |          element. List-like includes list, tuple, array, Series, and must be
 |          the same size as the index and its dtype must exactly match the
 |          index&#39;s type.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame with changed index.
 |      
 |      See Also
 |      --------
 |      DataFrame.set_index : Set row labels.
 |      DataFrame.reset_index : Remove row labels or move them to new columns.
 |      DataFrame.reindex_like : Change to same indices as other DataFrame.
 |      
 |      Examples
 |      --------
 |      ``DataFrame.reindex`` supports two calling conventions
 |      
 |      * ``(index=index_labels, columns=column_labels, ...)``
 |      * ``(labels, axis={&#39;index&#39;, &#39;columns&#39;}, ...)``
 |      
 |      We *highly* recommend using keyword arguments to clarify your
 |      intent.
 |      
 |      Create a dataframe with some fictional data.
 |      
 |      &gt;&gt;&gt; index = [&#39;Firefox&#39;, &#39;Chrome&#39;, &#39;Safari&#39;, &#39;IE10&#39;, &#39;Konqueror&#39;]
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;http_status&#39;: [200, 200, 404, 404, 301],
 |      ...                   &#39;response_time&#39;: [0.04, 0.02, 0.07, 0.08, 1.0]},
 |      ...                   index=index)
 |      &gt;&gt;&gt; df
 |                 http_status  response_time
 |      Firefox            200           0.04
 |      Chrome             200           0.02
 |      Safari             404           0.07
 |      IE10               404           0.08
 |      Konqueror          301           1.00
 |      
 |      Create a new index and reindex the dataframe. By default
 |      values in the new index that do not have corresponding
 |      records in the dataframe are assigned ``NaN``.
 |      
 |      &gt;&gt;&gt; new_index = [&#39;Safari&#39;, &#39;Iceweasel&#39;, &#39;Comodo Dragon&#39;, &#39;IE10&#39;,
 |      ...              &#39;Chrome&#39;]
 |      &gt;&gt;&gt; df.reindex(new_index)
 |                     http_status  response_time
 |      Safari               404.0           0.07
 |      Iceweasel              NaN            NaN
 |      Comodo Dragon          NaN            NaN
 |      IE10                 404.0           0.08
 |      Chrome               200.0           0.02
 |      
 |      We can fill in the missing values by passing a value to
 |      the keyword ``fill_value``. Because the index is not monotonically
 |      increasing or decreasing, we cannot use arguments to the keyword
 |      ``method`` to fill the ``NaN`` values.
 |      
 |      &gt;&gt;&gt; df.reindex(new_index, fill_value=0)
 |                     http_status  response_time
 |      Safari                 404           0.07
 |      Iceweasel                0           0.00
 |      Comodo Dragon            0           0.00
 |      IE10                   404           0.08
 |      Chrome                 200           0.02
 |      
 |      &gt;&gt;&gt; df.reindex(new_index, fill_value=&#39;missing&#39;)
 |                    http_status response_time
 |      Safari                404          0.07
 |      Iceweasel         missing       missing
 |      Comodo Dragon     missing       missing
 |      IE10                  404          0.08
 |      Chrome                200          0.02
 |      
 |      We can also reindex the columns.
 |      
 |      &gt;&gt;&gt; df.reindex(columns=[&#39;http_status&#39;, &#39;user_agent&#39;])
 |                 http_status  user_agent
 |      Firefox            200         NaN
 |      Chrome             200         NaN
 |      Safari             404         NaN
 |      IE10               404         NaN
 |      Konqueror          301         NaN
 |      
 |      Or we can use &quot;axis-style&quot; keyword arguments
 |      
 |      &gt;&gt;&gt; df.reindex([&#39;http_status&#39;, &#39;user_agent&#39;], axis=&quot;columns&quot;)
 |                 http_status  user_agent
 |      Firefox            200         NaN
 |      Chrome             200         NaN
 |      Safari             404         NaN
 |      IE10               404         NaN
 |      Konqueror          301         NaN
 |      
 |      To further illustrate the filling functionality in
 |      ``reindex``, we will create a dataframe with a
 |      monotonically increasing index (for example, a sequence
 |      of dates).
 |      
 |      &gt;&gt;&gt; date_index = pd.date_range(&#39;1/1/2010&#39;, periods=6, freq=&#39;D&#39;)
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&quot;prices&quot;: [100, 101, np.nan, 100, 89, 88]},
 |      ...                    index=date_index)
 |      &gt;&gt;&gt; df2
 |                  prices
 |      2010-01-01   100.0
 |      2010-01-02   101.0
 |      2010-01-03     NaN
 |      2010-01-04   100.0
 |      2010-01-05    89.0
 |      2010-01-06    88.0
 |      
 |      Suppose we decide to expand the dataframe to cover a wider
 |      date range.
 |      
 |      &gt;&gt;&gt; date_index2 = pd.date_range(&#39;12/29/2009&#39;, periods=10, freq=&#39;D&#39;)
 |      &gt;&gt;&gt; df2.reindex(date_index2)
 |                  prices
 |      2009-12-29     NaN
 |      2009-12-30     NaN
 |      2009-12-31     NaN
 |      2010-01-01   100.0
 |      2010-01-02   101.0
 |      2010-01-03     NaN
 |      2010-01-04   100.0
 |      2010-01-05    89.0
 |      2010-01-06    88.0
 |      2010-01-07     NaN
 |      
 |      The index entries that did not have a value in the original data frame
 |      (for example, &#39;2009-12-29&#39;) are by default filled with ``NaN``.
 |      If desired, we can fill in the missing values using one of several
 |      options.
 |      
 |      For example, to back-propagate the last valid value to fill the ``NaN``
 |      values, pass ``bfill`` as an argument to the ``method`` keyword.
 |      
 |      &gt;&gt;&gt; df2.reindex(date_index2, method=&#39;bfill&#39;)
 |                  prices
 |      2009-12-29   100.0
 |      2009-12-30   100.0
 |      2009-12-31   100.0
 |      2010-01-01   100.0
 |      2010-01-02   101.0
 |      2010-01-03     NaN
 |      2010-01-04   100.0
 |      2010-01-05    89.0
 |      2010-01-06    88.0
 |      2010-01-07     NaN
 |      
 |      Please note that the ``NaN`` value present in the original dataframe
 |      (at index value 2010-01-03) will not be filled by any of the
 |      value propagation schemes. This is because filling while reindexing
 |      does not look at dataframe values, but only compares the original and
 |      desired indexes. If you do want to fill in the ``NaN`` values present
 |      in the original dataframe, use the ``fillna()`` method.
 |      
 |      See the :ref:`user guide &lt;basics.reindexing&gt;` for more.
 |  
 |  rename(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False, level=None, errors=&#39;ignore&#39;)
 |      Alter axes labels.
 |      
 |      Function / dict values must be unique (1-to-1). Labels not contained in
 |      a dict / Series will be left as-is. Extra labels listed don&#39;t throw an
 |      error.
 |      
 |      See the :ref:`user guide &lt;basics.rename&gt;` for more.
 |      
 |      Parameters
 |      ----------
 |      mapper : dict-like or function
 |          Dict-like or function transformations to apply to
 |          that axis&#39; values. Use either ``mapper`` and ``axis`` to
 |          specify the axis to target with ``mapper``, or ``index`` and
 |          ``columns``.
 |      index : dict-like or function
 |          Alternative to specifying axis (``mapper, axis=0``
 |          is equivalent to ``index=mapper``).
 |      columns : dict-like or function
 |          Alternative to specifying axis (``mapper, axis=1``
 |          is equivalent to ``columns=mapper``).
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Axis to target with ``mapper``. Can be either the axis name
 |          (&#39;index&#39;, &#39;columns&#39;) or number (0, 1). The default is &#39;index&#39;.
 |      copy : bool, default True
 |          Also copy underlying data.
 |      inplace : bool, default False
 |          Whether to return a new DataFrame. If True then value of copy is
 |          ignored.
 |      level : int or level name, default None
 |          In case of a MultiIndex, only rename labels in the specified
 |          level.
 |      errors : {&#39;ignore&#39;, &#39;raise&#39;}, default &#39;ignore&#39;
 |          If &#39;raise&#39;, raise a `KeyError` when a dict-like `mapper`, `index`,
 |          or `columns` contains labels that are not present in the Index
 |          being transformed.
 |          If &#39;ignore&#39;, existing keys will be renamed and extra keys will be
 |          ignored.
 |      
 |      Returns
 |      -------
 |      DataFrame or None
 |          DataFrame with the renamed axis labels or None if ``inplace=True``.
 |      
 |      Raises
 |      ------
 |      KeyError
 |          If any of the labels is not found in the selected axis and
 |          &quot;errors=&#39;raise&#39;&quot;.
 |      
 |      See Also
 |      --------
 |      DataFrame.rename_axis : Set the name of the axis.
 |      
 |      Examples
 |      --------
 |      ``DataFrame.rename`` supports two calling conventions
 |      
 |      * ``(index=index_mapper, columns=columns_mapper, ...)``
 |      * ``(mapper, axis={&#39;index&#39;, &#39;columns&#39;}, ...)``
 |      
 |      We *highly* recommend using keyword arguments to clarify your
 |      intent.
 |      
 |      Rename columns using a mapping:
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2, 3], &quot;B&quot;: [4, 5, 6]})
 |      &gt;&gt;&gt; df.rename(columns={&quot;A&quot;: &quot;a&quot;, &quot;B&quot;: &quot;c&quot;})
 |         a  c
 |      0  1  4
 |      1  2  5
 |      2  3  6
 |      
 |      Rename index using a mapping:
 |      
 |      &gt;&gt;&gt; df.rename(index={0: &quot;x&quot;, 1: &quot;y&quot;, 2: &quot;z&quot;})
 |         A  B
 |      x  1  4
 |      y  2  5
 |      z  3  6
 |      
 |      Cast index labels to a different type:
 |      
 |      &gt;&gt;&gt; df.index
 |      RangeIndex(start=0, stop=3, step=1)
 |      &gt;&gt;&gt; df.rename(index=str).index
 |      Index([&#39;0&#39;, &#39;1&#39;, &#39;2&#39;], dtype=&#39;object&#39;)
 |      
 |      &gt;&gt;&gt; df.rename(columns={&quot;A&quot;: &quot;a&quot;, &quot;B&quot;: &quot;b&quot;, &quot;C&quot;: &quot;c&quot;}, errors=&quot;raise&quot;)
 |      Traceback (most recent call last):
 |      KeyError: [&#39;C&#39;] not found in axis
 |      
 |      Using axis-style parameters:
 |      
 |      &gt;&gt;&gt; df.rename(str.lower, axis=&#39;columns&#39;)
 |         a  b
 |      0  1  4
 |      1  2  5
 |      2  3  6
 |      
 |      &gt;&gt;&gt; df.rename({1: 2, 2: 4}, axis=&#39;index&#39;)
 |         A  B
 |      0  1  4
 |      2  2  5
 |      4  3  6
 |  
 |  reorder_levels(self, order: &#39;Sequence[Axis]&#39;, axis: &#39;Axis&#39; = 0) -&gt; &#39;DataFrame&#39;
 |      Rearrange index levels using input order. May not drop or duplicate levels.
 |      
 |      Parameters
 |      ----------
 |      order : list of int or list of str
 |          List representing new level order. Reference level by number
 |          (position) or by key (label).
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Where to reorder levels.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |  
 |  replace(self, to_replace=None, value=None, inplace: &#39;bool&#39; = False, limit=None, regex: &#39;bool&#39; = False, method: &#39;str&#39; = &#39;pad&#39;)
 |      Replace values given in `to_replace` with `value`.
 |      
 |      Values of the DataFrame are replaced with other values dynamically.
 |      
 |      This differs from updating with ``.loc`` or ``.iloc``, which require
 |      you to specify a location to update with some value.
 |      
 |      Parameters
 |      ----------
 |      to_replace : str, regex, list, dict, Series, int, float, or None
 |          How to find the values that will be replaced.
 |      
 |          * numeric, str or regex:
 |      
 |              - numeric: numeric values equal to `to_replace` will be
 |                  replaced with `value`
 |              - str: string exactly matching `to_replace` will be replaced
 |                  with `value`
 |              - regex: regexs matching `to_replace` will be replaced with
 |                  `value`
 |      
 |          * list of str, regex, or numeric:
 |      
 |              - First, if `to_replace` and `value` are both lists, they
 |                  **must** be the same length.
 |              - Second, if ``regex=True`` then all of the strings in **both**
 |                  lists will be interpreted as regexs otherwise they will match
 |                  directly. This doesn&#39;t matter much for `value` since there
 |                  are only a few possible substitution regexes you can use.
 |              - str, regex and numeric rules apply as above.
 |      
 |          * dict:
 |      
 |              - Dicts can be used to specify different replacement values
 |                  for different existing values. For example,
 |                  ``{&#39;a&#39;: &#39;b&#39;, &#39;y&#39;: &#39;z&#39;}`` replaces the value &#39;a&#39; with &#39;b&#39; and
 |                  &#39;y&#39; with &#39;z&#39;. To use a dict in this way the `value`
 |                  parameter should be `None`.
 |              - For a DataFrame a dict can specify that different values
 |                  should be replaced in different columns. For example,
 |                  ``{&#39;a&#39;: 1, &#39;b&#39;: &#39;z&#39;}`` looks for the value 1 in column &#39;a&#39;
 |                  and the value &#39;z&#39; in column &#39;b&#39; and replaces these values
 |                  with whatever is specified in `value`. The `value` parameter
 |                  should not be ``None`` in this case. You can treat this as a
 |                  special case of passing two lists except that you are
 |                  specifying the column to search in.
 |              - For a DataFrame nested dictionaries, e.g.,
 |                  ``{&#39;a&#39;: {&#39;b&#39;: np.nan}}``, are read as follows: look in column
 |                  &#39;a&#39; for the value &#39;b&#39; and replace it with NaN. The `value`
 |                  parameter should be ``None`` to use a nested dict in this
 |                  way. You can nest regular expressions as well. Note that
 |                  column names (the top-level dictionary keys in a nested
 |                  dictionary) **cannot** be regular expressions.
 |      
 |          * None:
 |      
 |              - This means that the `regex` argument must be a string,
 |                  compiled regular expression, or list, dict, ndarray or
 |                  Series of such elements. If `value` is also ``None`` then
 |                  this **must** be a nested dictionary or Series.
 |      
 |          See the examples section for examples of each of these.
 |      value : scalar, dict, list, str, regex, default None
 |          Value to replace any values matching `to_replace` with.
 |          For a DataFrame a dict of values can be used to specify which
 |          value to use for each column (columns not in the dict will not be
 |          filled). Regular expressions, strings and lists or dicts of such
 |          objects are also allowed.
 |      
 |      inplace : bool, default False
 |          If True, performs operation inplace and returns None.
 |      limit : int, default None
 |          Maximum size gap to forward or backward fill.
 |      regex : bool or same types as `to_replace`, default False
 |          Whether to interpret `to_replace` and/or `value` as regular
 |          expressions. If this is ``True`` then `to_replace` *must* be a
 |          string. Alternatively, this could be a regular expression or a
 |          list, dict, or array of regular expressions in which case
 |          `to_replace` must be ``None``.
 |      method : {&#39;pad&#39;, &#39;ffill&#39;, &#39;bfill&#39;, `None`}
 |          The method to use when for replacement, when `to_replace` is a
 |          scalar, list or tuple and `value` is ``None``.
 |      
 |          .. versionchanged:: 0.23.0
 |              Added to DataFrame.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Object after replacement.
 |      
 |      Raises
 |      ------
 |      AssertionError
 |          * If `regex` is not a ``bool`` and `to_replace` is not
 |              ``None``.
 |      
 |      TypeError
 |          * If `to_replace` is not a scalar, array-like, ``dict``, or ``None``
 |          * If `to_replace` is a ``dict`` and `value` is not a ``list``,
 |              ``dict``, ``ndarray``, or ``Series``
 |          * If `to_replace` is ``None`` and `regex` is not compilable
 |              into a regular expression or is a list, dict, ndarray, or
 |              Series.
 |          * When replacing multiple ``bool`` or ``datetime64`` objects and
 |              the arguments to `to_replace` does not match the type of the
 |              value being replaced
 |      
 |      ValueError
 |          * If a ``list`` or an ``ndarray`` is passed to `to_replace` and
 |              `value` but they are not the same length.
 |      
 |      See Also
 |      --------
 |      DataFrame.fillna : Fill NA values.
 |      DataFrame.where : Replace values based on boolean condition.
 |      Series.str.replace : Simple string replacement.
 |      
 |      Notes
 |      -----
 |      * Regex substitution is performed under the hood with ``re.sub``. The
 |          rules for substitution for ``re.sub`` are the same.
 |      * Regular expressions will only substitute on strings, meaning you
 |          cannot provide, for example, a regular expression matching floating
 |          point numbers and expect the columns in your frame that have a
 |          numeric dtype to be matched. However, if those floating point
 |          numbers *are* strings, then you can do this.
 |      * This method has *a lot* of options. You are encouraged to experiment
 |          and play with this method to gain intuition about how it works.
 |      * When dict is used as the `to_replace` value, it is like
 |          key(s) in the dict are the to_replace part and
 |          value(s) in the dict are the value parameter.
 |      
 |      Examples
 |      --------
 |      
 |      **Scalar `to_replace` and `value`**
 |      
 |      &gt;&gt;&gt; s = pd.Series([0, 1, 2, 3, 4])
 |      &gt;&gt;&gt; s.replace(0, 5)
 |      0    5
 |      1    1
 |      2    2
 |      3    3
 |      4    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [0, 1, 2, 3, 4],
 |      ...                    &#39;B&#39;: [5, 6, 7, 8, 9],
 |      ...                    &#39;C&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;]})
 |      &gt;&gt;&gt; df.replace(0, 5)
 |          A  B  C
 |      0  5  5  a
 |      1  1  6  b
 |      2  2  7  c
 |      3  3  8  d
 |      4  4  9  e
 |      
 |      **List-like `to_replace`**
 |      
 |      &gt;&gt;&gt; df.replace([0, 1, 2, 3], 4)
 |          A  B  C
 |      0  4  5  a
 |      1  4  6  b
 |      2  4  7  c
 |      3  4  8  d
 |      4  4  9  e
 |      
 |      &gt;&gt;&gt; df.replace([0, 1, 2, 3], [4, 3, 2, 1])
 |          A  B  C
 |      0  4  5  a
 |      1  3  6  b
 |      2  2  7  c
 |      3  1  8  d
 |      4  4  9  e
 |      
 |      &gt;&gt;&gt; s.replace([1, 2], method=&#39;bfill&#39;)
 |      0    0
 |      1    3
 |      2    3
 |      3    3
 |      4    4
 |      dtype: int64
 |      
 |      **dict-like `to_replace`**
 |      
 |      &gt;&gt;&gt; df.replace({0: 10, 1: 100})
 |              A  B  C
 |      0   10  5  a
 |      1  100  6  b
 |      2    2  7  c
 |      3    3  8  d
 |      4    4  9  e
 |      
 |      &gt;&gt;&gt; df.replace({&#39;A&#39;: 0, &#39;B&#39;: 5}, 100)
 |              A    B  C
 |      0  100  100  a
 |      1    1    6  b
 |      2    2    7  c
 |      3    3    8  d
 |      4    4    9  e
 |      
 |      &gt;&gt;&gt; df.replace({&#39;A&#39;: {0: 100, 4: 400}})
 |              A  B  C
 |      0  100  5  a
 |      1    1  6  b
 |      2    2  7  c
 |      3    3  8  d
 |      4  400  9  e
 |      
 |      **Regular expression `to_replace`**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [&#39;bat&#39;, &#39;foo&#39;, &#39;bait&#39;],
 |      ...                    &#39;B&#39;: [&#39;abc&#39;, &#39;bar&#39;, &#39;xyz&#39;]})
 |      &gt;&gt;&gt; df.replace(to_replace=r&#39;^ba.$&#39;, value=&#39;new&#39;, regex=True)
 |              A    B
 |      0   new  abc
 |      1   foo  new
 |      2  bait  xyz
 |      
 |      &gt;&gt;&gt; df.replace({&#39;A&#39;: r&#39;^ba.$&#39;}, {&#39;A&#39;: &#39;new&#39;}, regex=True)
 |              A    B
 |      0   new  abc
 |      1   foo  bar
 |      2  bait  xyz
 |      
 |      &gt;&gt;&gt; df.replace(regex=r&#39;^ba.$&#39;, value=&#39;new&#39;)
 |              A    B
 |      0   new  abc
 |      1   foo  new
 |      2  bait  xyz
 |      
 |      &gt;&gt;&gt; df.replace(regex={r&#39;^ba.$&#39;: &#39;new&#39;, &#39;foo&#39;: &#39;xyz&#39;})
 |              A    B
 |      0   new  abc
 |      1   xyz  new
 |      2  bait  xyz
 |      
 |      &gt;&gt;&gt; df.replace(regex=[r&#39;^ba.$&#39;, &#39;foo&#39;], value=&#39;new&#39;)
 |              A    B
 |      0   new  abc
 |      1   new  new
 |      2  bait  xyz
 |      
 |      Compare the behavior of ``s.replace({&#39;a&#39;: None})`` and
 |      ``s.replace(&#39;a&#39;, None)`` to understand the peculiarities
 |      of the `to_replace` parameter:
 |      
 |      &gt;&gt;&gt; s = pd.Series([10, &#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;a&#39;])
 |      
 |      When one uses a dict as the `to_replace` value, it is like the
 |      value(s) in the dict are equal to the `value` parameter.
 |      ``s.replace({&#39;a&#39;: None})`` is equivalent to
 |      ``s.replace(to_replace={&#39;a&#39;: None}, value=None, method=None)``:
 |      
 |      &gt;&gt;&gt; s.replace({&#39;a&#39;: None})
 |      0      10
 |      1    None
 |      2    None
 |      3       b
 |      4    None
 |      dtype: object
 |      
 |      When ``value=None`` and `to_replace` is a scalar, list or
 |      tuple, `replace` uses the method parameter (default &#39;pad&#39;) to do the
 |      replacement. So this is why the &#39;a&#39; values are being replaced by 10
 |      in rows 1 and 2 and &#39;b&#39; in row 4 in this case.
 |      The command ``s.replace(&#39;a&#39;, None)`` is actually equivalent to
 |      ``s.replace(to_replace=&#39;a&#39;, value=None, method=&#39;pad&#39;)``:
 |      
 |      &gt;&gt;&gt; s.replace(&#39;a&#39;, None)
 |      0    10
 |      1    10
 |      2    10
 |      3     b
 |      4     b
 |      dtype: object
 |  
 |  resample(self, rule, axis=0, closed: &#39;str | None&#39; = None, label: &#39;str | None&#39; = None, convention: &#39;str&#39; = &#39;start&#39;, kind: &#39;str | None&#39; = None, loffset=None, base: &#39;int | None&#39; = None, on=None, level=None, origin: &#39;str | TimestampConvertibleTypes&#39; = &#39;start_day&#39;, offset: &#39;TimedeltaConvertibleTypes | None&#39; = None) -&gt; &#39;Resampler&#39;
 |      Resample time-series data.
 |      
 |      Convenience method for frequency conversion and resampling of time series.
 |      The object must have a datetime-like index (`DatetimeIndex`, `PeriodIndex`,
 |      or `TimedeltaIndex`), or the caller must pass the label of a datetime-like
 |      series/index to the ``on``/``level`` keyword parameter.
 |      
 |      Parameters
 |      ----------
 |      rule : DateOffset, Timedelta or str
 |          The offset string or object representing target conversion.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Which axis to use for up- or down-sampling. For `Series` this
 |          will default to 0, i.e. along the rows. Must be
 |          `DatetimeIndex`, `TimedeltaIndex` or `PeriodIndex`.
 |      closed : {&#39;right&#39;, &#39;left&#39;}, default None
 |          Which side of bin interval is closed. The default is &#39;left&#39;
 |          for all frequency offsets except for &#39;M&#39;, &#39;A&#39;, &#39;Q&#39;, &#39;BM&#39;,
 |          &#39;BA&#39;, &#39;BQ&#39;, and &#39;W&#39; which all have a default of &#39;right&#39;.
 |      label : {&#39;right&#39;, &#39;left&#39;}, default None
 |          Which bin edge label to label bucket with. The default is &#39;left&#39;
 |          for all frequency offsets except for &#39;M&#39;, &#39;A&#39;, &#39;Q&#39;, &#39;BM&#39;,
 |          &#39;BA&#39;, &#39;BQ&#39;, and &#39;W&#39; which all have a default of &#39;right&#39;.
 |      convention : {&#39;start&#39;, &#39;end&#39;, &#39;s&#39;, &#39;e&#39;}, default &#39;start&#39;
 |          For `PeriodIndex` only, controls whether to use the start or
 |          end of `rule`.
 |      kind : {&#39;timestamp&#39;, &#39;period&#39;}, optional, default None
 |          Pass &#39;timestamp&#39; to convert the resulting index to a
 |          `DateTimeIndex` or &#39;period&#39; to convert it to a `PeriodIndex`.
 |          By default the input representation is retained.
 |      loffset : timedelta, default None
 |          Adjust the resampled time labels.
 |      
 |          .. deprecated:: 1.1.0
 |              You should add the loffset to the `df.index` after the resample.
 |              See below.
 |      
 |      base : int, default 0
 |          For frequencies that evenly subdivide 1 day, the &quot;origin&quot; of the
 |          aggregated intervals. For example, for &#39;5min&#39; frequency, base could
 |          range from 0 through 4. Defaults to 0.
 |      
 |          .. deprecated:: 1.1.0
 |              The new arguments that you should use are &#39;offset&#39; or &#39;origin&#39;.
 |      
 |      on : str, optional
 |          For a DataFrame, column to use instead of index for resampling.
 |          Column must be datetime-like.
 |      level : str or int, optional
 |          For a MultiIndex, level (name or number) to use for
 |          resampling. `level` must be datetime-like.
 |      origin : {&#39;epoch&#39;, &#39;start&#39;, &#39;start_day&#39;, &#39;end&#39;, &#39;end_day&#39;}, Timestamp
 |          or str, default &#39;start_day&#39;
 |          The timestamp on which to adjust the grouping. The timezone of origin
 |          must match the timezone of the index.
 |          If a timestamp is not used, these values are also supported:
 |      
 |          - &#39;epoch&#39;: `origin` is 1970-01-01
 |          - &#39;start&#39;: `origin` is the first value of the timeseries
 |          - &#39;start_day&#39;: `origin` is the first day at midnight of the timeseries
 |      
 |          .. versionadded:: 1.1.0
 |      
 |          - &#39;end&#39;: `origin` is the last value of the timeseries
 |          - &#39;end_day&#39;: `origin` is the ceiling midnight of the last day
 |      
 |          .. versionadded:: 1.3.0
 |      
 |      offset : Timedelta or str, default is None
 |          An offset timedelta added to the origin.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      pandas.core.Resampler
 |          :class:`~pandas.core.Resampler` object.
 |      
 |      See Also
 |      --------
 |      Series.resample : Resample a Series.
 |      DataFrame.resample : Resample a DataFrame.
 |      groupby : Group DataFrame by mapping, function, label, or list of labels.
 |      asfreq : Reindex a DataFrame with the given frequency without grouping.
 |      
 |      Notes
 |      -----
 |      See the `user guide
 |      &lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#resampling&gt;`__
 |      for more.
 |      
 |      To learn more about the offset strings, please see `this link
 |      &lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects&gt;`__.
 |      
 |      Examples
 |      --------
 |      Start by creating a series with 9 one minute timestamps.
 |      
 |      &gt;&gt;&gt; index = pd.date_range(&#39;1/1/2000&#39;, periods=9, freq=&#39;T&#39;)
 |      &gt;&gt;&gt; series = pd.Series(range(9), index=index)
 |      &gt;&gt;&gt; series
 |      2000-01-01 00:00:00    0
 |      2000-01-01 00:01:00    1
 |      2000-01-01 00:02:00    2
 |      2000-01-01 00:03:00    3
 |      2000-01-01 00:04:00    4
 |      2000-01-01 00:05:00    5
 |      2000-01-01 00:06:00    6
 |      2000-01-01 00:07:00    7
 |      2000-01-01 00:08:00    8
 |      Freq: T, dtype: int64
 |      
 |      Downsample the series into 3 minute bins and sum the values
 |      of the timestamps falling into a bin.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;3T&#39;).sum()
 |      2000-01-01 00:00:00     3
 |      2000-01-01 00:03:00    12
 |      2000-01-01 00:06:00    21
 |      Freq: 3T, dtype: int64
 |      
 |      Downsample the series into 3 minute bins as above, but label each
 |      bin using the right edge instead of the left. Please note that the
 |      value in the bucket used as the label is not included in the bucket,
 |      which it labels. For example, in the original series the
 |      bucket ``2000-01-01 00:03:00`` contains the value 3, but the summed
 |      value in the resampled bucket with the label ``2000-01-01 00:03:00``
 |      does not include 3 (if it did, the summed value would be 6, not 3).
 |      To include this value close the right side of the bin interval as
 |      illustrated in the example below this one.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;3T&#39;, label=&#39;right&#39;).sum()
 |      2000-01-01 00:03:00     3
 |      2000-01-01 00:06:00    12
 |      2000-01-01 00:09:00    21
 |      Freq: 3T, dtype: int64
 |      
 |      Downsample the series into 3 minute bins as above, but close the right
 |      side of the bin interval.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;3T&#39;, label=&#39;right&#39;, closed=&#39;right&#39;).sum()
 |      2000-01-01 00:00:00     0
 |      2000-01-01 00:03:00     6
 |      2000-01-01 00:06:00    15
 |      2000-01-01 00:09:00    15
 |      Freq: 3T, dtype: int64
 |      
 |      Upsample the series into 30 second bins.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;30S&#39;).asfreq()[0:5]   # Select first 5 rows
 |      2000-01-01 00:00:00   0.0
 |      2000-01-01 00:00:30   NaN
 |      2000-01-01 00:01:00   1.0
 |      2000-01-01 00:01:30   NaN
 |      2000-01-01 00:02:00   2.0
 |      Freq: 30S, dtype: float64
 |      
 |      Upsample the series into 30 second bins and fill the ``NaN``
 |      values using the ``pad`` method.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;30S&#39;).pad()[0:5]
 |      2000-01-01 00:00:00    0
 |      2000-01-01 00:00:30    0
 |      2000-01-01 00:01:00    1
 |      2000-01-01 00:01:30    1
 |      2000-01-01 00:02:00    2
 |      Freq: 30S, dtype: int64
 |      
 |      Upsample the series into 30 second bins and fill the
 |      ``NaN`` values using the ``bfill`` method.
 |      
 |      &gt;&gt;&gt; series.resample(&#39;30S&#39;).bfill()[0:5]
 |      2000-01-01 00:00:00    0
 |      2000-01-01 00:00:30    1
 |      2000-01-01 00:01:00    1
 |      2000-01-01 00:01:30    2
 |      2000-01-01 00:02:00    2
 |      Freq: 30S, dtype: int64
 |      
 |      Pass a custom function via ``apply``
 |      
 |      &gt;&gt;&gt; def custom_resampler(arraylike):
 |      ...     return np.sum(arraylike) + 5
 |      ...
 |      &gt;&gt;&gt; series.resample(&#39;3T&#39;).apply(custom_resampler)
 |      2000-01-01 00:00:00     8
 |      2000-01-01 00:03:00    17
 |      2000-01-01 00:06:00    26
 |      Freq: 3T, dtype: int64
 |      
 |      For a Series with a PeriodIndex, the keyword `convention` can be
 |      used to control whether to use the start or end of `rule`.
 |      
 |      Resample a year by quarter using &#39;start&#39; `convention`. Values are
 |      assigned to the first quarter of the period.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2], index=pd.period_range(&#39;2012-01-01&#39;,
 |      ...                                             freq=&#39;A&#39;,
 |      ...                                             periods=2))
 |      &gt;&gt;&gt; s
 |      2012    1
 |      2013    2
 |      Freq: A-DEC, dtype: int64
 |      &gt;&gt;&gt; s.resample(&#39;Q&#39;, convention=&#39;start&#39;).asfreq()
 |      2012Q1    1.0
 |      2012Q2    NaN
 |      2012Q3    NaN
 |      2012Q4    NaN
 |      2013Q1    2.0
 |      2013Q2    NaN
 |      2013Q3    NaN
 |      2013Q4    NaN
 |      Freq: Q-DEC, dtype: float64
 |      
 |      Resample quarters by month using &#39;end&#39; `convention`. Values are
 |      assigned to the last month of the period.
 |      
 |      &gt;&gt;&gt; q = pd.Series([1, 2, 3, 4], index=pd.period_range(&#39;2018-01-01&#39;,
 |      ...                                                   freq=&#39;Q&#39;,
 |      ...                                                   periods=4))
 |      &gt;&gt;&gt; q
 |      2018Q1    1
 |      2018Q2    2
 |      2018Q3    3
 |      2018Q4    4
 |      Freq: Q-DEC, dtype: int64
 |      &gt;&gt;&gt; q.resample(&#39;M&#39;, convention=&#39;end&#39;).asfreq()
 |      2018-03    1.0
 |      2018-04    NaN
 |      2018-05    NaN
 |      2018-06    2.0
 |      2018-07    NaN
 |      2018-08    NaN
 |      2018-09    3.0
 |      2018-10    NaN
 |      2018-11    NaN
 |      2018-12    4.0
 |      Freq: M, dtype: float64
 |      
 |      For DataFrame objects, the keyword `on` can be used to specify the
 |      column instead of the index for resampling.
 |      
 |      &gt;&gt;&gt; d = {&#39;price&#39;: [10, 11, 9, 13, 14, 18, 17, 19],
 |      ...      &#39;volume&#39;: [50, 60, 40, 100, 50, 100, 40, 50]}
 |      &gt;&gt;&gt; df = pd.DataFrame(d)
 |      &gt;&gt;&gt; df[&#39;week_starting&#39;] = pd.date_range(&#39;01/01/2018&#39;,
 |      ...                                     periods=8,
 |      ...                                     freq=&#39;W&#39;)
 |      &gt;&gt;&gt; df
 |         price  volume week_starting
 |      0     10      50    2018-01-07
 |      1     11      60    2018-01-14
 |      2      9      40    2018-01-21
 |      3     13     100    2018-01-28
 |      4     14      50    2018-02-04
 |      5     18     100    2018-02-11
 |      6     17      40    2018-02-18
 |      7     19      50    2018-02-25
 |      &gt;&gt;&gt; df.resample(&#39;M&#39;, on=&#39;week_starting&#39;).mean()
 |                     price  volume
 |      week_starting
 |      2018-01-31     10.75    62.5
 |      2018-02-28     17.00    60.0
 |      
 |      For a DataFrame with MultiIndex, the keyword `level` can be used to
 |      specify on which level the resampling needs to take place.
 |      
 |      &gt;&gt;&gt; days = pd.date_range(&#39;1/1/2000&#39;, periods=4, freq=&#39;D&#39;)
 |      &gt;&gt;&gt; d2 = {&#39;price&#39;: [10, 11, 9, 13, 14, 18, 17, 19],
 |      ...       &#39;volume&#39;: [50, 60, 40, 100, 50, 100, 40, 50]}
 |      &gt;&gt;&gt; df2 = pd.DataFrame(
 |      ...     d2,
 |      ...     index=pd.MultiIndex.from_product(
 |      ...         [days, [&#39;morning&#39;, &#39;afternoon&#39;]]
 |      ...     )
 |      ... )
 |      &gt;&gt;&gt; df2
 |                            price  volume
 |      2000-01-01 morning       10      50
 |                 afternoon     11      60
 |      2000-01-02 morning        9      40
 |                 afternoon     13     100
 |      2000-01-03 morning       14      50
 |                 afternoon     18     100
 |      2000-01-04 morning       17      40
 |                 afternoon     19      50
 |      &gt;&gt;&gt; df2.resample(&#39;D&#39;, level=0).sum()
 |                  price  volume
 |      2000-01-01     21     110
 |      2000-01-02     22     140
 |      2000-01-03     32     150
 |      2000-01-04     36      90
 |      
 |      If you want to adjust the start of the bins based on a fixed timestamp:
 |      
 |      &gt;&gt;&gt; start, end = &#39;2000-10-01 23:30:00&#39;, &#39;2000-10-02 00:30:00&#39;
 |      &gt;&gt;&gt; rng = pd.date_range(start, end, freq=&#39;7min&#39;)
 |      &gt;&gt;&gt; ts = pd.Series(np.arange(len(rng)) * 3, index=rng)
 |      &gt;&gt;&gt; ts
 |      2000-10-01 23:30:00     0
 |      2000-10-01 23:37:00     3
 |      2000-10-01 23:44:00     6
 |      2000-10-01 23:51:00     9
 |      2000-10-01 23:58:00    12
 |      2000-10-02 00:05:00    15
 |      2000-10-02 00:12:00    18
 |      2000-10-02 00:19:00    21
 |      2000-10-02 00:26:00    24
 |      Freq: 7T, dtype: int64
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;).sum()
 |      2000-10-01 23:14:00     0
 |      2000-10-01 23:31:00     9
 |      2000-10-01 23:48:00    21
 |      2000-10-02 00:05:00    54
 |      2000-10-02 00:22:00    24
 |      Freq: 17T, dtype: int64
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, origin=&#39;epoch&#39;).sum()
 |      2000-10-01 23:18:00     0
 |      2000-10-01 23:35:00    18
 |      2000-10-01 23:52:00    27
 |      2000-10-02 00:09:00    39
 |      2000-10-02 00:26:00    24
 |      Freq: 17T, dtype: int64
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, origin=&#39;2000-01-01&#39;).sum()
 |      2000-10-01 23:24:00     3
 |      2000-10-01 23:41:00    15
 |      2000-10-01 23:58:00    45
 |      2000-10-02 00:15:00    45
 |      Freq: 17T, dtype: int64
 |      
 |      If you want to adjust the start of the bins with an `offset` Timedelta, the two
 |      following lines are equivalent:
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, origin=&#39;start&#39;).sum()
 |      2000-10-01 23:30:00     9
 |      2000-10-01 23:47:00    21
 |      2000-10-02 00:04:00    54
 |      2000-10-02 00:21:00    24
 |      Freq: 17T, dtype: int64
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, offset=&#39;23h30min&#39;).sum()
 |      2000-10-01 23:30:00     9
 |      2000-10-01 23:47:00    21
 |      2000-10-02 00:04:00    54
 |      2000-10-02 00:21:00    24
 |      Freq: 17T, dtype: int64
 |      
 |      If you want to take the largest Timestamp as the end of the bins:
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, origin=&#39;end&#39;).sum()
 |      2000-10-01 23:35:00     0
 |      2000-10-01 23:52:00    18
 |      2000-10-02 00:09:00    27
 |      2000-10-02 00:26:00    63
 |      Freq: 17T, dtype: int64
 |      
 |      In contrast with the `start_day`, you can use `end_day` to take the ceiling
 |      midnight of the largest Timestamp as the end of the bins and drop the bins
 |      not containing data:
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, origin=&#39;end_day&#39;).sum()
 |      2000-10-01 23:38:00     3
 |      2000-10-01 23:55:00    15
 |      2000-10-02 00:12:00    45
 |      2000-10-02 00:29:00    45
 |      Freq: 17T, dtype: int64
 |      
 |      To replace the use of the deprecated `base` argument, you can now use `offset`,
 |      in this example it is equivalent to have `base=2`:
 |      
 |      &gt;&gt;&gt; ts.resample(&#39;17min&#39;, offset=&#39;2min&#39;).sum()
 |      2000-10-01 23:16:00     0
 |      2000-10-01 23:33:00     9
 |      2000-10-01 23:50:00    36
 |      2000-10-02 00:07:00    39
 |      2000-10-02 00:24:00    24
 |      Freq: 17T, dtype: int64
 |      
 |      To replace the use of the deprecated `loffset` argument:
 |      
 |      &gt;&gt;&gt; from pandas.tseries.frequencies import to_offset
 |      &gt;&gt;&gt; loffset = &#39;19min&#39;
 |      &gt;&gt;&gt; ts_out = ts.resample(&#39;17min&#39;).sum()
 |      &gt;&gt;&gt; ts_out.index = ts_out.index + to_offset(loffset)
 |      &gt;&gt;&gt; ts_out
 |      2000-10-01 23:33:00     0
 |      2000-10-01 23:50:00     9
 |      2000-10-02 00:07:00    21
 |      2000-10-02 00:24:00    54
 |      2000-10-02 00:41:00    24
 |      Freq: 17T, dtype: int64
 |  
 |  reset_index(self, level: &#39;Hashable | Sequence[Hashable] | None&#39; = None, drop: &#39;bool&#39; = False, inplace: &#39;bool&#39; = False, col_level: &#39;Hashable&#39; = 0, col_fill: &#39;Hashable&#39; = &#39;&#39;) -&gt; &#39;DataFrame | None&#39;
 |      Reset the index, or a level of it.
 |      
 |      Reset the index of the DataFrame, and use the default one instead.
 |      If the DataFrame has a MultiIndex, this method can remove one or more
 |      levels.
 |      
 |      Parameters
 |      ----------
 |      level : int, str, tuple, or list, default None
 |          Only remove the given levels from the index. Removes all levels by
 |          default.
 |      drop : bool, default False
 |          Do not try to insert index into dataframe columns. This resets
 |          the index to the default integer index.
 |      inplace : bool, default False
 |          Modify the DataFrame in place (do not create a new object).
 |      col_level : int or str, default 0
 |          If the columns have multiple levels, determines which level the
 |          labels are inserted into. By default it is inserted into the first
 |          level.
 |      col_fill : object, default &#39;&#39;
 |          If the columns have multiple levels, determines how the other
 |          levels are named. If None then the index name is repeated.
 |      
 |      Returns
 |      -------
 |      DataFrame or None
 |          DataFrame with the new index or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      DataFrame.set_index : Opposite of reset_index.
 |      DataFrame.reindex : Change to new indices or expand indices.
 |      DataFrame.reindex_like : Change to same indices as other DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([(&#39;bird&#39;, 389.0),
 |      ...                    (&#39;bird&#39;, 24.0),
 |      ...                    (&#39;mammal&#39;, 80.5),
 |      ...                    (&#39;mammal&#39;, np.nan)],
 |      ...                   index=[&#39;falcon&#39;, &#39;parrot&#39;, &#39;lion&#39;, &#39;monkey&#39;],
 |      ...                   columns=(&#39;class&#39;, &#39;max_speed&#39;))
 |      &gt;&gt;&gt; df
 |               class  max_speed
 |      falcon    bird      389.0
 |      parrot    bird       24.0
 |      lion    mammal       80.5
 |      monkey  mammal        NaN
 |      
 |      When we reset the index, the old index is added as a column, and a
 |      new sequential index is used:
 |      
 |      &gt;&gt;&gt; df.reset_index()
 |          index   class  max_speed
 |      0  falcon    bird      389.0
 |      1  parrot    bird       24.0
 |      2    lion  mammal       80.5
 |      3  monkey  mammal        NaN
 |      
 |      We can use the `drop` parameter to avoid the old index being added as
 |      a column:
 |      
 |      &gt;&gt;&gt; df.reset_index(drop=True)
 |          class  max_speed
 |      0    bird      389.0
 |      1    bird       24.0
 |      2  mammal       80.5
 |      3  mammal        NaN
 |      
 |      You can also use `reset_index` with `MultiIndex`.
 |      
 |      &gt;&gt;&gt; index = pd.MultiIndex.from_tuples([(&#39;bird&#39;, &#39;falcon&#39;),
 |      ...                                    (&#39;bird&#39;, &#39;parrot&#39;),
 |      ...                                    (&#39;mammal&#39;, &#39;lion&#39;),
 |      ...                                    (&#39;mammal&#39;, &#39;monkey&#39;)],
 |      ...                                   names=[&#39;class&#39;, &#39;name&#39;])
 |      &gt;&gt;&gt; columns = pd.MultiIndex.from_tuples([(&#39;speed&#39;, &#39;max&#39;),
 |      ...                                      (&#39;species&#39;, &#39;type&#39;)])
 |      &gt;&gt;&gt; df = pd.DataFrame([(389.0, &#39;fly&#39;),
 |      ...                    ( 24.0, &#39;fly&#39;),
 |      ...                    ( 80.5, &#39;run&#39;),
 |      ...                    (np.nan, &#39;jump&#39;)],
 |      ...                   index=index,
 |      ...                   columns=columns)
 |      &gt;&gt;&gt; df
 |                     speed species
 |                       max    type
 |      class  name
 |      bird   falcon  389.0     fly
 |             parrot   24.0     fly
 |      mammal lion     80.5     run
 |             monkey    NaN    jump
 |      
 |      If the index has multiple levels, we can reset a subset of them:
 |      
 |      &gt;&gt;&gt; df.reset_index(level=&#39;class&#39;)
 |               class  speed species
 |                        max    type
 |      name
 |      falcon    bird  389.0     fly
 |      parrot    bird   24.0     fly
 |      lion    mammal   80.5     run
 |      monkey  mammal    NaN    jump
 |      
 |      If we are not dropping the index, by default, it is placed in the top
 |      level. We can place it in another level:
 |      
 |      &gt;&gt;&gt; df.reset_index(level=&#39;class&#39;, col_level=1)
 |                      speed species
 |               class    max    type
 |      name
 |      falcon    bird  389.0     fly
 |      parrot    bird   24.0     fly
 |      lion    mammal   80.5     run
 |      monkey  mammal    NaN    jump
 |      
 |      When the index is inserted under another level, we can specify under
 |      which one with the parameter `col_fill`:
 |      
 |      &gt;&gt;&gt; df.reset_index(level=&#39;class&#39;, col_level=1, col_fill=&#39;species&#39;)
 |                    species  speed species
 |                      class    max    type
 |      name
 |      falcon           bird  389.0     fly
 |      parrot           bird   24.0     fly
 |      lion           mammal   80.5     run
 |      monkey         mammal    NaN    jump
 |      
 |      If we specify a nonexistent level for `col_fill`, it is created:
 |      
 |      &gt;&gt;&gt; df.reset_index(level=&#39;class&#39;, col_level=1, col_fill=&#39;genus&#39;)
 |                      genus  speed species
 |                      class    max    type
 |      name
 |      falcon           bird  389.0     fly
 |      parrot           bird   24.0     fly
 |      lion           mammal   80.5     run
 |      monkey         mammal    NaN    jump
 |  
 |  rfloordiv(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Integer division of dataframe and other, element-wise (binary operator `rfloordiv`).
 |      
 |      Equivalent to ``other // dataframe``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `floordiv`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  rmod(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Modulo of dataframe and other, element-wise (binary operator `rmod`).
 |      
 |      Equivalent to ``other % dataframe``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `mod`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  rmul(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Multiplication of dataframe and other, element-wise (binary operator `rmul`).
 |      
 |      Equivalent to ``other * dataframe``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `mul`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  round(self, decimals: &#39;int | dict[IndexLabel, int] | Series&#39; = 0, *args, **kwargs) -&gt; &#39;DataFrame&#39;
 |      Round a DataFrame to a variable number of decimal places.
 |      
 |      Parameters
 |      ----------
 |      decimals : int, dict, Series
 |          Number of decimal places to round each column to. If an int is
 |          given, round each column to the same number of places.
 |          Otherwise dict and Series round to variable numbers of places.
 |          Column names should be in the keys if `decimals` is a
 |          dict-like, or in the index if `decimals` is a Series. Any
 |          columns not included in `decimals` will be left as is. Elements
 |          of `decimals` which are not columns of the input will be
 |          ignored.
 |      *args
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with numpy.
 |      **kwargs
 |          Additional keywords have no effect but might be accepted for
 |          compatibility with numpy.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          A DataFrame with the affected columns rounded to the specified
 |          number of decimal places.
 |      
 |      See Also
 |      --------
 |      numpy.around : Round a numpy array to the given number of decimals.
 |      Series.round : Round a Series to the given number of decimals.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([(.21, .32), (.01, .67), (.66, .03), (.21, .18)],
 |      ...                   columns=[&#39;dogs&#39;, &#39;cats&#39;])
 |      &gt;&gt;&gt; df
 |          dogs  cats
 |      0  0.21  0.32
 |      1  0.01  0.67
 |      2  0.66  0.03
 |      3  0.21  0.18
 |      
 |      By providing an integer each column is rounded to the same number
 |      of decimal places
 |      
 |      &gt;&gt;&gt; df.round(1)
 |          dogs  cats
 |      0   0.2   0.3
 |      1   0.0   0.7
 |      2   0.7   0.0
 |      3   0.2   0.2
 |      
 |      With a dict, the number of places for specific columns can be
 |      specified with the column names as key and the number of decimal
 |      places as value
 |      
 |      &gt;&gt;&gt; df.round({&#39;dogs&#39;: 1, &#39;cats&#39;: 0})
 |          dogs  cats
 |      0   0.2   0.0
 |      1   0.0   1.0
 |      2   0.7   0.0
 |      3   0.2   0.0
 |      
 |      Using a Series, the number of places for specific columns can be
 |      specified with the column names as index and the number of
 |      decimal places as value
 |      
 |      &gt;&gt;&gt; decimals = pd.Series([0, 1], index=[&#39;cats&#39;, &#39;dogs&#39;])
 |      &gt;&gt;&gt; df.round(decimals)
 |          dogs  cats
 |      0   0.2   0.0
 |      1   0.0   1.0
 |      2   0.7   0.0
 |      3   0.2   0.0
 |  
 |  rpow(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Exponential power of dataframe and other, element-wise (binary operator `rpow`).
 |      
 |      Equivalent to ``other ** dataframe``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `pow`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  rsub(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Subtraction of dataframe and other, element-wise (binary operator `rsub`).
 |      
 |      Equivalent to ``other - dataframe``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `sub`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  rtruediv(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Floating division of dataframe and other, element-wise (binary operator `rtruediv`).
 |      
 |      Equivalent to ``other / dataframe``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `truediv`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  select_dtypes(self, include=None, exclude=None) -&gt; &#39;DataFrame&#39;
 |      Return a subset of the DataFrame&#39;s columns based on the column dtypes.
 |      
 |      Parameters
 |      ----------
 |      include, exclude : scalar or list-like
 |          A selection of dtypes or strings to be included/excluded. At least
 |          one of these parameters must be supplied.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          The subset of the frame including the dtypes in ``include`` and
 |          excluding the dtypes in ``exclude``.
 |      
 |      Raises
 |      ------
 |      ValueError
 |          * If both of ``include`` and ``exclude`` are empty
 |          * If ``include`` and ``exclude`` have overlapping elements
 |          * If any kind of string dtype is passed in.
 |      
 |      See Also
 |      --------
 |      DataFrame.dtypes: Return Series with the data type of each column.
 |      
 |      Notes
 |      -----
 |      * To select all *numeric* types, use ``np.number`` or ``&#39;number&#39;``
 |      * To select strings you must use the ``object`` dtype, but note that
 |        this will return *all* object dtype columns
 |      * See the `numpy dtype hierarchy
 |        &lt;https://numpy.org/doc/stable/reference/arrays.scalars.html&gt;`__
 |      * To select datetimes, use ``np.datetime64``, ``&#39;datetime&#39;`` or
 |        ``&#39;datetime64&#39;``
 |      * To select timedeltas, use ``np.timedelta64``, ``&#39;timedelta&#39;`` or
 |        ``&#39;timedelta64&#39;``
 |      * To select Pandas categorical dtypes, use ``&#39;category&#39;``
 |      * To select Pandas datetimetz dtypes, use ``&#39;datetimetz&#39;`` (new in
 |        0.20.0) or ``&#39;datetime64[ns, tz]&#39;``
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;a&#39;: [1, 2] * 3,
 |      ...                    &#39;b&#39;: [True, False] * 3,
 |      ...                    &#39;c&#39;: [1.0, 2.0] * 3})
 |      &gt;&gt;&gt; df
 |              a      b  c
 |      0       1   True  1.0
 |      1       2  False  2.0
 |      2       1   True  1.0
 |      3       2  False  2.0
 |      4       1   True  1.0
 |      5       2  False  2.0
 |      
 |      &gt;&gt;&gt; df.select_dtypes(include=&#39;bool&#39;)
 |         b
 |      0  True
 |      1  False
 |      2  True
 |      3  False
 |      4  True
 |      5  False
 |      
 |      &gt;&gt;&gt; df.select_dtypes(include=[&#39;float64&#39;])
 |         c
 |      0  1.0
 |      1  2.0
 |      2  1.0
 |      3  2.0
 |      4  1.0
 |      5  2.0
 |      
 |      &gt;&gt;&gt; df.select_dtypes(exclude=[&#39;int64&#39;])
 |             b    c
 |      0   True  1.0
 |      1  False  2.0
 |      2   True  1.0
 |      3  False  2.0
 |      4   True  1.0
 |      5  False  2.0
 |  
 |  sem(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
 |      Return unbiased standard error of the mean over requested axis.
 |      
 |      Normalized by N-1 by default. This can be changed using the ddof argument
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      ddof : int, default 1
 |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,
 |          where N represents the number of elements.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |      
 |      Notes
 |      -----
 |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the
 |      default `ddof=1`)
 |  
 |  set_axis(self, labels, axis: &#39;Axis&#39; = 0, inplace: &#39;bool&#39; = False)
 |      Assign desired index to given axis.
 |      
 |      Indexes for column or row labels can be changed by assigning
 |      a list-like or Index.
 |      
 |      Parameters
 |      ----------
 |      labels : list-like, Index
 |          The values for the new index.
 |      
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to update. The value 0 identifies the rows, and 1 identifies the columns.
 |      
 |      inplace : bool, default False
 |          Whether to return a new DataFrame instance.
 |      
 |      Returns
 |      -------
 |      renamed : DataFrame or None
 |          An object of type DataFrame or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      DataFrame.rename_axis : Alter the name of the index or columns.
 |      
 |              Examples
 |              --------
 |              &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2, 3], &quot;B&quot;: [4, 5, 6]})
 |      
 |              Change the row labels.
 |      
 |              &gt;&gt;&gt; df.set_axis([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;], axis=&#39;index&#39;)
 |                 A  B
 |              a  1  4
 |              b  2  5
 |              c  3  6
 |      
 |              Change the column labels.
 |      
 |              &gt;&gt;&gt; df.set_axis([&#39;I&#39;, &#39;II&#39;], axis=&#39;columns&#39;)
 |                 I  II
 |              0  1   4
 |              1  2   5
 |              2  3   6
 |      
 |              Now, update the labels inplace.
 |      
 |              &gt;&gt;&gt; df.set_axis([&#39;i&#39;, &#39;ii&#39;], axis=&#39;columns&#39;, inplace=True)
 |              &gt;&gt;&gt; df
 |                 i  ii
 |              0  1   4
 |              1  2   5
 |              2  3   6
 |  
 |  set_index(self, keys, drop: &#39;bool&#39; = True, append: &#39;bool&#39; = False, inplace: &#39;bool&#39; = False, verify_integrity: &#39;bool&#39; = False)
 |      Set the DataFrame index using existing columns.
 |      
 |      Set the DataFrame index (row labels) using one or more existing
 |      columns or arrays (of the correct length). The index can replace the
 |      existing index or expand on it.
 |      
 |      Parameters
 |      ----------
 |      keys : label or array-like or list of labels/arrays
 |          This parameter can be either a single column key, a single array of
 |          the same length as the calling DataFrame, or a list containing an
 |          arbitrary combination of column keys and arrays. Here, &quot;array&quot;
 |          encompasses :class:`Series`, :class:`Index`, ``np.ndarray``, and
 |          instances of :class:`~collections.abc.Iterator`.
 |      drop : bool, default True
 |          Delete columns to be used as the new index.
 |      append : bool, default False
 |          Whether to append columns to existing index.
 |      inplace : bool, default False
 |          If True, modifies the DataFrame in place (do not create a new object).
 |      verify_integrity : bool, default False
 |          Check the new index for duplicates. Otherwise defer the check until
 |          necessary. Setting to False will improve the performance of this
 |          method.
 |      
 |      Returns
 |      -------
 |      DataFrame or None
 |          Changed row labels or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      DataFrame.reset_index : Opposite of set_index.
 |      DataFrame.reindex : Change to new indices or expand indices.
 |      DataFrame.reindex_like : Change to same indices as other DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;month&#39;: [1, 4, 7, 10],
 |      ...                    &#39;year&#39;: [2012, 2014, 2013, 2014],
 |      ...                    &#39;sale&#39;: [55, 40, 84, 31]})
 |      &gt;&gt;&gt; df
 |         month  year  sale
 |      0      1  2012    55
 |      1      4  2014    40
 |      2      7  2013    84
 |      3     10  2014    31
 |      
 |      Set the index to become the &#39;month&#39; column:
 |      
 |      &gt;&gt;&gt; df.set_index(&#39;month&#39;)
 |             year  sale
 |      month
 |      1      2012    55
 |      4      2014    40
 |      7      2013    84
 |      10     2014    31
 |      
 |      Create a MultiIndex using columns &#39;year&#39; and &#39;month&#39;:
 |      
 |      &gt;&gt;&gt; df.set_index([&#39;year&#39;, &#39;month&#39;])
 |                  sale
 |      year  month
 |      2012  1     55
 |      2014  4     40
 |      2013  7     84
 |      2014  10    31
 |      
 |      Create a MultiIndex using an Index and a column:
 |      
 |      &gt;&gt;&gt; df.set_index([pd.Index([1, 2, 3, 4]), &#39;year&#39;])
 |               month  sale
 |         year
 |      1  2012  1      55
 |      2  2014  4      40
 |      3  2013  7      84
 |      4  2014  10     31
 |      
 |      Create a MultiIndex using two Series:
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
 |      &gt;&gt;&gt; df.set_index([s, s**2])
 |            month  year  sale
 |      1 1       1  2012    55
 |      2 4       4  2014    40
 |      3 9       7  2013    84
 |      4 16     10  2014    31
 |  
 |  shift(self, periods=1, freq: &#39;Frequency | None&#39; = None, axis: &#39;Axis&#39; = 0, fill_value=&lt;no_default&gt;) -&gt; &#39;DataFrame&#39;
 |      Shift index by desired number of periods with an optional time `freq`.
 |      
 |      When `freq` is not passed, shift the index without realigning the data.
 |      If `freq` is passed (in this case, the index must be date or datetime,
 |      or it will raise a `NotImplementedError`), the index will be
 |      increased using the periods and the `freq`. `freq` can be inferred
 |      when specified as &quot;infer&quot; as long as either freq or inferred_freq
 |      attribute is set in the index.
 |      
 |      Parameters
 |      ----------
 |      periods : int
 |          Number of periods to shift. Can be positive or negative.
 |      freq : DateOffset, tseries.offsets, timedelta, or str, optional
 |          Offset to use from the tseries module or time rule (e.g. &#39;EOM&#39;).
 |          If `freq` is specified then the index values are shifted but the
 |          data is not realigned. That is, use `freq` if you would like to
 |          extend the index when shifting and preserve the original data.
 |          If `freq` is specified as &quot;infer&quot; then it will be inferred from
 |          the freq or inferred_freq attributes of the index. If neither of
 |          those attributes exist, a ValueError is thrown.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}, default None
 |          Shift direction.
 |      fill_value : object, optional
 |          The scalar value to use for newly introduced missing values.
 |          the default depends on the dtype of `self`.
 |          For numeric data, ``np.nan`` is used.
 |          For datetime, timedelta, or period data, etc. :attr:`NaT` is used.
 |          For extension dtypes, ``self.dtype.na_value`` is used.
 |      
 |          .. versionchanged:: 1.1.0
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Copy of input object, shifted.
 |      
 |      See Also
 |      --------
 |      Index.shift : Shift values of Index.
 |      DatetimeIndex.shift : Shift values of DatetimeIndex.
 |      PeriodIndex.shift : Shift values of PeriodIndex.
 |      tshift : Shift the time index, using the index&#39;s frequency if
 |          available.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;Col1&quot;: [10, 20, 15, 30, 45],
 |      ...                    &quot;Col2&quot;: [13, 23, 18, 33, 48],
 |      ...                    &quot;Col3&quot;: [17, 27, 22, 37, 52]},
 |      ...                   index=pd.date_range(&quot;2020-01-01&quot;, &quot;2020-01-05&quot;))
 |      &gt;&gt;&gt; df
 |                  Col1  Col2  Col3
 |      2020-01-01    10    13    17
 |      2020-01-02    20    23    27
 |      2020-01-03    15    18    22
 |      2020-01-04    30    33    37
 |      2020-01-05    45    48    52
 |      
 |      &gt;&gt;&gt; df.shift(periods=3)
 |                  Col1  Col2  Col3
 |      2020-01-01   NaN   NaN   NaN
 |      2020-01-02   NaN   NaN   NaN
 |      2020-01-03   NaN   NaN   NaN
 |      2020-01-04  10.0  13.0  17.0
 |      2020-01-05  20.0  23.0  27.0
 |      
 |      &gt;&gt;&gt; df.shift(periods=1, axis=&quot;columns&quot;)
 |                  Col1  Col2  Col3
 |      2020-01-01   NaN    10    13
 |      2020-01-02   NaN    20    23
 |      2020-01-03   NaN    15    18
 |      2020-01-04   NaN    30    33
 |      2020-01-05   NaN    45    48
 |      
 |      &gt;&gt;&gt; df.shift(periods=3, fill_value=0)
 |                  Col1  Col2  Col3
 |      2020-01-01     0     0     0
 |      2020-01-02     0     0     0
 |      2020-01-03     0     0     0
 |      2020-01-04    10    13    17
 |      2020-01-05    20    23    27
 |      
 |      &gt;&gt;&gt; df.shift(periods=3, freq=&quot;D&quot;)
 |                  Col1  Col2  Col3
 |      2020-01-04    10    13    17
 |      2020-01-05    20    23    27
 |      2020-01-06    15    18    22
 |      2020-01-07    30    33    37
 |      2020-01-08    45    48    52
 |      
 |      &gt;&gt;&gt; df.shift(periods=3, freq=&quot;infer&quot;)
 |                  Col1  Col2  Col3
 |      2020-01-04    10    13    17
 |      2020-01-05    20    23    27
 |      2020-01-06    15    18    22
 |      2020-01-07    30    33    37
 |      2020-01-08    45    48    52
 |  
 |  skew(self, axis=None, skipna=None, level=None, numeric_only=None, **kwargs)
 |      Return unbiased skew over requested axis.
 |      
 |      Normalized by N-1.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |          Axis for the function to be applied on.
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |  
 |  sort_index(self, axis: &#39;Axis&#39; = 0, level: &#39;Level | None&#39; = None, ascending: &#39;bool | int | Sequence[bool | int]&#39; = True, inplace: &#39;bool&#39; = False, kind: &#39;str&#39; = &#39;quicksort&#39;, na_position: &#39;str&#39; = &#39;last&#39;, sort_remaining: &#39;bool&#39; = True, ignore_index: &#39;bool&#39; = False, key: &#39;IndexKeyFunc&#39; = None)
 |      Sort object by labels (along an axis).
 |      
 |      Returns a new DataFrame sorted by label if `inplace` argument is
 |      ``False``, otherwise updates the original DataFrame and returns None.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis along which to sort.  The value 0 identifies the rows,
 |          and 1 identifies the columns.
 |      level : int or level name or list of ints or list of level names
 |          If not None, sort on values in specified index level(s).
 |      ascending : bool or list-like of bools, default True
 |          Sort ascending vs. descending. When the index is a MultiIndex the
 |          sort direction can be controlled for each level individually.
 |      inplace : bool, default False
 |          If True, perform operation in-place.
 |      kind : {&#39;quicksort&#39;, &#39;mergesort&#39;, &#39;heapsort&#39;, &#39;stable&#39;}, default &#39;quicksort&#39;
 |          Choice of sorting algorithm. See also :func:`numpy.sort` for more
 |          information. `mergesort` and `stable` are the only stable algorithms. For
 |          DataFrames, this option is only applied when sorting on a single
 |          column or label.
 |      na_position : {&#39;first&#39;, &#39;last&#39;}, default &#39;last&#39;
 |          Puts NaNs at the beginning if `first`; `last` puts NaNs at the end.
 |          Not implemented for MultiIndex.
 |      sort_remaining : bool, default True
 |          If True and sorting by level and index is multilevel, sort by other
 |          levels too (in order) after sorting by specified level.
 |      ignore_index : bool, default False
 |          If True, the resulting axis will be labeled 0, 1, …, n - 1.
 |      
 |          .. versionadded:: 1.0.0
 |      
 |      key : callable, optional
 |          If not None, apply the key function to the index values
 |          before sorting. This is similar to the `key` argument in the
 |          builtin :meth:`sorted` function, with the notable difference that
 |          this `key` function should be *vectorized*. It should expect an
 |          ``Index`` and return an ``Index`` of the same shape. For MultiIndex
 |          inputs, the key is applied *per level*.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      DataFrame or None
 |          The original DataFrame sorted by the labels or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      Series.sort_index : Sort Series by the index.
 |      DataFrame.sort_values : Sort DataFrame by the value.
 |      Series.sort_values : Sort Series by the value.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([1, 2, 3, 4, 5], index=[100, 29, 234, 1, 150],
 |      ...                   columns=[&#39;A&#39;])
 |      &gt;&gt;&gt; df.sort_index()
 |           A
 |      1    4
 |      29   2
 |      100  1
 |      150  5
 |      234  3
 |      
 |      By default, it sorts in ascending order, to sort in descending order,
 |      use ``ascending=False``
 |      
 |      &gt;&gt;&gt; df.sort_index(ascending=False)
 |           A
 |      234  3
 |      150  5
 |      100  1
 |      29   2
 |      1    4
 |      
 |      A key function can be specified which is applied to the index before
 |      sorting. For a ``MultiIndex`` this is applied to each level separately.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;a&quot;: [1, 2, 3, 4]}, index=[&#39;A&#39;, &#39;b&#39;, &#39;C&#39;, &#39;d&#39;])
 |      &gt;&gt;&gt; df.sort_index(key=lambda x: x.str.lower())
 |         a
 |      A  1
 |      b  2
 |      C  3
 |      d  4
 |  
 |  sort_values(self, by, axis: &#39;Axis&#39; = 0, ascending=True, inplace: &#39;bool&#39; = False, kind: &#39;str&#39; = &#39;quicksort&#39;, na_position: &#39;str&#39; = &#39;last&#39;, ignore_index: &#39;bool&#39; = False, key: &#39;ValueKeyFunc&#39; = None)
 |      Sort by the values along either axis.
 |      
 |      Parameters
 |      ----------
 |              by : str or list of str
 |                  Name or list of names to sort by.
 |      
 |                  - if `axis` is 0 or `&#39;index&#39;` then `by` may contain index
 |                    levels and/or column labels.
 |                  - if `axis` is 1 or `&#39;columns&#39;` then `by` may contain column
 |                    levels and/or index labels.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |           Axis to be sorted.
 |      ascending : bool or list of bool, default True
 |           Sort ascending vs. descending. Specify list for multiple sort
 |           orders.  If this is a list of bools, must match the length of
 |           the by.
 |      inplace : bool, default False
 |           If True, perform operation in-place.
 |      kind : {&#39;quicksort&#39;, &#39;mergesort&#39;, &#39;heapsort&#39;, &#39;stable&#39;}, default &#39;quicksort&#39;
 |           Choice of sorting algorithm. See also :func:`numpy.sort` for more
 |           information. `mergesort` and `stable` are the only stable algorithms. For
 |           DataFrames, this option is only applied when sorting on a single
 |           column or label.
 |      na_position : {&#39;first&#39;, &#39;last&#39;}, default &#39;last&#39;
 |           Puts NaNs at the beginning if `first`; `last` puts NaNs at the
 |           end.
 |      ignore_index : bool, default False
 |           If True, the resulting axis will be labeled 0, 1, …, n - 1.
 |      
 |           .. versionadded:: 1.0.0
 |      
 |      key : callable, optional
 |          Apply the key function to the values
 |          before sorting. This is similar to the `key` argument in the
 |          builtin :meth:`sorted` function, with the notable difference that
 |          this `key` function should be *vectorized*. It should expect a
 |          ``Series`` and return a Series with the same shape as the input.
 |          It will be applied to each column in `by` independently.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      DataFrame or None
 |          DataFrame with sorted values or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      DataFrame.sort_index : Sort a DataFrame by the index.
 |      Series.sort_values : Similar method for a Series.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;col1&#39;: [&#39;A&#39;, &#39;A&#39;, &#39;B&#39;, np.nan, &#39;D&#39;, &#39;C&#39;],
 |      ...     &#39;col2&#39;: [2, 1, 9, 8, 7, 4],
 |      ...     &#39;col3&#39;: [0, 1, 9, 4, 2, 3],
 |      ...     &#39;col4&#39;: [&#39;a&#39;, &#39;B&#39;, &#39;c&#39;, &#39;D&#39;, &#39;e&#39;, &#39;F&#39;]
 |      ... })
 |      &gt;&gt;&gt; df
 |        col1  col2  col3 col4
 |      0    A     2     0    a
 |      1    A     1     1    B
 |      2    B     9     9    c
 |      3  NaN     8     4    D
 |      4    D     7     2    e
 |      5    C     4     3    F
 |      
 |      Sort by col1
 |      
 |      &gt;&gt;&gt; df.sort_values(by=[&#39;col1&#39;])
 |        col1  col2  col3 col4
 |      0    A     2     0    a
 |      1    A     1     1    B
 |      2    B     9     9    c
 |      5    C     4     3    F
 |      4    D     7     2    e
 |      3  NaN     8     4    D
 |      
 |      Sort by multiple columns
 |      
 |      &gt;&gt;&gt; df.sort_values(by=[&#39;col1&#39;, &#39;col2&#39;])
 |        col1  col2  col3 col4
 |      1    A     1     1    B
 |      0    A     2     0    a
 |      2    B     9     9    c
 |      5    C     4     3    F
 |      4    D     7     2    e
 |      3  NaN     8     4    D
 |      
 |      Sort Descending
 |      
 |      &gt;&gt;&gt; df.sort_values(by=&#39;col1&#39;, ascending=False)
 |        col1  col2  col3 col4
 |      4    D     7     2    e
 |      5    C     4     3    F
 |      2    B     9     9    c
 |      0    A     2     0    a
 |      1    A     1     1    B
 |      3  NaN     8     4    D
 |      
 |      Putting NAs first
 |      
 |      &gt;&gt;&gt; df.sort_values(by=&#39;col1&#39;, ascending=False, na_position=&#39;first&#39;)
 |        col1  col2  col3 col4
 |      3  NaN     8     4    D
 |      4    D     7     2    e
 |      5    C     4     3    F
 |      2    B     9     9    c
 |      0    A     2     0    a
 |      1    A     1     1    B
 |      
 |      Sorting with a key function
 |      
 |      &gt;&gt;&gt; df.sort_values(by=&#39;col4&#39;, key=lambda col: col.str.lower())
 |         col1  col2  col3 col4
 |      0    A     2     0    a
 |      1    A     1     1    B
 |      2    B     9     9    c
 |      3  NaN     8     4    D
 |      4    D     7     2    e
 |      5    C     4     3    F
 |      
 |      Natural sort with the key argument,
 |      using the `natsort &lt;https://github.com/SethMMorton/natsort&gt;` package.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...    &quot;time&quot;: [&#39;0hr&#39;, &#39;128hr&#39;, &#39;72hr&#39;, &#39;48hr&#39;, &#39;96hr&#39;],
 |      ...    &quot;value&quot;: [10, 20, 30, 40, 50]
 |      ... })
 |      &gt;&gt;&gt; df
 |          time  value
 |      0    0hr     10
 |      1  128hr     20
 |      2   72hr     30
 |      3   48hr     40
 |      4   96hr     50
 |      &gt;&gt;&gt; from natsort import index_natsorted
 |      &gt;&gt;&gt; df.sort_values(
 |      ...    by=&quot;time&quot;,
 |      ...    key=lambda x: np.argsort(index_natsorted(df[&quot;time&quot;]))
 |      ... )
 |          time  value
 |      0    0hr     10
 |      3   48hr     40
 |      2   72hr     30
 |      4   96hr     50
 |      1  128hr     20
 |  
 |  stack(self, level: &#39;Level&#39; = -1, dropna: &#39;bool&#39; = True)
 |      Stack the prescribed level(s) from columns to index.
 |      
 |      Return a reshaped DataFrame or Series having a multi-level
 |      index with one or more new inner-most levels compared to the current
 |      DataFrame. The new inner-most levels are created by pivoting the
 |      columns of the current dataframe:
 |      
 |        - if the columns have a single level, the output is a Series;
 |        - if the columns have multiple levels, the new index
 |          level(s) is (are) taken from the prescribed level(s) and
 |          the output is a DataFrame.
 |      
 |      Parameters
 |      ----------
 |      level : int, str, list, default -1
 |          Level(s) to stack from the column axis onto the index
 |          axis, defined as one index or label, or a list of indices
 |          or labels.
 |      dropna : bool, default True
 |          Whether to drop rows in the resulting Frame/Series with
 |          missing values. Stacking a column level onto the index
 |          axis can create combinations of index and column values
 |          that are missing from the original dataframe. See Examples
 |          section.
 |      
 |      Returns
 |      -------
 |      DataFrame or Series
 |          Stacked dataframe or series.
 |      
 |      See Also
 |      --------
 |      DataFrame.unstack : Unstack prescribed level(s) from index axis
 |           onto column axis.
 |      DataFrame.pivot : Reshape dataframe from long format to wide
 |           format.
 |      DataFrame.pivot_table : Create a spreadsheet-style pivot table
 |           as a DataFrame.
 |      
 |      Notes
 |      -----
 |      The function is named by analogy with a collection of books
 |      being reorganized from being side by side on a horizontal
 |      position (the columns of the dataframe) to being stacked
 |      vertically on top of each other (in the index of the
 |      dataframe).
 |      
 |      Examples
 |      --------
 |      **Single level columns**
 |      
 |      &gt;&gt;&gt; df_single_level_cols = pd.DataFrame([[0, 1], [2, 3]],
 |      ...                                     index=[&#39;cat&#39;, &#39;dog&#39;],
 |      ...                                     columns=[&#39;weight&#39;, &#39;height&#39;])
 |      
 |      Stacking a dataframe with a single level column axis returns a Series:
 |      
 |      &gt;&gt;&gt; df_single_level_cols
 |           weight height
 |      cat       0      1
 |      dog       2      3
 |      &gt;&gt;&gt; df_single_level_cols.stack()
 |      cat  weight    0
 |           height    1
 |      dog  weight    2
 |           height    3
 |      dtype: int64
 |      
 |      **Multi level columns: simple case**
 |      
 |      &gt;&gt;&gt; multicol1 = pd.MultiIndex.from_tuples([(&#39;weight&#39;, &#39;kg&#39;),
 |      ...                                        (&#39;weight&#39;, &#39;pounds&#39;)])
 |      &gt;&gt;&gt; df_multi_level_cols1 = pd.DataFrame([[1, 2], [2, 4]],
 |      ...                                     index=[&#39;cat&#39;, &#39;dog&#39;],
 |      ...                                     columns=multicol1)
 |      
 |      Stacking a dataframe with a multi-level column axis:
 |      
 |      &gt;&gt;&gt; df_multi_level_cols1
 |           weight
 |               kg    pounds
 |      cat       1        2
 |      dog       2        4
 |      &gt;&gt;&gt; df_multi_level_cols1.stack()
 |                  weight
 |      cat kg           1
 |          pounds       2
 |      dog kg           2
 |          pounds       4
 |      
 |      **Missing values**
 |      
 |      &gt;&gt;&gt; multicol2 = pd.MultiIndex.from_tuples([(&#39;weight&#39;, &#39;kg&#39;),
 |      ...                                        (&#39;height&#39;, &#39;m&#39;)])
 |      &gt;&gt;&gt; df_multi_level_cols2 = pd.DataFrame([[1.0, 2.0], [3.0, 4.0]],
 |      ...                                     index=[&#39;cat&#39;, &#39;dog&#39;],
 |      ...                                     columns=multicol2)
 |      
 |      It is common to have missing values when stacking a dataframe
 |      with multi-level columns, as the stacked dataframe typically
 |      has more values than the original dataframe. Missing values
 |      are filled with NaNs:
 |      
 |      &gt;&gt;&gt; df_multi_level_cols2
 |          weight height
 |              kg      m
 |      cat    1.0    2.0
 |      dog    3.0    4.0
 |      &gt;&gt;&gt; df_multi_level_cols2.stack()
 |              height  weight
 |      cat kg     NaN     1.0
 |          m      2.0     NaN
 |      dog kg     NaN     3.0
 |          m      4.0     NaN
 |      
 |      **Prescribing the level(s) to be stacked**
 |      
 |      The first parameter controls which level or levels are stacked:
 |      
 |      &gt;&gt;&gt; df_multi_level_cols2.stack(0)
 |                   kg    m
 |      cat height  NaN  2.0
 |          weight  1.0  NaN
 |      dog height  NaN  4.0
 |          weight  3.0  NaN
 |      &gt;&gt;&gt; df_multi_level_cols2.stack([0, 1])
 |      cat  height  m     2.0
 |           weight  kg    1.0
 |      dog  height  m     4.0
 |           weight  kg    3.0
 |      dtype: float64
 |      
 |      **Dropping missing values**
 |      
 |      &gt;&gt;&gt; df_multi_level_cols3 = pd.DataFrame([[None, 1.0], [2.0, 3.0]],
 |      ...                                     index=[&#39;cat&#39;, &#39;dog&#39;],
 |      ...                                     columns=multicol2)
 |      
 |      Note that rows where all values are missing are dropped by
 |      default but this behaviour can be controlled via the dropna
 |      keyword parameter:
 |      
 |      &gt;&gt;&gt; df_multi_level_cols3
 |          weight height
 |              kg      m
 |      cat    NaN    1.0
 |      dog    2.0    3.0
 |      &gt;&gt;&gt; df_multi_level_cols3.stack(dropna=False)
 |              height  weight
 |      cat kg     NaN     NaN
 |          m      1.0     NaN
 |      dog kg     NaN     2.0
 |          m      3.0     NaN
 |      &gt;&gt;&gt; df_multi_level_cols3.stack(dropna=True)
 |              height  weight
 |      cat m      1.0     NaN
 |      dog kg     NaN     2.0
 |          m      3.0     NaN
 |  
 |  std(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
 |      Return sample standard deviation over requested axis.
 |      
 |      Normalized by N-1 by default. This can be changed using the ddof argument
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      ddof : int, default 1
 |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,
 |          where N represents the number of elements.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |      
 |      Notes
 |      -----
 |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the
 |      default `ddof=1`)
 |  
 |  sub(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Subtraction of dataframe and other, element-wise (binary operator `sub`).
 |      
 |      Equivalent to ``dataframe - other``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `rsub`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  subtract = sub(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |  
 |  sum(self, axis=None, skipna=None, level=None, numeric_only=None, min_count=0, **kwargs)
 |      Return the sum of the values over the requested axis.
 |      
 |      This is equivalent to the method ``numpy.sum``.
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |          Axis for the function to be applied on.
 |      skipna : bool, default True
 |          Exclude NA/null values when computing the result.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      min_count : int, default 0
 |          The required number of valid values to perform the operation. If fewer than
 |          ``min_count`` non-NA values are present the result will be NA.
 |      **kwargs
 |          Additional keyword arguments to be passed to the function.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |      
 |      See Also
 |      --------
 |      Series.sum : Return the sum.
 |      Series.min : Return the minimum.
 |      Series.max : Return the maximum.
 |      Series.idxmin : Return the index of the minimum.
 |      Series.idxmax : Return the index of the maximum.
 |      DataFrame.sum : Return the sum over the requested axis.
 |      DataFrame.min : Return the minimum over the requested axis.
 |      DataFrame.max : Return the maximum over the requested axis.
 |      DataFrame.idxmin : Return the index of the minimum over the requested axis.
 |      DataFrame.idxmax : Return the index of the maximum over the requested axis.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; idx = pd.MultiIndex.from_arrays([
 |      ...     [&#39;warm&#39;, &#39;warm&#39;, &#39;cold&#39;, &#39;cold&#39;],
 |      ...     [&#39;dog&#39;, &#39;falcon&#39;, &#39;fish&#39;, &#39;spider&#39;]],
 |      ...     names=[&#39;blooded&#39;, &#39;animal&#39;])
 |      &gt;&gt;&gt; s = pd.Series([4, 2, 0, 8], name=&#39;legs&#39;, index=idx)
 |      &gt;&gt;&gt; s
 |      blooded  animal
 |      warm     dog       4
 |               falcon    2
 |      cold     fish      0
 |               spider    8
 |      Name: legs, dtype: int64
 |      
 |      &gt;&gt;&gt; s.sum()
 |      14
 |      
 |      By default, the sum of an empty or all-NA Series is ``0``.
 |      
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).sum()  # min_count=0 is the default
 |      0.0
 |      
 |      This can be controlled with the ``min_count`` parameter. For example, if
 |      you&#39;d like the sum of an empty series to be NaN, pass ``min_count=1``.
 |      
 |      &gt;&gt;&gt; pd.Series([], dtype=&quot;float64&quot;).sum(min_count=1)
 |      nan
 |      
 |      Thanks to the ``skipna`` parameter, ``min_count`` handles all-NA and
 |      empty series identically.
 |      
 |      &gt;&gt;&gt; pd.Series([np.nan]).sum()
 |      0.0
 |      
 |      &gt;&gt;&gt; pd.Series([np.nan]).sum(min_count=1)
 |      nan
 |  
 |  swaplevel(self, i: &#39;Axis&#39; = -2, j: &#39;Axis&#39; = -1, axis: &#39;Axis&#39; = 0) -&gt; &#39;DataFrame&#39;
 |      Swap levels i and j in a :class:`MultiIndex`.
 |      
 |      Default is to swap the two innermost levels of the index.
 |      
 |      Parameters
 |      ----------
 |      i, j : int or str
 |          Levels of the indices to be swapped. Can pass level name as string.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |                  The axis to swap levels on. 0 or &#39;index&#39; for row-wise, 1 or
 |                  &#39;columns&#39; for column-wise.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          DataFrame with levels swapped in MultiIndex.
 |      
 |      Examples
 |              --------
 |              &gt;&gt;&gt; df = pd.DataFrame(
 |              ...     {&quot;Grade&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;C&quot;]},
 |              ...     index=[
 |              ...         [&quot;Final exam&quot;, &quot;Final exam&quot;, &quot;Coursework&quot;, &quot;Coursework&quot;],
 |              ...         [&quot;History&quot;, &quot;Geography&quot;, &quot;History&quot;, &quot;Geography&quot;],
 |              ...         [&quot;January&quot;, &quot;February&quot;, &quot;March&quot;, &quot;April&quot;],
 |              ...     ],
 |              ... )
 |              &gt;&gt;&gt; df
 |                                                  Grade
 |              Final exam  History     January      A
 |                          Geography   February     B
 |              Coursework  History     March        A
 |                          Geography   April        C
 |      
 |              In the following example, we will swap the levels of the indices.
 |              Here, we will swap the levels column-wise, but levels can be swapped row-wise
 |              in a similar manner. Note that column-wise is the default behaviour.
 |              By not supplying any arguments for i and j, we swap the last and second to
 |              last indices.
 |      
 |              &gt;&gt;&gt; df.swaplevel()
 |                                                  Grade
 |              Final exam  January     History         A
 |                          February    Geography       B
 |              Coursework  March       History         A
 |                          April       Geography       C
 |      
 |              By supplying one argument, we can choose which index to swap the last
 |              index with. We can for example swap the first index with the last one as
 |              follows.
 |      
 |              &gt;&gt;&gt; df.swaplevel(0)
 |                                                  Grade
 |              January     History     Final exam      A
 |              February    Geography   Final exam      B
 |              March       History     Coursework      A
 |              April       Geography   Coursework      C
 |      
 |              We can also define explicitly which indices we want to swap by supplying values
 |              for both i and j. Here, we for example swap the first and second indices.
 |      
 |              &gt;&gt;&gt; df.swaplevel(0, 1)
 |                                                  Grade
 |              History     Final exam  January         A
 |              Geography   Final exam  February        B
 |              History     Coursework  March           A
 |              Geography   Coursework  April           C
 |  
 |  to_dict(self, orient: &#39;str&#39; = &#39;dict&#39;, into=&lt;class &#39;dict&#39;&gt;)
 |      Convert the DataFrame to a dictionary.
 |      
 |      The type of the key-value pairs can be customized with the parameters
 |      (see below).
 |      
 |      Parameters
 |      ----------
 |      orient : str {&#39;dict&#39;, &#39;list&#39;, &#39;series&#39;, &#39;split&#39;, &#39;records&#39;, &#39;index&#39;}
 |          Determines the type of the values of the dictionary.
 |      
 |          - &#39;dict&#39; (default) : dict like {column -&gt; {index -&gt; value}}
 |          - &#39;list&#39; : dict like {column -&gt; [values]}
 |          - &#39;series&#39; : dict like {column -&gt; Series(values)}
 |          - &#39;split&#39; : dict like
 |            {&#39;index&#39; -&gt; [index], &#39;columns&#39; -&gt; [columns], &#39;data&#39; -&gt; [values]}
 |          - &#39;records&#39; : list like
 |            [{column -&gt; value}, ... , {column -&gt; value}]
 |          - &#39;index&#39; : dict like {index -&gt; {column -&gt; value}}
 |      
 |          Abbreviations are allowed. `s` indicates `series` and `sp`
 |          indicates `split`.
 |      
 |      into : class, default dict
 |          The collections.abc.Mapping subclass used for all Mappings
 |          in the return value.  Can be the actual class or an empty
 |          instance of the mapping type you want.  If you want a
 |          collections.defaultdict, you must pass it initialized.
 |      
 |      Returns
 |      -------
 |      dict, list or collections.abc.Mapping
 |          Return a collections.abc.Mapping object representing the DataFrame.
 |          The resulting transformation depends on the `orient` parameter.
 |      
 |      See Also
 |      --------
 |      DataFrame.from_dict: Create a DataFrame from a dictionary.
 |      DataFrame.to_json: Convert a DataFrame to JSON format.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;col1&#39;: [1, 2],
 |      ...                    &#39;col2&#39;: [0.5, 0.75]},
 |      ...                   index=[&#39;row1&#39;, &#39;row2&#39;])
 |      &gt;&gt;&gt; df
 |            col1  col2
 |      row1     1  0.50
 |      row2     2  0.75
 |      &gt;&gt;&gt; df.to_dict()
 |      {&#39;col1&#39;: {&#39;row1&#39;: 1, &#39;row2&#39;: 2}, &#39;col2&#39;: {&#39;row1&#39;: 0.5, &#39;row2&#39;: 0.75}}
 |      
 |      You can specify the return orientation.
 |      
 |      &gt;&gt;&gt; df.to_dict(&#39;series&#39;)
 |      {&#39;col1&#39;: row1    1
 |               row2    2
 |      Name: col1, dtype: int64,
 |      &#39;col2&#39;: row1    0.50
 |              row2    0.75
 |      Name: col2, dtype: float64}
 |      
 |      &gt;&gt;&gt; df.to_dict(&#39;split&#39;)
 |      {&#39;index&#39;: [&#39;row1&#39;, &#39;row2&#39;], &#39;columns&#39;: [&#39;col1&#39;, &#39;col2&#39;],
 |       &#39;data&#39;: [[1, 0.5], [2, 0.75]]}
 |      
 |      &gt;&gt;&gt; df.to_dict(&#39;records&#39;)
 |      [{&#39;col1&#39;: 1, &#39;col2&#39;: 0.5}, {&#39;col1&#39;: 2, &#39;col2&#39;: 0.75}]
 |      
 |      &gt;&gt;&gt; df.to_dict(&#39;index&#39;)
 |      {&#39;row1&#39;: {&#39;col1&#39;: 1, &#39;col2&#39;: 0.5}, &#39;row2&#39;: {&#39;col1&#39;: 2, &#39;col2&#39;: 0.75}}
 |      
 |      You can also specify the mapping type.
 |      
 |      &gt;&gt;&gt; from collections import OrderedDict, defaultdict
 |      &gt;&gt;&gt; df.to_dict(into=OrderedDict)
 |      OrderedDict([(&#39;col1&#39;, OrderedDict([(&#39;row1&#39;, 1), (&#39;row2&#39;, 2)])),
 |                   (&#39;col2&#39;, OrderedDict([(&#39;row1&#39;, 0.5), (&#39;row2&#39;, 0.75)]))])
 |      
 |      If you want a `defaultdict`, you need to initialize it:
 |      
 |      &gt;&gt;&gt; dd = defaultdict(list)
 |      &gt;&gt;&gt; df.to_dict(&#39;records&#39;, into=dd)
 |      [defaultdict(&lt;class &#39;list&#39;&gt;, {&#39;col1&#39;: 1, &#39;col2&#39;: 0.5}),
 |       defaultdict(&lt;class &#39;list&#39;&gt;, {&#39;col1&#39;: 2, &#39;col2&#39;: 0.75})]
 |  
 |  to_feather(self, path: &#39;FilePathOrBuffer[AnyStr]&#39;, **kwargs) -&gt; &#39;None&#39;
 |      Write a DataFrame to the binary Feather format.
 |      
 |      Parameters
 |      ----------
 |      path : str or file-like object
 |          If a string, it will be used as Root Directory path.
 |      **kwargs :
 |          Additional keywords passed to :func:`pyarrow.feather.write_feather`.
 |          Starting with pyarrow 0.17, this includes the `compression`,
 |          `compression_level`, `chunksize` and `version` keywords.
 |      
 |          .. versionadded:: 1.1.0
 |  
 |  to_gbq(self, destination_table: &#39;str&#39;, project_id: &#39;str | None&#39; = None, chunksize: &#39;int | None&#39; = None, reauth: &#39;bool&#39; = False, if_exists: &#39;str&#39; = &#39;fail&#39;, auth_local_webserver: &#39;bool&#39; = False, table_schema: &#39;list[dict[str, str]] | None&#39; = None, location: &#39;str | None&#39; = None, progress_bar: &#39;bool&#39; = True, credentials=None) -&gt; &#39;None&#39;
 |      Write a DataFrame to a Google BigQuery table.
 |      
 |      This function requires the `pandas-gbq package
 |      &lt;https://pandas-gbq.readthedocs.io&gt;`__.
 |      
 |      See the `How to authenticate with Google BigQuery
 |      &lt;https://pandas-gbq.readthedocs.io/en/latest/howto/authentication.html&gt;`__
 |      guide for authentication instructions.
 |      
 |      Parameters
 |      ----------
 |      destination_table : str
 |          Name of table to be written, in the form ``dataset.tablename``.
 |      project_id : str, optional
 |          Google BigQuery Account project ID. Optional when available from
 |          the environment.
 |      chunksize : int, optional
 |          Number of rows to be inserted in each chunk from the dataframe.
 |          Set to ``None`` to load the whole dataframe at once.
 |      reauth : bool, default False
 |          Force Google BigQuery to re-authenticate the user. This is useful
 |          if multiple accounts are used.
 |      if_exists : str, default &#39;fail&#39;
 |          Behavior when the destination table exists. Value can be one of:
 |      
 |          ``&#39;fail&#39;``
 |              If table exists raise pandas_gbq.gbq.TableCreationError.
 |          ``&#39;replace&#39;``
 |              If table exists, drop it, recreate it, and insert data.
 |          ``&#39;append&#39;``
 |              If table exists, insert data. Create if does not exist.
 |      auth_local_webserver : bool, default False
 |          Use the `local webserver flow`_ instead of the `console flow`_
 |          when getting user credentials.
 |      
 |          .. _local webserver flow:
 |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_local_server
 |          .. _console flow:
 |              https://google-auth-oauthlib.readthedocs.io/en/latest/reference/google_auth_oauthlib.flow.html#google_auth_oauthlib.flow.InstalledAppFlow.run_console
 |      
 |          *New in version 0.2.0 of pandas-gbq*.
 |      table_schema : list of dicts, optional
 |          List of BigQuery table fields to which according DataFrame
 |          columns conform to, e.g. ``[{&#39;name&#39;: &#39;col1&#39;, &#39;type&#39;:
 |          &#39;STRING&#39;},...]``. If schema is not provided, it will be
 |          generated according to dtypes of DataFrame columns. See
 |          BigQuery API documentation on available names of a field.
 |      
 |          *New in version 0.3.1 of pandas-gbq*.
 |      location : str, optional
 |          Location where the load job should run. See the `BigQuery locations
 |          documentation
 |          &lt;https://cloud.google.com/bigquery/docs/dataset-locations&gt;`__ for a
 |          list of available locations. The location must match that of the
 |          target dataset.
 |      
 |          *New in version 0.5.0 of pandas-gbq*.
 |      progress_bar : bool, default True
 |          Use the library `tqdm` to show the progress bar for the upload,
 |          chunk by chunk.
 |      
 |          *New in version 0.5.0 of pandas-gbq*.
 |      credentials : google.auth.credentials.Credentials, optional
 |          Credentials for accessing Google APIs. Use this parameter to
 |          override default credentials, such as to use Compute Engine
 |          :class:`google.auth.compute_engine.Credentials` or Service
 |          Account :class:`google.oauth2.service_account.Credentials`
 |          directly.
 |      
 |          *New in version 0.8.0 of pandas-gbq*.
 |      
 |      See Also
 |      --------
 |      pandas_gbq.to_gbq : This function in the pandas-gbq library.
 |      read_gbq : Read a DataFrame from Google BigQuery.
 |  
 |  to_html(self, buf: &#39;FilePathOrBuffer[str] | None&#39; = None, columns: &#39;Sequence[str] | None&#39; = None, col_space: &#39;ColspaceArgType | None&#39; = None, header: &#39;bool | Sequence[str]&#39; = True, index: &#39;bool&#39; = True, na_rep: &#39;str&#39; = &#39;NaN&#39;, formatters: &#39;FormattersType | None&#39; = None, float_format: &#39;FloatFormatType | None&#39; = None, sparsify: &#39;bool | None&#39; = None, index_names: &#39;bool&#39; = True, justify: &#39;str | None&#39; = None, max_rows: &#39;int | None&#39; = None, max_cols: &#39;int | None&#39; = None, show_dimensions: &#39;bool | str&#39; = False, decimal: &#39;str&#39; = &#39;.&#39;, bold_rows: &#39;bool&#39; = True, classes: &#39;str | list | tuple | None&#39; = None, escape: &#39;bool&#39; = True, notebook: &#39;bool&#39; = False, border: &#39;int | None&#39; = None, table_id: &#39;str | None&#39; = None, render_links: &#39;bool&#39; = False, encoding: &#39;str | None&#39; = None)
 |      Render a DataFrame as an HTML table.
 |      
 |      Parameters
 |      ----------
 |      buf : str, Path or StringIO-like, optional, default None
 |          Buffer to write to. If None, the output is returned as a string.
 |      columns : sequence, optional, default None
 |          The subset of columns to write. Writes all columns by default.
 |      col_space : str or int, list or dict of int or str, optional
 |          The minimum width of each column in CSS length units.  An int is assumed to be px units.
 |      
 |          .. versionadded:: 0.25.0
 |              Ability to use str.
 |      header : bool, optional
 |          Whether to print column labels, default True.
 |      index : bool, optional, default True
 |          Whether to print index (row) labels.
 |      na_rep : str, optional, default &#39;NaN&#39;
 |          String representation of ``NaN`` to use.
 |      formatters : list, tuple or dict of one-param. functions, optional
 |          Formatter functions to apply to columns&#39; elements by position or
 |          name.
 |          The result of each function must be a unicode string.
 |          List/tuple must be of length equal to the number of columns.
 |      float_format : one-parameter function, optional, default None
 |          Formatter function to apply to columns&#39; elements if they are
 |          floats. This function must return a unicode string and will be
 |          applied only to the non-``NaN`` elements, with ``NaN`` being
 |          handled by ``na_rep``.
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |      sparsify : bool, optional, default True
 |          Set to False for a DataFrame with a hierarchical index to print
 |          every multiindex key at each row.
 |      index_names : bool, optional, default True
 |          Prints the names of the indexes.
 |      justify : str, default None
 |          How to justify the column labels. If None uses the option from
 |          the print configuration (controlled by set_option), &#39;right&#39; out
 |          of the box. Valid values are
 |      
 |          * left
 |          * right
 |          * center
 |          * justify
 |          * justify-all
 |          * start
 |          * end
 |          * inherit
 |          * match-parent
 |          * initial
 |          * unset.
 |      max_rows : int, optional
 |          Maximum number of rows to display in the console.
 |      min_rows : int, optional
 |          The number of rows to display in the console in a truncated repr
 |          (when number of rows is above `max_rows`).
 |      max_cols : int, optional
 |          Maximum number of columns to display in the console.
 |      show_dimensions : bool, default False
 |          Display DataFrame dimensions (number of rows by number of columns).
 |      decimal : str, default &#39;.&#39;
 |          Character recognized as decimal separator, e.g. &#39;,&#39; in Europe.
 |      
 |      bold_rows : bool, default True
 |          Make the row labels bold in the output.
 |      classes : str or list or tuple, default None
 |          CSS class(es) to apply to the resulting html table.
 |      escape : bool, default True
 |          Convert the characters &lt;, &gt;, and &amp; to HTML-safe sequences.
 |      notebook : {True, False}, default False
 |          Whether the generated HTML is for IPython Notebook.
 |      border : int
 |          A ``border=border`` attribute is included in the opening
 |          `&lt;table&gt;` tag. Default ``pd.options.display.html.border``.
 |      encoding : str, default &quot;utf-8&quot;
 |          Set character encoding.
 |      
 |          .. versionadded:: 1.0
 |      
 |      table_id : str, optional
 |          A css id is included in the opening `&lt;table&gt;` tag if specified.
 |      render_links : bool, default False
 |          Convert URLs to HTML links.
 |      
 |      Returns
 |      -------
 |      str or None
 |          If buf is None, returns the result as a string. Otherwise returns
 |          None.
 |      
 |      See Also
 |      --------
 |      to_string : Convert DataFrame to a string.
 |  
 |  to_markdown(self, buf: &#39;IO[str] | str | None&#39; = None, mode: &#39;str&#39; = &#39;wt&#39;, index: &#39;bool&#39; = True, storage_options: &#39;StorageOptions&#39; = None, **kwargs) -&gt; &#39;str | None&#39;
 |      Print DataFrame in Markdown-friendly format.
 |      
 |      .. versionadded:: 1.0.0
 |      
 |      Parameters
 |      ----------
 |      buf : str, Path or StringIO-like, optional, default None
 |          Buffer to write to. If None, the output is returned as a string.
 |      mode : str, optional
 |          Mode in which file is opened, &quot;wt&quot; by default.
 |      index : bool, optional, default True
 |          Add index (row) labels.
 |      
 |          .. versionadded:: 1.1.0
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib`` as header options. For other URLs (e.g.
 |          starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are forwarded to
 |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      **kwargs
 |          These parameters will be passed to `tabulate                 &lt;https://pypi.org/project/tabulate&gt;`_.
 |      
 |      Returns
 |      -------
 |      str
 |          DataFrame in Markdown-friendly format.
 |      
 |      Notes
 |      -----
 |      Requires the `tabulate &lt;https://pypi.org/project/tabulate&gt;`_ package.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([&quot;elk&quot;, &quot;pig&quot;, &quot;dog&quot;, &quot;quetzal&quot;], name=&quot;animal&quot;)
 |      &gt;&gt;&gt; print(s.to_markdown())
 |      |    | animal   |
 |      |---:|:---------|
 |      |  0 | elk      |
 |      |  1 | pig      |
 |      |  2 | dog      |
 |      |  3 | quetzal  |
 |      
 |      Output markdown with a tabulate option.
 |      
 |      &gt;&gt;&gt; print(s.to_markdown(tablefmt=&quot;grid&quot;))
 |      +----+----------+
 |      |    | animal   |
 |      +====+==========+
 |      |  0 | elk      |
 |      +----+----------+
 |      |  1 | pig      |
 |      +----+----------+
 |      |  2 | dog      |
 |      +----+----------+
 |      |  3 | quetzal  |
 |      +----+----------+
 |  
 |  to_numpy(self, dtype: &#39;NpDtype | None&#39; = None, copy: &#39;bool&#39; = False, na_value=&lt;no_default&gt;) -&gt; &#39;np.ndarray&#39;
 |      Convert the DataFrame to a NumPy array.
 |      
 |      By default, the dtype of the returned array will be the common NumPy
 |      dtype of all types in the DataFrame. For example, if the dtypes are
 |      ``float16`` and ``float32``, the results dtype will be ``float32``.
 |      This may require copying data and coercing values, which may be
 |      expensive.
 |      
 |      Parameters
 |      ----------
 |      dtype : str or numpy.dtype, optional
 |          The dtype to pass to :meth:`numpy.asarray`.
 |      copy : bool, default False
 |          Whether to ensure that the returned value is not a view on
 |          another array. Note that ``copy=False`` does not *ensure* that
 |          ``to_numpy()`` is no-copy. Rather, ``copy=True`` ensure that
 |          a copy is made, even if not strictly necessary.
 |      na_value : Any, optional
 |          The value to use for missing values. The default value depends
 |          on `dtype` and the dtypes of the DataFrame columns.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      numpy.ndarray
 |      
 |      See Also
 |      --------
 |      Series.to_numpy : Similar method for Series.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; pd.DataFrame({&quot;A&quot;: [1, 2], &quot;B&quot;: [3, 4]}).to_numpy()
 |      array([[1, 3],
 |             [2, 4]])
 |      
 |      With heterogeneous data, the lowest common type will have to
 |      be used.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2], &quot;B&quot;: [3.0, 4.5]})
 |      &gt;&gt;&gt; df.to_numpy()
 |      array([[1. , 3. ],
 |             [2. , 4.5]])
 |      
 |      For a mix of numeric and non-numeric types, the output array will
 |      have object dtype.
 |      
 |      &gt;&gt;&gt; df[&#39;C&#39;] = pd.date_range(&#39;2000&#39;, periods=2)
 |      &gt;&gt;&gt; df.to_numpy()
 |      array([[1, 3.0, Timestamp(&#39;2000-01-01 00:00:00&#39;)],
 |             [2, 4.5, Timestamp(&#39;2000-01-02 00:00:00&#39;)]], dtype=object)
 |  
 |  to_parquet(self, path: &#39;FilePathOrBuffer | None&#39; = None, engine: &#39;str&#39; = &#39;auto&#39;, compression: &#39;str | None&#39; = &#39;snappy&#39;, index: &#39;bool | None&#39; = None, partition_cols: &#39;list[str] | None&#39; = None, storage_options: &#39;StorageOptions&#39; = None, **kwargs) -&gt; &#39;bytes | None&#39;
 |      Write a DataFrame to the binary parquet format.
 |      
 |      This function writes the dataframe as a `parquet file
 |      &lt;https://parquet.apache.org/&gt;`_. You can choose different parquet
 |      backends, and have the option of compression. See
 |      :ref:`the user guide &lt;io.parquet&gt;` for more details.
 |      
 |      Parameters
 |      ----------
 |      path : str or file-like object, default None
 |          If a string, it will be used as Root Directory path
 |          when writing a partitioned dataset. By file-like object,
 |          we refer to objects with a write() method, such as a file handle
 |          (e.g. via builtin open function) or io.BytesIO. The engine
 |          fastparquet does not accept file-like objects. If path is None,
 |          a bytes object is returned.
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |          Previously this was &quot;fname&quot;
 |      
 |      engine : {&#39;auto&#39;, &#39;pyarrow&#39;, &#39;fastparquet&#39;}, default &#39;auto&#39;
 |          Parquet library to use. If &#39;auto&#39;, then the option
 |          ``io.parquet.engine`` is used. The default ``io.parquet.engine``
 |          behavior is to try &#39;pyarrow&#39;, falling back to &#39;fastparquet&#39; if
 |          &#39;pyarrow&#39; is unavailable.
 |      compression : {&#39;snappy&#39;, &#39;gzip&#39;, &#39;brotli&#39;, None}, default &#39;snappy&#39;
 |          Name of the compression to use. Use ``None`` for no compression.
 |      index : bool, default None
 |          If ``True``, include the dataframe&#39;s index(es) in the file output.
 |          If ``False``, they will not be written to the file.
 |          If ``None``, similar to ``True`` the dataframe&#39;s index(es)
 |          will be saved. However, instead of being saved as values,
 |          the RangeIndex will be stored as a range in the metadata so it
 |          doesn&#39;t require much space and is faster. Other indexes will
 |          be included as columns in the file output.
 |      partition_cols : list, optional, default None
 |          Column names by which to partition the dataset.
 |          Columns are partitioned in the order they are given.
 |          Must be None if path is not a string.
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib`` as header options. For other URLs (e.g.
 |          starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are forwarded to
 |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      **kwargs
 |          Additional arguments passed to the parquet library. See
 |          :ref:`pandas io &lt;io.parquet&gt;` for more details.
 |      
 |      Returns
 |      -------
 |      bytes if no path argument is provided else None
 |      
 |      See Also
 |      --------
 |      read_parquet : Read a parquet file.
 |      DataFrame.to_csv : Write a csv file.
 |      DataFrame.to_sql : Write to a sql table.
 |      DataFrame.to_hdf : Write to hdf.
 |      
 |      Notes
 |      -----
 |      This function requires either the `fastparquet
 |      &lt;https://pypi.org/project/fastparquet&gt;`_ or `pyarrow
 |      &lt;https://arrow.apache.org/docs/python/&gt;`_ library.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(data={&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]})
 |      &gt;&gt;&gt; df.to_parquet(&#39;df.parquet.gzip&#39;,
 |      ...               compression=&#39;gzip&#39;)  # doctest: +SKIP
 |      &gt;&gt;&gt; pd.read_parquet(&#39;df.parquet.gzip&#39;)  # doctest: +SKIP
 |         col1  col2
 |      0     1     3
 |      1     2     4
 |      
 |      If you want to get a buffer to the parquet content you can use a io.BytesIO
 |      object, as long as you don&#39;t use partition_cols, which creates multiple files.
 |      
 |      &gt;&gt;&gt; import io
 |      &gt;&gt;&gt; f = io.BytesIO()
 |      &gt;&gt;&gt; df.to_parquet(f)
 |      &gt;&gt;&gt; f.seek(0)
 |      0
 |      &gt;&gt;&gt; content = f.read()
 |  
 |  to_period(self, freq: &#39;Frequency | None&#39; = None, axis: &#39;Axis&#39; = 0, copy: &#39;bool&#39; = True) -&gt; &#39;DataFrame&#39;
 |      Convert DataFrame from DatetimeIndex to PeriodIndex.
 |      
 |      Convert DataFrame from DatetimeIndex to PeriodIndex with desired
 |      frequency (inferred from index if not passed).
 |      
 |      Parameters
 |      ----------
 |      freq : str, default
 |          Frequency of the PeriodIndex.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to convert (the index by default).
 |      copy : bool, default True
 |          If False then underlying input data is not copied.
 |      
 |      Returns
 |      -------
 |      DataFrame with PeriodIndex
 |  
 |  to_records(self, index=True, column_dtypes=None, index_dtypes=None) -&gt; &#39;np.recarray&#39;
 |      Convert DataFrame to a NumPy record array.
 |      
 |      Index will be included as the first field of the record array if
 |      requested.
 |      
 |      Parameters
 |      ----------
 |      index : bool, default True
 |          Include index in resulting record array, stored in &#39;index&#39;
 |          field or using the index label, if set.
 |      column_dtypes : str, type, dict, default None
 |          If a string or type, the data type to store all columns. If
 |          a dictionary, a mapping of column names and indices (zero-indexed)
 |          to specific data types.
 |      index_dtypes : str, type, dict, default None
 |          If a string or type, the data type to store all index levels. If
 |          a dictionary, a mapping of index level names and indices
 |          (zero-indexed) to specific data types.
 |      
 |          This mapping is applied only if `index=True`.
 |      
 |      Returns
 |      -------
 |      numpy.recarray
 |          NumPy ndarray with the DataFrame labels as fields and each row
 |          of the DataFrame as entries.
 |      
 |      See Also
 |      --------
 |      DataFrame.from_records: Convert structured or record ndarray
 |          to DataFrame.
 |      numpy.recarray: An ndarray that allows field access using
 |          attributes, analogous to typed columns in a
 |          spreadsheet.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [1, 2], &#39;B&#39;: [0.5, 0.75]},
 |      ...                   index=[&#39;a&#39;, &#39;b&#39;])
 |      &gt;&gt;&gt; df
 |         A     B
 |      a  1  0.50
 |      b  2  0.75
 |      &gt;&gt;&gt; df.to_records()
 |      rec.array([(&#39;a&#39;, 1, 0.5 ), (&#39;b&#39;, 2, 0.75)],
 |                dtype=[(&#39;index&#39;, &#39;O&#39;), (&#39;A&#39;, &#39;&lt;i8&#39;), (&#39;B&#39;, &#39;&lt;f8&#39;)])
 |      
 |      If the DataFrame index has no label then the recarray field name
 |      is set to &#39;index&#39;. If the index has a label then this is used as the
 |      field name:
 |      
 |      &gt;&gt;&gt; df.index = df.index.rename(&quot;I&quot;)
 |      &gt;&gt;&gt; df.to_records()
 |      rec.array([(&#39;a&#39;, 1, 0.5 ), (&#39;b&#39;, 2, 0.75)],
 |                dtype=[(&#39;I&#39;, &#39;O&#39;), (&#39;A&#39;, &#39;&lt;i8&#39;), (&#39;B&#39;, &#39;&lt;f8&#39;)])
 |      
 |      The index can be excluded from the record array:
 |      
 |      &gt;&gt;&gt; df.to_records(index=False)
 |      rec.array([(1, 0.5 ), (2, 0.75)],
 |                dtype=[(&#39;A&#39;, &#39;&lt;i8&#39;), (&#39;B&#39;, &#39;&lt;f8&#39;)])
 |      
 |      Data types can be specified for the columns:
 |      
 |      &gt;&gt;&gt; df.to_records(column_dtypes={&quot;A&quot;: &quot;int32&quot;})
 |      rec.array([(&#39;a&#39;, 1, 0.5 ), (&#39;b&#39;, 2, 0.75)],
 |                dtype=[(&#39;I&#39;, &#39;O&#39;), (&#39;A&#39;, &#39;&lt;i4&#39;), (&#39;B&#39;, &#39;&lt;f8&#39;)])
 |      
 |      As well as for the index:
 |      
 |      &gt;&gt;&gt; df.to_records(index_dtypes=&quot;&lt;S2&quot;)
 |      rec.array([(b&#39;a&#39;, 1, 0.5 ), (b&#39;b&#39;, 2, 0.75)],
 |                dtype=[(&#39;I&#39;, &#39;S2&#39;), (&#39;A&#39;, &#39;&lt;i8&#39;), (&#39;B&#39;, &#39;&lt;f8&#39;)])
 |      
 |      &gt;&gt;&gt; index_dtypes = f&quot;&lt;S{df.index.str.len().max()}&quot;
 |      &gt;&gt;&gt; df.to_records(index_dtypes=index_dtypes)
 |      rec.array([(b&#39;a&#39;, 1, 0.5 ), (b&#39;b&#39;, 2, 0.75)],
 |                dtype=[(&#39;I&#39;, &#39;S1&#39;), (&#39;A&#39;, &#39;&lt;i8&#39;), (&#39;B&#39;, &#39;&lt;f8&#39;)])
 |  
 |  to_stata(self, path: &#39;FilePathOrBuffer&#39;, convert_dates: &#39;dict[Hashable, str] | None&#39; = None, write_index: &#39;bool&#39; = True, byteorder: &#39;str | None&#39; = None, time_stamp: &#39;datetime.datetime | None&#39; = None, data_label: &#39;str | None&#39; = None, variable_labels: &#39;dict[Hashable, str] | None&#39; = None, version: &#39;int | None&#39; = 114, convert_strl: &#39;Sequence[Hashable] | None&#39; = None, compression: &#39;CompressionOptions&#39; = &#39;infer&#39;, storage_options: &#39;StorageOptions&#39; = None) -&gt; &#39;None&#39;
 |      Export DataFrame object to Stata dta format.
 |      
 |      Writes the DataFrame to a Stata dataset file.
 |      &quot;dta&quot; files contain a Stata dataset.
 |      
 |      Parameters
 |      ----------
 |      path : str, buffer or path object
 |          String, path object (pathlib.Path or py._path.local.LocalPath) or
 |          object implementing a binary write() function. If using a buffer
 |          then the buffer will not be automatically closed after the file
 |          data has been written.
 |      
 |          .. versionchanged:: 1.0.0
 |      
 |          Previously this was &quot;fname&quot;
 |      
 |      convert_dates : dict
 |          Dictionary mapping columns containing datetime types to stata
 |          internal format to use when writing the dates. Options are &#39;tc&#39;,
 |          &#39;td&#39;, &#39;tm&#39;, &#39;tw&#39;, &#39;th&#39;, &#39;tq&#39;, &#39;ty&#39;. Column can be either an integer
 |          or a name. Datetime columns that do not have a conversion type
 |          specified will be converted to &#39;tc&#39;. Raises NotImplementedError if
 |          a datetime column has timezone information.
 |      write_index : bool
 |          Write the index to Stata dataset.
 |      byteorder : str
 |          Can be &quot;&gt;&quot;, &quot;&lt;&quot;, &quot;little&quot;, or &quot;big&quot;. default is `sys.byteorder`.
 |      time_stamp : datetime
 |          A datetime to use as file creation date.  Default is the current
 |          time.
 |      data_label : str, optional
 |          A label for the data set.  Must be 80 characters or smaller.
 |      variable_labels : dict
 |          Dictionary containing columns as keys and variable labels as
 |          values. Each label must be 80 characters or smaller.
 |      version : {114, 117, 118, 119, None}, default 114
 |          Version to use in the output dta file. Set to None to let pandas
 |          decide between 118 or 119 formats depending on the number of
 |          columns in the frame. Version 114 can be read by Stata 10 and
 |          later. Version 117 can be read by Stata 13 or later. Version 118
 |          is supported in Stata 14 and later. Version 119 is supported in
 |          Stata 15 and later. Version 114 limits string variables to 244
 |          characters or fewer while versions 117 and later allow strings
 |          with lengths up to 2,000,000 characters. Versions 118 and 119
 |          support Unicode characters, and version 119 supports more than
 |          32,767 variables.
 |      
 |          Version 119 should usually only be used when the number of
 |          variables exceeds the capacity of dta format 118. Exporting
 |          smaller datasets in format 119 may have unintended consequences,
 |          and, as of November 2020, Stata SE cannot read version 119 files.
 |      
 |          .. versionchanged:: 1.0.0
 |      
 |              Added support for formats 118 and 119.
 |      
 |      convert_strl : list, optional
 |          List of column names to convert to string columns to Stata StrL
 |          format. Only available if version is 117.  Storing strings in the
 |          StrL format can produce smaller dta files if strings have more than
 |          8 characters and values are repeated.
 |      compression : str or dict, default &#39;infer&#39;
 |          For on-the-fly compression of the output dta. If string, specifies
 |          compression mode. If dict, value at key &#39;method&#39; specifies
 |          compression mode. Compression mode must be one of {&#39;infer&#39;, &#39;gzip&#39;,
 |          &#39;bz2&#39;, &#39;zip&#39;, &#39;xz&#39;, None}. If compression mode is &#39;infer&#39; and
 |          `fname` is path-like, then detect compression from the following
 |          extensions: &#39;.gz&#39;, &#39;.bz2&#39;, &#39;.zip&#39;, or &#39;.xz&#39; (otherwise no
 |          compression). If dict and compression mode is one of {&#39;zip&#39;,
 |          &#39;gzip&#39;, &#39;bz2&#39;}, or inferred as one of the above, other entries
 |          passed as additional compression options.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib`` as header options. For other URLs (e.g.
 |          starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are forwarded to
 |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      Raises
 |      ------
 |      NotImplementedError
 |          * If datetimes contain timezone information
 |          * Column dtype is not representable in Stata
 |      ValueError
 |          * Columns listed in convert_dates are neither datetime64[ns]
 |            or datetime.datetime
 |          * Column listed in convert_dates is not in DataFrame
 |          * Categorical label contains more than 32,000 characters
 |      
 |      See Also
 |      --------
 |      read_stata : Import Stata data files.
 |      io.stata.StataWriter : Low-level writer for Stata data files.
 |      io.stata.StataWriter117 : Low-level writer for version 117 files.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;animal&#39;: [&#39;falcon&#39;, &#39;parrot&#39;, &#39;falcon&#39;,
 |      ...                               &#39;parrot&#39;],
 |      ...                    &#39;speed&#39;: [350, 18, 361, 15]})
 |      &gt;&gt;&gt; df.to_stata(&#39;animals.dta&#39;)  # doctest: +SKIP
 |  
 |  to_string(self, buf: &#39;FilePathOrBuffer[str] | None&#39; = None, columns: &#39;Sequence[str] | None&#39; = None, col_space: &#39;int | None&#39; = None, header: &#39;bool | Sequence[str]&#39; = True, index: &#39;bool&#39; = True, na_rep: &#39;str&#39; = &#39;NaN&#39;, formatters: &#39;fmt.FormattersType | None&#39; = None, float_format: &#39;fmt.FloatFormatType | None&#39; = None, sparsify: &#39;bool | None&#39; = None, index_names: &#39;bool&#39; = True, justify: &#39;str | None&#39; = None, max_rows: &#39;int | None&#39; = None, min_rows: &#39;int | None&#39; = None, max_cols: &#39;int | None&#39; = None, show_dimensions: &#39;bool&#39; = False, decimal: &#39;str&#39; = &#39;.&#39;, line_width: &#39;int | None&#39; = None, max_colwidth: &#39;int | None&#39; = None, encoding: &#39;str | None&#39; = None) -&gt; &#39;str | None&#39;
 |      Render a DataFrame to a console-friendly tabular output.
 |      
 |      Parameters
 |      ----------
 |      buf : str, Path or StringIO-like, optional, default None
 |          Buffer to write to. If None, the output is returned as a string.
 |      columns : sequence, optional, default None
 |          The subset of columns to write. Writes all columns by default.
 |      col_space : int, list or dict of int, optional
 |          The minimum width of each column.
 |      header : bool or sequence, optional
 |          Write out the column names. If a list of strings is given, it is assumed to be aliases for the column names.
 |      index : bool, optional, default True
 |          Whether to print index (row) labels.
 |      na_rep : str, optional, default &#39;NaN&#39;
 |          String representation of ``NaN`` to use.
 |      formatters : list, tuple or dict of one-param. functions, optional
 |          Formatter functions to apply to columns&#39; elements by position or
 |          name.
 |          The result of each function must be a unicode string.
 |          List/tuple must be of length equal to the number of columns.
 |      float_format : one-parameter function, optional, default None
 |          Formatter function to apply to columns&#39; elements if they are
 |          floats. This function must return a unicode string and will be
 |          applied only to the non-``NaN`` elements, with ``NaN`` being
 |          handled by ``na_rep``.
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |      sparsify : bool, optional, default True
 |          Set to False for a DataFrame with a hierarchical index to print
 |          every multiindex key at each row.
 |      index_names : bool, optional, default True
 |          Prints the names of the indexes.
 |      justify : str, default None
 |          How to justify the column labels. If None uses the option from
 |          the print configuration (controlled by set_option), &#39;right&#39; out
 |          of the box. Valid values are
 |      
 |          * left
 |          * right
 |          * center
 |          * justify
 |          * justify-all
 |          * start
 |          * end
 |          * inherit
 |          * match-parent
 |          * initial
 |          * unset.
 |      max_rows : int, optional
 |          Maximum number of rows to display in the console.
 |      min_rows : int, optional
 |          The number of rows to display in the console in a truncated repr
 |          (when number of rows is above `max_rows`).
 |      max_cols : int, optional
 |          Maximum number of columns to display in the console.
 |      show_dimensions : bool, default False
 |          Display DataFrame dimensions (number of rows by number of columns).
 |      decimal : str, default &#39;.&#39;
 |          Character recognized as decimal separator, e.g. &#39;,&#39; in Europe.
 |      
 |      line_width : int, optional
 |          Width to wrap a line in characters.
 |      max_colwidth : int, optional
 |          Max width to truncate each column in characters. By default, no limit.
 |      
 |          .. versionadded:: 1.0.0
 |      encoding : str, default &quot;utf-8&quot;
 |          Set character encoding.
 |      
 |          .. versionadded:: 1.0
 |      
 |      Returns
 |      -------
 |      str or None
 |          If buf is None, returns the result as a string. Otherwise returns
 |          None.
 |      
 |      See Also
 |      --------
 |      to_html : Convert DataFrame to HTML.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; d = {&#39;col1&#39;: [1, 2, 3], &#39;col2&#39;: [4, 5, 6]}
 |      &gt;&gt;&gt; df = pd.DataFrame(d)
 |      &gt;&gt;&gt; print(df.to_string())
 |         col1  col2
 |      0     1     4
 |      1     2     5
 |      2     3     6
 |  
 |  to_timestamp(self, freq: &#39;Frequency | None&#39; = None, how: &#39;str&#39; = &#39;start&#39;, axis: &#39;Axis&#39; = 0, copy: &#39;bool&#39; = True) -&gt; &#39;DataFrame&#39;
 |      Cast to DatetimeIndex of timestamps, at *beginning* of period.
 |      
 |      Parameters
 |      ----------
 |      freq : str, default frequency of PeriodIndex
 |          Desired frequency.
 |      how : {&#39;s&#39;, &#39;e&#39;, &#39;start&#39;, &#39;end&#39;}
 |          Convention for converting period to timestamp; start of period
 |          vs. end.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to convert (the index by default).
 |      copy : bool, default True
 |          If False then underlying input data is not copied.
 |      
 |      Returns
 |      -------
 |      DataFrame with DatetimeIndex
 |  
 |  to_xml(self, path_or_buffer: &#39;FilePathOrBuffer | None&#39; = None, index: &#39;bool&#39; = True, root_name: &#39;str | None&#39; = &#39;data&#39;, row_name: &#39;str | None&#39; = &#39;row&#39;, na_rep: &#39;str | None&#39; = None, attr_cols: &#39;str | list[str] | None&#39; = None, elem_cols: &#39;str | list[str] | None&#39; = None, namespaces: &#39;dict[str | None, str] | None&#39; = None, prefix: &#39;str | None&#39; = None, encoding: &#39;str&#39; = &#39;utf-8&#39;, xml_declaration: &#39;bool | None&#39; = True, pretty_print: &#39;bool | None&#39; = True, parser: &#39;str | None&#39; = &#39;lxml&#39;, stylesheet: &#39;FilePathOrBuffer | None&#39; = None, compression: &#39;CompressionOptions&#39; = &#39;infer&#39;, storage_options: &#39;StorageOptions&#39; = None) -&gt; &#39;str | None&#39;
 |      Render a DataFrame to an XML document.
 |      
 |      .. versionadded:: 1.3.0
 |      
 |      Parameters
 |      ----------
 |      path_or_buffer : str, path object or file-like object, optional
 |          File to write output to. If None, the output is returned as a
 |          string.
 |      index : bool, default True
 |          Whether to include index in XML document.
 |      root_name : str, default &#39;data&#39;
 |          The name of root element in XML document.
 |      row_name : str, default &#39;row&#39;
 |          The name of row element in XML document.
 |      na_rep : str, optional
 |          Missing data representation.
 |      attr_cols : list-like, optional
 |          List of columns to write as attributes in row element.
 |          Hierarchical columns will be flattened with underscore
 |          delimiting the different levels.
 |      elem_cols : list-like, optional
 |          List of columns to write as children in row element. By default,
 |          all columns output as children of row element. Hierarchical
 |          columns will be flattened with underscore delimiting the
 |          different levels.
 |      namespaces : dict, optional
 |          All namespaces to be defined in root element. Keys of dict
 |          should be prefix names and values of dict corresponding URIs.
 |          Default namespaces should be given empty string key. For
 |          example, ::
 |      
 |              namespaces = {&quot;&quot;: &quot;https://example.com&quot;}
 |      
 |      prefix : str, optional
 |          Namespace prefix to be used for every element and/or attribute
 |          in document. This should be one of the keys in ``namespaces``
 |          dict.
 |      encoding : str, default &#39;utf-8&#39;
 |          Encoding of the resulting document.
 |      xml_declaration : bool, default True
 |          Whether to include the XML declaration at start of document.
 |      pretty_print : bool, default True
 |          Whether output should be pretty printed with indentation and
 |          line breaks.
 |      parser : {&#39;lxml&#39;,&#39;etree&#39;}, default &#39;lxml&#39;
 |          Parser module to use for building of tree. Only &#39;lxml&#39; and
 |          &#39;etree&#39; are supported. With &#39;lxml&#39;, the ability to use XSLT
 |          stylesheet is supported.
 |      stylesheet : str, path object or file-like object, optional
 |          A URL, file-like object, or a raw string containing an XSLT
 |          script used to transform the raw XML output. Script should use
 |          layout of elements and attributes from original output. This
 |          argument requires ``lxml`` to be installed. Only XSLT 1.0
 |          scripts and not later versions is currently supported.
 |      compression : {&#39;infer&#39;, &#39;gzip&#39;, &#39;bz2&#39;, &#39;zip&#39;, &#39;xz&#39;, None}, default &#39;infer&#39;
 |          For on-the-fly decompression of on-disk data. If &#39;infer&#39;, then use
 |          gzip, bz2, zip or xz if path_or_buffer is a string ending in
 |          &#39;.gz&#39;, &#39;.bz2&#39;, &#39;.zip&#39;, or &#39;xz&#39;, respectively, and no decompression
 |          otherwise. If using &#39;zip&#39;, the ZIP file must contain only one data
 |          file to be read in. Set to None for no decompression.
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib`` as header options. For other URLs (e.g.
 |          starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are forwarded to
 |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.
 |      
 |      Returns
 |      -------
 |      None or str
 |          If ``io`` is None, returns the resulting XML format as a
 |          string. Otherwise returns None.
 |      
 |      See Also
 |      --------
 |      to_json : Convert the pandas object to a JSON string.
 |      to_html : Convert DataFrame to a html.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;shape&#39;: [&#39;square&#39;, &#39;circle&#39;, &#39;triangle&#39;],
 |      ...                    &#39;degrees&#39;: [360, 360, 180],
 |      ...                    &#39;sides&#39;: [4, np.nan, 3]})
 |      
 |      &gt;&gt;&gt; df.to_xml()  # doctest: +SKIP
 |      &lt;?xml version=&#39;1.0&#39; encoding=&#39;utf-8&#39;?&gt;
 |      &lt;data&gt;
 |        &lt;row&gt;
 |          &lt;index&gt;0&lt;/index&gt;
 |          &lt;shape&gt;square&lt;/shape&gt;
 |          &lt;degrees&gt;360&lt;/degrees&gt;
 |          &lt;sides&gt;4.0&lt;/sides&gt;
 |        &lt;/row&gt;
 |        &lt;row&gt;
 |          &lt;index&gt;1&lt;/index&gt;
 |          &lt;shape&gt;circle&lt;/shape&gt;
 |          &lt;degrees&gt;360&lt;/degrees&gt;
 |          &lt;sides/&gt;
 |        &lt;/row&gt;
 |        &lt;row&gt;
 |          &lt;index&gt;2&lt;/index&gt;
 |          &lt;shape&gt;triangle&lt;/shape&gt;
 |          &lt;degrees&gt;180&lt;/degrees&gt;
 |          &lt;sides&gt;3.0&lt;/sides&gt;
 |        &lt;/row&gt;
 |      &lt;/data&gt;
 |      
 |      &gt;&gt;&gt; df.to_xml(attr_cols=[
 |      ...           &#39;index&#39;, &#39;shape&#39;, &#39;degrees&#39;, &#39;sides&#39;
 |      ...           ])  # doctest: +SKIP
 |      &lt;?xml version=&#39;1.0&#39; encoding=&#39;utf-8&#39;?&gt;
 |      &lt;data&gt;
 |        &lt;row index=&quot;0&quot; shape=&quot;square&quot; degrees=&quot;360&quot; sides=&quot;4.0&quot;/&gt;
 |        &lt;row index=&quot;1&quot; shape=&quot;circle&quot; degrees=&quot;360&quot;/&gt;
 |        &lt;row index=&quot;2&quot; shape=&quot;triangle&quot; degrees=&quot;180&quot; sides=&quot;3.0&quot;/&gt;
 |      &lt;/data&gt;
 |      
 |      &gt;&gt;&gt; df.to_xml(namespaces={&quot;doc&quot;: &quot;https://example.com&quot;},
 |      ...           prefix=&quot;doc&quot;)  # doctest: +SKIP
 |      &lt;?xml version=&#39;1.0&#39; encoding=&#39;utf-8&#39;?&gt;
 |      &lt;doc:data xmlns:doc=&quot;https://example.com&quot;&gt;
 |        &lt;doc:row&gt;
 |          &lt;doc:index&gt;0&lt;/doc:index&gt;
 |          &lt;doc:shape&gt;square&lt;/doc:shape&gt;
 |          &lt;doc:degrees&gt;360&lt;/doc:degrees&gt;
 |          &lt;doc:sides&gt;4.0&lt;/doc:sides&gt;
 |        &lt;/doc:row&gt;
 |        &lt;doc:row&gt;
 |          &lt;doc:index&gt;1&lt;/doc:index&gt;
 |          &lt;doc:shape&gt;circle&lt;/doc:shape&gt;
 |          &lt;doc:degrees&gt;360&lt;/doc:degrees&gt;
 |          &lt;doc:sides/&gt;
 |        &lt;/doc:row&gt;
 |        &lt;doc:row&gt;
 |          &lt;doc:index&gt;2&lt;/doc:index&gt;
 |          &lt;doc:shape&gt;triangle&lt;/doc:shape&gt;
 |          &lt;doc:degrees&gt;180&lt;/doc:degrees&gt;
 |          &lt;doc:sides&gt;3.0&lt;/doc:sides&gt;
 |        &lt;/doc:row&gt;
 |      &lt;/doc:data&gt;
 |  
 |  transform(self, func: &#39;AggFuncType&#39;, axis: &#39;Axis&#39; = 0, *args, **kwargs) -&gt; &#39;DataFrame&#39;
 |      Call ``func`` on self producing a DataFrame with transformed values.
 |      
 |      Produced DataFrame will have same axis length as self.
 |      
 |      Parameters
 |      ----------
 |      func : function, str, list-like or dict-like
 |          Function to use for transforming the data. If a function, must either
 |          work when passed a DataFrame or when passed to DataFrame.apply. If func
 |          is both list-like and dict-like, dict-like behavior takes precedence.
 |      
 |          Accepted combinations are:
 |      
 |          - function
 |          - string function name
 |          - list-like of functions and/or function names, e.g. ``[np.exp, &#39;sqrt&#39;]``
 |          - dict-like of axis labels -&gt; functions, function names or list-like of such.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |              If 0 or &#39;index&#39;: apply function to each column.
 |              If 1 or &#39;columns&#39;: apply function to each row.
 |      *args
 |          Positional arguments to pass to `func`.
 |      **kwargs
 |          Keyword arguments to pass to `func`.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          A DataFrame that must have the same length as self.
 |      
 |      Raises
 |      ------
 |      ValueError : If the returned DataFrame has a different length than self.
 |      
 |      See Also
 |      --------
 |      DataFrame.agg : Only perform aggregating type operations.
 |      DataFrame.apply : Invoke function on a DataFrame.
 |      
 |      Notes
 |      -----
 |      Functions that mutate the passed object can produce unexpected
 |      behavior or errors and are not supported. See :ref:`gotchas.udf-mutation`
 |      for more details.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: range(3), &#39;B&#39;: range(1, 4)})
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  0  1
 |      1  1  2
 |      2  2  3
 |      &gt;&gt;&gt; df.transform(lambda x: x + 1)
 |         A  B
 |      0  1  2
 |      1  2  3
 |      2  3  4
 |      
 |      Even though the resulting DataFrame must have the same length as the
 |      input DataFrame, it is possible to provide several input functions:
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(3))
 |      &gt;&gt;&gt; s
 |      0    0
 |      1    1
 |      2    2
 |      dtype: int64
 |      &gt;&gt;&gt; s.transform([np.sqrt, np.exp])
 |             sqrt        exp
 |      0  0.000000   1.000000
 |      1  1.000000   2.718282
 |      2  1.414214   7.389056
 |      
 |      You can call transform on a GroupBy object:
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &quot;Date&quot;: [
 |      ...         &quot;2015-05-08&quot;, &quot;2015-05-07&quot;, &quot;2015-05-06&quot;, &quot;2015-05-05&quot;,
 |      ...         &quot;2015-05-08&quot;, &quot;2015-05-07&quot;, &quot;2015-05-06&quot;, &quot;2015-05-05&quot;],
 |      ...     &quot;Data&quot;: [5, 8, 6, 1, 50, 100, 60, 120],
 |      ... })
 |      &gt;&gt;&gt; df
 |               Date  Data
 |      0  2015-05-08     5
 |      1  2015-05-07     8
 |      2  2015-05-06     6
 |      3  2015-05-05     1
 |      4  2015-05-08    50
 |      5  2015-05-07   100
 |      6  2015-05-06    60
 |      7  2015-05-05   120
 |      &gt;&gt;&gt; df.groupby(&#39;Date&#39;)[&#39;Data&#39;].transform(&#39;sum&#39;)
 |      0     55
 |      1    108
 |      2     66
 |      3    121
 |      4     55
 |      5    108
 |      6     66
 |      7    121
 |      Name: Data, dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &quot;c&quot;: [1, 1, 1, 2, 2, 2, 2],
 |      ...     &quot;type&quot;: [&quot;m&quot;, &quot;n&quot;, &quot;o&quot;, &quot;m&quot;, &quot;m&quot;, &quot;n&quot;, &quot;n&quot;]
 |      ... })
 |      &gt;&gt;&gt; df
 |         c type
 |      0  1    m
 |      1  1    n
 |      2  1    o
 |      3  2    m
 |      4  2    m
 |      5  2    n
 |      6  2    n
 |      &gt;&gt;&gt; df[&#39;size&#39;] = df.groupby(&#39;c&#39;)[&#39;type&#39;].transform(len)
 |      &gt;&gt;&gt; df
 |         c type size
 |      0  1    m    3
 |      1  1    n    3
 |      2  1    o    3
 |      3  2    m    4
 |      4  2    m    4
 |      5  2    n    4
 |      6  2    n    4
 |  
 |  transpose(self, *args, copy: &#39;bool&#39; = False) -&gt; &#39;DataFrame&#39;
 |      Transpose index and columns.
 |      
 |      Reflect the DataFrame over its main diagonal by writing rows as columns
 |      and vice-versa. The property :attr:`.T` is an accessor to the method
 |      :meth:`transpose`.
 |      
 |      Parameters
 |      ----------
 |      *args : tuple, optional
 |          Accepted for compatibility with NumPy.
 |      copy : bool, default False
 |          Whether to copy the data after transposing, even for DataFrames
 |          with a single dtype.
 |      
 |          Note that a copy is always required for mixed dtype DataFrames,
 |          or for DataFrames with any extension types.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          The transposed DataFrame.
 |      
 |      See Also
 |      --------
 |      numpy.transpose : Permute the dimensions of a given array.
 |      
 |      Notes
 |      -----
 |      Transposing a DataFrame with mixed dtypes will result in a homogeneous
 |      DataFrame with the `object` dtype. In such a case, a copy of the data
 |      is always made.
 |      
 |      Examples
 |      --------
 |      **Square DataFrame with homogeneous dtype**
 |      
 |      &gt;&gt;&gt; d1 = {&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]}
 |      &gt;&gt;&gt; df1 = pd.DataFrame(data=d1)
 |      &gt;&gt;&gt; df1
 |         col1  col2
 |      0     1     3
 |      1     2     4
 |      
 |      &gt;&gt;&gt; df1_transposed = df1.T # or df1.transpose()
 |      &gt;&gt;&gt; df1_transposed
 |            0  1
 |      col1  1  2
 |      col2  3  4
 |      
 |      When the dtype is homogeneous in the original DataFrame, we get a
 |      transposed DataFrame with the same dtype:
 |      
 |      &gt;&gt;&gt; df1.dtypes
 |      col1    int64
 |      col2    int64
 |      dtype: object
 |      &gt;&gt;&gt; df1_transposed.dtypes
 |      0    int64
 |      1    int64
 |      dtype: object
 |      
 |      **Non-square DataFrame with mixed dtypes**
 |      
 |      &gt;&gt;&gt; d2 = {&#39;name&#39;: [&#39;Alice&#39;, &#39;Bob&#39;],
 |      ...       &#39;score&#39;: [9.5, 8],
 |      ...       &#39;employed&#39;: [False, True],
 |      ...       &#39;kids&#39;: [0, 0]}
 |      &gt;&gt;&gt; df2 = pd.DataFrame(data=d2)
 |      &gt;&gt;&gt; df2
 |          name  score  employed  kids
 |      0  Alice    9.5     False     0
 |      1    Bob    8.0      True     0
 |      
 |      &gt;&gt;&gt; df2_transposed = df2.T # or df2.transpose()
 |      &gt;&gt;&gt; df2_transposed
 |                    0     1
 |      name      Alice   Bob
 |      score       9.5   8.0
 |      employed  False  True
 |      kids          0     0
 |      
 |      When the DataFrame has mixed dtypes, we get a transposed DataFrame with
 |      the `object` dtype:
 |      
 |      &gt;&gt;&gt; df2.dtypes
 |      name         object
 |      score       float64
 |      employed       bool
 |      kids          int64
 |      dtype: object
 |      &gt;&gt;&gt; df2_transposed.dtypes
 |      0    object
 |      1    object
 |      dtype: object
 |  
 |  truediv(self, other, axis=&#39;columns&#39;, level=None, fill_value=None)
 |      Get Floating division of dataframe and other, element-wise (binary operator `truediv`).
 |      
 |      Equivalent to ``dataframe / other``, but with support to substitute a fill_value
 |      for missing data in one of the inputs. With reverse version, `rtruediv`.
 |      
 |      Among flexible wrappers (`add`, `sub`, `mul`, `div`, `mod`, `pow`) to
 |      arithmetic operators: `+`, `-`, `*`, `/`, `//`, `%`, `**`.
 |      
 |      Parameters
 |      ----------
 |      other : scalar, sequence, Series, or DataFrame
 |          Any single or multiple element data structure, or list-like object.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}
 |          Whether to compare by the index (0 or &#39;index&#39;) or columns
 |          (1 or &#39;columns&#39;). For Series input, axis to match Series index on.
 |      level : int or label
 |          Broadcast across a level, matching Index values on the
 |          passed MultiIndex level.
 |      fill_value : float or None, default None
 |          Fill existing missing (NaN) values, and any new element needed for
 |          successful DataFrame alignment, with this value before computation.
 |          If data in both corresponding DataFrame locations is missing
 |          the result will be missing.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          Result of the arithmetic operation.
 |      
 |      See Also
 |      --------
 |      DataFrame.add : Add DataFrames.
 |      DataFrame.sub : Subtract DataFrames.
 |      DataFrame.mul : Multiply DataFrames.
 |      DataFrame.div : Divide DataFrames (float division).
 |      DataFrame.truediv : Divide DataFrames (float division).
 |      DataFrame.floordiv : Divide DataFrames (integer division).
 |      DataFrame.mod : Calculate modulo (remainder after division).
 |      DataFrame.pow : Calculate exponential power.
 |      
 |      Notes
 |      -----
 |      Mismatched indices will be unioned together.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;angles&#39;: [0, 3, 4],
 |      ...                    &#39;degrees&#39;: [360, 180, 360]},
 |      ...                   index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; df
 |                 angles  degrees
 |      circle          0      360
 |      triangle        3      180
 |      rectangle       4      360
 |      
 |      Add a scalar with operator version which return the same
 |      results.
 |      
 |      &gt;&gt;&gt; df + 1
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      &gt;&gt;&gt; df.add(1)
 |                 angles  degrees
 |      circle          1      361
 |      triangle        4      181
 |      rectangle       5      361
 |      
 |      Divide by constant with reverse version.
 |      
 |      &gt;&gt;&gt; df.div(10)
 |                 angles  degrees
 |      circle        0.0     36.0
 |      triangle      0.3     18.0
 |      rectangle     0.4     36.0
 |      
 |      &gt;&gt;&gt; df.rdiv(10)
 |                   angles   degrees
 |      circle          inf  0.027778
 |      triangle   3.333333  0.055556
 |      rectangle  2.500000  0.027778
 |      
 |      Subtract a list and Series by axis with operator version.
 |      
 |      &gt;&gt;&gt; df - [1, 2]
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub([1, 2], axis=&#39;columns&#39;)
 |                 angles  degrees
 |      circle         -1      358
 |      triangle        2      178
 |      rectangle       3      358
 |      
 |      &gt;&gt;&gt; df.sub(pd.Series([1, 1, 1], index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;]),
 |      ...        axis=&#39;index&#39;)
 |                 angles  degrees
 |      circle         -1      359
 |      triangle        2      179
 |      rectangle       3      359
 |      
 |      Multiply a DataFrame of different shape with operator version.
 |      
 |      &gt;&gt;&gt; other = pd.DataFrame({&#39;angles&#39;: [0, 3, 4]},
 |      ...                      index=[&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;])
 |      &gt;&gt;&gt; other
 |                 angles
 |      circle          0
 |      triangle        3
 |      rectangle       4
 |      
 |      &gt;&gt;&gt; df * other
 |                 angles  degrees
 |      circle          0      NaN
 |      triangle        9      NaN
 |      rectangle      16      NaN
 |      
 |      &gt;&gt;&gt; df.mul(other, fill_value=0)
 |                 angles  degrees
 |      circle          0      0.0
 |      triangle        9      0.0
 |      rectangle      16      0.0
 |      
 |      Divide by a MultiIndex by level.
 |      
 |      &gt;&gt;&gt; df_multindex = pd.DataFrame({&#39;angles&#39;: [0, 3, 4, 4, 5, 6],
 |      ...                              &#39;degrees&#39;: [360, 180, 360, 360, 540, 720]},
 |      ...                             index=[[&#39;A&#39;, &#39;A&#39;, &#39;A&#39;, &#39;B&#39;, &#39;B&#39;, &#39;B&#39;],
 |      ...                                    [&#39;circle&#39;, &#39;triangle&#39;, &#39;rectangle&#39;,
 |      ...                                     &#39;square&#39;, &#39;pentagon&#39;, &#39;hexagon&#39;]])
 |      &gt;&gt;&gt; df_multindex
 |                   angles  degrees
 |      A circle          0      360
 |        triangle        3      180
 |        rectangle       4      360
 |      B square          4      360
 |        pentagon        5      540
 |        hexagon         6      720
 |      
 |      &gt;&gt;&gt; df.div(df_multindex, level=1, fill_value=0)
 |                   angles  degrees
 |      A circle        NaN      1.0
 |        triangle      1.0      1.0
 |        rectangle     1.0      1.0
 |      B square        0.0      0.0
 |        pentagon      0.0      0.0
 |        hexagon       0.0      0.0
 |  
 |  unstack(self, level: &#39;Level&#39; = -1, fill_value=None)
 |      Pivot a level of the (necessarily hierarchical) index labels.
 |      
 |      Returns a DataFrame having a new level of column labels whose inner-most level
 |      consists of the pivoted index labels.
 |      
 |      If the index is not a MultiIndex, the output will be a Series
 |      (the analogue of stack when the columns are not a MultiIndex).
 |      
 |      Parameters
 |      ----------
 |      level : int, str, or list of these, default -1 (last level)
 |          Level(s) of index to unstack, can pass level name.
 |      fill_value : int, str or dict
 |          Replace NaN with this value if the unstack produces missing values.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |      
 |      See Also
 |      --------
 |      DataFrame.pivot : Pivot a table based on column values.
 |      DataFrame.stack : Pivot a level of the column labels (inverse operation
 |          from `unstack`).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; index = pd.MultiIndex.from_tuples([(&#39;one&#39;, &#39;a&#39;), (&#39;one&#39;, &#39;b&#39;),
 |      ...                                    (&#39;two&#39;, &#39;a&#39;), (&#39;two&#39;, &#39;b&#39;)])
 |      &gt;&gt;&gt; s = pd.Series(np.arange(1.0, 5.0), index=index)
 |      &gt;&gt;&gt; s
 |      one  a   1.0
 |           b   2.0
 |      two  a   3.0
 |           b   4.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.unstack(level=-1)
 |           a   b
 |      one  1.0  2.0
 |      two  3.0  4.0
 |      
 |      &gt;&gt;&gt; s.unstack(level=0)
 |         one  two
 |      a  1.0   3.0
 |      b  2.0   4.0
 |      
 |      &gt;&gt;&gt; df = s.unstack(level=0)
 |      &gt;&gt;&gt; df.unstack()
 |      one  a  1.0
 |           b  2.0
 |      two  a  3.0
 |           b  4.0
 |      dtype: float64
 |  
 |  update(self, other, join: &#39;str&#39; = &#39;left&#39;, overwrite: &#39;bool&#39; = True, filter_func=None, errors: &#39;str&#39; = &#39;ignore&#39;) -&gt; &#39;None&#39;
 |      Modify in place using non-NA values from another DataFrame.
 |      
 |      Aligns on indices. There is no return value.
 |      
 |      Parameters
 |      ----------
 |      other : DataFrame, or object coercible into a DataFrame
 |          Should have at least one matching index/column label
 |          with the original DataFrame. If a Series is passed,
 |          its name attribute must be set, and that will be
 |          used as the column name to align with the original DataFrame.
 |      join : {&#39;left&#39;}, default &#39;left&#39;
 |          Only left join is implemented, keeping the index and columns of the
 |          original object.
 |      overwrite : bool, default True
 |          How to handle non-NA values for overlapping keys:
 |      
 |          * True: overwrite original DataFrame&#39;s values
 |            with values from `other`.
 |          * False: only update values that are NA in
 |            the original DataFrame.
 |      
 |      filter_func : callable(1d-array) -&gt; bool 1d-array, optional
 |          Can choose to replace values other than NA. Return True for values
 |          that should be updated.
 |      errors : {&#39;raise&#39;, &#39;ignore&#39;}, default &#39;ignore&#39;
 |          If &#39;raise&#39;, will raise a ValueError if the DataFrame and `other`
 |          both contain non-NA data in the same place.
 |      
 |      Returns
 |      -------
 |      None : method directly changes calling object
 |      
 |      Raises
 |      ------
 |      ValueError
 |          * When `errors=&#39;raise&#39;` and there&#39;s overlapping non-NA data.
 |          * When `errors` is not either `&#39;ignore&#39;` or `&#39;raise&#39;`
 |      NotImplementedError
 |          * If `join != &#39;left&#39;`
 |      
 |      See Also
 |      --------
 |      dict.update : Similar method for dictionaries.
 |      DataFrame.merge : For column(s)-on-column(s) operations.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [1, 2, 3],
 |      ...                    &#39;B&#39;: [400, 500, 600]})
 |      &gt;&gt;&gt; new_df = pd.DataFrame({&#39;B&#39;: [4, 5, 6],
 |      ...                        &#39;C&#39;: [7, 8, 9]})
 |      &gt;&gt;&gt; df.update(new_df)
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  1  4
 |      1  2  5
 |      2  3  6
 |      
 |      The DataFrame&#39;s length does not increase as a result of the update,
 |      only values at matching index/column labels are updated.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;],
 |      ...                    &#39;B&#39;: [&#39;x&#39;, &#39;y&#39;, &#39;z&#39;]})
 |      &gt;&gt;&gt; new_df = pd.DataFrame({&#39;B&#39;: [&#39;d&#39;, &#39;e&#39;, &#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;]})
 |      &gt;&gt;&gt; df.update(new_df)
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  a  d
 |      1  b  e
 |      2  c  f
 |      
 |      For Series, its name attribute must be set.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;],
 |      ...                    &#39;B&#39;: [&#39;x&#39;, &#39;y&#39;, &#39;z&#39;]})
 |      &gt;&gt;&gt; new_column = pd.Series([&#39;d&#39;, &#39;e&#39;], name=&#39;B&#39;, index=[0, 2])
 |      &gt;&gt;&gt; df.update(new_column)
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  a  d
 |      1  b  y
 |      2  c  e
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;],
 |      ...                    &#39;B&#39;: [&#39;x&#39;, &#39;y&#39;, &#39;z&#39;]})
 |      &gt;&gt;&gt; new_df = pd.DataFrame({&#39;B&#39;: [&#39;d&#39;, &#39;e&#39;]}, index=[1, 2])
 |      &gt;&gt;&gt; df.update(new_df)
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  a  x
 |      1  b  d
 |      2  c  e
 |      
 |      If `other` contains NaNs the corresponding values are not updated
 |      in the original dataframe.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [1, 2, 3],
 |      ...                    &#39;B&#39;: [400, 500, 600]})
 |      &gt;&gt;&gt; new_df = pd.DataFrame({&#39;B&#39;: [4, np.nan, 6]})
 |      &gt;&gt;&gt; df.update(new_df)
 |      &gt;&gt;&gt; df
 |         A      B
 |      0  1    4.0
 |      1  2  500.0
 |      2  3    6.0
 |  
 |  value_counts(self, subset: &#39;Sequence[Hashable] | None&#39; = None, normalize: &#39;bool&#39; = False, sort: &#39;bool&#39; = True, ascending: &#39;bool&#39; = False, dropna: &#39;bool&#39; = True)
 |      Return a Series containing counts of unique rows in the DataFrame.
 |      
 |      .. versionadded:: 1.1.0
 |      
 |      Parameters
 |      ----------
 |      subset : list-like, optional
 |          Columns to use when counting unique combinations.
 |      normalize : bool, default False
 |          Return proportions rather than frequencies.
 |      sort : bool, default True
 |          Sort by frequencies.
 |      ascending : bool, default False
 |          Sort in ascending order.
 |      dropna : bool, default True
 |          Don’t include counts of rows that contain NA values.
 |      
 |          .. versionadded:: 1.3.0
 |      
 |      Returns
 |      -------
 |      Series
 |      
 |      See Also
 |      --------
 |      Series.value_counts: Equivalent method on Series.
 |      
 |      Notes
 |      -----
 |      The returned Series will have a MultiIndex with one level per input
 |      column. By default, rows that contain any NA values are omitted from
 |      the result. By default, the resulting Series will be in descending
 |      order so that the first element is the most frequently-occurring row.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;num_legs&#39;: [2, 4, 4, 6],
 |      ...                    &#39;num_wings&#39;: [2, 0, 0, 0]},
 |      ...                   index=[&#39;falcon&#39;, &#39;dog&#39;, &#39;cat&#39;, &#39;ant&#39;])
 |      &gt;&gt;&gt; df
 |              num_legs  num_wings
 |      falcon         2          2
 |      dog            4          0
 |      cat            4          0
 |      ant            6          0
 |      
 |      &gt;&gt;&gt; df.value_counts()
 |      num_legs  num_wings
 |      4         0            2
 |      2         2            1
 |      6         0            1
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df.value_counts(sort=False)
 |      num_legs  num_wings
 |      2         2            1
 |      4         0            2
 |      6         0            1
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df.value_counts(ascending=True)
 |      num_legs  num_wings
 |      2         2            1
 |      6         0            1
 |      4         0            2
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df.value_counts(normalize=True)
 |      num_legs  num_wings
 |      4         0            0.50
 |      2         2            0.25
 |      6         0            0.25
 |      dtype: float64
 |      
 |      With `dropna` set to `False` we can also count rows with NA values.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;first_name&#39;: [&#39;John&#39;, &#39;Anne&#39;, &#39;John&#39;, &#39;Beth&#39;],
 |      ...                    &#39;middle_name&#39;: [&#39;Smith&#39;, pd.NA, pd.NA, &#39;Louise&#39;]})
 |      &gt;&gt;&gt; df
 |        first_name middle_name
 |      0       John       Smith
 |      1       Anne        &lt;NA&gt;
 |      2       John        &lt;NA&gt;
 |      3       Beth      Louise
 |      
 |      &gt;&gt;&gt; df.value_counts()
 |      first_name  middle_name
 |      Beth        Louise         1
 |      John        Smith          1
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df.value_counts(dropna=False)
 |      first_name  middle_name
 |      Anne        NaN            1
 |      Beth        Louise         1
 |      John        Smith          1
 |                  NaN            1
 |      dtype: int64
 |  
 |  var(self, axis=None, skipna=None, level=None, ddof=1, numeric_only=None, **kwargs)
 |      Return unbiased variance over requested axis.
 |      
 |      Normalized by N-1 by default. This can be changed using the ddof argument
 |      
 |      Parameters
 |      ----------
 |      axis : {index (0), columns (1)}
 |      skipna : bool, default True
 |          Exclude NA/null values. If an entire row/column is NA, the result
 |          will be NA.
 |      level : int or level name, default None
 |          If the axis is a MultiIndex (hierarchical), count along a
 |          particular level, collapsing into a Series.
 |      ddof : int, default 1
 |          Delta Degrees of Freedom. The divisor used in calculations is N - ddof,
 |          where N represents the number of elements.
 |      numeric_only : bool, default None
 |          Include only float, int, boolean columns. If None, will attempt to use
 |          everything, then use only numeric data. Not implemented for Series.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame (if level specified)
 |      
 |      Notes
 |      -----
 |      To have the same behaviour as `numpy.std`, use `ddof=0` (instead of the
 |      default `ddof=1`)
 |  
 |  where(self, cond, other=nan, inplace=False, axis=None, level=None, errors=&#39;raise&#39;, try_cast=&lt;no_default&gt;)
 |      Replace values where the condition is False.
 |      
 |      Parameters
 |      ----------
 |      cond : bool Series/DataFrame, array-like, or callable
 |          Where `cond` is True, keep the original value. Where
 |          False, replace with corresponding value from `other`.
 |          If `cond` is callable, it is computed on the Series/DataFrame and
 |          should return boolean Series/DataFrame or array. The callable must
 |          not change input Series/DataFrame (though pandas doesn&#39;t check it).
 |      other : scalar, Series/DataFrame, or callable
 |          Entries where `cond` is False are replaced with
 |          corresponding value from `other`.
 |          If other is callable, it is computed on the Series/DataFrame and
 |          should return scalar or Series/DataFrame. The callable must not
 |          change input Series/DataFrame (though pandas doesn&#39;t check it).
 |      inplace : bool, default False
 |          Whether to perform the operation in place on the data.
 |      axis : int, default None
 |          Alignment axis if needed.
 |      level : int, default None
 |          Alignment level if needed.
 |      errors : str, {&#39;raise&#39;, &#39;ignore&#39;}, default &#39;raise&#39;
 |          Note that currently this parameter won&#39;t affect
 |          the results and will always coerce to a suitable dtype.
 |      
 |          - &#39;raise&#39; : allow exceptions to be raised.
 |          - &#39;ignore&#39; : suppress exceptions. On error return original object.
 |      
 |      try_cast : bool, default None
 |          Try to cast the result back to the input type (if possible).
 |      
 |          .. deprecated:: 1.3.0
 |              Manually cast back if necessary.
 |      
 |      Returns
 |      -------
 |      Same type as caller or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      :func:`DataFrame.mask` : Return an object of same shape as
 |          self.
 |      
 |      Notes
 |      -----
 |      The where method is an application of the if-then idiom. For each
 |      element in the calling DataFrame, if ``cond`` is ``True`` the
 |      element is used; otherwise the corresponding element from the DataFrame
 |      ``other`` is used.
 |      
 |      The signature for :func:`DataFrame.where` differs from
 |      :func:`numpy.where`. Roughly ``df1.where(m, df2)`` is equivalent to
 |      ``np.where(m, df1, df2)``.
 |      
 |      For further details and examples see the ``where`` documentation in
 |      :ref:`indexing &lt;indexing.where_mask&gt;`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series(range(5))
 |      &gt;&gt;&gt; s.where(s &gt; 0)
 |      0    NaN
 |      1    1.0
 |      2    2.0
 |      3    3.0
 |      4    4.0
 |      dtype: float64
 |      &gt;&gt;&gt; s.mask(s &gt; 0)
 |      0    0.0
 |      1    NaN
 |      2    NaN
 |      3    NaN
 |      4    NaN
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.where(s &gt; 1, 10)
 |      0    10
 |      1    10
 |      2    2
 |      3    3
 |      4    4
 |      dtype: int64
 |      &gt;&gt;&gt; s.mask(s &gt; 1, 10)
 |      0     0
 |      1     1
 |      2    10
 |      3    10
 |      4    10
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame(np.arange(10).reshape(-1, 2), columns=[&#39;A&#39;, &#39;B&#39;])
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  0  1
 |      1  2  3
 |      2  4  5
 |      3  6  7
 |      4  8  9
 |      &gt;&gt;&gt; m = df % 3 == 0
 |      &gt;&gt;&gt; df.where(m, -df)
 |         A  B
 |      0  0 -1
 |      1 -2  3
 |      2 -4 -5
 |      3  6 -7
 |      4 -8  9
 |      &gt;&gt;&gt; df.where(m, -df) == np.where(m, df, -df)
 |            A     B
 |      0  True  True
 |      1  True  True
 |      2  True  True
 |      3  True  True
 |      4  True  True
 |      &gt;&gt;&gt; df.where(m, -df) == df.mask(~m, -df)
 |            A     B
 |      0  True  True
 |      1  True  True
 |      2  True  True
 |      3  True  True
 |      4  True  True
 |  
 |  ----------------------------------------------------------------------
 |  Class methods defined here:
 |  
 |  from_dict(data, orient: &#39;str&#39; = &#39;columns&#39;, dtype: &#39;Dtype | None&#39; = None, columns=None) -&gt; &#39;DataFrame&#39; from builtins.type
 |      Construct DataFrame from dict of array-like or dicts.
 |      
 |      Creates DataFrame object from dictionary by columns or by index
 |      allowing dtype specification.
 |      
 |      Parameters
 |      ----------
 |      data : dict
 |          Of the form {field : array-like} or {field : dict}.
 |      orient : {&#39;columns&#39;, &#39;index&#39;}, default &#39;columns&#39;
 |          The &quot;orientation&quot; of the data. If the keys of the passed dict
 |          should be the columns of the resulting DataFrame, pass &#39;columns&#39;
 |          (default). Otherwise if the keys should be rows, pass &#39;index&#39;.
 |      dtype : dtype, default None
 |          Data type to force, otherwise infer.
 |      columns : list, default None
 |          Column labels to use when ``orient=&#39;index&#39;``. Raises a ValueError
 |          if used with ``orient=&#39;columns&#39;``.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |      
 |      See Also
 |      --------
 |      DataFrame.from_records : DataFrame from structured ndarray, sequence
 |          of tuples or dicts, or DataFrame.
 |      DataFrame : DataFrame object creation using constructor.
 |      
 |      Examples
 |      --------
 |      By default the keys of the dict become the DataFrame columns:
 |      
 |      &gt;&gt;&gt; data = {&#39;col_1&#39;: [3, 2, 1, 0], &#39;col_2&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]}
 |      &gt;&gt;&gt; pd.DataFrame.from_dict(data)
 |         col_1 col_2
 |      0      3     a
 |      1      2     b
 |      2      1     c
 |      3      0     d
 |      
 |      Specify ``orient=&#39;index&#39;`` to create the DataFrame using dictionary
 |      keys as rows:
 |      
 |      &gt;&gt;&gt; data = {&#39;row_1&#39;: [3, 2, 1, 0], &#39;row_2&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;]}
 |      &gt;&gt;&gt; pd.DataFrame.from_dict(data, orient=&#39;index&#39;)
 |             0  1  2  3
 |      row_1  3  2  1  0
 |      row_2  a  b  c  d
 |      
 |      When using the &#39;index&#39; orientation, the column names can be
 |      specified manually:
 |      
 |      &gt;&gt;&gt; pd.DataFrame.from_dict(data, orient=&#39;index&#39;,
 |      ...                        columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;])
 |             A  B  C  D
 |      row_1  3  2  1  0
 |      row_2  a  b  c  d
 |  
 |  from_records(data, index=None, exclude=None, columns=None, coerce_float: &#39;bool&#39; = False, nrows: &#39;int | None&#39; = None) -&gt; &#39;DataFrame&#39; from builtins.type
 |      Convert structured or record ndarray to DataFrame.
 |      
 |      Creates a DataFrame object from a structured ndarray, sequence of
 |      tuples or dicts, or DataFrame.
 |      
 |      Parameters
 |      ----------
 |      data : structured ndarray, sequence of tuples or dicts, or DataFrame
 |          Structured input data.
 |      index : str, list of fields, array-like
 |          Field of array to use as the index, alternately a specific set of
 |          input labels to use.
 |      exclude : sequence, default None
 |          Columns or fields to exclude.
 |      columns : sequence, default None
 |          Column names to use. If the passed data do not have names
 |          associated with them, this argument provides names for the
 |          columns. Otherwise this argument indicates the order of the columns
 |          in the result (any names not found in the data will become all-NA
 |          columns).
 |      coerce_float : bool, default False
 |          Attempt to convert values of non-string, non-numeric objects (like
 |          decimal.Decimal) to floating point, useful for SQL result sets.
 |      nrows : int, default None
 |          Number of rows to read if data is an iterator.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |      
 |      See Also
 |      --------
 |      DataFrame.from_dict : DataFrame from dict of array-like or dicts.
 |      DataFrame : DataFrame object creation using constructor.
 |      
 |      Examples
 |      --------
 |      Data can be provided as a structured ndarray:
 |      
 |      &gt;&gt;&gt; data = np.array([(3, &#39;a&#39;), (2, &#39;b&#39;), (1, &#39;c&#39;), (0, &#39;d&#39;)],
 |      ...                 dtype=[(&#39;col_1&#39;, &#39;i4&#39;), (&#39;col_2&#39;, &#39;U1&#39;)])
 |      &gt;&gt;&gt; pd.DataFrame.from_records(data)
 |         col_1 col_2
 |      0      3     a
 |      1      2     b
 |      2      1     c
 |      3      0     d
 |      
 |      Data can be provided as a list of dicts:
 |      
 |      &gt;&gt;&gt; data = [{&#39;col_1&#39;: 3, &#39;col_2&#39;: &#39;a&#39;},
 |      ...         {&#39;col_1&#39;: 2, &#39;col_2&#39;: &#39;b&#39;},
 |      ...         {&#39;col_1&#39;: 1, &#39;col_2&#39;: &#39;c&#39;},
 |      ...         {&#39;col_1&#39;: 0, &#39;col_2&#39;: &#39;d&#39;}]
 |      &gt;&gt;&gt; pd.DataFrame.from_records(data)
 |         col_1 col_2
 |      0      3     a
 |      1      2     b
 |      2      1     c
 |      3      0     d
 |      
 |      Data can be provided as a list of tuples with corresponding columns:
 |      
 |      &gt;&gt;&gt; data = [(3, &#39;a&#39;), (2, &#39;b&#39;), (1, &#39;c&#39;), (0, &#39;d&#39;)]
 |      &gt;&gt;&gt; pd.DataFrame.from_records(data, columns=[&#39;col_1&#39;, &#39;col_2&#39;])
 |         col_1 col_2
 |      0      3     a
 |      1      2     b
 |      2      1     c
 |      3      0     d
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors defined here:
 |  
 |  T
 |  
 |  axes
 |      Return a list representing the axes of the DataFrame.
 |      
 |      It has the row axis labels and column axis labels as the only members.
 |      They are returned in that order.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]})
 |      &gt;&gt;&gt; df.axes
 |      [RangeIndex(start=0, stop=2, step=1), Index([&#39;col1&#39;, &#39;col2&#39;],
 |      dtype=&#39;object&#39;)]
 |  
 |  columns
 |      The column labels of the DataFrame.
 |  
 |  index
 |      The index (row labels) of the DataFrame.
 |  
 |  shape
 |      Return a tuple representing the dimensionality of the DataFrame.
 |      
 |      See Also
 |      --------
 |      ndarray.shape : Tuple of array dimensions.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]})
 |      &gt;&gt;&gt; df.shape
 |      (2, 2)
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4],
 |      ...                    &#39;col3&#39;: [5, 6]})
 |      &gt;&gt;&gt; df.shape
 |      (2, 3)
 |  
 |  style
 |      Returns a Styler object.
 |      
 |      Contains methods for building a styled HTML representation of the DataFrame.
 |      
 |      See Also
 |      --------
 |      io.formats.style.Styler : Helps style a DataFrame or Series according to the
 |          data with HTML and CSS.
 |  
 |  values
 |      Return a Numpy representation of the DataFrame.
 |      
 |      .. warning::
 |      
 |         We recommend using :meth:`DataFrame.to_numpy` instead.
 |      
 |      Only the values in the DataFrame will be returned, the axes labels
 |      will be removed.
 |      
 |      Returns
 |      -------
 |      numpy.ndarray
 |          The values of the DataFrame.
 |      
 |      See Also
 |      --------
 |      DataFrame.to_numpy : Recommended alternative to this method.
 |      DataFrame.index : Retrieve the index labels.
 |      DataFrame.columns : Retrieving the column names.
 |      
 |      Notes
 |      -----
 |      The dtype will be a lower-common-denominator dtype (implicit
 |      upcasting); that is to say if the dtypes (even of numeric types)
 |      are mixed, the one that accommodates all will be chosen. Use this
 |      with care if you are not dealing with the blocks.
 |      
 |      e.g. If the dtypes are float16 and float32, dtype will be upcast to
 |      float32.  If dtypes are int32 and uint8, dtype will be upcast to
 |      int32. By :func:`numpy.find_common_type` convention, mixing int64
 |      and uint64 will result in a float64 dtype.
 |      
 |      Examples
 |      --------
 |      A DataFrame where all columns are the same type (e.g., int64) results
 |      in an array of the same type.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;age&#39;:    [ 3,  29],
 |      ...                    &#39;height&#39;: [94, 170],
 |      ...                    &#39;weight&#39;: [31, 115]})
 |      &gt;&gt;&gt; df
 |         age  height  weight
 |      0    3      94      31
 |      1   29     170     115
 |      &gt;&gt;&gt; df.dtypes
 |      age       int64
 |      height    int64
 |      weight    int64
 |      dtype: object
 |      &gt;&gt;&gt; df.values
 |      array([[  3,  94,  31],
 |             [ 29, 170, 115]])
 |      
 |      A DataFrame with mixed type columns(e.g., str/object, int64, float32)
 |      results in an ndarray of the broadest type that accommodates these
 |      mixed types (e.g., object).
 |      
 |      &gt;&gt;&gt; df2 = pd.DataFrame([(&#39;parrot&#39;,   24.0, &#39;second&#39;),
 |      ...                     (&#39;lion&#39;,     80.5, 1),
 |      ...                     (&#39;monkey&#39;, np.nan, None)],
 |      ...                   columns=(&#39;name&#39;, &#39;max_speed&#39;, &#39;rank&#39;))
 |      &gt;&gt;&gt; df2.dtypes
 |      name          object
 |      max_speed    float64
 |      rank          object
 |      dtype: object
 |      &gt;&gt;&gt; df2.values
 |      array([[&#39;parrot&#39;, 24.0, &#39;second&#39;],
 |             [&#39;lion&#39;, 80.5, 1],
 |             [&#39;monkey&#39;, nan, None]], dtype=object)
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes defined here:
 |  
 |  __annotations__ = {&#39;_AXIS_TO_AXIS_NUMBER&#39;: &#39;dict[Axis, int]&#39;, &#39;_access...
 |  
 |  plot = &lt;class &#39;pandas.plotting._core.PlotAccessor&#39;&gt;
 |      Make plots of Series or DataFrame.
 |      
 |      Uses the backend specified by the
 |      option ``plotting.backend``. By default, matplotlib is used.
 |      
 |      Parameters
 |      ----------
 |      data : Series or DataFrame
 |          The object for which the method is called.
 |      x : label or position, default None
 |          Only used if data is a DataFrame.
 |      y : label, position or list of label, positions, default None
 |          Allows plotting of one column versus another. Only used if data is a
 |          DataFrame.
 |      kind : str
 |          The kind of plot to produce:
 |      
 |          - &#39;line&#39; : line plot (default)
 |          - &#39;bar&#39; : vertical bar plot
 |          - &#39;barh&#39; : horizontal bar plot
 |          - &#39;hist&#39; : histogram
 |          - &#39;box&#39; : boxplot
 |          - &#39;kde&#39; : Kernel Density Estimation plot
 |          - &#39;density&#39; : same as &#39;kde&#39;
 |          - &#39;area&#39; : area plot
 |          - &#39;pie&#39; : pie plot
 |          - &#39;scatter&#39; : scatter plot (DataFrame only)
 |          - &#39;hexbin&#39; : hexbin plot (DataFrame only)
 |      ax : matplotlib axes object, default None
 |          An axes of the current figure.
 |      subplots : bool, default False
 |          Make separate subplots for each column.
 |      sharex : bool, default True if ax is None else False
 |          In case ``subplots=True``, share x axis and set some x axis labels
 |          to invisible; defaults to True if ax is None otherwise False if
 |          an ax is passed in; Be aware, that passing in both an ax and
 |          ``sharex=True`` will alter all x axis labels for all axis in a figure.
 |      sharey : bool, default False
 |          In case ``subplots=True``, share y axis and set some y axis labels to invisible.
 |      layout : tuple, optional
 |          (rows, columns) for the layout of subplots.
 |      figsize : a tuple (width, height) in inches
 |          Size of a figure object.
 |      use_index : bool, default True
 |          Use index as ticks for x axis.
 |      title : str or list
 |          Title to use for the plot. If a string is passed, print the string
 |          at the top of the figure. If a list is passed and `subplots` is
 |          True, print each item in the list above the corresponding subplot.
 |      grid : bool, default None (matlab style default)
 |          Axis grid lines.
 |      legend : bool or {&#39;reverse&#39;}
 |          Place legend on axis subplots.
 |      style : list or dict
 |          The matplotlib line style per column.
 |      logx : bool or &#39;sym&#39;, default False
 |          Use log scaling or symlog scaling on x axis.
 |          .. versionchanged:: 0.25.0
 |      
 |      logy : bool or &#39;sym&#39; default False
 |          Use log scaling or symlog scaling on y axis.
 |          .. versionchanged:: 0.25.0
 |      
 |      loglog : bool or &#39;sym&#39;, default False
 |          Use log scaling or symlog scaling on both x and y axes.
 |          .. versionchanged:: 0.25.0
 |      
 |      xticks : sequence
 |          Values to use for the xticks.
 |      yticks : sequence
 |          Values to use for the yticks.
 |      xlim : 2-tuple/list
 |          Set the x limits of the current axes.
 |      ylim : 2-tuple/list
 |          Set the y limits of the current axes.
 |      xlabel : label, optional
 |          Name to use for the xlabel on x-axis. Default uses index name as xlabel, or the
 |          x-column name for planar plots.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |             Now applicable to planar plots (`scatter`, `hexbin`).
 |      
 |      ylabel : label, optional
 |          Name to use for the ylabel on y-axis. Default will show no ylabel, or the
 |          y-column name for planar plots.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |             Now applicable to planar plots (`scatter`, `hexbin`).
 |      
 |      rot : int, default None
 |          Rotation for ticks (xticks for vertical, yticks for horizontal
 |          plots).
 |      fontsize : int, default None
 |          Font size for xticks and yticks.
 |      colormap : str or matplotlib colormap object, default None
 |          Colormap to select colors from. If string, load colormap with that
 |          name from matplotlib.
 |      colorbar : bool, optional
 |          If True, plot colorbar (only relevant for &#39;scatter&#39; and &#39;hexbin&#39;
 |          plots).
 |      position : float
 |          Specify relative alignments for bar plot layout.
 |          From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5
 |          (center).
 |      table : bool, Series or DataFrame, default False
 |          If True, draw a table using the data in the DataFrame and the data
 |          will be transposed to meet matplotlib&#39;s default layout.
 |          If a Series or DataFrame is passed, use passed data to draw a
 |          table.
 |      yerr : DataFrame, Series, array-like, dict and str
 |          See :ref:`Plotting with Error Bars &lt;visualization.errorbars&gt;` for
 |          detail.
 |      xerr : DataFrame, Series, array-like, dict and str
 |          Equivalent to yerr.
 |      stacked : bool, default False in line and bar plots, and True in area plot
 |          If True, create stacked plot.
 |      sort_columns : bool, default False
 |          Sort column names to determine plot ordering.
 |      secondary_y : bool or sequence, default False
 |          Whether to plot on the secondary y-axis if a list/tuple, which
 |          columns to plot on secondary y-axis.
 |      mark_right : bool, default True
 |          When using a secondary_y axis, automatically mark the column
 |          labels with &quot;(right)&quot; in the legend.
 |      include_bool : bool, default is False
 |          If True, boolean values can be plotted.
 |      backend : str, default None
 |          Backend to use instead of the backend specified in the option
 |          ``plotting.backend``. For instance, &#39;matplotlib&#39;. Alternatively, to
 |          specify the ``plotting.backend`` for the whole session, set
 |          ``pd.options.plotting.backend``.
 |      
 |          .. versionadded:: 1.0.0
 |      
 |      **kwargs
 |          Options to pass to matplotlib plotting method.
 |      
 |      Returns
 |      -------
 |      :class:`matplotlib.axes.Axes` or numpy.ndarray of them
 |          If the backend is not the default matplotlib one, the return value
 |          will be the object returned by the backend.
 |      
 |      Notes
 |      -----
 |      - See matplotlib documentation online for more on this subject
 |      - If `kind` = &#39;bar&#39; or &#39;barh&#39;, you can specify relative alignments
 |        for bar plot layout by `position` keyword.
 |        From 0 (left/bottom-end) to 1 (right/top-end). Default is 0.5
 |        (center)
 |  
 |  sparse = &lt;class &#39;pandas.core.arrays.sparse.accessor.SparseFrameAccesso...
 |      DataFrame accessor for sparse data.
 |      
 |      .. versionadded:: 0.25.0
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pandas.core.generic.NDFrame:
 |  
 |  __abs__(self: &#39;FrameOrSeries&#39;) -&gt; &#39;FrameOrSeries&#39;
 |  
 |  __array__(self, dtype: &#39;NpDtype | None&#39; = None) -&gt; &#39;np.ndarray&#39;
 |  
 |  __array_ufunc__(self, ufunc: &#39;np.ufunc&#39;, method: &#39;str&#39;, *inputs: &#39;Any&#39;, **kwargs: &#39;Any&#39;)
 |  
 |  __array_wrap__(self, result: &#39;np.ndarray&#39;, context: &#39;tuple[Callable, tuple[Any, ...], int] | None&#39; = None)
 |      Gets called after a ufunc and other functions.
 |      
 |      Parameters
 |      ----------
 |      result: np.ndarray
 |          The result of the ufunc or other function called on the NumPy array
 |          returned by __array__
 |      context: tuple of (func, tuple, int)
 |          This parameter is returned by ufuncs as a 3-element tuple: (name of the
 |          ufunc, arguments of the ufunc, domain of the ufunc), but is not set by
 |          other numpy functions.q
 |      
 |      Notes
 |      -----
 |      Series implements __array_ufunc_ so this not called for ufunc on Series.
 |  
 |  __bool__ = __nonzero__(self)
 |  
 |  __contains__(self, key) -&gt; &#39;bool_t&#39;
 |      True if the key is in the info axis
 |  
 |  __copy__(self: &#39;FrameOrSeries&#39;, deep: &#39;bool_t&#39; = True) -&gt; &#39;FrameOrSeries&#39;
 |  
 |  __deepcopy__(self: &#39;FrameOrSeries&#39;, memo=None) -&gt; &#39;FrameOrSeries&#39;
 |      Parameters
 |      ----------
 |      memo, default None
 |          Standard signature. Unused
 |  
 |  __delitem__(self, key) -&gt; &#39;None&#39;
 |      Delete item
 |  
 |  __finalize__(self: &#39;FrameOrSeries&#39;, other, method: &#39;str | None&#39; = None, **kwargs) -&gt; &#39;FrameOrSeries&#39;
 |      Propagate metadata from other to self.
 |      
 |      Parameters
 |      ----------
 |      other : the object from which to get the attributes that we are going
 |          to propagate
 |      method : str, optional
 |          A passed method name providing context on where ``__finalize__``
 |          was called.
 |      
 |          .. warning::
 |      
 |             The value passed as `method` are not currently considered
 |             stable across pandas releases.
 |  
 |  __getattr__(self, name: &#39;str&#39;)
 |      After regular attribute access, try looking up the name
 |      This allows simpler access to columns for interactive use.
 |  
 |  __getstate__(self) -&gt; &#39;dict[str, Any]&#39;
 |  
 |  __iadd__(self, other)
 |  
 |  __iand__(self, other)
 |  
 |  __ifloordiv__(self, other)
 |  
 |  __imod__(self, other)
 |  
 |  __imul__(self, other)
 |  
 |  __invert__(self)
 |  
 |  __ior__(self, other)
 |  
 |  __ipow__(self, other)
 |  
 |  __isub__(self, other)
 |  
 |  __iter__(self)
 |      Iterate over info axis.
 |      
 |      Returns
 |      -------
 |      iterator
 |          Info axis as iterator.
 |  
 |  __itruediv__(self, other)
 |  
 |  __ixor__(self, other)
 |  
 |  __neg__(self)
 |  
 |  __nonzero__(self)
 |  
 |  __pos__(self)
 |  
 |  __round__(self: &#39;FrameOrSeries&#39;, decimals: &#39;int&#39; = 0) -&gt; &#39;FrameOrSeries&#39;
 |  
 |  __setattr__(self, name: &#39;str&#39;, value) -&gt; &#39;None&#39;
 |      After regular attribute access, try setting the name
 |      This allows simpler access to columns for interactive use.
 |  
 |  __setstate__(self, state)
 |  
 |  abs(self: &#39;FrameOrSeries&#39;) -&gt; &#39;FrameOrSeries&#39;
 |      Return a Series/DataFrame with absolute numeric value of each element.
 |      
 |      This function only applies to elements that are all numeric.
 |      
 |      Returns
 |      -------
 |      abs
 |          Series/DataFrame containing the absolute value of each element.
 |      
 |      See Also
 |      --------
 |      numpy.absolute : Calculate the absolute value element-wise.
 |      
 |      Notes
 |      -----
 |      For ``complex`` inputs, ``1.2 + 1j``, the absolute value is
 |      :math:`\sqrt{ a^2 + b^2 }`.
 |      
 |      Examples
 |      --------
 |      Absolute numeric values in a Series.
 |      
 |      &gt;&gt;&gt; s = pd.Series([-1.10, 2, -3.33, 4])
 |      &gt;&gt;&gt; s.abs()
 |      0    1.10
 |      1    2.00
 |      2    3.33
 |      3    4.00
 |      dtype: float64
 |      
 |      Absolute numeric values in a Series with complex numbers.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1.2 + 1j])
 |      &gt;&gt;&gt; s.abs()
 |      0    1.56205
 |      dtype: float64
 |      
 |      Absolute numeric values in a Series with a Timedelta element.
 |      
 |      &gt;&gt;&gt; s = pd.Series([pd.Timedelta(&#39;1 days&#39;)])
 |      &gt;&gt;&gt; s.abs()
 |      0   1 days
 |      dtype: timedelta64[ns]
 |      
 |      Select rows with data closest to certain value using argsort (from
 |      `StackOverflow &lt;https://stackoverflow.com/a/17758115&gt;`__).
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;a&#39;: [4, 5, 6, 7],
 |      ...     &#39;b&#39;: [10, 20, 30, 40],
 |      ...     &#39;c&#39;: [100, 50, -30, -50]
 |      ... })
 |      &gt;&gt;&gt; df
 |           a    b    c
 |      0    4   10  100
 |      1    5   20   50
 |      2    6   30  -30
 |      3    7   40  -50
 |      &gt;&gt;&gt; df.loc[(df.c - 43).abs().argsort()]
 |           a    b    c
 |      1    5   20   50
 |      0    4   10  100
 |      2    6   30  -30
 |      3    7   40  -50
 |  
 |  add_prefix(self: &#39;FrameOrSeries&#39;, prefix: &#39;str&#39;) -&gt; &#39;FrameOrSeries&#39;
 |      Prefix labels with string `prefix`.
 |      
 |      For Series, the row labels are prefixed.
 |      For DataFrame, the column labels are prefixed.
 |      
 |      Parameters
 |      ----------
 |      prefix : str
 |          The string to add before each label.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          New Series or DataFrame with updated labels.
 |      
 |      See Also
 |      --------
 |      Series.add_suffix: Suffix row labels with string `suffix`.
 |      DataFrame.add_suffix: Suffix column labels with string `suffix`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
 |      &gt;&gt;&gt; s
 |      0    1
 |      1    2
 |      2    3
 |      3    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.add_prefix(&#39;item_&#39;)
 |      item_0    1
 |      item_1    2
 |      item_2    3
 |      item_3    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4], &#39;B&#39;: [3, 4, 5, 6]})
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  1  3
 |      1  2  4
 |      2  3  5
 |      3  4  6
 |      
 |      &gt;&gt;&gt; df.add_prefix(&#39;col_&#39;)
 |           col_A  col_B
 |      0       1       3
 |      1       2       4
 |      2       3       5
 |      3       4       6
 |  
 |  add_suffix(self: &#39;FrameOrSeries&#39;, suffix: &#39;str&#39;) -&gt; &#39;FrameOrSeries&#39;
 |      Suffix labels with string `suffix`.
 |      
 |      For Series, the row labels are suffixed.
 |      For DataFrame, the column labels are suffixed.
 |      
 |      Parameters
 |      ----------
 |      suffix : str
 |          The string to add after each label.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          New Series or DataFrame with updated labels.
 |      
 |      See Also
 |      --------
 |      Series.add_prefix: Prefix row labels with string `prefix`.
 |      DataFrame.add_prefix: Prefix column labels with string `prefix`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
 |      &gt;&gt;&gt; s
 |      0    1
 |      1    2
 |      2    3
 |      3    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.add_suffix(&#39;_item&#39;)
 |      0_item    1
 |      1_item    2
 |      2_item    3
 |      3_item    4
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4], &#39;B&#39;: [3, 4, 5, 6]})
 |      &gt;&gt;&gt; df
 |         A  B
 |      0  1  3
 |      1  2  4
 |      2  3  5
 |      3  4  6
 |      
 |      &gt;&gt;&gt; df.add_suffix(&#39;_col&#39;)
 |           A_col  B_col
 |      0       1       3
 |      1       2       4
 |      2       3       5
 |      3       4       6
 |  
 |  asof(self, where, subset=None)
 |      Return the last row(s) without any NaNs before `where`.
 |      
 |      The last row (for each element in `where`, if list) without any
 |      NaN is taken.
 |      In case of a :class:`~pandas.DataFrame`, the last row without NaN
 |      considering only the subset of columns (if not `None`)
 |      
 |      If there is no good value, NaN is returned for a Series or
 |      a Series of NaN values for a DataFrame
 |      
 |      Parameters
 |      ----------
 |      where : date or array-like of dates
 |          Date(s) before which the last row(s) are returned.
 |      subset : str or array-like of str, default `None`
 |          For DataFrame, if not `None`, only use these columns to
 |          check for NaNs.
 |      
 |      Returns
 |      -------
 |      scalar, Series, or DataFrame
 |      
 |          The return can be:
 |      
 |          * scalar : when `self` is a Series and `where` is a scalar
 |          * Series: when `self` is a Series and `where` is an array-like,
 |            or when `self` is a DataFrame and `where` is a scalar
 |          * DataFrame : when `self` is a DataFrame and `where` is an
 |            array-like
 |      
 |          Return scalar, Series, or DataFrame.
 |      
 |      See Also
 |      --------
 |      merge_asof : Perform an asof merge. Similar to left join.
 |      
 |      Notes
 |      -----
 |      Dates are assumed to be sorted. Raises if this is not the case.
 |      
 |      Examples
 |      --------
 |      A Series and a scalar `where`.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, np.nan, 4], index=[10, 20, 30, 40])
 |      &gt;&gt;&gt; s
 |      10    1.0
 |      20    2.0
 |      30    NaN
 |      40    4.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.asof(20)
 |      2.0
 |      
 |      For a sequence `where`, a Series is returned. The first value is
 |      NaN, because the first element of `where` is before the first
 |      index value.
 |      
 |      &gt;&gt;&gt; s.asof([5, 20])
 |      5     NaN
 |      20    2.0
 |      dtype: float64
 |      
 |      Missing values are not considered. The following is ``2.0``, not
 |      NaN, even though NaN is at the index location for ``30``.
 |      
 |      &gt;&gt;&gt; s.asof(30)
 |      2.0
 |      
 |      Take all columns into consideration
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;a&#39;: [10, 20, 30, 40, 50],
 |      ...                    &#39;b&#39;: [None, None, None, None, 500]},
 |      ...                   index=pd.DatetimeIndex([&#39;2018-02-27 09:01:00&#39;,
 |      ...                                           &#39;2018-02-27 09:02:00&#39;,
 |      ...                                           &#39;2018-02-27 09:03:00&#39;,
 |      ...                                           &#39;2018-02-27 09:04:00&#39;,
 |      ...                                           &#39;2018-02-27 09:05:00&#39;]))
 |      &gt;&gt;&gt; df.asof(pd.DatetimeIndex([&#39;2018-02-27 09:03:30&#39;,
 |      ...                           &#39;2018-02-27 09:04:30&#39;]))
 |                            a   b
 |      2018-02-27 09:03:30 NaN NaN
 |      2018-02-27 09:04:30 NaN NaN
 |      
 |      Take a single column into consideration
 |      
 |      &gt;&gt;&gt; df.asof(pd.DatetimeIndex([&#39;2018-02-27 09:03:30&#39;,
 |      ...                           &#39;2018-02-27 09:04:30&#39;]),
 |      ...         subset=[&#39;a&#39;])
 |                               a   b
 |      2018-02-27 09:03:30   30.0 NaN
 |      2018-02-27 09:04:30   40.0 NaN
 |  
 |  astype(self: &#39;FrameOrSeries&#39;, dtype, copy: &#39;bool_t&#39; = True, errors: &#39;str&#39; = &#39;raise&#39;) -&gt; &#39;FrameOrSeries&#39;
 |      Cast a pandas object to a specified dtype ``dtype``.
 |      
 |      Parameters
 |      ----------
 |      dtype : data type, or dict of column name -&gt; data type
 |          Use a numpy.dtype or Python type to cast entire pandas object to
 |          the same type. Alternatively, use {col: dtype, ...}, where col is a
 |          column label and dtype is a numpy.dtype or Python type to cast one
 |          or more of the DataFrame&#39;s columns to column-specific types.
 |      copy : bool, default True
 |          Return a copy when ``copy=True`` (be very careful setting
 |          ``copy=False`` as changes to values then may propagate to other
 |          pandas objects).
 |      errors : {&#39;raise&#39;, &#39;ignore&#39;}, default &#39;raise&#39;
 |          Control raising of exceptions on invalid data for provided dtype.
 |      
 |          - ``raise`` : allow exceptions to be raised
 |          - ``ignore`` : suppress exceptions. On error return original object.
 |      
 |      Returns
 |      -------
 |      casted : same type as caller
 |      
 |      See Also
 |      --------
 |      to_datetime : Convert argument to datetime.
 |      to_timedelta : Convert argument to timedelta.
 |      to_numeric : Convert argument to a numeric type.
 |      numpy.ndarray.astype : Cast a numpy array to a specified type.
 |      
 |      Notes
 |      -----
 |      .. deprecated:: 1.3.0
 |      
 |          Using ``astype`` to convert from timezone-naive dtype to
 |          timezone-aware dtype is deprecated and will raise in a
 |          future version.  Use :meth:`Series.dt.tz_localize` instead.
 |      
 |      Examples
 |      --------
 |      Create a DataFrame:
 |      
 |      &gt;&gt;&gt; d = {&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]}
 |      &gt;&gt;&gt; df = pd.DataFrame(data=d)
 |      &gt;&gt;&gt; df.dtypes
 |      col1    int64
 |      col2    int64
 |      dtype: object
 |      
 |      Cast all columns to int32:
 |      
 |      &gt;&gt;&gt; df.astype(&#39;int32&#39;).dtypes
 |      col1    int32
 |      col2    int32
 |      dtype: object
 |      
 |      Cast col1 to int32 using a dictionary:
 |      
 |      &gt;&gt;&gt; df.astype({&#39;col1&#39;: &#39;int32&#39;}).dtypes
 |      col1    int32
 |      col2    int64
 |      dtype: object
 |      
 |      Create a series:
 |      
 |      &gt;&gt;&gt; ser = pd.Series([1, 2], dtype=&#39;int32&#39;)
 |      &gt;&gt;&gt; ser
 |      0    1
 |      1    2
 |      dtype: int32
 |      &gt;&gt;&gt; ser.astype(&#39;int64&#39;)
 |      0    1
 |      1    2
 |      dtype: int64
 |      
 |      Convert to categorical type:
 |      
 |      &gt;&gt;&gt; ser.astype(&#39;category&#39;)
 |      0    1
 |      1    2
 |      dtype: category
 |      Categories (2, int64): [1, 2]
 |      
 |      Convert to ordered categorical type with custom ordering:
 |      
 |      &gt;&gt;&gt; from pandas.api.types import CategoricalDtype
 |      &gt;&gt;&gt; cat_dtype = CategoricalDtype(
 |      ...     categories=[2, 1], ordered=True)
 |      &gt;&gt;&gt; ser.astype(cat_dtype)
 |      0    1
 |      1    2
 |      dtype: category
 |      Categories (2, int64): [2 &lt; 1]
 |      
 |      Note that using ``copy=False`` and changing data on a new
 |      pandas object may propagate changes:
 |      
 |      &gt;&gt;&gt; s1 = pd.Series([1, 2])
 |      &gt;&gt;&gt; s2 = s1.astype(&#39;int64&#39;, copy=False)
 |      &gt;&gt;&gt; s2[0] = 10
 |      &gt;&gt;&gt; s1  # note that s1[0] has changed too
 |      0    10
 |      1     2
 |      dtype: int64
 |      
 |      Create a series of dates:
 |      
 |      &gt;&gt;&gt; ser_date = pd.Series(pd.date_range(&#39;20200101&#39;, periods=3))
 |      &gt;&gt;&gt; ser_date
 |      0   2020-01-01
 |      1   2020-01-02
 |      2   2020-01-03
 |      dtype: datetime64[ns]
 |  
 |  at_time(self: &#39;FrameOrSeries&#39;, time, asof: &#39;bool_t&#39; = False, axis=None) -&gt; &#39;FrameOrSeries&#39;
 |      Select values at particular time of day (e.g., 9:30AM).
 |      
 |      Parameters
 |      ----------
 |      time : datetime.time or str
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the index is not  a :class:`DatetimeIndex`
 |      
 |      See Also
 |      --------
 |      between_time : Select values between particular times of the day.
 |      first : Select initial periods of time series based on a date offset.
 |      last : Select final periods of time series based on a date offset.
 |      DatetimeIndex.indexer_at_time : Get just the index locations for
 |          values at particular time of the day.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; i = pd.date_range(&#39;2018-04-09&#39;, periods=4, freq=&#39;12H&#39;)
 |      &gt;&gt;&gt; ts = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4]}, index=i)
 |      &gt;&gt;&gt; ts
 |                           A
 |      2018-04-09 00:00:00  1
 |      2018-04-09 12:00:00  2
 |      2018-04-10 00:00:00  3
 |      2018-04-10 12:00:00  4
 |      
 |      &gt;&gt;&gt; ts.at_time(&#39;12:00&#39;)
 |                           A
 |      2018-04-09 12:00:00  2
 |      2018-04-10 12:00:00  4
 |  
 |  backfill = bfill(self: &#39;FrameOrSeries&#39;, axis: &#39;None | Axis&#39; = None, inplace: &#39;bool_t&#39; = False, limit: &#39;None | int&#39; = None, downcast=None) -&gt; &#39;FrameOrSeries | None&#39;
 |      Synonym for :meth:`DataFrame.fillna` with ``method=&#39;bfill&#39;``.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame or None
 |          Object with missing values filled or None if ``inplace=True``.
 |  
 |  between_time(self: &#39;FrameOrSeries&#39;, start_time, end_time, include_start: &#39;bool_t&#39; = True, include_end: &#39;bool_t&#39; = True, axis=None) -&gt; &#39;FrameOrSeries&#39;
 |      Select values between particular times of the day (e.g., 9:00-9:30 AM).
 |      
 |      By setting ``start_time`` to be later than ``end_time``,
 |      you can get the times that are *not* between the two times.
 |      
 |      Parameters
 |      ----------
 |      start_time : datetime.time or str
 |          Initial time as a time filter limit.
 |      end_time : datetime.time or str
 |          End time as a time filter limit.
 |      include_start : bool, default True
 |          Whether the start time needs to be included in the result.
 |      include_end : bool, default True
 |          Whether the end time needs to be included in the result.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Determine range time on index or columns value.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Data from the original object filtered to the specified dates range.
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the index is not  a :class:`DatetimeIndex`
 |      
 |      See Also
 |      --------
 |      at_time : Select values at a particular time of the day.
 |      first : Select initial periods of time series based on a date offset.
 |      last : Select final periods of time series based on a date offset.
 |      DatetimeIndex.indexer_between_time : Get just the index locations for
 |          values between particular times of the day.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; i = pd.date_range(&#39;2018-04-09&#39;, periods=4, freq=&#39;1D20min&#39;)
 |      &gt;&gt;&gt; ts = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4]}, index=i)
 |      &gt;&gt;&gt; ts
 |                           A
 |      2018-04-09 00:00:00  1
 |      2018-04-10 00:20:00  2
 |      2018-04-11 00:40:00  3
 |      2018-04-12 01:00:00  4
 |      
 |      &gt;&gt;&gt; ts.between_time(&#39;0:15&#39;, &#39;0:45&#39;)
 |                           A
 |      2018-04-10 00:20:00  2
 |      2018-04-11 00:40:00  3
 |      
 |      You get the times that are *not* between two times by setting
 |      ``start_time`` later than ``end_time``:
 |      
 |      &gt;&gt;&gt; ts.between_time(&#39;0:45&#39;, &#39;0:15&#39;)
 |                           A
 |      2018-04-09 00:00:00  1
 |      2018-04-12 01:00:00  4
 |  
 |  bool(self)
 |      Return the bool of a single element Series or DataFrame.
 |      
 |      This must be a boolean scalar value, either True or False. It will raise a
 |      ValueError if the Series or DataFrame does not have exactly 1 element, or that
 |      element is not boolean (integer values 0 and 1 will also raise an exception).
 |      
 |      Returns
 |      -------
 |      bool
 |          The value in the Series or DataFrame.
 |      
 |      See Also
 |      --------
 |      Series.astype : Change the data type of a Series, including to boolean.
 |      DataFrame.astype : Change the data type of a DataFrame, including to boolean.
 |      numpy.bool_ : NumPy boolean data type, used by pandas for boolean values.
 |      
 |      Examples
 |      --------
 |      The method will only work for single element objects with a boolean value:
 |      
 |      &gt;&gt;&gt; pd.Series([True]).bool()
 |      True
 |      &gt;&gt;&gt; pd.Series([False]).bool()
 |      False
 |      
 |      &gt;&gt;&gt; pd.DataFrame({&#39;col&#39;: [True]}).bool()
 |      True
 |      &gt;&gt;&gt; pd.DataFrame({&#39;col&#39;: [False]}).bool()
 |      False
 |  
 |  convert_dtypes(self: &#39;FrameOrSeries&#39;, infer_objects: &#39;bool_t&#39; = True, convert_string: &#39;bool_t&#39; = True, convert_integer: &#39;bool_t&#39; = True, convert_boolean: &#39;bool_t&#39; = True, convert_floating: &#39;bool_t&#39; = True) -&gt; &#39;FrameOrSeries&#39;
 |      Convert columns to best possible dtypes using dtypes supporting ``pd.NA``.
 |      
 |      .. versionadded:: 1.0.0
 |      
 |      Parameters
 |      ----------
 |      infer_objects : bool, default True
 |          Whether object dtypes should be converted to the best possible types.
 |      convert_string : bool, default True
 |          Whether object dtypes should be converted to ``StringDtype()``.
 |      convert_integer : bool, default True
 |          Whether, if possible, conversion can be done to integer extension types.
 |      convert_boolean : bool, defaults True
 |          Whether object dtypes should be converted to ``BooleanDtypes()``.
 |      convert_floating : bool, defaults True
 |          Whether, if possible, conversion can be done to floating extension types.
 |          If `convert_integer` is also True, preference will be give to integer
 |          dtypes if the floats can be faithfully casted to integers.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Copy of input object with new dtype.
 |      
 |      See Also
 |      --------
 |      infer_objects : Infer dtypes of objects.
 |      to_datetime : Convert argument to datetime.
 |      to_timedelta : Convert argument to timedelta.
 |      to_numeric : Convert argument to a numeric type.
 |      
 |      Notes
 |      -----
 |      By default, ``convert_dtypes`` will attempt to convert a Series (or each
 |      Series in a DataFrame) to dtypes that support ``pd.NA``. By using the options
 |      ``convert_string``, ``convert_integer``, ``convert_boolean`` and
 |      ``convert_boolean``, it is possible to turn off individual conversions
 |      to ``StringDtype``, the integer extension types, ``BooleanDtype``
 |      or floating extension types, respectively.
 |      
 |      For object-dtyped columns, if ``infer_objects`` is ``True``, use the inference
 |      rules as during normal Series/DataFrame construction.  Then, if possible,
 |      convert to ``StringDtype``, ``BooleanDtype`` or an appropriate integer
 |      or floating extension type, otherwise leave as ``object``.
 |      
 |      If the dtype is integer, convert to an appropriate integer extension type.
 |      
 |      If the dtype is numeric, and consists of all integers, convert to an
 |      appropriate integer extension type. Otherwise, convert to an
 |      appropriate floating extension type.
 |      
 |      .. versionchanged:: 1.2
 |          Starting with pandas 1.2, this method also converts float columns
 |          to the nullable floating extension type.
 |      
 |      In the future, as new dtypes are added that support ``pd.NA``, the results
 |      of this method will change to support those new dtypes.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(
 |      ...     {
 |      ...         &quot;a&quot;: pd.Series([1, 2, 3], dtype=np.dtype(&quot;int32&quot;)),
 |      ...         &quot;b&quot;: pd.Series([&quot;x&quot;, &quot;y&quot;, &quot;z&quot;], dtype=np.dtype(&quot;O&quot;)),
 |      ...         &quot;c&quot;: pd.Series([True, False, np.nan], dtype=np.dtype(&quot;O&quot;)),
 |      ...         &quot;d&quot;: pd.Series([&quot;h&quot;, &quot;i&quot;, np.nan], dtype=np.dtype(&quot;O&quot;)),
 |      ...         &quot;e&quot;: pd.Series([10, np.nan, 20], dtype=np.dtype(&quot;float&quot;)),
 |      ...         &quot;f&quot;: pd.Series([np.nan, 100.5, 200], dtype=np.dtype(&quot;float&quot;)),
 |      ...     }
 |      ... )
 |      
 |      Start with a DataFrame with default dtypes.
 |      
 |      &gt;&gt;&gt; df
 |         a  b      c    d     e      f
 |      0  1  x   True    h  10.0    NaN
 |      1  2  y  False    i   NaN  100.5
 |      2  3  z    NaN  NaN  20.0  200.0
 |      
 |      &gt;&gt;&gt; df.dtypes
 |      a      int32
 |      b     object
 |      c     object
 |      d     object
 |      e    float64
 |      f    float64
 |      dtype: object
 |      
 |      Convert the DataFrame to use best possible dtypes.
 |      
 |      &gt;&gt;&gt; dfn = df.convert_dtypes()
 |      &gt;&gt;&gt; dfn
 |         a  b      c     d     e      f
 |      0  1  x   True     h    10   &lt;NA&gt;
 |      1  2  y  False     i  &lt;NA&gt;  100.5
 |      2  3  z   &lt;NA&gt;  &lt;NA&gt;    20  200.0
 |      
 |      &gt;&gt;&gt; dfn.dtypes
 |      a      Int32
 |      b     string
 |      c    boolean
 |      d     string
 |      e      Int64
 |      f    Float64
 |      dtype: object
 |      
 |      Start with a Series of strings and missing data represented by ``np.nan``.
 |      
 |      &gt;&gt;&gt; s = pd.Series([&quot;a&quot;, &quot;b&quot;, np.nan])
 |      &gt;&gt;&gt; s
 |      0      a
 |      1      b
 |      2    NaN
 |      dtype: object
 |      
 |      Obtain a Series with dtype ``StringDtype``.
 |      
 |      &gt;&gt;&gt; s.convert_dtypes()
 |      0       a
 |      1       b
 |      2    &lt;NA&gt;
 |      dtype: string
 |  
 |  copy(self: &#39;FrameOrSeries&#39;, deep: &#39;bool_t&#39; = True) -&gt; &#39;FrameOrSeries&#39;
 |      Make a copy of this object&#39;s indices and data.
 |      
 |      When ``deep=True`` (default), a new object will be created with a
 |      copy of the calling object&#39;s data and indices. Modifications to
 |      the data or indices of the copy will not be reflected in the
 |      original object (see notes below).
 |      
 |      When ``deep=False``, a new object will be created without copying
 |      the calling object&#39;s data or index (only references to the data
 |      and index are copied). Any changes to the data of the original
 |      will be reflected in the shallow copy (and vice versa).
 |      
 |      Parameters
 |      ----------
 |      deep : bool, default True
 |          Make a deep copy, including a copy of the data and the indices.
 |          With ``deep=False`` neither the indices nor the data are copied.
 |      
 |      Returns
 |      -------
 |      copy : Series or DataFrame
 |          Object type matches caller.
 |      
 |      Notes
 |      -----
 |      When ``deep=True``, data is copied but actual Python objects
 |      will not be copied recursively, only the reference to the object.
 |      This is in contrast to `copy.deepcopy` in the Standard Library,
 |      which recursively copies object data (see examples below).
 |      
 |      While ``Index`` objects are copied when ``deep=True``, the underlying
 |      numpy array is not copied for performance reasons. Since ``Index`` is
 |      immutable, the underlying data can be safely shared and a copy
 |      is not needed.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series([1, 2], index=[&quot;a&quot;, &quot;b&quot;])
 |      &gt;&gt;&gt; s
 |      a    1
 |      b    2
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s_copy = s.copy()
 |      &gt;&gt;&gt; s_copy
 |      a    1
 |      b    2
 |      dtype: int64
 |      
 |      **Shallow copy versus default (deep) copy:**
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2], index=[&quot;a&quot;, &quot;b&quot;])
 |      &gt;&gt;&gt; deep = s.copy()
 |      &gt;&gt;&gt; shallow = s.copy(deep=False)
 |      
 |      Shallow copy shares data and index with original.
 |      
 |      &gt;&gt;&gt; s is shallow
 |      False
 |      &gt;&gt;&gt; s.values is shallow.values and s.index is shallow.index
 |      True
 |      
 |      Deep copy has own copy of data and index.
 |      
 |      &gt;&gt;&gt; s is deep
 |      False
 |      &gt;&gt;&gt; s.values is deep.values or s.index is deep.index
 |      False
 |      
 |      Updates to the data shared by shallow copy and original is reflected
 |      in both; deep copy remains unchanged.
 |      
 |      &gt;&gt;&gt; s[0] = 3
 |      &gt;&gt;&gt; shallow[1] = 4
 |      &gt;&gt;&gt; s
 |      a    3
 |      b    4
 |      dtype: int64
 |      &gt;&gt;&gt; shallow
 |      a    3
 |      b    4
 |      dtype: int64
 |      &gt;&gt;&gt; deep
 |      a    1
 |      b    2
 |      dtype: int64
 |      
 |      Note that when copying an object containing Python objects, a deep copy
 |      will copy the data, but will not do so recursively. Updating a nested
 |      data object will be reflected in the deep copy.
 |      
 |      &gt;&gt;&gt; s = pd.Series([[1, 2], [3, 4]])
 |      &gt;&gt;&gt; deep = s.copy()
 |      &gt;&gt;&gt; s[0][0] = 10
 |      &gt;&gt;&gt; s
 |      0    [10, 2]
 |      1     [3, 4]
 |      dtype: object
 |      &gt;&gt;&gt; deep
 |      0    [10, 2]
 |      1     [3, 4]
 |      dtype: object
 |  
 |  describe(self: &#39;FrameOrSeries&#39;, percentiles=None, include=None, exclude=None, datetime_is_numeric=False) -&gt; &#39;FrameOrSeries&#39;
 |      Generate descriptive statistics.
 |      
 |      Descriptive statistics include those that summarize the central
 |      tendency, dispersion and shape of a
 |      dataset&#39;s distribution, excluding ``NaN`` values.
 |      
 |      Analyzes both numeric and object series, as well
 |      as ``DataFrame`` column sets of mixed data types. The output
 |      will vary depending on what is provided. Refer to the notes
 |      below for more detail.
 |      
 |      Parameters
 |      ----------
 |      percentiles : list-like of numbers, optional
 |          The percentiles to include in the output. All should
 |          fall between 0 and 1. The default is
 |          ``[.25, .5, .75]``, which returns the 25th, 50th, and
 |          75th percentiles.
 |      include : &#39;all&#39;, list-like of dtypes or None (default), optional
 |          A white list of data types to include in the result. Ignored
 |          for ``Series``. Here are the options:
 |      
 |          - &#39;all&#39; : All columns of the input will be included in the output.
 |          - A list-like of dtypes : Limits the results to the
 |            provided data types.
 |            To limit the result to numeric types submit
 |            ``numpy.number``. To limit it instead to object columns submit
 |            the ``numpy.object`` data type. Strings
 |            can also be used in the style of
 |            ``select_dtypes`` (e.g. ``df.describe(include=[&#39;O&#39;])``). To
 |            select pandas categorical columns, use ``&#39;category&#39;``
 |          - None (default) : The result will include all numeric columns.
 |      exclude : list-like of dtypes or None (default), optional,
 |          A black list of data types to omit from the result. Ignored
 |          for ``Series``. Here are the options:
 |      
 |          - A list-like of dtypes : Excludes the provided data types
 |            from the result. To exclude numeric types submit
 |            ``numpy.number``. To exclude object columns submit the data
 |            type ``numpy.object``. Strings can also be used in the style of
 |            ``select_dtypes`` (e.g. ``df.describe(include=[&#39;O&#39;])``). To
 |            exclude pandas categorical columns, use ``&#39;category&#39;``
 |          - None (default) : The result will exclude nothing.
 |      datetime_is_numeric : bool, default False
 |          Whether to treat datetime dtypes as numeric. This affects statistics
 |          calculated for the column. For DataFrame input, this also
 |          controls whether datetime columns are included by default.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Summary statistics of the Series or Dataframe provided.
 |      
 |      See Also
 |      --------
 |      DataFrame.count: Count number of non-NA/null observations.
 |      DataFrame.max: Maximum of the values in the object.
 |      DataFrame.min: Minimum of the values in the object.
 |      DataFrame.mean: Mean of the values.
 |      DataFrame.std: Standard deviation of the observations.
 |      DataFrame.select_dtypes: Subset of a DataFrame including/excluding
 |          columns based on their dtype.
 |      
 |      Notes
 |      -----
 |      For numeric data, the result&#39;s index will include ``count``,
 |      ``mean``, ``std``, ``min``, ``max`` as well as lower, ``50`` and
 |      upper percentiles. By default the lower percentile is ``25`` and the
 |      upper percentile is ``75``. The ``50`` percentile is the
 |      same as the median.
 |      
 |      For object data (e.g. strings or timestamps), the result&#39;s index
 |      will include ``count``, ``unique``, ``top``, and ``freq``. The ``top``
 |      is the most common value. The ``freq`` is the most common value&#39;s
 |      frequency. Timestamps also include the ``first`` and ``last`` items.
 |      
 |      If multiple object values have the highest count, then the
 |      ``count`` and ``top`` results will be arbitrarily chosen from
 |      among those with the highest count.
 |      
 |      For mixed data types provided via a ``DataFrame``, the default is to
 |      return only an analysis of numeric columns. If the dataframe consists
 |      only of object and categorical data without any numeric columns, the
 |      default is to return an analysis of both the object and categorical
 |      columns. If ``include=&#39;all&#39;`` is provided as an option, the result
 |      will include a union of attributes of each type.
 |      
 |      The `include` and `exclude` parameters can be used to limit
 |      which columns in a ``DataFrame`` are analyzed for the output.
 |      The parameters are ignored when analyzing a ``Series``.
 |      
 |      Examples
 |      --------
 |      Describing a numeric ``Series``.
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3])
 |      &gt;&gt;&gt; s.describe()
 |      count    3.0
 |      mean     2.0
 |      std      1.0
 |      min      1.0
 |      25%      1.5
 |      50%      2.0
 |      75%      2.5
 |      max      3.0
 |      dtype: float64
 |      
 |      Describing a categorical ``Series``.
 |      
 |      &gt;&gt;&gt; s = pd.Series([&#39;a&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;])
 |      &gt;&gt;&gt; s.describe()
 |      count     4
 |      unique    3
 |      top       a
 |      freq      2
 |      dtype: object
 |      
 |      Describing a timestamp ``Series``.
 |      
 |      &gt;&gt;&gt; s = pd.Series([
 |      ...   np.datetime64(&quot;2000-01-01&quot;),
 |      ...   np.datetime64(&quot;2010-01-01&quot;),
 |      ...   np.datetime64(&quot;2010-01-01&quot;)
 |      ... ])
 |      &gt;&gt;&gt; s.describe(datetime_is_numeric=True)
 |      count                      3
 |      mean     2006-09-01 08:00:00
 |      min      2000-01-01 00:00:00
 |      25%      2004-12-31 12:00:00
 |      50%      2010-01-01 00:00:00
 |      75%      2010-01-01 00:00:00
 |      max      2010-01-01 00:00:00
 |      dtype: object
 |      
 |      Describing a ``DataFrame``. By default only numeric fields
 |      are returned.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;categorical&#39;: pd.Categorical([&#39;d&#39;,&#39;e&#39;,&#39;f&#39;]),
 |      ...                    &#39;numeric&#39;: [1, 2, 3],
 |      ...                    &#39;object&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]
 |      ...                   })
 |      &gt;&gt;&gt; df.describe()
 |             numeric
 |      count      3.0
 |      mean       2.0
 |      std        1.0
 |      min        1.0
 |      25%        1.5
 |      50%        2.0
 |      75%        2.5
 |      max        3.0
 |      
 |      Describing all columns of a ``DataFrame`` regardless of data type.
 |      
 |      &gt;&gt;&gt; df.describe(include=&#39;all&#39;)  # doctest: +SKIP
 |             categorical  numeric object
 |      count            3      3.0      3
 |      unique           3      NaN      3
 |      top              f      NaN      a
 |      freq             1      NaN      1
 |      mean           NaN      2.0    NaN
 |      std            NaN      1.0    NaN
 |      min            NaN      1.0    NaN
 |      25%            NaN      1.5    NaN
 |      50%            NaN      2.0    NaN
 |      75%            NaN      2.5    NaN
 |      max            NaN      3.0    NaN
 |      
 |      Describing a column from a ``DataFrame`` by accessing it as
 |      an attribute.
 |      
 |      &gt;&gt;&gt; df.numeric.describe()
 |      count    3.0
 |      mean     2.0
 |      std      1.0
 |      min      1.0
 |      25%      1.5
 |      50%      2.0
 |      75%      2.5
 |      max      3.0
 |      Name: numeric, dtype: float64
 |      
 |      Including only numeric columns in a ``DataFrame`` description.
 |      
 |      &gt;&gt;&gt; df.describe(include=[np.number])
 |             numeric
 |      count      3.0
 |      mean       2.0
 |      std        1.0
 |      min        1.0
 |      25%        1.5
 |      50%        2.0
 |      75%        2.5
 |      max        3.0
 |      
 |      Including only string columns in a ``DataFrame`` description.
 |      
 |      &gt;&gt;&gt; df.describe(include=[object])  # doctest: +SKIP
 |             object
 |      count       3
 |      unique      3
 |      top         a
 |      freq        1
 |      
 |      Including only categorical columns from a ``DataFrame`` description.
 |      
 |      &gt;&gt;&gt; df.describe(include=[&#39;category&#39;])
 |             categorical
 |      count            3
 |      unique           3
 |      top              d
 |      freq             1
 |      
 |      Excluding numeric columns from a ``DataFrame`` description.
 |      
 |      &gt;&gt;&gt; df.describe(exclude=[np.number])  # doctest: +SKIP
 |             categorical object
 |      count            3      3
 |      unique           3      3
 |      top              f      a
 |      freq             1      1
 |      
 |      Excluding object columns from a ``DataFrame`` description.
 |      
 |      &gt;&gt;&gt; df.describe(exclude=[object])  # doctest: +SKIP
 |             categorical  numeric
 |      count            3      3.0
 |      unique           3      NaN
 |      top              f      NaN
 |      freq             1      NaN
 |      mean           NaN      2.0
 |      std            NaN      1.0
 |      min            NaN      1.0
 |      25%            NaN      1.5
 |      50%            NaN      2.0
 |      75%            NaN      2.5
 |      max            NaN      3.0
 |  
 |  droplevel(self: &#39;FrameOrSeries&#39;, level, axis=0) -&gt; &#39;FrameOrSeries&#39;
 |      Return Series/DataFrame with requested index / column level(s) removed.
 |      
 |      Parameters
 |      ----------
 |      level : int, str, or list-like
 |          If a string is given, must be the name of a level
 |          If list-like, elements must be names or positional indexes
 |          of levels.
 |      
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Axis along which the level(s) is removed:
 |      
 |          * 0 or &#39;index&#39;: remove level(s) in column.
 |          * 1 or &#39;columns&#39;: remove level(s) in row.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame
 |          Series/DataFrame with requested index / column level(s) removed.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([
 |      ...     [1, 2, 3, 4],
 |      ...     [5, 6, 7, 8],
 |      ...     [9, 10, 11, 12]
 |      ... ]).set_index([0, 1]).rename_axis([&#39;a&#39;, &#39;b&#39;])
 |      
 |      &gt;&gt;&gt; df.columns = pd.MultiIndex.from_tuples([
 |      ...     (&#39;c&#39;, &#39;e&#39;), (&#39;d&#39;, &#39;f&#39;)
 |      ... ], names=[&#39;level_1&#39;, &#39;level_2&#39;])
 |      
 |      &gt;&gt;&gt; df
 |      level_1   c   d
 |      level_2   e   f
 |      a b
 |      1 2      3   4
 |      5 6      7   8
 |      9 10    11  12
 |      
 |      &gt;&gt;&gt; df.droplevel(&#39;a&#39;)
 |      level_1   c   d
 |      level_2   e   f
 |      b
 |      2        3   4
 |      6        7   8
 |      10      11  12
 |      
 |      &gt;&gt;&gt; df.droplevel(&#39;level_2&#39;, axis=1)
 |      level_1   c   d
 |      a b
 |      1 2      3   4
 |      5 6      7   8
 |      9 10    11  12
 |  
 |  equals(self, other: &#39;object&#39;) -&gt; &#39;bool_t&#39;
 |      Test whether two objects contain the same elements.
 |      
 |      This function allows two Series or DataFrames to be compared against
 |      each other to see if they have the same shape and elements. NaNs in
 |      the same location are considered equal.
 |      
 |      The row/column index do not need to have the same type, as long
 |      as the values are considered equal. Corresponding columns must be of
 |      the same dtype.
 |      
 |      Parameters
 |      ----------
 |      other : Series or DataFrame
 |          The other Series or DataFrame to be compared with the first.
 |      
 |      Returns
 |      -------
 |      bool
 |          True if all elements are the same in both objects, False
 |          otherwise.
 |      
 |      See Also
 |      --------
 |      Series.eq : Compare two Series objects of the same length
 |          and return a Series where each element is True if the element
 |          in each Series is equal, False otherwise.
 |      DataFrame.eq : Compare two DataFrame objects of the same shape and
 |          return a DataFrame where each element is True if the respective
 |          element in each DataFrame is equal, False otherwise.
 |      testing.assert_series_equal : Raises an AssertionError if left and
 |          right are not equal. Provides an easy interface to ignore
 |          inequality in dtypes, indexes and precision among others.
 |      testing.assert_frame_equal : Like assert_series_equal, but targets
 |          DataFrames.
 |      numpy.array_equal : Return True if two arrays have the same shape
 |          and elements, False otherwise.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({1: [10], 2: [20]})
 |      &gt;&gt;&gt; df
 |          1   2
 |      0  10  20
 |      
 |      DataFrames df and exactly_equal have the same types and values for
 |      their elements and column labels, which will return True.
 |      
 |      &gt;&gt;&gt; exactly_equal = pd.DataFrame({1: [10], 2: [20]})
 |      &gt;&gt;&gt; exactly_equal
 |          1   2
 |      0  10  20
 |      &gt;&gt;&gt; df.equals(exactly_equal)
 |      True
 |      
 |      DataFrames df and different_column_type have the same element
 |      types and values, but have different types for the column labels,
 |      which will still return True.
 |      
 |      &gt;&gt;&gt; different_column_type = pd.DataFrame({1.0: [10], 2.0: [20]})
 |      &gt;&gt;&gt; different_column_type
 |         1.0  2.0
 |      0   10   20
 |      &gt;&gt;&gt; df.equals(different_column_type)
 |      True
 |      
 |      DataFrames df and different_data_type have different types for the
 |      same values for their elements, and will return False even though
 |      their column labels are the same values and types.
 |      
 |      &gt;&gt;&gt; different_data_type = pd.DataFrame({1: [10.0], 2: [20.0]})
 |      &gt;&gt;&gt; different_data_type
 |            1     2
 |      0  10.0  20.0
 |      &gt;&gt;&gt; df.equals(different_data_type)
 |      False
 |  
 |  ewm(self, com: &#39;float | None&#39; = None, span: &#39;float | None&#39; = None, halflife: &#39;float | TimedeltaConvertibleTypes | None&#39; = None, alpha: &#39;float | None&#39; = None, min_periods: &#39;int | None&#39; = 0, adjust: &#39;bool_t&#39; = True, ignore_na: &#39;bool_t&#39; = False, axis: &#39;Axis&#39; = 0, times: &#39;str | np.ndarray | FrameOrSeries | None&#39; = None) -&gt; &#39;ExponentialMovingWindow&#39;
 |      Provide exponential weighted (EW) functions.
 |      
 |      Available EW functions: ``mean()``, ``var()``, ``std()``, ``corr()``, ``cov()``.
 |      
 |      Exactly one parameter: ``com``, ``span``, ``halflife``, or ``alpha`` must be
 |      provided.
 |      
 |      Parameters
 |      ----------
 |      com : float, optional
 |          Specify decay in terms of center of mass,
 |          :math:`\alpha = 1 / (1 + com)`, for :math:`com \geq 0`.
 |      span : float, optional
 |          Specify decay in terms of span,
 |          :math:`\alpha = 2 / (span + 1)`, for :math:`span \geq 1`.
 |      halflife : float, str, timedelta, optional
 |          Specify decay in terms of half-life,
 |          :math:`\alpha = 1 - \exp\left(-\ln(2) / halflife\right)`, for
 |          :math:`halflife &gt; 0`.
 |      
 |          If ``times`` is specified, the time unit (str or timedelta) over which an
 |          observation decays to half its value. Only applicable to ``mean()``
 |          and halflife value will not apply to the other functions.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      alpha : float, optional
 |          Specify smoothing factor :math:`\alpha` directly,
 |          :math:`0 &lt; \alpha \leq 1`.
 |      min_periods : int, default 0
 |          Minimum number of observations in window required to have a value
 |          (otherwise result is NA).
 |      adjust : bool, default True
 |          Divide by decaying adjustment factor in beginning periods to account
 |          for imbalance in relative weightings (viewing EWMA as a moving average).
 |      
 |          - When ``adjust=True`` (default), the EW function is calculated using weights
 |            :math:`w_i = (1 - \alpha)^i`. For example, the EW moving average of the series
 |            [:math:`x_0, x_1, ..., x_t`] would be:
 |      
 |          .. math::
 |              y_t = \frac{x_t + (1 - \alpha)x_{t-1} + (1 - \alpha)^2 x_{t-2} + ... + (1 -
 |              \alpha)^t x_0}{1 + (1 - \alpha) + (1 - \alpha)^2 + ... + (1 - \alpha)^t}
 |      
 |          - When ``adjust=False``, the exponentially weighted function is calculated
 |            recursively:
 |      
 |          .. math::
 |              \begin{split}
 |                  y_0 &amp;= x_0\\
 |                  y_t &amp;= (1 - \alpha) y_{t-1} + \alpha x_t,
 |              \end{split}
 |      ignore_na : bool, default False
 |          Ignore missing values when calculating weights; specify ``True`` to reproduce
 |          pre-0.15.0 behavior.
 |      
 |          - When ``ignore_na=False`` (default), weights are based on absolute positions.
 |            For example, the weights of :math:`x_0` and :math:`x_2` used in calculating
 |            the final weighted average of [:math:`x_0`, None, :math:`x_2`] are
 |            :math:`(1-\alpha)^2` and :math:`1` if ``adjust=True``, and
 |            :math:`(1-\alpha)^2` and :math:`\alpha` if ``adjust=False``.
 |      
 |          - When ``ignore_na=True`` (reproducing pre-0.15.0 behavior), weights are based
 |            on relative positions. For example, the weights of :math:`x_0` and :math:`x_2`
 |            used in calculating the final weighted average of
 |            [:math:`x_0`, None, :math:`x_2`] are :math:`1-\alpha` and :math:`1` if
 |            ``adjust=True``, and :math:`1-\alpha` and :math:`\alpha` if ``adjust=False``.
 |      axis : {0, 1}, default 0
 |          The axis to use. The value 0 identifies the rows, and 1
 |          identifies the columns.
 |      times : str, np.ndarray, Series, default None
 |      
 |          .. versionadded:: 1.1.0
 |      
 |          Times corresponding to the observations. Must be monotonically increasing and
 |          ``datetime64[ns]`` dtype.
 |      
 |          If str, the name of the column in the DataFrame representing the times.
 |      
 |          If 1-D array like, a sequence with the same shape as the observations.
 |      
 |          Only applicable to ``mean()``.
 |      
 |      Returns
 |      -------
 |      DataFrame
 |          A Window sub-classed for the particular operation.
 |      
 |      See Also
 |      --------
 |      rolling : Provides rolling window calculations.
 |      expanding : Provides expanding transformations.
 |      
 |      Notes
 |      -----
 |      
 |      More details can be found at:
 |      :ref:`Exponentially weighted windows &lt;window.exponentially_weighted&gt;`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;B&#39;: [0, 1, 2, np.nan, 4]})
 |      &gt;&gt;&gt; df
 |           B
 |      0  0.0
 |      1  1.0
 |      2  2.0
 |      3  NaN
 |      4  4.0
 |      
 |      &gt;&gt;&gt; df.ewm(com=0.5).mean()
 |                B
 |      0  0.000000
 |      1  0.750000
 |      2  1.615385
 |      3  1.615385
 |      4  3.670213
 |      
 |      Specifying ``times`` with a timedelta ``halflife`` when computing mean.
 |      
 |      &gt;&gt;&gt; times = [&#39;2020-01-01&#39;, &#39;2020-01-03&#39;, &#39;2020-01-10&#39;, &#39;2020-01-15&#39;, &#39;2020-01-17&#39;]
 |      &gt;&gt;&gt; df.ewm(halflife=&#39;4 days&#39;, times=pd.DatetimeIndex(times)).mean()
 |                B
 |      0  0.000000
 |      1  0.585786
 |      2  1.523889
 |      3  1.523889
 |      4  3.233686
 |  
 |  expanding(self, min_periods: &#39;int&#39; = 1, center: &#39;bool_t | None&#39; = None, axis: &#39;Axis&#39; = 0, method: &#39;str&#39; = &#39;single&#39;) -&gt; &#39;Expanding&#39;
 |      Provide expanding transformations.
 |      
 |      Parameters
 |      ----------
 |      min_periods : int, default 1
 |          Minimum number of observations in window required to have a value
 |          (otherwise result is NA).
 |      center : bool, default False
 |          Set the labels at the center of the window.
 |      axis : int or str, default 0
 |      method : str {&#39;single&#39;, &#39;table&#39;}, default &#39;single&#39;
 |          Execute the rolling operation per single column or row (``&#39;single&#39;``)
 |          or over the entire object (``&#39;table&#39;``).
 |      
 |          This argument is only implemented when specifying ``engine=&#39;numba&#39;``
 |          in the method call.
 |      
 |          .. versionadded:: 1.3.0
 |      
 |      Returns
 |      -------
 |      a Window sub-classed for the particular operation
 |      
 |      See Also
 |      --------
 |      rolling : Provides rolling window calculations.
 |      ewm : Provides exponential weighted functions.
 |      
 |      Notes
 |      -----
 |      By default, the result is set to the right edge of the window. This can be
 |      changed to the center of the window by setting ``center=True``.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;B&quot;: [0, 1, 2, np.nan, 4]})
 |      &gt;&gt;&gt; df
 |           B
 |      0  0.0
 |      1  1.0
 |      2  2.0
 |      3  NaN
 |      4  4.0
 |      
 |      &gt;&gt;&gt; df.expanding(2).sum()
 |           B
 |      0  NaN
 |      1  1.0
 |      2  3.0
 |      3  3.0
 |      4  7.0
 |  
 |  filter(self: &#39;FrameOrSeries&#39;, items=None, like: &#39;str | None&#39; = None, regex: &#39;str | None&#39; = None, axis=None) -&gt; &#39;FrameOrSeries&#39;
 |      Subset the dataframe rows or columns according to the specified index labels.
 |      
 |      Note that this routine does not filter a dataframe on its
 |      contents. The filter is applied to the labels of the index.
 |      
 |      Parameters
 |      ----------
 |      items : list-like
 |          Keep labels from axis which are in items.
 |      like : str
 |          Keep labels from axis for which &quot;like in label == True&quot;.
 |      regex : str (regular expression)
 |          Keep labels from axis for which re.search(regex, label) == True.
 |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None
 |          The axis to filter on, expressed either as an index (int)
 |          or axis name (str). By default this is the info axis,
 |          &#39;index&#39; for Series, &#39;columns&#39; for DataFrame.
 |      
 |      Returns
 |      -------
 |      same type as input object
 |      
 |      See Also
 |      --------
 |      DataFrame.loc : Access a group of rows and columns
 |          by label(s) or a boolean array.
 |      
 |      Notes
 |      -----
 |      The ``items``, ``like``, and ``regex`` parameters are
 |      enforced to be mutually exclusive.
 |      
 |      ``axis`` defaults to the info axis that is used when indexing
 |      with ``[]``.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(np.array(([1, 2, 3], [4, 5, 6])),
 |      ...                   index=[&#39;mouse&#39;, &#39;rabbit&#39;],
 |      ...                   columns=[&#39;one&#39;, &#39;two&#39;, &#39;three&#39;])
 |      &gt;&gt;&gt; df
 |              one  two  three
 |      mouse     1    2      3
 |      rabbit    4    5      6
 |      
 |      &gt;&gt;&gt; # select columns by name
 |      &gt;&gt;&gt; df.filter(items=[&#39;one&#39;, &#39;three&#39;])
 |               one  three
 |      mouse     1      3
 |      rabbit    4      6
 |      
 |      &gt;&gt;&gt; # select columns by regular expression
 |      &gt;&gt;&gt; df.filter(regex=&#39;e$&#39;, axis=1)
 |               one  three
 |      mouse     1      3
 |      rabbit    4      6
 |      
 |      &gt;&gt;&gt; # select rows containing &#39;bbi&#39;
 |      &gt;&gt;&gt; df.filter(like=&#39;bbi&#39;, axis=0)
 |               one  two  three
 |      rabbit    4    5      6
 |  
 |  first(self: &#39;FrameOrSeries&#39;, offset) -&gt; &#39;FrameOrSeries&#39;
 |      Select initial periods of time series data based on a date offset.
 |      
 |      When having a DataFrame with dates as index, this function can
 |      select the first few rows based on a date offset.
 |      
 |      Parameters
 |      ----------
 |      offset : str, DateOffset or dateutil.relativedelta
 |          The offset length of the data that will be selected. For instance,
 |          &#39;1M&#39; will display all the rows having their index within the first month.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          A subset of the caller.
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the index is not  a :class:`DatetimeIndex`
 |      
 |      See Also
 |      --------
 |      last : Select final periods of time series based on a date offset.
 |      at_time : Select values at a particular time of the day.
 |      between_time : Select values between particular times of the day.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; i = pd.date_range(&#39;2018-04-09&#39;, periods=4, freq=&#39;2D&#39;)
 |      &gt;&gt;&gt; ts = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4]}, index=i)
 |      &gt;&gt;&gt; ts
 |                  A
 |      2018-04-09  1
 |      2018-04-11  2
 |      2018-04-13  3
 |      2018-04-15  4
 |      
 |      Get the rows for the first 3 days:
 |      
 |      &gt;&gt;&gt; ts.first(&#39;3D&#39;)
 |                  A
 |      2018-04-09  1
 |      2018-04-11  2
 |      
 |      Notice the data for 3 first calendar days were returned, not the first
 |      3 days observed in the dataset, and therefore data for 2018-04-13 was
 |      not returned.
 |  
 |  first_valid_index(self) -&gt; &#39;Hashable | None&#39;
 |      Return index for first non-NA value or None, if no NA value is found.
 |      
 |      Returns
 |      -------
 |      scalar : type of index
 |      
 |      Notes
 |      -----
 |      If all elements are non-NA/null, returns None.
 |      Also returns None for empty Series/DataFrame.
 |  
 |  get(self, key, default=None)
 |      Get item from object for given key (ex: DataFrame column).
 |      
 |      Returns default value if not found.
 |      
 |      Parameters
 |      ----------
 |      key : object
 |      
 |      Returns
 |      -------
 |      value : same type as items contained in object
 |  
 |  head(self: &#39;FrameOrSeries&#39;, n: &#39;int&#39; = 5) -&gt; &#39;FrameOrSeries&#39;
 |      Return the first `n` rows.
 |      
 |      This function returns the first `n` rows for the object based
 |      on position. It is useful for quickly testing if your object
 |      has the right type of data in it.
 |      
 |      For negative values of `n`, this function returns all rows except
 |      the last `n` rows, equivalent to ``df[:-n]``.
 |      
 |      Parameters
 |      ----------
 |      n : int, default 5
 |          Number of rows to select.
 |      
 |      Returns
 |      -------
 |      same type as caller
 |          The first `n` rows of the caller object.
 |      
 |      See Also
 |      --------
 |      DataFrame.tail: Returns the last `n` rows.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;animal&#39;: [&#39;alligator&#39;, &#39;bee&#39;, &#39;falcon&#39;, &#39;lion&#39;,
 |      ...                    &#39;monkey&#39;, &#39;parrot&#39;, &#39;shark&#39;, &#39;whale&#39;, &#39;zebra&#39;]})
 |      &gt;&gt;&gt; df
 |            animal
 |      0  alligator
 |      1        bee
 |      2     falcon
 |      3       lion
 |      4     monkey
 |      5     parrot
 |      6      shark
 |      7      whale
 |      8      zebra
 |      
 |      Viewing the first 5 lines
 |      
 |      &gt;&gt;&gt; df.head()
 |            animal
 |      0  alligator
 |      1        bee
 |      2     falcon
 |      3       lion
 |      4     monkey
 |      
 |      Viewing the first `n` lines (three in this case)
 |      
 |      &gt;&gt;&gt; df.head(3)
 |            animal
 |      0  alligator
 |      1        bee
 |      2     falcon
 |      
 |      For negative values of `n`
 |      
 |      &gt;&gt;&gt; df.head(-3)
 |            animal
 |      0  alligator
 |      1        bee
 |      2     falcon
 |      3       lion
 |      4     monkey
 |      5     parrot
 |  
 |  infer_objects(self: &#39;FrameOrSeries&#39;) -&gt; &#39;FrameOrSeries&#39;
 |      Attempt to infer better dtypes for object columns.
 |      
 |      Attempts soft conversion of object-dtyped
 |      columns, leaving non-object and unconvertible
 |      columns unchanged. The inference rules are the
 |      same as during normal Series/DataFrame construction.
 |      
 |      Returns
 |      -------
 |      converted : same type as input object
 |      
 |      See Also
 |      --------
 |      to_datetime : Convert argument to datetime.
 |      to_timedelta : Convert argument to timedelta.
 |      to_numeric : Convert argument to numeric type.
 |      convert_dtypes : Convert argument to best possible dtype.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [&quot;a&quot;, 1, 2, 3]})
 |      &gt;&gt;&gt; df = df.iloc[1:]
 |      &gt;&gt;&gt; df
 |         A
 |      1  1
 |      2  2
 |      3  3
 |      
 |      &gt;&gt;&gt; df.dtypes
 |      A    object
 |      dtype: object
 |      
 |      &gt;&gt;&gt; df.infer_objects().dtypes
 |      A    int64
 |      dtype: object
 |  
 |  keys(self)
 |      Get the &#39;info axis&#39; (see Indexing for more).
 |      
 |      This is index for Series, columns for DataFrame.
 |      
 |      Returns
 |      -------
 |      Index
 |          Info axis.
 |  
 |  last(self: &#39;FrameOrSeries&#39;, offset) -&gt; &#39;FrameOrSeries&#39;
 |      Select final periods of time series data based on a date offset.
 |      
 |      For a DataFrame with a sorted DatetimeIndex, this function
 |      selects the last few rows based on a date offset.
 |      
 |      Parameters
 |      ----------
 |      offset : str, DateOffset, dateutil.relativedelta
 |          The offset length of the data that will be selected. For instance,
 |          &#39;3D&#39; will display all the rows having their index within the last 3 days.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          A subset of the caller.
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the index is not  a :class:`DatetimeIndex`
 |      
 |      See Also
 |      --------
 |      first : Select initial periods of time series based on a date offset.
 |      at_time : Select values at a particular time of the day.
 |      between_time : Select values between particular times of the day.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; i = pd.date_range(&#39;2018-04-09&#39;, periods=4, freq=&#39;2D&#39;)
 |      &gt;&gt;&gt; ts = pd.DataFrame({&#39;A&#39;: [1, 2, 3, 4]}, index=i)
 |      &gt;&gt;&gt; ts
 |                  A
 |      2018-04-09  1
 |      2018-04-11  2
 |      2018-04-13  3
 |      2018-04-15  4
 |      
 |      Get the rows for the last 3 days:
 |      
 |      &gt;&gt;&gt; ts.last(&#39;3D&#39;)
 |                  A
 |      2018-04-13  3
 |      2018-04-15  4
 |      
 |      Notice the data for 3 last calendar days were returned, not the last
 |      3 observed days in the dataset, and therefore data for 2018-04-11 was
 |      not returned.
 |  
 |  last_valid_index(self) -&gt; &#39;Hashable | None&#39;
 |      Return index for last non-NA value or None, if no NA value is found.
 |      
 |      Returns
 |      -------
 |      scalar : type of index
 |      
 |      Notes
 |      -----
 |      If all elements are non-NA/null, returns None.
 |      Also returns None for empty Series/DataFrame.
 |  
 |  pad = ffill(self: &#39;FrameOrSeries&#39;, axis: &#39;None | Axis&#39; = None, inplace: &#39;bool_t&#39; = False, limit: &#39;None | int&#39; = None, downcast=None) -&gt; &#39;FrameOrSeries | None&#39;
 |      Synonym for :meth:`DataFrame.fillna` with ``method=&#39;ffill&#39;``.
 |      
 |      Returns
 |      -------
 |      Series/DataFrame or None
 |          Object with missing values filled or None if ``inplace=True``.
 |  
 |  pct_change(self: &#39;FrameOrSeries&#39;, periods=1, fill_method=&#39;pad&#39;, limit=None, freq=None, **kwargs) -&gt; &#39;FrameOrSeries&#39;
 |      Percentage change between the current and a prior element.
 |      
 |      Computes the percentage change from the immediately previous row by
 |      default. This is useful in comparing the percentage of change in a time
 |      series of elements.
 |      
 |      Parameters
 |      ----------
 |      periods : int, default 1
 |          Periods to shift for forming percent change.
 |      fill_method : str, default &#39;pad&#39;
 |          How to handle NAs before computing percent changes.
 |      limit : int, default None
 |          The number of consecutive NAs to fill before stopping.
 |      freq : DateOffset, timedelta, or str, optional
 |          Increment to use from time series API (e.g. &#39;M&#39; or BDay()).
 |      **kwargs
 |          Additional keyword arguments are passed into
 |          `DataFrame.shift` or `Series.shift`.
 |      
 |      Returns
 |      -------
 |      chg : Series or DataFrame
 |          The same type as the calling object.
 |      
 |      See Also
 |      --------
 |      Series.diff : Compute the difference of two elements in a Series.
 |      DataFrame.diff : Compute the difference of two elements in a DataFrame.
 |      Series.shift : Shift the index by some number of periods.
 |      DataFrame.shift : Shift the index by some number of periods.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([90, 91, 85])
 |      &gt;&gt;&gt; s
 |      0    90
 |      1    91
 |      2    85
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; s.pct_change()
 |      0         NaN
 |      1    0.011111
 |      2   -0.065934
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.pct_change(periods=2)
 |      0         NaN
 |      1         NaN
 |      2   -0.055556
 |      dtype: float64
 |      
 |      See the percentage change in a Series where filling NAs with last
 |      valid observation forward to next valid.
 |      
 |      &gt;&gt;&gt; s = pd.Series([90, 91, None, 85])
 |      &gt;&gt;&gt; s
 |      0    90.0
 |      1    91.0
 |      2     NaN
 |      3    85.0
 |      dtype: float64
 |      
 |      &gt;&gt;&gt; s.pct_change(fill_method=&#39;ffill&#39;)
 |      0         NaN
 |      1    0.011111
 |      2    0.000000
 |      3   -0.065934
 |      dtype: float64
 |      
 |      **DataFrame**
 |      
 |      Percentage change in French franc, Deutsche Mark, and Italian lira from
 |      1980-01-01 to 1980-03-01.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;FR&#39;: [4.0405, 4.0963, 4.3149],
 |      ...     &#39;GR&#39;: [1.7246, 1.7482, 1.8519],
 |      ...     &#39;IT&#39;: [804.74, 810.01, 860.13]},
 |      ...     index=[&#39;1980-01-01&#39;, &#39;1980-02-01&#39;, &#39;1980-03-01&#39;])
 |      &gt;&gt;&gt; df
 |                      FR      GR      IT
 |      1980-01-01  4.0405  1.7246  804.74
 |      1980-02-01  4.0963  1.7482  810.01
 |      1980-03-01  4.3149  1.8519  860.13
 |      
 |      &gt;&gt;&gt; df.pct_change()
 |                        FR        GR        IT
 |      1980-01-01       NaN       NaN       NaN
 |      1980-02-01  0.013810  0.013684  0.006549
 |      1980-03-01  0.053365  0.059318  0.061876
 |      
 |      Percentage of change in GOOG and APPL stock volume. Shows computing
 |      the percentage change between columns.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({
 |      ...     &#39;2016&#39;: [1769950, 30586265],
 |      ...     &#39;2015&#39;: [1500923, 40912316],
 |      ...     &#39;2014&#39;: [1371819, 41403351]},
 |      ...     index=[&#39;GOOG&#39;, &#39;APPL&#39;])
 |      &gt;&gt;&gt; df
 |                2016      2015      2014
 |      GOOG   1769950   1500923   1371819
 |      APPL  30586265  40912316  41403351
 |      
 |      &gt;&gt;&gt; df.pct_change(axis=&#39;columns&#39;, periods=-1)
 |                2016      2015  2014
 |      GOOG  0.179241  0.094112   NaN
 |      APPL -0.252395 -0.011860   NaN
 |  
 |  pipe(self, func: &#39;Callable[..., T] | tuple[Callable[..., T], str]&#39;, *args, **kwargs) -&gt; &#39;T&#39;
 |      Apply func(self, \*args, \*\*kwargs).
 |      
 |      Parameters
 |      ----------
 |      func : function
 |          Function to apply to the Series/DataFrame.
 |          ``args``, and ``kwargs`` are passed into ``func``.
 |          Alternatively a ``(callable, data_keyword)`` tuple where
 |          ``data_keyword`` is a string indicating the keyword of
 |          ``callable`` that expects the Series/DataFrame.
 |      args : iterable, optional
 |          Positional arguments passed into ``func``.
 |      kwargs : mapping, optional
 |          A dictionary of keyword arguments passed into ``func``.
 |      
 |      Returns
 |      -------
 |      object : the return type of ``func``.
 |      
 |      See Also
 |      --------
 |      DataFrame.apply : Apply a function along input axis of DataFrame.
 |      DataFrame.applymap : Apply a function elementwise on a whole DataFrame.
 |      Series.map : Apply a mapping correspondence on a
 |          :class:`~pandas.Series`.
 |      
 |      Notes
 |      -----
 |      Use ``.pipe`` when chaining together functions that expect
 |      Series, DataFrames or GroupBy objects. Instead of writing
 |      
 |      &gt;&gt;&gt; func(g(h(df), arg1=a), arg2=b, arg3=c)  # doctest: +SKIP
 |      
 |      You can write
 |      
 |      &gt;&gt;&gt; (df.pipe(h)
 |      ...    .pipe(g, arg1=a)
 |      ...    .pipe(func, arg2=b, arg3=c)
 |      ... )  # doctest: +SKIP
 |      
 |      If you have a function that takes the data as (say) the second
 |      argument, pass a tuple indicating which keyword expects the
 |      data. For example, suppose ``f`` takes its data as ``arg2``:
 |      
 |      &gt;&gt;&gt; (df.pipe(h)
 |      ...    .pipe(g, arg1=a)
 |      ...    .pipe((func, &#39;arg2&#39;), arg1=a, arg3=c)
 |      ...  )  # doctest: +SKIP
 |  
 |  rank(self: &#39;FrameOrSeries&#39;, axis=0, method: &#39;str&#39; = &#39;average&#39;, numeric_only: &#39;bool_t | None&#39; = None, na_option: &#39;str&#39; = &#39;keep&#39;, ascending: &#39;bool_t&#39; = True, pct: &#39;bool_t&#39; = False) -&gt; &#39;FrameOrSeries&#39;
 |      Compute numerical data ranks (1 through n) along axis.
 |      
 |      By default, equal values are assigned a rank that is the average of the
 |      ranks of those values.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Index to direct ranking.
 |      method : {&#39;average&#39;, &#39;min&#39;, &#39;max&#39;, &#39;first&#39;, &#39;dense&#39;}, default &#39;average&#39;
 |          How to rank the group of records that have the same value (i.e. ties):
 |      
 |          * average: average rank of the group
 |          * min: lowest rank in the group
 |          * max: highest rank in the group
 |          * first: ranks assigned in order they appear in the array
 |          * dense: like &#39;min&#39;, but rank always increases by 1 between groups.
 |      
 |      numeric_only : bool, optional
 |          For DataFrame objects, rank only numeric columns if set to True.
 |      na_option : {&#39;keep&#39;, &#39;top&#39;, &#39;bottom&#39;}, default &#39;keep&#39;
 |          How to rank NaN values:
 |      
 |          * keep: assign NaN rank to NaN values
 |          * top: assign lowest rank to NaN values
 |          * bottom: assign highest rank to NaN values
 |      
 |      ascending : bool, default True
 |          Whether or not the elements should be ranked in ascending order.
 |      pct : bool, default False
 |          Whether or not to display the returned rankings in percentile
 |          form.
 |      
 |      Returns
 |      -------
 |      same type as caller
 |          Return a Series or DataFrame with data ranks as values.
 |      
 |      See Also
 |      --------
 |      core.groupby.GroupBy.rank : Rank of values within each group.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(data={&#39;Animal&#39;: [&#39;cat&#39;, &#39;penguin&#39;, &#39;dog&#39;,
 |      ...                                    &#39;spider&#39;, &#39;snake&#39;],
 |      ...                         &#39;Number_legs&#39;: [4, 2, 4, 8, np.nan]})
 |      &gt;&gt;&gt; df
 |          Animal  Number_legs
 |      0      cat          4.0
 |      1  penguin          2.0
 |      2      dog          4.0
 |      3   spider          8.0
 |      4    snake          NaN
 |      
 |      The following example shows how the method behaves with the above
 |      parameters:
 |      
 |      * default_rank: this is the default behaviour obtained without using
 |        any parameter.
 |      * max_rank: setting ``method = &#39;max&#39;`` the records that have the
 |        same values are ranked using the highest rank (e.g.: since &#39;cat&#39;
 |        and &#39;dog&#39; are both in the 2nd and 3rd position, rank 3 is assigned.)
 |      * NA_bottom: choosing ``na_option = &#39;bottom&#39;``, if there are records
 |        with NaN values they are placed at the bottom of the ranking.
 |      * pct_rank: when setting ``pct = True``, the ranking is expressed as
 |        percentile rank.
 |      
 |      &gt;&gt;&gt; df[&#39;default_rank&#39;] = df[&#39;Number_legs&#39;].rank()
 |      &gt;&gt;&gt; df[&#39;max_rank&#39;] = df[&#39;Number_legs&#39;].rank(method=&#39;max&#39;)
 |      &gt;&gt;&gt; df[&#39;NA_bottom&#39;] = df[&#39;Number_legs&#39;].rank(na_option=&#39;bottom&#39;)
 |      &gt;&gt;&gt; df[&#39;pct_rank&#39;] = df[&#39;Number_legs&#39;].rank(pct=True)
 |      &gt;&gt;&gt; df
 |          Animal  Number_legs  default_rank  max_rank  NA_bottom  pct_rank
 |      0      cat          4.0           2.5       3.0        2.5     0.625
 |      1  penguin          2.0           1.0       1.0        1.0     0.250
 |      2      dog          4.0           2.5       3.0        2.5     0.625
 |      3   spider          8.0           4.0       4.0        4.0     1.000
 |      4    snake          NaN           NaN       NaN        5.0       NaN
 |  
 |  reindex_like(self: &#39;FrameOrSeries&#39;, other, method: &#39;str | None&#39; = None, copy: &#39;bool_t&#39; = True, limit=None, tolerance=None) -&gt; &#39;FrameOrSeries&#39;
 |      Return an object with matching indices as other object.
 |      
 |      Conform the object to the same index on all axes. Optional
 |      filling logic, placing NaN in locations having no value
 |      in the previous index. A new object is produced unless the
 |      new index is equivalent to the current one and copy=False.
 |      
 |      Parameters
 |      ----------
 |      other : Object of the same data type
 |          Its row and column indices are used to define the new indices
 |          of this object.
 |      method : {None, &#39;backfill&#39;/&#39;bfill&#39;, &#39;pad&#39;/&#39;ffill&#39;, &#39;nearest&#39;}
 |          Method to use for filling holes in reindexed DataFrame.
 |          Please note: this is only applicable to DataFrames/Series with a
 |          monotonically increasing/decreasing index.
 |      
 |          * None (default): don&#39;t fill gaps
 |          * pad / ffill: propagate last valid observation forward to next
 |            valid
 |          * backfill / bfill: use next valid observation to fill gap
 |          * nearest: use nearest valid observations to fill gap.
 |      
 |      copy : bool, default True
 |          Return a new object, even if the passed indexes are the same.
 |      limit : int, default None
 |          Maximum number of consecutive labels to fill for inexact matches.
 |      tolerance : optional
 |          Maximum distance between original and new labels for inexact
 |          matches. The values of the index at the matching locations must
 |          satisfy the equation ``abs(index[indexer] - target) &lt;= tolerance``.
 |      
 |          Tolerance may be a scalar value, which applies the same tolerance
 |          to all values, or list-like, which applies variable tolerance per
 |          element. List-like includes list, tuple, array, Series, and must be
 |          the same size as the index and its dtype must exactly match the
 |          index&#39;s type.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Same type as caller, but with changed indices on each axis.
 |      
 |      See Also
 |      --------
 |      DataFrame.set_index : Set row labels.
 |      DataFrame.reset_index : Remove row labels or move them to new columns.
 |      DataFrame.reindex : Change to new indices or expand indices.
 |      
 |      Notes
 |      -----
 |      Same as calling
 |      ``.reindex(index=other.index, columns=other.columns,...)``.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df1 = pd.DataFrame([[24.3, 75.7, &#39;high&#39;],
 |      ...                     [31, 87.8, &#39;high&#39;],
 |      ...                     [22, 71.6, &#39;medium&#39;],
 |      ...                     [35, 95, &#39;medium&#39;]],
 |      ...                    columns=[&#39;temp_celsius&#39;, &#39;temp_fahrenheit&#39;,
 |      ...                             &#39;windspeed&#39;],
 |      ...                    index=pd.date_range(start=&#39;2014-02-12&#39;,
 |      ...                                        end=&#39;2014-02-15&#39;, freq=&#39;D&#39;))
 |      
 |      &gt;&gt;&gt; df1
 |                  temp_celsius  temp_fahrenheit windspeed
 |      2014-02-12          24.3             75.7      high
 |      2014-02-13          31.0             87.8      high
 |      2014-02-14          22.0             71.6    medium
 |      2014-02-15          35.0             95.0    medium
 |      
 |      &gt;&gt;&gt; df2 = pd.DataFrame([[28, &#39;low&#39;],
 |      ...                     [30, &#39;low&#39;],
 |      ...                     [35.1, &#39;medium&#39;]],
 |      ...                    columns=[&#39;temp_celsius&#39;, &#39;windspeed&#39;],
 |      ...                    index=pd.DatetimeIndex([&#39;2014-02-12&#39;, &#39;2014-02-13&#39;,
 |      ...                                            &#39;2014-02-15&#39;]))
 |      
 |      &gt;&gt;&gt; df2
 |                  temp_celsius windspeed
 |      2014-02-12          28.0       low
 |      2014-02-13          30.0       low
 |      2014-02-15          35.1    medium
 |      
 |      &gt;&gt;&gt; df2.reindex_like(df1)
 |                  temp_celsius  temp_fahrenheit windspeed
 |      2014-02-12          28.0              NaN       low
 |      2014-02-13          30.0              NaN       low
 |      2014-02-14           NaN              NaN       NaN
 |      2014-02-15          35.1              NaN    medium
 |  
 |  rename_axis(self, mapper=None, index=None, columns=None, axis=None, copy=True, inplace=False)
 |      Set the name of the axis for the index or columns.
 |      
 |      Parameters
 |      ----------
 |      mapper : scalar, list-like, optional
 |          Value to set the axis name attribute.
 |      index, columns : scalar, list-like, dict-like or function, optional
 |          A scalar, list-like, dict-like or functions transformations to
 |          apply to that axis&#39; values.
 |          Note that the ``columns`` parameter is not allowed if the
 |          object is a Series. This parameter only apply for DataFrame
 |          type objects.
 |      
 |          Use either ``mapper`` and ``axis`` to
 |          specify the axis to target with ``mapper``, or ``index``
 |          and/or ``columns``.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          The axis to rename.
 |      copy : bool, default True
 |          Also copy underlying data.
 |      inplace : bool, default False
 |          Modifies the object directly, instead of creating a new Series
 |          or DataFrame.
 |      
 |      Returns
 |      -------
 |      Series, DataFrame, or None
 |          The same type as the caller or None if ``inplace=True``.
 |      
 |      See Also
 |      --------
 |      Series.rename : Alter Series index labels or name.
 |      DataFrame.rename : Alter DataFrame index labels or name.
 |      Index.rename : Set new names on index.
 |      
 |      Notes
 |      -----
 |      ``DataFrame.rename_axis`` supports two calling conventions
 |      
 |      * ``(index=index_mapper, columns=columns_mapper, ...)``
 |      * ``(mapper, axis={&#39;index&#39;, &#39;columns&#39;}, ...)``
 |      
 |      The first calling convention will only modify the names of
 |      the index and/or the names of the Index object that is the columns.
 |      In this case, the parameter ``copy`` is ignored.
 |      
 |      The second calling convention will modify the names of the
 |      corresponding index if mapper is a list or a scalar.
 |      However, if mapper is dict-like or a function, it will use the
 |      deprecated behavior of modifying the axis *labels*.
 |      
 |      We *highly* recommend using keyword arguments to clarify your
 |      intent.
 |      
 |      Examples
 |      --------
 |      **Series**
 |      
 |      &gt;&gt;&gt; s = pd.Series([&quot;dog&quot;, &quot;cat&quot;, &quot;monkey&quot;])
 |      &gt;&gt;&gt; s
 |      0       dog
 |      1       cat
 |      2    monkey
 |      dtype: object
 |      &gt;&gt;&gt; s.rename_axis(&quot;animal&quot;)
 |      animal
 |      0    dog
 |      1    cat
 |      2    monkey
 |      dtype: object
 |      
 |      **DataFrame**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;num_legs&quot;: [4, 4, 2],
 |      ...                    &quot;num_arms&quot;: [0, 0, 2]},
 |      ...                   [&quot;dog&quot;, &quot;cat&quot;, &quot;monkey&quot;])
 |      &gt;&gt;&gt; df
 |              num_legs  num_arms
 |      dog            4         0
 |      cat            4         0
 |      monkey         2         2
 |      &gt;&gt;&gt; df = df.rename_axis(&quot;animal&quot;)
 |      &gt;&gt;&gt; df
 |              num_legs  num_arms
 |      animal
 |      dog            4         0
 |      cat            4         0
 |      monkey         2         2
 |      &gt;&gt;&gt; df = df.rename_axis(&quot;limbs&quot;, axis=&quot;columns&quot;)
 |      &gt;&gt;&gt; df
 |      limbs   num_legs  num_arms
 |      animal
 |      dog            4         0
 |      cat            4         0
 |      monkey         2         2
 |      
 |      **MultiIndex**
 |      
 |      &gt;&gt;&gt; df.index = pd.MultiIndex.from_product([[&#39;mammal&#39;],
 |      ...                                        [&#39;dog&#39;, &#39;cat&#39;, &#39;monkey&#39;]],
 |      ...                                       names=[&#39;type&#39;, &#39;name&#39;])
 |      &gt;&gt;&gt; df
 |      limbs          num_legs  num_arms
 |      type   name
 |      mammal dog            4         0
 |             cat            4         0
 |             monkey         2         2
 |      
 |      &gt;&gt;&gt; df.rename_axis(index={&#39;type&#39;: &#39;class&#39;})
 |      limbs          num_legs  num_arms
 |      class  name
 |      mammal dog            4         0
 |             cat            4         0
 |             monkey         2         2
 |      
 |      &gt;&gt;&gt; df.rename_axis(columns=str.upper)
 |      LIMBS          num_legs  num_arms
 |      type   name
 |      mammal dog            4         0
 |             cat            4         0
 |             monkey         2         2
 |  
 |  rolling(self, window: &#39;int | timedelta | BaseOffset | BaseIndexer&#39;, min_periods: &#39;int | None&#39; = None, center: &#39;bool_t&#39; = False, win_type: &#39;str | None&#39; = None, on: &#39;str | None&#39; = None, axis: &#39;Axis&#39; = 0, closed: &#39;str | None&#39; = None, method: &#39;str&#39; = &#39;single&#39;)
 |      Provide rolling window calculations.
 |      
 |      Parameters
 |      ----------
 |      window : int, offset, or BaseIndexer subclass
 |          Size of the moving window. This is the number of observations used for
 |          calculating the statistic. Each window will be a fixed size.
 |      
 |          If its an offset then this will be the time period of each window. Each
 |          window will be a variable sized based on the observations included in
 |          the time-period. This is only valid for datetimelike indexes.
 |      
 |          If a BaseIndexer subclass is passed, calculates the window boundaries
 |          based on the defined ``get_window_bounds`` method. Additional rolling
 |          keyword arguments, namely `min_periods`, `center`, and
 |          `closed` will be passed to `get_window_bounds`.
 |      min_periods : int, default None
 |          Minimum number of observations in window required to have a value
 |          (otherwise result is NA). For a window that is specified by an offset,
 |          `min_periods` will default to 1. Otherwise, `min_periods` will default
 |          to the size of the window.
 |      center : bool, default False
 |          Set the labels at the center of the window.
 |      win_type : str, default None
 |          Provide a window type. If ``None``, all points are evenly weighted.
 |          See the notes below for further information.
 |      on : str, optional
 |          For a DataFrame, a datetime-like column or Index level on which
 |          to calculate the rolling window, rather than the DataFrame&#39;s index.
 |          Provided integer column is ignored and excluded from result since
 |          an integer index is not used to calculate the rolling window.
 |      axis : int or str, default 0
 |      closed : str, default None
 |          Make the interval closed on the &#39;right&#39;, &#39;left&#39;, &#39;both&#39; or
 |          &#39;neither&#39; endpoints. Defaults to &#39;right&#39;.
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |              The closed parameter with fixed windows is now supported.
 |      method : str {&#39;single&#39;, &#39;table&#39;}, default &#39;single&#39;
 |          Execute the rolling operation per single column or row (``&#39;single&#39;``)
 |          or over the entire object (``&#39;table&#39;``).
 |      
 |          This argument is only implemented when specifying ``engine=&#39;numba&#39;``
 |          in the method call.
 |      
 |          .. versionadded:: 1.3.0
 |      
 |      Returns
 |      -------
 |      a Window or Rolling sub-classed for the particular operation
 |      
 |      See Also
 |      --------
 |      expanding : Provides expanding transformations.
 |      ewm : Provides exponential weighted functions.
 |      
 |      Notes
 |      -----
 |      By default, the result is set to the right edge of the window. This can be
 |      changed to the center of the window by setting ``center=True``.
 |      
 |      To learn more about the offsets &amp; frequency strings, please see `this link
 |      &lt;https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases&gt;`__.
 |      
 |      If ``win_type=None``, all points are evenly weighted; otherwise, ``win_type``
 |      can accept a string of any `scipy.signal window function
 |      &lt;https://docs.scipy.org/doc/scipy/reference/signal.windows.html#module-scipy.signal.windows&gt;`__.
 |      
 |      Certain Scipy window types require additional parameters to be passed
 |      in the aggregation function. The additional parameters must match
 |      the keywords specified in the Scipy window type method signature.
 |      Please see the third example below on how to add the additional parameters.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;B&#39;: [0, 1, 2, np.nan, 4]})
 |      &gt;&gt;&gt; df
 |           B
 |      0  0.0
 |      1  1.0
 |      2  2.0
 |      3  NaN
 |      4  4.0
 |      
 |      Rolling sum with a window length of 2, using the &#39;triang&#39;
 |      window type.
 |      
 |      &gt;&gt;&gt; df.rolling(2, win_type=&#39;triang&#39;).sum()
 |           B
 |      0  NaN
 |      1  0.5
 |      2  1.5
 |      3  NaN
 |      4  NaN
 |      
 |      Rolling sum with a window length of 2, using the &#39;gaussian&#39;
 |      window type (note how we need to specify std).
 |      
 |      &gt;&gt;&gt; df.rolling(2, win_type=&#39;gaussian&#39;).sum(std=3)
 |                B
 |      0       NaN
 |      1  0.986207
 |      2  2.958621
 |      3       NaN
 |      4       NaN
 |      
 |      Rolling sum with a window length of 2, min_periods defaults
 |      to the window length.
 |      
 |      &gt;&gt;&gt; df.rolling(2).sum()
 |           B
 |      0  NaN
 |      1  1.0
 |      2  3.0
 |      3  NaN
 |      4  NaN
 |      
 |      Same as above, but explicitly set the min_periods
 |      
 |      &gt;&gt;&gt; df.rolling(2, min_periods=1).sum()
 |           B
 |      0  0.0
 |      1  1.0
 |      2  3.0
 |      3  2.0
 |      4  4.0
 |      
 |      Same as above, but with forward-looking windows
 |      
 |      &gt;&gt;&gt; indexer = pd.api.indexers.FixedForwardWindowIndexer(window_size=2)
 |      &gt;&gt;&gt; df.rolling(window=indexer, min_periods=1).sum()
 |           B
 |      0  1.0
 |      1  3.0
 |      2  2.0
 |      3  4.0
 |      4  4.0
 |      
 |      A ragged (meaning not-a-regular frequency), time-indexed DataFrame
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;B&#39;: [0, 1, 2, np.nan, 4]},
 |      ...                   index = [pd.Timestamp(&#39;20130101 09:00:00&#39;),
 |      ...                            pd.Timestamp(&#39;20130101 09:00:02&#39;),
 |      ...                            pd.Timestamp(&#39;20130101 09:00:03&#39;),
 |      ...                            pd.Timestamp(&#39;20130101 09:00:05&#39;),
 |      ...                            pd.Timestamp(&#39;20130101 09:00:06&#39;)])
 |      
 |      &gt;&gt;&gt; df
 |                             B
 |      2013-01-01 09:00:00  0.0
 |      2013-01-01 09:00:02  1.0
 |      2013-01-01 09:00:03  2.0
 |      2013-01-01 09:00:05  NaN
 |      2013-01-01 09:00:06  4.0
 |      
 |      Contrasting to an integer rolling window, this will roll a variable
 |      length window corresponding to the time period.
 |      The default for min_periods is 1.
 |      
 |      &gt;&gt;&gt; df.rolling(&#39;2s&#39;).sum()
 |                             B
 |      2013-01-01 09:00:00  0.0
 |      2013-01-01 09:00:02  1.0
 |      2013-01-01 09:00:03  3.0
 |      2013-01-01 09:00:05  NaN
 |      2013-01-01 09:00:06  4.0
 |  
 |  sample(self: &#39;FrameOrSeries&#39;, n=None, frac: &#39;float | None&#39; = None, replace: &#39;bool_t&#39; = False, weights=None, random_state=None, axis: &#39;Axis | None&#39; = None, ignore_index: &#39;bool_t&#39; = False) -&gt; &#39;FrameOrSeries&#39;
 |      Return a random sample of items from an axis of object.
 |      
 |      You can use `random_state` for reproducibility.
 |      
 |      Parameters
 |      ----------
 |      n : int, optional
 |          Number of items from axis to return. Cannot be used with `frac`.
 |          Default = 1 if `frac` = None.
 |      frac : float, optional
 |          Fraction of axis items to return. Cannot be used with `n`.
 |      replace : bool, default False
 |          Allow or disallow sampling of the same row more than once.
 |      weights : str or ndarray-like, optional
 |          Default &#39;None&#39; results in equal probability weighting.
 |          If passed a Series, will align with target object on index. Index
 |          values in weights not found in sampled object will be ignored and
 |          index values in sampled object not in weights will be assigned
 |          weights of zero.
 |          If called on a DataFrame, will accept the name of a column
 |          when axis = 0.
 |          Unless weights are a Series, weights must be same length as axis
 |          being sampled.
 |          If weights do not sum to 1, they will be normalized to sum to 1.
 |          Missing values in the weights column will be treated as zero.
 |          Infinite values not allowed.
 |      random_state : int, array-like, BitGenerator, np.random.RandomState, optional
 |          If int, array-like, or BitGenerator (NumPy&gt;=1.17), seed for
 |          random number generator
 |          If np.random.RandomState, use as numpy RandomState object.
 |      
 |          .. versionchanged:: 1.1.0
 |      
 |              array-like and BitGenerator (for NumPy&gt;=1.17) object now passed to
 |              np.random.RandomState() as seed
 |      
 |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default None
 |          Axis to sample. Accepts axis number or name. Default is stat axis
 |          for given data type (0 for Series and DataFrames).
 |      ignore_index : bool, default False
 |          If True, the resulting index will be labeled 0, 1, …, n - 1.
 |      
 |          .. versionadded:: 1.3.0
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          A new object of same type as caller containing `n` items randomly
 |          sampled from the caller object.
 |      
 |      See Also
 |      --------
 |      DataFrameGroupBy.sample: Generates random samples from each group of a
 |          DataFrame object.
 |      SeriesGroupBy.sample: Generates random samples from each group of a
 |          Series object.
 |      numpy.random.choice: Generates a random sample from a given 1-D numpy
 |          array.
 |      
 |      Notes
 |      -----
 |      If `frac` &gt; 1, `replacement` should be set to `True`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;num_legs&#39;: [2, 4, 8, 0],
 |      ...                    &#39;num_wings&#39;: [2, 0, 0, 0],
 |      ...                    &#39;num_specimen_seen&#39;: [10, 2, 1, 8]},
 |      ...                   index=[&#39;falcon&#39;, &#39;dog&#39;, &#39;spider&#39;, &#39;fish&#39;])
 |      &gt;&gt;&gt; df
 |              num_legs  num_wings  num_specimen_seen
 |      falcon         2          2                 10
 |      dog            4          0                  2
 |      spider         8          0                  1
 |      fish           0          0                  8
 |      
 |      Extract 3 random elements from the ``Series`` ``df[&#39;num_legs&#39;]``:
 |      Note that we use `random_state` to ensure the reproducibility of
 |      the examples.
 |      
 |      &gt;&gt;&gt; df[&#39;num_legs&#39;].sample(n=3, random_state=1)
 |      fish      0
 |      spider    8
 |      falcon    2
 |      Name: num_legs, dtype: int64
 |      
 |      A random 50% sample of the ``DataFrame`` with replacement:
 |      
 |      &gt;&gt;&gt; df.sample(frac=0.5, replace=True, random_state=1)
 |            num_legs  num_wings  num_specimen_seen
 |      dog          4          0                  2
 |      fish         0          0                  8
 |      
 |      An upsample sample of the ``DataFrame`` with replacement:
 |      Note that `replace` parameter has to be `True` for `frac` parameter &gt; 1.
 |      
 |      &gt;&gt;&gt; df.sample(frac=2, replace=True, random_state=1)
 |              num_legs  num_wings  num_specimen_seen
 |      dog            4          0                  2
 |      fish           0          0                  8
 |      falcon         2          2                 10
 |      falcon         2          2                 10
 |      fish           0          0                  8
 |      dog            4          0                  2
 |      fish           0          0                  8
 |      dog            4          0                  2
 |      
 |      Using a DataFrame column as weights. Rows with larger value in the
 |      `num_specimen_seen` column are more likely to be sampled.
 |      
 |      &gt;&gt;&gt; df.sample(n=2, weights=&#39;num_specimen_seen&#39;, random_state=1)
 |              num_legs  num_wings  num_specimen_seen
 |      falcon         2          2                 10
 |      fish           0          0                  8
 |  
 |  set_flags(self: &#39;FrameOrSeries&#39;, *, copy: &#39;bool_t&#39; = False, allows_duplicate_labels: &#39;bool_t | None&#39; = None) -&gt; &#39;FrameOrSeries&#39;
 |      Return a new object with updated flags.
 |      
 |      Parameters
 |      ----------
 |      allows_duplicate_labels : bool, optional
 |          Whether the returned object allows duplicate labels.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          The same type as the caller.
 |      
 |      See Also
 |      --------
 |      DataFrame.attrs : Global metadata applying to this dataset.
 |      DataFrame.flags : Global flags applying to this object.
 |      
 |      Notes
 |      -----
 |      This method returns a new object that&#39;s a view on the same data
 |      as the input. Mutating the input or the output values will be reflected
 |      in the other.
 |      
 |      This method is intended to be used in method chains.
 |      
 |      &quot;Flags&quot; differ from &quot;metadata&quot;. Flags reflect properties of the
 |      pandas object (the Series or DataFrame). Metadata refer to properties
 |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2]})
 |      &gt;&gt;&gt; df.flags.allows_duplicate_labels
 |      True
 |      &gt;&gt;&gt; df2 = df.set_flags(allows_duplicate_labels=False)
 |      &gt;&gt;&gt; df2.flags.allows_duplicate_labels
 |      False
 |  
 |  slice_shift(self: &#39;FrameOrSeries&#39;, periods: &#39;int&#39; = 1, axis=0) -&gt; &#39;FrameOrSeries&#39;
 |      Equivalent to `shift` without copying data.
 |      The shifted data will not include the dropped periods and the
 |      shifted axis will be smaller than the original.
 |      
 |      .. deprecated:: 1.2.0
 |          slice_shift is deprecated,
 |          use DataFrame/Series.shift instead.
 |      
 |      Parameters
 |      ----------
 |      periods : int
 |          Number of periods to move, can be positive or negative.
 |      
 |      Returns
 |      -------
 |      shifted : same type as caller
 |      
 |      Notes
 |      -----
 |      While the `slice_shift` is faster than `shift`, you may pay for it
 |      later during alignment.
 |  
 |  squeeze(self, axis=None)
 |      Squeeze 1 dimensional axis objects into scalars.
 |      
 |      Series or DataFrames with a single element are squeezed to a scalar.
 |      DataFrames with a single column or a single row are squeezed to a
 |      Series. Otherwise the object is unchanged.
 |      
 |      This method is most useful when you don&#39;t know if your
 |      object is a Series or DataFrame, but you do know it has just a single
 |      column. In that case you can safely call `squeeze` to ensure you have a
 |      Series.
 |      
 |      Parameters
 |      ----------
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}, default None
 |          A specific axis to squeeze. By default, all length-1 axes are
 |          squeezed.
 |      
 |      Returns
 |      -------
 |      DataFrame, Series, or scalar
 |          The projection after squeezing `axis` or all the axes.
 |      
 |      See Also
 |      --------
 |      Series.iloc : Integer-location based indexing for selecting scalars.
 |      DataFrame.iloc : Integer-location based indexing for selecting Series.
 |      Series.to_frame : Inverse of DataFrame.squeeze for a
 |          single-column DataFrame.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; primes = pd.Series([2, 3, 5, 7])
 |      
 |      Slicing might produce a Series with a single value:
 |      
 |      &gt;&gt;&gt; even_primes = primes[primes % 2 == 0]
 |      &gt;&gt;&gt; even_primes
 |      0    2
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; even_primes.squeeze()
 |      2
 |      
 |      Squeezing objects with more than one value in every axis does nothing:
 |      
 |      &gt;&gt;&gt; odd_primes = primes[primes % 2 == 1]
 |      &gt;&gt;&gt; odd_primes
 |      1    3
 |      2    5
 |      3    7
 |      dtype: int64
 |      
 |      &gt;&gt;&gt; odd_primes.squeeze()
 |      1    3
 |      2    5
 |      3    7
 |      dtype: int64
 |      
 |      Squeezing is even more effective when used with DataFrames.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [3, 4]], columns=[&#39;a&#39;, &#39;b&#39;])
 |      &gt;&gt;&gt; df
 |         a  b
 |      0  1  2
 |      1  3  4
 |      
 |      Slicing a single column will produce a DataFrame with the columns
 |      having only one value:
 |      
 |      &gt;&gt;&gt; df_a = df[[&#39;a&#39;]]
 |      &gt;&gt;&gt; df_a
 |         a
 |      0  1
 |      1  3
 |      
 |      So the columns can be squeezed down, resulting in a Series:
 |      
 |      &gt;&gt;&gt; df_a.squeeze(&#39;columns&#39;)
 |      0    1
 |      1    3
 |      Name: a, dtype: int64
 |      
 |      Slicing a single row from a single column will produce a single
 |      scalar DataFrame:
 |      
 |      &gt;&gt;&gt; df_0a = df.loc[df.index &lt; 1, [&#39;a&#39;]]
 |      &gt;&gt;&gt; df_0a
 |         a
 |      0  1
 |      
 |      Squeezing the rows produces a single scalar Series:
 |      
 |      &gt;&gt;&gt; df_0a.squeeze(&#39;rows&#39;)
 |      a    1
 |      Name: 0, dtype: int64
 |      
 |      Squeezing all axes will project directly into a scalar:
 |      
 |      &gt;&gt;&gt; df_0a.squeeze()
 |      1
 |  
 |  swapaxes(self: &#39;FrameOrSeries&#39;, axis1, axis2, copy=True) -&gt; &#39;FrameOrSeries&#39;
 |      Interchange axes and swap values axes appropriately.
 |      
 |      Returns
 |      -------
 |      y : same as input
 |  
 |  tail(self: &#39;FrameOrSeries&#39;, n: &#39;int&#39; = 5) -&gt; &#39;FrameOrSeries&#39;
 |      Return the last `n` rows.
 |      
 |      This function returns last `n` rows from the object based on
 |      position. It is useful for quickly verifying data, for example,
 |      after sorting or appending rows.
 |      
 |      For negative values of `n`, this function returns all rows except
 |      the first `n` rows, equivalent to ``df[n:]``.
 |      
 |      Parameters
 |      ----------
 |      n : int, default 5
 |          Number of rows to select.
 |      
 |      Returns
 |      -------
 |      type of caller
 |          The last `n` rows of the caller object.
 |      
 |      See Also
 |      --------
 |      DataFrame.head : The first `n` rows of the caller object.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;animal&#39;: [&#39;alligator&#39;, &#39;bee&#39;, &#39;falcon&#39;, &#39;lion&#39;,
 |      ...                    &#39;monkey&#39;, &#39;parrot&#39;, &#39;shark&#39;, &#39;whale&#39;, &#39;zebra&#39;]})
 |      &gt;&gt;&gt; df
 |            animal
 |      0  alligator
 |      1        bee
 |      2     falcon
 |      3       lion
 |      4     monkey
 |      5     parrot
 |      6      shark
 |      7      whale
 |      8      zebra
 |      
 |      Viewing the last 5 lines
 |      
 |      &gt;&gt;&gt; df.tail()
 |         animal
 |      4  monkey
 |      5  parrot
 |      6   shark
 |      7   whale
 |      8   zebra
 |      
 |      Viewing the last `n` lines (three in this case)
 |      
 |      &gt;&gt;&gt; df.tail(3)
 |        animal
 |      6  shark
 |      7  whale
 |      8  zebra
 |      
 |      For negative values of `n`
 |      
 |      &gt;&gt;&gt; df.tail(-3)
 |         animal
 |      3    lion
 |      4  monkey
 |      5  parrot
 |      6   shark
 |      7   whale
 |      8   zebra
 |  
 |  take(self: &#39;FrameOrSeries&#39;, indices, axis=0, is_copy: &#39;bool_t | None&#39; = None, **kwargs) -&gt; &#39;FrameOrSeries&#39;
 |      Return the elements in the given *positional* indices along an axis.
 |      
 |      This means that we are not indexing according to actual values in
 |      the index attribute of the object. We are indexing according to the
 |      actual position of the element in the object.
 |      
 |      Parameters
 |      ----------
 |      indices : array-like
 |          An array of ints indicating which positions to take.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;, None}, default 0
 |          The axis on which to select elements. ``0`` means that we are
 |          selecting rows, ``1`` means that we are selecting columns.
 |      is_copy : bool
 |          Before pandas 1.0, ``is_copy=False`` can be specified to ensure
 |          that the return value is an actual copy. Starting with pandas 1.0,
 |          ``take`` always returns a copy, and the keyword is therefore
 |          deprecated.
 |      
 |          .. deprecated:: 1.0.0
 |      **kwargs
 |          For compatibility with :meth:`numpy.take`. Has no effect on the
 |          output.
 |      
 |      Returns
 |      -------
 |      taken : same type as caller
 |          An array-like containing the elements taken from the object.
 |      
 |      See Also
 |      --------
 |      DataFrame.loc : Select a subset of a DataFrame by labels.
 |      DataFrame.iloc : Select a subset of a DataFrame by positions.
 |      numpy.take : Take elements from an array along an axis.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([(&#39;falcon&#39;, &#39;bird&#39;, 389.0),
 |      ...                    (&#39;parrot&#39;, &#39;bird&#39;, 24.0),
 |      ...                    (&#39;lion&#39;, &#39;mammal&#39;, 80.5),
 |      ...                    (&#39;monkey&#39;, &#39;mammal&#39;, np.nan)],
 |      ...                   columns=[&#39;name&#39;, &#39;class&#39;, &#39;max_speed&#39;],
 |      ...                   index=[0, 2, 3, 1])
 |      &gt;&gt;&gt; df
 |           name   class  max_speed
 |      0  falcon    bird      389.0
 |      2  parrot    bird       24.0
 |      3    lion  mammal       80.5
 |      1  monkey  mammal        NaN
 |      
 |      Take elements at positions 0 and 3 along the axis 0 (default).
 |      
 |      Note how the actual indices selected (0 and 1) do not correspond to
 |      our selected indices 0 and 3. That&#39;s because we are selecting the 0th
 |      and 3rd rows, not rows whose indices equal 0 and 3.
 |      
 |      &gt;&gt;&gt; df.take([0, 3])
 |           name   class  max_speed
 |      0  falcon    bird      389.0
 |      1  monkey  mammal        NaN
 |      
 |      Take elements at indices 1 and 2 along the axis 1 (column selection).
 |      
 |      &gt;&gt;&gt; df.take([1, 2], axis=1)
 |          class  max_speed
 |      0    bird      389.0
 |      2    bird       24.0
 |      3  mammal       80.5
 |      1  mammal        NaN
 |      
 |      We may take elements using negative integers for positive indices,
 |      starting from the end of the object, just like with Python lists.
 |      
 |      &gt;&gt;&gt; df.take([-1, -2])
 |           name   class  max_speed
 |      1  monkey  mammal        NaN
 |      3    lion  mammal       80.5
 |  
 |  to_clipboard(self, excel: &#39;bool_t&#39; = True, sep: &#39;str | None&#39; = None, **kwargs) -&gt; &#39;None&#39;
 |      Copy object to the system clipboard.
 |      
 |      Write a text representation of object to the system clipboard.
 |      This can be pasted into Excel, for example.
 |      
 |      Parameters
 |      ----------
 |      excel : bool, default True
 |          Produce output in a csv format for easy pasting into excel.
 |      
 |          - True, use the provided separator for csv pasting.
 |          - False, write a string representation of the object to the clipboard.
 |      
 |      sep : str, default ``&#39;\t&#39;``
 |          Field delimiter.
 |      **kwargs
 |          These parameters will be passed to DataFrame.to_csv.
 |      
 |      See Also
 |      --------
 |      DataFrame.to_csv : Write a DataFrame to a comma-separated values
 |          (csv) file.
 |      read_clipboard : Read text from clipboard and pass to read_table.
 |      
 |      Notes
 |      -----
 |      Requirements for your platform.
 |      
 |        - Linux : `xclip`, or `xsel` (with `PyQt4` modules)
 |        - Windows : none
 |        - OS X : none
 |      
 |      Examples
 |      --------
 |      Copy the contents of a DataFrame to the clipboard.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2, 3], [4, 5, 6]], columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      
 |      &gt;&gt;&gt; df.to_clipboard(sep=&#39;,&#39;)  # doctest: +SKIP
 |      ... # Wrote the following to the system clipboard:
 |      ... # ,A,B,C
 |      ... # 0,1,2,3
 |      ... # 1,4,5,6
 |      
 |      We can omit the index by passing the keyword `index` and setting
 |      it to false.
 |      
 |      &gt;&gt;&gt; df.to_clipboard(sep=&#39;,&#39;, index=False)  # doctest: +SKIP
 |      ... # Wrote the following to the system clipboard:
 |      ... # A,B,C
 |      ... # 1,2,3
 |      ... # 4,5,6
 |  
 |  to_csv(self, path_or_buf: &#39;FilePathOrBuffer[AnyStr] | None&#39; = None, sep: &#39;str&#39; = &#39;,&#39;, na_rep: &#39;str&#39; = &#39;&#39;, float_format: &#39;str | None&#39; = None, columns: &#39;Sequence[Hashable] | None&#39; = None, header: &#39;bool_t | list[str]&#39; = True, index: &#39;bool_t&#39; = True, index_label: &#39;IndexLabel | None&#39; = None, mode: &#39;str&#39; = &#39;w&#39;, encoding: &#39;str | None&#39; = None, compression: &#39;CompressionOptions&#39; = &#39;infer&#39;, quoting: &#39;int | None&#39; = None, quotechar: &#39;str&#39; = &#39;&quot;&#39;, line_terminator: &#39;str | None&#39; = None, chunksize: &#39;int | None&#39; = None, date_format: &#39;str | None&#39; = None, doublequote: &#39;bool_t&#39; = True, escapechar: &#39;str | None&#39; = None, decimal: &#39;str&#39; = &#39;.&#39;, errors: &#39;str&#39; = &#39;strict&#39;, storage_options: &#39;StorageOptions&#39; = None) -&gt; &#39;str | None&#39;
 |      Write object to a comma-separated values (csv) file.
 |      
 |      Parameters
 |      ----------
 |      path_or_buf : str or file handle, default None
 |          File path or object, if None is provided the result is returned as
 |          a string.  If a non-binary file object is passed, it should be opened
 |          with `newline=&#39;&#39;`, disabling universal newlines. If a binary
 |          file object is passed, `mode` might need to contain a `&#39;b&#39;`.
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |             Support for binary file objects was introduced.
 |      
 |      sep : str, default &#39;,&#39;
 |          String of length 1. Field delimiter for the output file.
 |      na_rep : str, default &#39;&#39;
 |          Missing data representation.
 |      float_format : str, default None
 |          Format string for floating point numbers.
 |      columns : sequence, optional
 |          Columns to write.
 |      header : bool or list of str, default True
 |          Write out the column names. If a list of strings is given it is
 |          assumed to be aliases for the column names.
 |      index : bool, default True
 |          Write row names (index).
 |      index_label : str or sequence, or False, default None
 |          Column label for index column(s) if desired. If None is given, and
 |          `header` and `index` are True, then the index names are used. A
 |          sequence should be given if the object uses MultiIndex. If
 |          False do not print fields for index names. Use index_label=False
 |          for easier importing in R.
 |      mode : str
 |          Python write mode, default &#39;w&#39;.
 |      encoding : str, optional
 |          A string representing the encoding to use in the output file,
 |          defaults to &#39;utf-8&#39;. `encoding` is not supported if `path_or_buf`
 |          is a non-binary file object.
 |      compression : str or dict, default &#39;infer&#39;
 |          If str, represents compression mode. If dict, value at &#39;method&#39; is
 |          the compression mode. Compression mode may be any of the following
 |          possible values: {&#39;infer&#39;, &#39;gzip&#39;, &#39;bz2&#39;, &#39;zip&#39;, &#39;xz&#39;, None}. If
 |          compression mode is &#39;infer&#39; and `path_or_buf` is path-like, then
 |          detect compression mode from the following extensions: &#39;.gz&#39;,
 |          &#39;.bz2&#39;, &#39;.zip&#39; or &#39;.xz&#39;. (otherwise no compression). If dict given
 |          and mode is one of {&#39;zip&#39;, &#39;gzip&#39;, &#39;bz2&#39;}, or inferred as
 |          one of the above, other entries passed as
 |          additional compression options.
 |      
 |          .. versionchanged:: 1.0.0
 |      
 |             May now be a dict with key &#39;method&#39; as compression mode
 |             and other entries as additional compression options if
 |             compression mode is &#39;zip&#39;.
 |      
 |          .. versionchanged:: 1.1.0
 |      
 |             Passing compression options as keys in dict is
 |             supported for compression modes &#39;gzip&#39; and &#39;bz2&#39;
 |             as well as &#39;zip&#39;.
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |              Compression is supported for binary file objects.
 |      
 |          .. versionchanged:: 1.2.0
 |      
 |              Previous versions forwarded dict entries for &#39;gzip&#39; to
 |              `gzip.open` instead of `gzip.GzipFile` which prevented
 |              setting `mtime`.
 |      
 |      quoting : optional constant from csv module
 |          Defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`
 |          then floats are converted to strings and thus csv.QUOTE_NONNUMERIC
 |          will treat them as non-numeric.
 |      quotechar : str, default &#39;\&quot;&#39;
 |          String of length 1. Character used to quote fields.
 |      line_terminator : str, optional
 |          The newline character or character sequence to use in the output
 |          file. Defaults to `os.linesep`, which depends on the OS in which
 |          this method is called (&#39;\\n&#39; for linux, &#39;\\r\\n&#39; for Windows, i.e.).
 |      chunksize : int or None
 |          Rows to write at a time.
 |      date_format : str, default None
 |          Format string for datetime objects.
 |      doublequote : bool, default True
 |          Control quoting of `quotechar` inside a field.
 |      escapechar : str, default None
 |          String of length 1. Character used to escape `sep` and `quotechar`
 |          when appropriate.
 |      decimal : str, default &#39;.&#39;
 |          Character recognized as decimal separator. E.g. use &#39;,&#39; for
 |          European data.
 |      errors : str, default &#39;strict&#39;
 |          Specifies how encoding and decoding errors are to be handled.
 |          See the errors argument for :func:`open` for a full list
 |          of options.
 |      
 |          .. versionadded:: 1.1.0
 |      
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib`` as header options. For other URLs (e.g.
 |          starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are forwarded to
 |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      Returns
 |      -------
 |      None or str
 |          If path_or_buf is None, returns the resulting csv format as a
 |          string. Otherwise returns None.
 |      
 |      See Also
 |      --------
 |      read_csv : Load a CSV file into a DataFrame.
 |      to_excel : Write DataFrame to an Excel file.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;name&#39;: [&#39;Raphael&#39;, &#39;Donatello&#39;],
 |      ...                    &#39;mask&#39;: [&#39;red&#39;, &#39;purple&#39;],
 |      ...                    &#39;weapon&#39;: [&#39;sai&#39;, &#39;bo staff&#39;]})
 |      &gt;&gt;&gt; df.to_csv(index=False)
 |      &#39;name,mask,weapon\nRaphael,red,sai\nDonatello,purple,bo staff\n&#39;
 |      
 |      Create &#39;out.zip&#39; containing &#39;out.csv&#39;
 |      
 |      &gt;&gt;&gt; compression_opts = dict(method=&#39;zip&#39;,
 |      ...                         archive_name=&#39;out.csv&#39;)  # doctest: +SKIP
 |      &gt;&gt;&gt; df.to_csv(&#39;out.zip&#39;, index=False,
 |      ...           compression=compression_opts)  # doctest: +SKIP
 |  
 |  to_excel(self, excel_writer, sheet_name: &#39;str&#39; = &#39;Sheet1&#39;, na_rep: &#39;str&#39; = &#39;&#39;, float_format: &#39;str | None&#39; = None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep=&#39;inf&#39;, verbose=True, freeze_panes=None, storage_options: &#39;StorageOptions&#39; = None) -&gt; &#39;None&#39;
 |      Write object to an Excel sheet.
 |      
 |      To write a single object to an Excel .xlsx file it is only necessary to
 |      specify a target file name. To write to multiple sheets it is necessary to
 |      create an `ExcelWriter` object with a target file name, and specify a sheet
 |      in the file to write to.
 |      
 |      Multiple sheets may be written to by specifying unique `sheet_name`.
 |      With all data written to the file it is necessary to save the changes.
 |      Note that creating an `ExcelWriter` object with a file name that already
 |      exists will result in the contents of the existing file being erased.
 |      
 |      Parameters
 |      ----------
 |      excel_writer : path-like, file-like, or ExcelWriter object
 |          File path or existing ExcelWriter.
 |      sheet_name : str, default &#39;Sheet1&#39;
 |          Name of sheet which will contain DataFrame.
 |      na_rep : str, default &#39;&#39;
 |          Missing data representation.
 |      float_format : str, optional
 |          Format string for floating point numbers. For example
 |          ``float_format=&quot;%.2f&quot;`` will format 0.1234 to 0.12.
 |      columns : sequence or list of str, optional
 |          Columns to write.
 |      header : bool or list of str, default True
 |          Write out the column names. If a list of string is given it is
 |          assumed to be aliases for the column names.
 |      index : bool, default True
 |          Write row names (index).
 |      index_label : str or sequence, optional
 |          Column label for index column(s) if desired. If not specified, and
 |          `header` and `index` are True, then the index names are used. A
 |          sequence should be given if the DataFrame uses MultiIndex.
 |      startrow : int, default 0
 |          Upper left cell row to dump data frame.
 |      startcol : int, default 0
 |          Upper left cell column to dump data frame.
 |      engine : str, optional
 |          Write engine to use, &#39;openpyxl&#39; or &#39;xlsxwriter&#39;. You can also set this
 |          via the options ``io.excel.xlsx.writer``, ``io.excel.xls.writer``, and
 |          ``io.excel.xlsm.writer``.
 |      
 |          .. deprecated:: 1.2.0
 |      
 |              As the `xlwt &lt;https://pypi.org/project/xlwt/&gt;`__ package is no longer
 |              maintained, the ``xlwt`` engine will be removed in a future version
 |              of pandas.
 |      
 |      merge_cells : bool, default True
 |          Write MultiIndex and Hierarchical Rows as merged cells.
 |      encoding : str, optional
 |          Encoding of the resulting excel file. Only necessary for xlwt,
 |          other writers support unicode natively.
 |      inf_rep : str, default &#39;inf&#39;
 |          Representation for infinity (there is no native representation for
 |          infinity in Excel).
 |      verbose : bool, default True
 |          Display more information in the error logs.
 |      freeze_panes : tuple of int (length 2), optional
 |          Specifies the one-based bottommost row and rightmost column that
 |          is to be frozen.
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib`` as header options. For other URLs (e.g.
 |          starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are forwarded to
 |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      See Also
 |      --------
 |      to_csv : Write DataFrame to a comma-separated values (csv) file.
 |      ExcelWriter : Class for writing DataFrame objects into excel sheets.
 |      read_excel : Read an Excel file into a pandas DataFrame.
 |      read_csv : Read a comma-separated values (csv) file into DataFrame.
 |      
 |      Notes
 |      -----
 |      For compatibility with :meth:`~DataFrame.to_csv`,
 |      to_excel serializes lists and dicts to strings before writing.
 |      
 |      Once a workbook has been saved it is not possible to write further
 |      data without rewriting the whole workbook.
 |      
 |      Examples
 |      --------
 |      
 |      Create, write to and save a workbook:
 |      
 |      &gt;&gt;&gt; df1 = pd.DataFrame([[&#39;a&#39;, &#39;b&#39;], [&#39;c&#39;, &#39;d&#39;]],
 |      ...                    index=[&#39;row 1&#39;, &#39;row 2&#39;],
 |      ...                    columns=[&#39;col 1&#39;, &#39;col 2&#39;])
 |      &gt;&gt;&gt; df1.to_excel(&quot;output.xlsx&quot;)  # doctest: +SKIP
 |      
 |      To specify the sheet name:
 |      
 |      &gt;&gt;&gt; df1.to_excel(&quot;output.xlsx&quot;,
 |      ...              sheet_name=&#39;Sheet_name_1&#39;)  # doctest: +SKIP
 |      
 |      If you wish to write to more than one sheet in the workbook, it is
 |      necessary to specify an ExcelWriter object:
 |      
 |      &gt;&gt;&gt; df2 = df1.copy()
 |      &gt;&gt;&gt; with pd.ExcelWriter(&#39;output.xlsx&#39;) as writer:  # doctest: +SKIP
 |      ...     df1.to_excel(writer, sheet_name=&#39;Sheet_name_1&#39;)
 |      ...     df2.to_excel(writer, sheet_name=&#39;Sheet_name_2&#39;)
 |      
 |      ExcelWriter can also be used to append to an existing Excel file:
 |      
 |      &gt;&gt;&gt; with pd.ExcelWriter(&#39;output.xlsx&#39;,
 |      ...                     mode=&#39;a&#39;) as writer:  # doctest: +SKIP
 |      ...     df.to_excel(writer, sheet_name=&#39;Sheet_name_3&#39;)
 |      
 |      To set the library that is used to write the Excel file,
 |      you can pass the `engine` keyword (the default engine is
 |      automatically chosen depending on the file extension):
 |      
 |      &gt;&gt;&gt; df1.to_excel(&#39;output1.xlsx&#39;, engine=&#39;xlsxwriter&#39;)  # doctest: +SKIP
 |  
 |  to_hdf(self, path_or_buf, key: &#39;str&#39;, mode: &#39;str&#39; = &#39;a&#39;, complevel: &#39;int | None&#39; = None, complib: &#39;str | None&#39; = None, append: &#39;bool_t&#39; = False, format: &#39;str | None&#39; = None, index: &#39;bool_t&#39; = True, min_itemsize: &#39;int | dict[str, int] | None&#39; = None, nan_rep=None, dropna: &#39;bool_t | None&#39; = None, data_columns: &#39;bool_t | list[str] | None&#39; = None, errors: &#39;str&#39; = &#39;strict&#39;, encoding: &#39;str&#39; = &#39;UTF-8&#39;) -&gt; &#39;None&#39;
 |      Write the contained data to an HDF5 file using HDFStore.
 |      
 |      Hierarchical Data Format (HDF) is self-describing, allowing an
 |      application to interpret the structure and contents of a file with
 |      no outside information. One HDF file can hold a mix of related objects
 |      which can be accessed as a group or as individual objects.
 |      
 |      In order to add another DataFrame or Series to an existing HDF file
 |      please use append mode and a different a key.
 |      
 |      .. warning::
 |      
 |         One can store a subclass of ``DataFrame`` or ``Series`` to HDF5,
 |         but the type of the subclass is lost upon storing.
 |      
 |      For more information see the :ref:`user guide &lt;io.hdf5&gt;`.
 |      
 |      Parameters
 |      ----------
 |      path_or_buf : str or pandas.HDFStore
 |          File path or HDFStore object.
 |      key : str
 |          Identifier for the group in the store.
 |      mode : {&#39;a&#39;, &#39;w&#39;, &#39;r+&#39;}, default &#39;a&#39;
 |          Mode to open file:
 |      
 |          - &#39;w&#39;: write, a new file is created (an existing file with
 |            the same name would be deleted).
 |          - &#39;a&#39;: append, an existing file is opened for reading and
 |            writing, and if the file does not exist it is created.
 |          - &#39;r+&#39;: similar to &#39;a&#39;, but the file must already exist.
 |      complevel : {0-9}, optional
 |          Specifies a compression level for data.
 |          A value of 0 disables compression.
 |      complib : {&#39;zlib&#39;, &#39;lzo&#39;, &#39;bzip2&#39;, &#39;blosc&#39;}, default &#39;zlib&#39;
 |          Specifies the compression library to be used.
 |          As of v0.20.2 these additional compressors for Blosc are supported
 |          (default if no compressor specified: &#39;blosc:blosclz&#39;):
 |          {&#39;blosc:blosclz&#39;, &#39;blosc:lz4&#39;, &#39;blosc:lz4hc&#39;, &#39;blosc:snappy&#39;,
 |          &#39;blosc:zlib&#39;, &#39;blosc:zstd&#39;}.
 |          Specifying a compression library which is not available issues
 |          a ValueError.
 |      append : bool, default False
 |          For Table formats, append the input data to the existing.
 |      format : {&#39;fixed&#39;, &#39;table&#39;, None}, default &#39;fixed&#39;
 |          Possible values:
 |      
 |          - &#39;fixed&#39;: Fixed format. Fast writing/reading. Not-appendable,
 |            nor searchable.
 |          - &#39;table&#39;: Table format. Write as a PyTables Table structure
 |            which may perform worse but allow more flexible operations
 |            like searching / selecting subsets of the data.
 |          - If None, pd.get_option(&#39;io.hdf.default_format&#39;) is checked,
 |            followed by fallback to &quot;fixed&quot;
 |      errors : str, default &#39;strict&#39;
 |          Specifies how encoding and decoding errors are to be handled.
 |          See the errors argument for :func:`open` for a full list
 |          of options.
 |      encoding : str, default &quot;UTF-8&quot;
 |      min_itemsize : dict or int, optional
 |          Map column names to minimum string sizes for columns.
 |      nan_rep : Any, optional
 |          How to represent null values as str.
 |          Not allowed with append=True.
 |      data_columns : list of columns or True, optional
 |          List of columns to create as indexed data columns for on-disk
 |          queries, or True to use all columns. By default only the axes
 |          of the object are indexed. See :ref:`io.hdf5-query-data-columns`.
 |          Applicable only to format=&#39;table&#39;.
 |      
 |      See Also
 |      --------
 |      read_hdf : Read from HDF file.
 |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.
 |      DataFrame.to_sql : Write to a SQL table.
 |      DataFrame.to_feather : Write out feather-format for DataFrames.
 |      DataFrame.to_csv : Write out to a csv file.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [1, 2, 3], &#39;B&#39;: [4, 5, 6]},
 |      ...                   index=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])
 |      &gt;&gt;&gt; df.to_hdf(&#39;data.h5&#39;, key=&#39;df&#39;, mode=&#39;w&#39;)
 |      
 |      We can add another object to the same file:
 |      
 |      &gt;&gt;&gt; s = pd.Series([1, 2, 3, 4])
 |      &gt;&gt;&gt; s.to_hdf(&#39;data.h5&#39;, key=&#39;s&#39;)
 |      
 |      Reading from HDF file:
 |      
 |      &gt;&gt;&gt; pd.read_hdf(&#39;data.h5&#39;, &#39;df&#39;)
 |      A  B
 |      a  1  4
 |      b  2  5
 |      c  3  6
 |      &gt;&gt;&gt; pd.read_hdf(&#39;data.h5&#39;, &#39;s&#39;)
 |      0    1
 |      1    2
 |      2    3
 |      3    4
 |      dtype: int64
 |      
 |      Deleting file with data:
 |      
 |      &gt;&gt;&gt; import os
 |      &gt;&gt;&gt; os.remove(&#39;data.h5&#39;)
 |  
 |  to_json(self, path_or_buf: &#39;FilePathOrBuffer | None&#39; = None, orient: &#39;str | None&#39; = None, date_format: &#39;str | None&#39; = None, double_precision: &#39;int&#39; = 10, force_ascii: &#39;bool_t&#39; = True, date_unit: &#39;str&#39; = &#39;ms&#39;, default_handler: &#39;Callable[[Any], JSONSerializable] | None&#39; = None, lines: &#39;bool_t&#39; = False, compression: &#39;CompressionOptions&#39; = &#39;infer&#39;, index: &#39;bool_t&#39; = True, indent: &#39;int | None&#39; = None, storage_options: &#39;StorageOptions&#39; = None) -&gt; &#39;str | None&#39;
 |      Convert the object to a JSON string.
 |      
 |      Note NaN&#39;s and None will be converted to null and datetime objects
 |      will be converted to UNIX timestamps.
 |      
 |      Parameters
 |      ----------
 |      path_or_buf : str or file handle, optional
 |          File path or object. If not specified, the result is returned as
 |          a string.
 |      orient : str
 |          Indication of expected JSON string format.
 |      
 |          * Series:
 |      
 |              - default is &#39;index&#39;
 |              - allowed values are: {&#39;split&#39;, &#39;records&#39;, &#39;index&#39;, &#39;table&#39;}.
 |      
 |          * DataFrame:
 |      
 |              - default is &#39;columns&#39;
 |              - allowed values are: {&#39;split&#39;, &#39;records&#39;, &#39;index&#39;, &#39;columns&#39;,
 |                &#39;values&#39;, &#39;table&#39;}.
 |      
 |          * The format of the JSON string:
 |      
 |              - &#39;split&#39; : dict like {&#39;index&#39; -&gt; [index], &#39;columns&#39; -&gt; [columns],
 |                &#39;data&#39; -&gt; [values]}
 |              - &#39;records&#39; : list like [{column -&gt; value}, ... , {column -&gt; value}]
 |              - &#39;index&#39; : dict like {index -&gt; {column -&gt; value}}
 |              - &#39;columns&#39; : dict like {column -&gt; {index -&gt; value}}
 |              - &#39;values&#39; : just the values array
 |              - &#39;table&#39; : dict like {&#39;schema&#39;: {schema}, &#39;data&#39;: {data}}
 |      
 |              Describing the data, where data component is like ``orient=&#39;records&#39;``.
 |      
 |      date_format : {None, &#39;epoch&#39;, &#39;iso&#39;}
 |          Type of date conversion. &#39;epoch&#39; = epoch milliseconds,
 |          &#39;iso&#39; = ISO8601. The default depends on the `orient`. For
 |          ``orient=&#39;table&#39;``, the default is &#39;iso&#39;. For all other orients,
 |          the default is &#39;epoch&#39;.
 |      double_precision : int, default 10
 |          The number of decimal places to use when encoding
 |          floating point values.
 |      force_ascii : bool, default True
 |          Force encoded string to be ASCII.
 |      date_unit : str, default &#39;ms&#39; (milliseconds)
 |          The time unit to encode to, governs timestamp and ISO8601
 |          precision.  One of &#39;s&#39;, &#39;ms&#39;, &#39;us&#39;, &#39;ns&#39; for second, millisecond,
 |          microsecond, and nanosecond respectively.
 |      default_handler : callable, default None
 |          Handler to call if object cannot otherwise be converted to a
 |          suitable format for JSON. Should receive a single argument which is
 |          the object to convert and return a serialisable object.
 |      lines : bool, default False
 |          If &#39;orient&#39; is &#39;records&#39; write out line-delimited json format. Will
 |          throw ValueError if incorrect &#39;orient&#39; since others are not
 |          list-like.
 |      
 |      compression : {&#39;infer&#39;, &#39;gzip&#39;, &#39;bz2&#39;, &#39;zip&#39;, &#39;xz&#39;, None}
 |      
 |          A string representing the compression to use in the output file,
 |          only used when the first argument is a filename. By default, the
 |          compression is inferred from the filename.
 |      index : bool, default True
 |          Whether to include the index values in the JSON string. Not
 |          including the index (``index=False``) is only supported when
 |          orient is &#39;split&#39; or &#39;table&#39;.
 |      indent : int, optional
 |         Length of whitespace used to indent each record.
 |      
 |         .. versionadded:: 1.0.0
 |      
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib`` as header options. For other URLs (e.g.
 |          starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are forwarded to
 |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      Returns
 |      -------
 |      None or str
 |          If path_or_buf is None, returns the resulting json format as a
 |          string. Otherwise returns None.
 |      
 |      See Also
 |      --------
 |      read_json : Convert a JSON string to pandas object.
 |      
 |      Notes
 |      -----
 |      The behavior of ``indent=0`` varies from the stdlib, which does not
 |      indent the output but does insert newlines. Currently, ``indent=0``
 |      and the default ``indent=None`` are equivalent in pandas, though this
 |      may change in a future release.
 |      
 |      ``orient=&#39;table&#39;`` contains a &#39;pandas_version&#39; field under &#39;schema&#39;.
 |      This stores the version of `pandas` used in the latest revision of the
 |      schema.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; import json
 |      &gt;&gt;&gt; df = pd.DataFrame(
 |      ...     [[&quot;a&quot;, &quot;b&quot;], [&quot;c&quot;, &quot;d&quot;]],
 |      ...     index=[&quot;row 1&quot;, &quot;row 2&quot;],
 |      ...     columns=[&quot;col 1&quot;, &quot;col 2&quot;],
 |      ... )
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;split&quot;)
 |      &gt;&gt;&gt; parsed = json.loads(result)
 |      &gt;&gt;&gt; json.dumps(parsed, indent=4)  # doctest: +SKIP
 |      {
 |          &quot;columns&quot;: [
 |              &quot;col 1&quot;,
 |              &quot;col 2&quot;
 |          ],
 |          &quot;index&quot;: [
 |              &quot;row 1&quot;,
 |              &quot;row 2&quot;
 |          ],
 |          &quot;data&quot;: [
 |              [
 |                  &quot;a&quot;,
 |                  &quot;b&quot;
 |              ],
 |              [
 |                  &quot;c&quot;,
 |                  &quot;d&quot;
 |              ]
 |          ]
 |      }
 |      
 |      Encoding/decoding a Dataframe using ``&#39;records&#39;`` formatted JSON.
 |      Note that index labels are not preserved with this encoding.
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;records&quot;)
 |      &gt;&gt;&gt; parsed = json.loads(result)
 |      &gt;&gt;&gt; json.dumps(parsed, indent=4)  # doctest: +SKIP
 |      [
 |          {
 |              &quot;col 1&quot;: &quot;a&quot;,
 |              &quot;col 2&quot;: &quot;b&quot;
 |          },
 |          {
 |              &quot;col 1&quot;: &quot;c&quot;,
 |              &quot;col 2&quot;: &quot;d&quot;
 |          }
 |      ]
 |      
 |      Encoding/decoding a Dataframe using ``&#39;index&#39;`` formatted JSON:
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;index&quot;)
 |      &gt;&gt;&gt; parsed = json.loads(result)
 |      &gt;&gt;&gt; json.dumps(parsed, indent=4)  # doctest: +SKIP
 |      {
 |          &quot;row 1&quot;: {
 |              &quot;col 1&quot;: &quot;a&quot;,
 |              &quot;col 2&quot;: &quot;b&quot;
 |          },
 |          &quot;row 2&quot;: {
 |              &quot;col 1&quot;: &quot;c&quot;,
 |              &quot;col 2&quot;: &quot;d&quot;
 |          }
 |      }
 |      
 |      Encoding/decoding a Dataframe using ``&#39;columns&#39;`` formatted JSON:
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;columns&quot;)
 |      &gt;&gt;&gt; parsed = json.loads(result)
 |      &gt;&gt;&gt; json.dumps(parsed, indent=4)  # doctest: +SKIP
 |      {
 |          &quot;col 1&quot;: {
 |              &quot;row 1&quot;: &quot;a&quot;,
 |              &quot;row 2&quot;: &quot;c&quot;
 |          },
 |          &quot;col 2&quot;: {
 |              &quot;row 1&quot;: &quot;b&quot;,
 |              &quot;row 2&quot;: &quot;d&quot;
 |          }
 |      }
 |      
 |      Encoding/decoding a Dataframe using ``&#39;values&#39;`` formatted JSON:
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;values&quot;)
 |      &gt;&gt;&gt; parsed = json.loads(result)
 |      &gt;&gt;&gt; json.dumps(parsed, indent=4)  # doctest: +SKIP
 |      [
 |          [
 |              &quot;a&quot;,
 |              &quot;b&quot;
 |          ],
 |          [
 |              &quot;c&quot;,
 |              &quot;d&quot;
 |          ]
 |      ]
 |      
 |      Encoding with Table Schema:
 |      
 |      &gt;&gt;&gt; result = df.to_json(orient=&quot;table&quot;)
 |      &gt;&gt;&gt; parsed = json.loads(result)
 |      &gt;&gt;&gt; json.dumps(parsed, indent=4)  # doctest: +SKIP
 |      {
 |          &quot;schema&quot;: {
 |              &quot;fields&quot;: [
 |                  {
 |                      &quot;name&quot;: &quot;index&quot;,
 |                      &quot;type&quot;: &quot;string&quot;
 |                  },
 |                  {
 |                      &quot;name&quot;: &quot;col 1&quot;,
 |                      &quot;type&quot;: &quot;string&quot;
 |                  },
 |                  {
 |                      &quot;name&quot;: &quot;col 2&quot;,
 |                      &quot;type&quot;: &quot;string&quot;
 |                  }
 |              ],
 |              &quot;primaryKey&quot;: [
 |                  &quot;index&quot;
 |              ],
 |              &quot;pandas_version&quot;: &quot;0.20.0&quot;
 |          },
 |          &quot;data&quot;: [
 |              {
 |                  &quot;index&quot;: &quot;row 1&quot;,
 |                  &quot;col 1&quot;: &quot;a&quot;,
 |                  &quot;col 2&quot;: &quot;b&quot;
 |              },
 |              {
 |                  &quot;index&quot;: &quot;row 2&quot;,
 |                  &quot;col 1&quot;: &quot;c&quot;,
 |                  &quot;col 2&quot;: &quot;d&quot;
 |              }
 |          ]
 |      }
 |  
 |  to_latex(self, buf=None, columns=None, col_space=None, header=True, index=True, na_rep=&#39;NaN&#39;, formatters=None, float_format=None, sparsify=None, index_names=True, bold_rows=False, column_format=None, longtable=None, escape=None, encoding=None, decimal=&#39;.&#39;, multicolumn=None, multicolumn_format=None, multirow=None, caption=None, label=None, position=None)
 |      Render object to a LaTeX tabular, longtable, or nested table/tabular.
 |      
 |      Requires ``\usepackage{booktabs}``.  The output can be copy/pasted
 |      into a main LaTeX document or read from an external file
 |      with ``\input{table.tex}``.
 |      
 |      .. versionchanged:: 1.0.0
 |         Added caption and label arguments.
 |      
 |      .. versionchanged:: 1.2.0
 |         Added position argument, changed meaning of caption argument.
 |      
 |      Parameters
 |      ----------
 |      buf : str, Path or StringIO-like, optional, default None
 |          Buffer to write to. If None, the output is returned as a string.
 |      columns : list of label, optional
 |          The subset of columns to write. Writes all columns by default.
 |      col_space : int, optional
 |          The minimum width of each column.
 |      header : bool or list of str, default True
 |          Write out the column names. If a list of strings is given,
 |          it is assumed to be aliases for the column names.
 |      index : bool, default True
 |          Write row names (index).
 |      na_rep : str, default &#39;NaN&#39;
 |          Missing data representation.
 |      formatters : list of functions or dict of {str: function}, optional
 |          Formatter functions to apply to columns&#39; elements by position or
 |          name. The result of each function must be a unicode string.
 |          List must be of length equal to the number of columns.
 |      float_format : one-parameter function or str, optional, default None
 |          Formatter for floating point numbers. For example
 |          ``float_format=&quot;%.2f&quot;`` and ``float_format=&quot;{:0.2f}&quot;.format`` will
 |          both result in 0.1234 being formatted as 0.12.
 |      sparsify : bool, optional
 |          Set to False for a DataFrame with a hierarchical index to print
 |          every multiindex key at each row. By default, the value will be
 |          read from the config module.
 |      index_names : bool, default True
 |          Prints the names of the indexes.
 |      bold_rows : bool, default False
 |          Make the row labels bold in the output.
 |      column_format : str, optional
 |          The columns format as specified in `LaTeX table format
 |          &lt;https://en.wikibooks.org/wiki/LaTeX/Tables&gt;`__ e.g. &#39;rcl&#39; for 3
 |          columns. By default, &#39;l&#39; will be used for all columns except
 |          columns of numbers, which default to &#39;r&#39;.
 |      longtable : bool, optional
 |          By default, the value will be read from the pandas config
 |          module. Use a longtable environment instead of tabular. Requires
 |          adding a \usepackage{longtable} to your LaTeX preamble.
 |      escape : bool, optional
 |          By default, the value will be read from the pandas config
 |          module. When set to False prevents from escaping latex special
 |          characters in column names.
 |      encoding : str, optional
 |          A string representing the encoding to use in the output file,
 |          defaults to &#39;utf-8&#39;.
 |      decimal : str, default &#39;.&#39;
 |          Character recognized as decimal separator, e.g. &#39;,&#39; in Europe.
 |      multicolumn : bool, default True
 |          Use \multicolumn to enhance MultiIndex columns.
 |          The default will be read from the config module.
 |      multicolumn_format : str, default &#39;l&#39;
 |          The alignment for multicolumns, similar to `column_format`
 |          The default will be read from the config module.
 |      multirow : bool, default False
 |          Use \multirow to enhance MultiIndex rows. Requires adding a
 |          \usepackage{multirow} to your LaTeX preamble. Will print
 |          centered labels (instead of top-aligned) across the contained
 |          rows, separating groups via clines. The default will be read
 |          from the pandas config module.
 |      caption : str or tuple, optional
 |          Tuple (full_caption, short_caption),
 |          which results in ``\caption[short_caption]{full_caption}``;
 |          if a single string is passed, no short caption will be set.
 |      
 |          .. versionadded:: 1.0.0
 |      
 |          .. versionchanged:: 1.2.0
 |             Optionally allow caption to be a tuple ``(full_caption, short_caption)``.
 |      
 |      label : str, optional
 |          The LaTeX label to be placed inside ``\label{}`` in the output.
 |          This is used with ``\ref{}`` in the main ``.tex`` file.
 |      
 |          .. versionadded:: 1.0.0
 |      position : str, optional
 |          The LaTeX positional argument for tables, to be placed after
 |          ``\begin{}`` in the output.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |              Returns
 |              -------
 |              str or None
 |                  If buf is None, returns the result as a string. Otherwise returns
 |                  None.
 |          
 |      See Also
 |      --------
 |      DataFrame.to_string : Render a DataFrame to a console-friendly
 |          tabular output.
 |      DataFrame.to_html : Render a DataFrame as an HTML table.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame(dict(name=[&#39;Raphael&#39;, &#39;Donatello&#39;],
 |      ...                   mask=[&#39;red&#39;, &#39;purple&#39;],
 |      ...                   weapon=[&#39;sai&#39;, &#39;bo staff&#39;]))
 |      &gt;&gt;&gt; print(df.to_latex(index=False))  # doctest: +NORMALIZE_WHITESPACE
 |      \begin{tabular}{lll}
 |       \toprule
 |             name &amp;    mask &amp;    weapon \\
 |       \midrule
 |          Raphael &amp;     red &amp;       sai \\
 |        Donatello &amp;  purple &amp;  bo staff \\
 |      \bottomrule
 |      \end{tabular}
 |  
 |  to_pickle(self, path, compression: &#39;CompressionOptions&#39; = &#39;infer&#39;, protocol: &#39;int&#39; = 4, storage_options: &#39;StorageOptions&#39; = None) -&gt; &#39;None&#39;
 |      Pickle (serialize) object to file.
 |      
 |      Parameters
 |      ----------
 |      path : str
 |          File path where the pickled object will be stored.
 |      compression : {&#39;infer&#39;, &#39;gzip&#39;, &#39;bz2&#39;, &#39;zip&#39;, &#39;xz&#39;, None},         default &#39;infer&#39;
 |          A string representing the compression to use in the output file. By
 |          default, infers from the file extension in specified path.
 |          Compression mode may be any of the following possible
 |          values: {‘infer’, ‘gzip’, ‘bz2’, ‘zip’, ‘xz’, None}. If compression
 |          mode is ‘infer’ and path_or_buf is path-like, then detect
 |          compression mode from the following extensions:
 |          ‘.gz’, ‘.bz2’, ‘.zip’ or ‘.xz’. (otherwise no compression).
 |          If dict given and mode is ‘zip’ or inferred as ‘zip’, other entries
 |          passed as additional compression options.
 |      protocol : int
 |          Int which indicates which protocol should be used by the pickler,
 |          default HIGHEST_PROTOCOL (see [1]_ paragraph 12.1.2). The possible
 |          values are 0, 1, 2, 3, 4, 5. A negative value for the protocol
 |          parameter is equivalent to setting its value to HIGHEST_PROTOCOL.
 |      
 |          .. [1] https://docs.python.org/3/library/pickle.html.
 |      
 |      storage_options : dict, optional
 |          Extra options that make sense for a particular storage connection, e.g.
 |          host, port, username, password, etc. For HTTP(S) URLs the key-value pairs
 |          are forwarded to ``urllib`` as header options. For other URLs (e.g.
 |          starting with &quot;s3://&quot;, and &quot;gcs://&quot;) the key-value pairs are forwarded to
 |          ``fsspec``. Please see ``fsspec`` and ``urllib`` for more details.
 |      
 |          .. versionadded:: 1.2.0
 |      
 |      See Also
 |      --------
 |      read_pickle : Load pickled pandas object (or any object) from file.
 |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.
 |      DataFrame.to_sql : Write DataFrame to a SQL database.
 |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; original_df = pd.DataFrame({&quot;foo&quot;: range(5), &quot;bar&quot;: range(5, 10)})
 |      &gt;&gt;&gt; original_df
 |         foo  bar
 |      0    0    5
 |      1    1    6
 |      2    2    7
 |      3    3    8
 |      4    4    9
 |      &gt;&gt;&gt; original_df.to_pickle(&quot;./dummy.pkl&quot;)
 |      
 |      &gt;&gt;&gt; unpickled_df = pd.read_pickle(&quot;./dummy.pkl&quot;)
 |      &gt;&gt;&gt; unpickled_df
 |         foo  bar
 |      0    0    5
 |      1    1    6
 |      2    2    7
 |      3    3    8
 |      4    4    9
 |      
 |      &gt;&gt;&gt; import os
 |      &gt;&gt;&gt; os.remove(&quot;./dummy.pkl&quot;)
 |  
 |  to_sql(self, name: &#39;str&#39;, con, schema=None, if_exists: &#39;str&#39; = &#39;fail&#39;, index: &#39;bool_t&#39; = True, index_label=None, chunksize=None, dtype: &#39;DtypeArg | None&#39; = None, method=None) -&gt; &#39;None&#39;
 |      Write records stored in a DataFrame to a SQL database.
 |      
 |      Databases supported by SQLAlchemy [1]_ are supported. Tables can be
 |      newly created, appended to, or overwritten.
 |      
 |      Parameters
 |      ----------
 |      name : str
 |          Name of SQL table.
 |      con : sqlalchemy.engine.(Engine or Connection) or sqlite3.Connection
 |          Using SQLAlchemy makes it possible to use any DB supported by that
 |          library. Legacy support is provided for sqlite3.Connection objects. The user
 |          is responsible for engine disposal and connection closure for the SQLAlchemy
 |          connectable See `here                 &lt;https://docs.sqlalchemy.org/en/13/core/connections.html&gt;`_.
 |      
 |      schema : str, optional
 |          Specify the schema (if database flavor supports this). If None, use
 |          default schema.
 |      if_exists : {&#39;fail&#39;, &#39;replace&#39;, &#39;append&#39;}, default &#39;fail&#39;
 |          How to behave if the table already exists.
 |      
 |          * fail: Raise a ValueError.
 |          * replace: Drop the table before inserting new values.
 |          * append: Insert new values to the existing table.
 |      
 |      index : bool, default True
 |          Write DataFrame index as a column. Uses `index_label` as the column
 |          name in the table.
 |      index_label : str or sequence, default None
 |          Column label for index column(s). If None is given (default) and
 |          `index` is True, then the index names are used.
 |          A sequence should be given if the DataFrame uses MultiIndex.
 |      chunksize : int, optional
 |          Specify the number of rows in each batch to be written at a time.
 |          By default, all rows will be written at once.
 |      dtype : dict or scalar, optional
 |          Specifying the datatype for columns. If a dictionary is used, the
 |          keys should be the column names and the values should be the
 |          SQLAlchemy types or strings for the sqlite3 legacy mode. If a
 |          scalar is provided, it will be applied to all columns.
 |      method : {None, &#39;multi&#39;, callable}, optional
 |          Controls the SQL insertion clause used:
 |      
 |          * None : Uses standard SQL ``INSERT`` clause (one per row).
 |          * &#39;multi&#39;: Pass multiple values in a single ``INSERT`` clause.
 |          * callable with signature ``(pd_table, conn, keys, data_iter)``.
 |      
 |          Details and a sample callable implementation can be found in the
 |          section :ref:`insert method &lt;io.sql.method&gt;`.
 |      
 |      Raises
 |      ------
 |      ValueError
 |          When the table already exists and `if_exists` is &#39;fail&#39; (the
 |          default).
 |      
 |      See Also
 |      --------
 |      read_sql : Read a DataFrame from a table.
 |      
 |      Notes
 |      -----
 |      Timezone aware datetime columns will be written as
 |      ``Timestamp with timezone`` type with SQLAlchemy if supported by the
 |      database. Otherwise, the datetimes will be stored as timezone unaware
 |      timestamps local to the original timezone.
 |      
 |      References
 |      ----------
 |      .. [1] https://docs.sqlalchemy.org
 |      .. [2] https://www.python.org/dev/peps/pep-0249/
 |      
 |      Examples
 |      --------
 |      Create an in-memory SQLite database.
 |      
 |      &gt;&gt;&gt; from sqlalchemy import create_engine
 |      &gt;&gt;&gt; engine = create_engine(&#39;sqlite://&#39;, echo=False)
 |      
 |      Create a table from scratch with 3 rows.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;name&#39; : [&#39;User 1&#39;, &#39;User 2&#39;, &#39;User 3&#39;]})
 |      &gt;&gt;&gt; df
 |           name
 |      0  User 1
 |      1  User 2
 |      2  User 3
 |      
 |      &gt;&gt;&gt; df.to_sql(&#39;users&#39;, con=engine)
 |      &gt;&gt;&gt; engine.execute(&quot;SELECT * FROM users&quot;).fetchall()
 |      [(0, &#39;User 1&#39;), (1, &#39;User 2&#39;), (2, &#39;User 3&#39;)]
 |      
 |      An `sqlalchemy.engine.Connection` can also be passed to `con`:
 |      
 |      &gt;&gt;&gt; with engine.begin() as connection:
 |      ...     df1 = pd.DataFrame({&#39;name&#39; : [&#39;User 4&#39;, &#39;User 5&#39;]})
 |      ...     df1.to_sql(&#39;users&#39;, con=connection, if_exists=&#39;append&#39;)
 |      
 |      This is allowed to support operations that require that the same
 |      DBAPI connection is used for the entire operation.
 |      
 |      &gt;&gt;&gt; df2 = pd.DataFrame({&#39;name&#39; : [&#39;User 6&#39;, &#39;User 7&#39;]})
 |      &gt;&gt;&gt; df2.to_sql(&#39;users&#39;, con=engine, if_exists=&#39;append&#39;)
 |      &gt;&gt;&gt; engine.execute(&quot;SELECT * FROM users&quot;).fetchall()
 |      [(0, &#39;User 1&#39;), (1, &#39;User 2&#39;), (2, &#39;User 3&#39;),
 |       (0, &#39;User 4&#39;), (1, &#39;User 5&#39;), (0, &#39;User 6&#39;),
 |       (1, &#39;User 7&#39;)]
 |      
 |      Overwrite the table with just ``df2``.
 |      
 |      &gt;&gt;&gt; df2.to_sql(&#39;users&#39;, con=engine, if_exists=&#39;replace&#39;,
 |      ...            index_label=&#39;id&#39;)
 |      &gt;&gt;&gt; engine.execute(&quot;SELECT * FROM users&quot;).fetchall()
 |      [(0, &#39;User 6&#39;), (1, &#39;User 7&#39;)]
 |      
 |      Specify the dtype (especially useful for integers with missing values).
 |      Notice that while pandas is forced to store the data as floating point,
 |      the database supports nullable integers. When fetching the data with
 |      Python, we get back integer scalars.
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, None, 2]})
 |      &gt;&gt;&gt; df
 |           A
 |      0  1.0
 |      1  NaN
 |      2  2.0
 |      
 |      &gt;&gt;&gt; from sqlalchemy.types import Integer
 |      &gt;&gt;&gt; df.to_sql(&#39;integers&#39;, con=engine, index=False,
 |      ...           dtype={&quot;A&quot;: Integer()})
 |      
 |      &gt;&gt;&gt; engine.execute(&quot;SELECT * FROM integers&quot;).fetchall()
 |      [(1,), (None,), (2,)]
 |  
 |  to_xarray(self)
 |      Return an xarray object from the pandas object.
 |      
 |      Returns
 |      -------
 |      xarray.DataArray or xarray.Dataset
 |          Data in the pandas structure converted to Dataset if the object is
 |          a DataFrame, or a DataArray if the object is a Series.
 |      
 |      See Also
 |      --------
 |      DataFrame.to_hdf : Write DataFrame to an HDF5 file.
 |      DataFrame.to_parquet : Write a DataFrame to the binary parquet format.
 |      
 |      Notes
 |      -----
 |      See the `xarray docs &lt;https://xarray.pydata.org/en/stable/&gt;`__
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([(&#39;falcon&#39;, &#39;bird&#39;, 389.0, 2),
 |      ...                    (&#39;parrot&#39;, &#39;bird&#39;, 24.0, 2),
 |      ...                    (&#39;lion&#39;, &#39;mammal&#39;, 80.5, 4),
 |      ...                    (&#39;monkey&#39;, &#39;mammal&#39;, np.nan, 4)],
 |      ...                   columns=[&#39;name&#39;, &#39;class&#39;, &#39;max_speed&#39;,
 |      ...                            &#39;num_legs&#39;])
 |      &gt;&gt;&gt; df
 |           name   class  max_speed  num_legs
 |      0  falcon    bird      389.0         2
 |      1  parrot    bird       24.0         2
 |      2    lion  mammal       80.5         4
 |      3  monkey  mammal        NaN         4
 |      
 |      &gt;&gt;&gt; df.to_xarray()
 |      &lt;xarray.Dataset&gt;
 |      Dimensions:    (index: 4)
 |      Coordinates:
 |        * index      (index) int64 0 1 2 3
 |      Data variables:
 |          name       (index) object &#39;falcon&#39; &#39;parrot&#39; &#39;lion&#39; &#39;monkey&#39;
 |          class      (index) object &#39;bird&#39; &#39;bird&#39; &#39;mammal&#39; &#39;mammal&#39;
 |          max_speed  (index) float64 389.0 24.0 80.5 nan
 |          num_legs   (index) int64 2 2 4 4
 |      
 |      &gt;&gt;&gt; df[&#39;max_speed&#39;].to_xarray()
 |      &lt;xarray.DataArray &#39;max_speed&#39; (index: 4)&gt;
 |      array([389. ,  24. ,  80.5,   nan])
 |      Coordinates:
 |        * index    (index) int64 0 1 2 3
 |      
 |      &gt;&gt;&gt; dates = pd.to_datetime([&#39;2018-01-01&#39;, &#39;2018-01-01&#39;,
 |      ...                         &#39;2018-01-02&#39;, &#39;2018-01-02&#39;])
 |      &gt;&gt;&gt; df_multiindex = pd.DataFrame({&#39;date&#39;: dates,
 |      ...                               &#39;animal&#39;: [&#39;falcon&#39;, &#39;parrot&#39;,
 |      ...                                          &#39;falcon&#39;, &#39;parrot&#39;],
 |      ...                               &#39;speed&#39;: [350, 18, 361, 15]})
 |      &gt;&gt;&gt; df_multiindex = df_multiindex.set_index([&#39;date&#39;, &#39;animal&#39;])
 |      
 |      &gt;&gt;&gt; df_multiindex
 |                         speed
 |      date       animal
 |      2018-01-01 falcon    350
 |                 parrot     18
 |      2018-01-02 falcon    361
 |                 parrot     15
 |      
 |      &gt;&gt;&gt; df_multiindex.to_xarray()
 |      &lt;xarray.Dataset&gt;
 |      Dimensions:  (animal: 2, date: 2)
 |      Coordinates:
 |        * date     (date) datetime64[ns] 2018-01-01 2018-01-02
 |        * animal   (animal) object &#39;falcon&#39; &#39;parrot&#39;
 |      Data variables:
 |          speed    (date, animal) int64 350 18 361 15
 |  
 |  truncate(self: &#39;FrameOrSeries&#39;, before=None, after=None, axis=None, copy: &#39;bool_t&#39; = True) -&gt; &#39;FrameOrSeries&#39;
 |      Truncate a Series or DataFrame before and after some index value.
 |      
 |      This is a useful shorthand for boolean indexing based on index
 |      values above or below certain thresholds.
 |      
 |      Parameters
 |      ----------
 |      before : date, str, int
 |          Truncate all rows before this index value.
 |      after : date, str, int
 |          Truncate all rows after this index value.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, optional
 |          Axis to truncate. Truncates the index (rows) by default.
 |      copy : bool, default is True,
 |          Return a copy of the truncated section.
 |      
 |      Returns
 |      -------
 |      type of caller
 |          The truncated Series or DataFrame.
 |      
 |      See Also
 |      --------
 |      DataFrame.loc : Select a subset of a DataFrame by label.
 |      DataFrame.iloc : Select a subset of a DataFrame by position.
 |      
 |      Notes
 |      -----
 |      If the index being truncated contains only datetime values,
 |      `before` and `after` may be specified as strings instead of
 |      Timestamps.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39;: [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;],
 |      ...                    &#39;B&#39;: [&#39;f&#39;, &#39;g&#39;, &#39;h&#39;, &#39;i&#39;, &#39;j&#39;],
 |      ...                    &#39;C&#39;: [&#39;k&#39;, &#39;l&#39;, &#39;m&#39;, &#39;n&#39;, &#39;o&#39;]},
 |      ...                   index=[1, 2, 3, 4, 5])
 |      &gt;&gt;&gt; df
 |         A  B  C
 |      1  a  f  k
 |      2  b  g  l
 |      3  c  h  m
 |      4  d  i  n
 |      5  e  j  o
 |      
 |      &gt;&gt;&gt; df.truncate(before=2, after=4)
 |         A  B  C
 |      2  b  g  l
 |      3  c  h  m
 |      4  d  i  n
 |      
 |      The columns of a DataFrame can be truncated.
 |      
 |      &gt;&gt;&gt; df.truncate(before=&quot;A&quot;, after=&quot;B&quot;, axis=&quot;columns&quot;)
 |         A  B
 |      1  a  f
 |      2  b  g
 |      3  c  h
 |      4  d  i
 |      5  e  j
 |      
 |      For Series, only rows can be truncated.
 |      
 |      &gt;&gt;&gt; df[&#39;A&#39;].truncate(before=2, after=4)
 |      2    b
 |      3    c
 |      4    d
 |      Name: A, dtype: object
 |      
 |      The index values in ``truncate`` can be datetimes or string
 |      dates.
 |      
 |      &gt;&gt;&gt; dates = pd.date_range(&#39;2016-01-01&#39;, &#39;2016-02-01&#39;, freq=&#39;s&#39;)
 |      &gt;&gt;&gt; df = pd.DataFrame(index=dates, data={&#39;A&#39;: 1})
 |      &gt;&gt;&gt; df.tail()
 |                           A
 |      2016-01-31 23:59:56  1
 |      2016-01-31 23:59:57  1
 |      2016-01-31 23:59:58  1
 |      2016-01-31 23:59:59  1
 |      2016-02-01 00:00:00  1
 |      
 |      &gt;&gt;&gt; df.truncate(before=pd.Timestamp(&#39;2016-01-05&#39;),
 |      ...             after=pd.Timestamp(&#39;2016-01-10&#39;)).tail()
 |                           A
 |      2016-01-09 23:59:56  1
 |      2016-01-09 23:59:57  1
 |      2016-01-09 23:59:58  1
 |      2016-01-09 23:59:59  1
 |      2016-01-10 00:00:00  1
 |      
 |      Because the index is a DatetimeIndex containing only dates, we can
 |      specify `before` and `after` as strings. They will be coerced to
 |      Timestamps before truncation.
 |      
 |      &gt;&gt;&gt; df.truncate(&#39;2016-01-05&#39;, &#39;2016-01-10&#39;).tail()
 |                           A
 |      2016-01-09 23:59:56  1
 |      2016-01-09 23:59:57  1
 |      2016-01-09 23:59:58  1
 |      2016-01-09 23:59:59  1
 |      2016-01-10 00:00:00  1
 |      
 |      Note that ``truncate`` assumes a 0 value for any unspecified time
 |      component (midnight). This differs from partial string slicing, which
 |      returns any partially matching dates.
 |      
 |      &gt;&gt;&gt; df.loc[&#39;2016-01-05&#39;:&#39;2016-01-10&#39;, :].tail()
 |                           A
 |      2016-01-10 23:59:55  1
 |      2016-01-10 23:59:56  1
 |      2016-01-10 23:59:57  1
 |      2016-01-10 23:59:58  1
 |      2016-01-10 23:59:59  1
 |  
 |  tshift(self: &#39;FrameOrSeries&#39;, periods: &#39;int&#39; = 1, freq=None, axis: &#39;Axis&#39; = 0) -&gt; &#39;FrameOrSeries&#39;
 |      Shift the time index, using the index&#39;s frequency if available.
 |      
 |      .. deprecated:: 1.1.0
 |          Use `shift` instead.
 |      
 |      Parameters
 |      ----------
 |      periods : int
 |          Number of periods to move, can be positive or negative.
 |      freq : DateOffset, timedelta, or str, default None
 |          Increment to use from the tseries module
 |          or time rule expressed as a string (e.g. &#39;EOM&#39;).
 |      axis : {0 or ‘index’, 1 or ‘columns’, None}, default 0
 |          Corresponds to the axis that contains the Index.
 |      
 |      Returns
 |      -------
 |      shifted : Series/DataFrame
 |      
 |      Notes
 |      -----
 |      If freq is not specified then tries to use the freq or inferred_freq
 |      attributes of the index. If neither of those attributes exist, a
 |      ValueError is thrown
 |  
 |  tz_convert(self: &#39;FrameOrSeries&#39;, tz, axis=0, level=None, copy: &#39;bool_t&#39; = True) -&gt; &#39;FrameOrSeries&#39;
 |      Convert tz-aware axis to target time zone.
 |      
 |      Parameters
 |      ----------
 |      tz : str or tzinfo object
 |      axis : the axis to convert
 |      level : int, str, default None
 |          If axis is a MultiIndex, convert a specific level. Otherwise
 |          must be None.
 |      copy : bool, default True
 |          Also make a copy of the underlying data.
 |      
 |      Returns
 |      -------
 |      {klass}
 |          Object with time zone converted axis.
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the axis is tz-naive.
 |  
 |  tz_localize(self: &#39;FrameOrSeries&#39;, tz, axis=0, level=None, copy: &#39;bool_t&#39; = True, ambiguous=&#39;raise&#39;, nonexistent: &#39;str&#39; = &#39;raise&#39;) -&gt; &#39;FrameOrSeries&#39;
 |      Localize tz-naive index of a Series or DataFrame to target time zone.
 |      
 |      This operation localizes the Index. To localize the values in a
 |      timezone-naive Series, use :meth:`Series.dt.tz_localize`.
 |      
 |      Parameters
 |      ----------
 |      tz : str or tzinfo
 |      axis : the axis to localize
 |      level : int, str, default None
 |          If axis ia a MultiIndex, localize a specific level. Otherwise
 |          must be None.
 |      copy : bool, default True
 |          Also make a copy of the underlying data.
 |      ambiguous : &#39;infer&#39;, bool-ndarray, &#39;NaT&#39;, default &#39;raise&#39;
 |          When clocks moved backward due to DST, ambiguous times may arise.
 |          For example in Central European Time (UTC+01), when going from
 |          03:00 DST to 02:00 non-DST, 02:30:00 local time occurs both at
 |          00:30:00 UTC and at 01:30:00 UTC. In such a situation, the
 |          `ambiguous` parameter dictates how ambiguous times should be
 |          handled.
 |      
 |          - &#39;infer&#39; will attempt to infer fall dst-transition hours based on
 |            order
 |          - bool-ndarray where True signifies a DST time, False designates
 |            a non-DST time (note that this flag is only applicable for
 |            ambiguous times)
 |          - &#39;NaT&#39; will return NaT where there are ambiguous times
 |          - &#39;raise&#39; will raise an AmbiguousTimeError if there are ambiguous
 |            times.
 |      nonexistent : str, default &#39;raise&#39;
 |          A nonexistent time does not exist in a particular timezone
 |          where clocks moved forward due to DST. Valid values are:
 |      
 |          - &#39;shift_forward&#39; will shift the nonexistent time forward to the
 |            closest existing time
 |          - &#39;shift_backward&#39; will shift the nonexistent time backward to the
 |            closest existing time
 |          - &#39;NaT&#39; will return NaT where there are nonexistent times
 |          - timedelta objects will shift nonexistent times by the timedelta
 |          - &#39;raise&#39; will raise an NonExistentTimeError if there are
 |            nonexistent times.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Same type as the input.
 |      
 |      Raises
 |      ------
 |      TypeError
 |          If the TimeSeries is tz-aware and tz is not None.
 |      
 |      Examples
 |      --------
 |      Localize local times:
 |      
 |      &gt;&gt;&gt; s = pd.Series([1],
 |      ...               index=pd.DatetimeIndex([&#39;2018-09-15 01:30:00&#39;]))
 |      &gt;&gt;&gt; s.tz_localize(&#39;CET&#39;)
 |      2018-09-15 01:30:00+02:00    1
 |      dtype: int64
 |      
 |      Be careful with DST changes. When there is sequential data, pandas
 |      can infer the DST time:
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(7),
 |      ...               index=pd.DatetimeIndex([&#39;2018-10-28 01:30:00&#39;,
 |      ...                                       &#39;2018-10-28 02:00:00&#39;,
 |      ...                                       &#39;2018-10-28 02:30:00&#39;,
 |      ...                                       &#39;2018-10-28 02:00:00&#39;,
 |      ...                                       &#39;2018-10-28 02:30:00&#39;,
 |      ...                                       &#39;2018-10-28 03:00:00&#39;,
 |      ...                                       &#39;2018-10-28 03:30:00&#39;]))
 |      &gt;&gt;&gt; s.tz_localize(&#39;CET&#39;, ambiguous=&#39;infer&#39;)
 |      2018-10-28 01:30:00+02:00    0
 |      2018-10-28 02:00:00+02:00    1
 |      2018-10-28 02:30:00+02:00    2
 |      2018-10-28 02:00:00+01:00    3
 |      2018-10-28 02:30:00+01:00    4
 |      2018-10-28 03:00:00+01:00    5
 |      2018-10-28 03:30:00+01:00    6
 |      dtype: int64
 |      
 |      In some cases, inferring the DST is impossible. In such cases, you can
 |      pass an ndarray to the ambiguous parameter to set the DST explicitly
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(3),
 |      ...               index=pd.DatetimeIndex([&#39;2018-10-28 01:20:00&#39;,
 |      ...                                       &#39;2018-10-28 02:36:00&#39;,
 |      ...                                       &#39;2018-10-28 03:46:00&#39;]))
 |      &gt;&gt;&gt; s.tz_localize(&#39;CET&#39;, ambiguous=np.array([True, True, False]))
 |      2018-10-28 01:20:00+02:00    0
 |      2018-10-28 02:36:00+02:00    1
 |      2018-10-28 03:46:00+01:00    2
 |      dtype: int64
 |      
 |      If the DST transition causes nonexistent times, you can shift these
 |      dates forward or backward with a timedelta object or `&#39;shift_forward&#39;`
 |      or `&#39;shift_backward&#39;`.
 |      
 |      &gt;&gt;&gt; s = pd.Series(range(2),
 |      ...               index=pd.DatetimeIndex([&#39;2015-03-29 02:30:00&#39;,
 |      ...                                       &#39;2015-03-29 03:30:00&#39;]))
 |      &gt;&gt;&gt; s.tz_localize(&#39;Europe/Warsaw&#39;, nonexistent=&#39;shift_forward&#39;)
 |      2015-03-29 03:00:00+02:00    0
 |      2015-03-29 03:30:00+02:00    1
 |      dtype: int64
 |      &gt;&gt;&gt; s.tz_localize(&#39;Europe/Warsaw&#39;, nonexistent=&#39;shift_backward&#39;)
 |      2015-03-29 01:59:59.999999999+01:00    0
 |      2015-03-29 03:30:00+02:00              1
 |      dtype: int64
 |      &gt;&gt;&gt; s.tz_localize(&#39;Europe/Warsaw&#39;, nonexistent=pd.Timedelta(&#39;1H&#39;))
 |      2015-03-29 03:30:00+02:00    0
 |      2015-03-29 03:30:00+02:00    1
 |      dtype: int64
 |  
 |  xs(self, key, axis=0, level=None, drop_level: &#39;bool_t&#39; = True)
 |      Return cross-section from the Series/DataFrame.
 |      
 |      This method takes a `key` argument to select data at a particular
 |      level of a MultiIndex.
 |      
 |      Parameters
 |      ----------
 |      key : label or tuple of label
 |          Label contained in the index, or partially in a MultiIndex.
 |      axis : {0 or &#39;index&#39;, 1 or &#39;columns&#39;}, default 0
 |          Axis to retrieve cross-section on.
 |      level : object, defaults to first n levels (n=1 or len(key))
 |          In case of a key partially contained in a MultiIndex, indicate
 |          which levels are used. Levels can be referred by label or position.
 |      drop_level : bool, default True
 |          If False, returns object with same levels as self.
 |      
 |      Returns
 |      -------
 |      Series or DataFrame
 |          Cross-section from the original Series or DataFrame
 |          corresponding to the selected index levels.
 |      
 |      See Also
 |      --------
 |      DataFrame.loc : Access a group of rows and columns
 |          by label(s) or a boolean array.
 |      DataFrame.iloc : Purely integer-location based indexing
 |          for selection by position.
 |      
 |      Notes
 |      -----
 |      `xs` can not be used to set values.
 |      
 |      MultiIndex Slicers is a generic way to get/set values on
 |      any level or levels.
 |      It is a superset of `xs` functionality, see
 |      :ref:`MultiIndex Slicers &lt;advanced.mi_slicers&gt;`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; d = {&#39;num_legs&#39;: [4, 4, 2, 2],
 |      ...      &#39;num_wings&#39;: [0, 0, 2, 2],
 |      ...      &#39;class&#39;: [&#39;mammal&#39;, &#39;mammal&#39;, &#39;mammal&#39;, &#39;bird&#39;],
 |      ...      &#39;animal&#39;: [&#39;cat&#39;, &#39;dog&#39;, &#39;bat&#39;, &#39;penguin&#39;],
 |      ...      &#39;locomotion&#39;: [&#39;walks&#39;, &#39;walks&#39;, &#39;flies&#39;, &#39;walks&#39;]}
 |      &gt;&gt;&gt; df = pd.DataFrame(data=d)
 |      &gt;&gt;&gt; df = df.set_index([&#39;class&#39;, &#39;animal&#39;, &#39;locomotion&#39;])
 |      &gt;&gt;&gt; df
 |                                 num_legs  num_wings
 |      class  animal  locomotion
 |      mammal cat     walks              4          0
 |             dog     walks              4          0
 |             bat     flies              2          2
 |      bird   penguin walks              2          2
 |      
 |      Get values at specified index
 |      
 |      &gt;&gt;&gt; df.xs(&#39;mammal&#39;)
 |                         num_legs  num_wings
 |      animal locomotion
 |      cat    walks              4          0
 |      dog    walks              4          0
 |      bat    flies              2          2
 |      
 |      Get values at several indexes
 |      
 |      &gt;&gt;&gt; df.xs((&#39;mammal&#39;, &#39;dog&#39;))
 |                  num_legs  num_wings
 |      locomotion
 |      walks              4          0
 |      
 |      Get values at specified index and level
 |      
 |      &gt;&gt;&gt; df.xs(&#39;cat&#39;, level=1)
 |                         num_legs  num_wings
 |      class  locomotion
 |      mammal walks              4          0
 |      
 |      Get values at several indexes and levels
 |      
 |      &gt;&gt;&gt; df.xs((&#39;bird&#39;, &#39;walks&#39;),
 |      ...       level=[0, &#39;locomotion&#39;])
 |               num_legs  num_wings
 |      animal
 |      penguin         2          2
 |      
 |      Get values at specified column and axis
 |      
 |      &gt;&gt;&gt; df.xs(&#39;num_wings&#39;, axis=1)
 |      class   animal   locomotion
 |      mammal  cat      walks         0
 |              dog      walks         0
 |              bat      flies         2
 |      bird    penguin  walks         2
 |      Name: num_wings, dtype: int64
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pandas.core.generic.NDFrame:
 |  
 |  attrs
 |      Dictionary of global attributes of this dataset.
 |      
 |      .. warning::
 |      
 |         attrs is experimental and may change without warning.
 |      
 |      See Also
 |      --------
 |      DataFrame.flags : Global flags applying to this object.
 |  
 |  dtypes
 |      Return the dtypes in the DataFrame.
 |      
 |      This returns a Series with the data type of each column.
 |      The result&#39;s index is the original DataFrame&#39;s columns. Columns
 |      with mixed types are stored with the ``object`` dtype. See
 |      :ref:`the User Guide &lt;basics.dtypes&gt;` for more.
 |      
 |      Returns
 |      -------
 |      pandas.Series
 |          The data type of each column.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;float&#39;: [1.0],
 |      ...                    &#39;int&#39;: [1],
 |      ...                    &#39;datetime&#39;: [pd.Timestamp(&#39;20180310&#39;)],
 |      ...                    &#39;string&#39;: [&#39;foo&#39;]})
 |      &gt;&gt;&gt; df.dtypes
 |      float              float64
 |      int                  int64
 |      datetime    datetime64[ns]
 |      string              object
 |      dtype: object
 |  
 |  empty
 |      Indicator whether DataFrame is empty.
 |      
 |      True if DataFrame is entirely empty (no items), meaning any of the
 |      axes are of length 0.
 |      
 |      Returns
 |      -------
 |      bool
 |          If DataFrame is empty, return True, if not return False.
 |      
 |      See Also
 |      --------
 |      Series.dropna : Return series without null values.
 |      DataFrame.dropna : Return DataFrame with labels on given axis omitted
 |          where (all or any) data are missing.
 |      
 |      Notes
 |      -----
 |      If DataFrame contains only NaNs, it is still not considered empty. See
 |      the example below.
 |      
 |      Examples
 |      --------
 |      An example of an actual empty DataFrame. Notice the index is empty:
 |      
 |      &gt;&gt;&gt; df_empty = pd.DataFrame({&#39;A&#39; : []})
 |      &gt;&gt;&gt; df_empty
 |      Empty DataFrame
 |      Columns: [A]
 |      Index: []
 |      &gt;&gt;&gt; df_empty.empty
 |      True
 |      
 |      If we only have NaNs in our DataFrame, it is not considered empty! We
 |      will need to drop the NaNs to make the DataFrame empty:
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;A&#39; : [np.nan]})
 |      &gt;&gt;&gt; df
 |          A
 |      0 NaN
 |      &gt;&gt;&gt; df.empty
 |      False
 |      &gt;&gt;&gt; df.dropna().empty
 |      True
 |  
 |  flags
 |      Get the properties associated with this pandas object.
 |      
 |      The available flags are
 |      
 |      * :attr:`Flags.allows_duplicate_labels`
 |      
 |      See Also
 |      --------
 |      Flags : Flags that apply to pandas objects.
 |      DataFrame.attrs : Global metadata applying to this dataset.
 |      
 |      Notes
 |      -----
 |      &quot;Flags&quot; differ from &quot;metadata&quot;. Flags reflect properties of the
 |      pandas object (the Series or DataFrame). Metadata refer to properties
 |      of the dataset, and should be stored in :attr:`DataFrame.attrs`.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame({&quot;A&quot;: [1, 2]})
 |      &gt;&gt;&gt; df.flags
 |      &lt;Flags(allows_duplicate_labels=True)&gt;
 |      
 |      Flags can be get or set using ``.``
 |      
 |      &gt;&gt;&gt; df.flags.allows_duplicate_labels
 |      True
 |      &gt;&gt;&gt; df.flags.allows_duplicate_labels = False
 |      
 |      Or by slicing with a key
 |      
 |      &gt;&gt;&gt; df.flags[&quot;allows_duplicate_labels&quot;]
 |      False
 |      &gt;&gt;&gt; df.flags[&quot;allows_duplicate_labels&quot;] = True
 |  
 |  ndim
 |      Return an int representing the number of axes / array dimensions.
 |      
 |      Return 1 if Series. Otherwise return 2 if DataFrame.
 |      
 |      See Also
 |      --------
 |      ndarray.ndim : Number of array dimensions.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series({&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3})
 |      &gt;&gt;&gt; s.ndim
 |      1
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]})
 |      &gt;&gt;&gt; df.ndim
 |      2
 |  
 |  size
 |      Return an int representing the number of elements in this object.
 |      
 |      Return the number of rows if Series. Otherwise return the number of
 |      rows times number of columns if DataFrame.
 |      
 |      See Also
 |      --------
 |      ndarray.size : Number of elements in the array.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; s = pd.Series({&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3})
 |      &gt;&gt;&gt; s.size
 |      3
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame({&#39;col1&#39;: [1, 2], &#39;col2&#39;: [3, 4]})
 |      &gt;&gt;&gt; df.size
 |      4
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from pandas.core.generic.NDFrame:
 |  
 |  __array_priority__ = 1000
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pandas.core.base.PandasObject:
 |  
 |  __sizeof__(self) -&gt; &#39;int&#39;
 |      Generates the total memory usage for an object that returns
 |      either a value or Series of values
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pandas.core.accessor.DirNamesMixin:
 |  
 |  __dir__(self) -&gt; &#39;list[str]&#39;
 |      Provide method name lookup and completion.
 |      
 |      Notes
 |      -----
 |      Only provide &#39;public&#39; methods.
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pandas.core.accessor.DirNamesMixin:
 |  
 |  __dict__
 |      dictionary for instance variables (if defined)
 |  
 |  __weakref__
 |      list of weak references to the object (if defined)
 |  
 |  ----------------------------------------------------------------------
 |  Data descriptors inherited from pandas.core.indexing.IndexingMixin:
 |  
 |  at
 |      Access a single value for a row/column label pair.
 |      
 |      Similar to ``loc``, in that both provide label-based lookups. Use
 |      ``at`` if you only need to get or set a single value in a DataFrame
 |      or Series.
 |      
 |      Raises
 |      ------
 |      KeyError
 |          If &#39;label&#39; does not exist in DataFrame.
 |      
 |      See Also
 |      --------
 |      DataFrame.iat : Access a single value for a row/column pair by integer
 |          position.
 |      DataFrame.loc : Access a group of rows and columns by label(s).
 |      Series.at : Access a single value using a label.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
 |      ...                   index=[4, 5, 6], columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; df
 |          A   B   C
 |      4   0   2   3
 |      5   0   4   1
 |      6  10  20  30
 |      
 |      Get value at specified row/column pair
 |      
 |      &gt;&gt;&gt; df.at[4, &#39;B&#39;]
 |      2
 |      
 |      Set value at specified row/column pair
 |      
 |      &gt;&gt;&gt; df.at[4, &#39;B&#39;] = 10
 |      &gt;&gt;&gt; df.at[4, &#39;B&#39;]
 |      10
 |      
 |      Get value within a Series
 |      
 |      &gt;&gt;&gt; df.loc[5].at[&#39;B&#39;]
 |      4
 |  
 |  iat
 |      Access a single value for a row/column pair by integer position.
 |      
 |      Similar to ``iloc``, in that both provide integer-based lookups. Use
 |      ``iat`` if you only need to get or set a single value in a DataFrame
 |      or Series.
 |      
 |      Raises
 |      ------
 |      IndexError
 |          When integer position is out of bounds.
 |      
 |      See Also
 |      --------
 |      DataFrame.at : Access a single value for a row/column label pair.
 |      DataFrame.loc : Access a group of rows and columns by label(s).
 |      DataFrame.iloc : Access a group of rows and columns by integer position(s).
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; df = pd.DataFrame([[0, 2, 3], [0, 4, 1], [10, 20, 30]],
 |      ...                   columns=[&#39;A&#39;, &#39;B&#39;, &#39;C&#39;])
 |      &gt;&gt;&gt; df
 |          A   B   C
 |      0   0   2   3
 |      1   0   4   1
 |      2  10  20  30
 |      
 |      Get value at specified row/column pair
 |      
 |      &gt;&gt;&gt; df.iat[1, 2]
 |      1
 |      
 |      Set value at specified row/column pair
 |      
 |      &gt;&gt;&gt; df.iat[1, 2] = 10
 |      &gt;&gt;&gt; df.iat[1, 2]
 |      10
 |      
 |      Get value within a series
 |      
 |      &gt;&gt;&gt; df.loc[0].iat[1]
 |      2
 |  
 |  iloc
 |      Purely integer-location based indexing for selection by position.
 |      
 |      ``.iloc[]`` is primarily integer position based (from ``0`` to
 |      ``length-1`` of the axis), but may also be used with a boolean
 |      array.
 |      
 |      Allowed inputs are:
 |      
 |      - An integer, e.g. ``5``.
 |      - A list or array of integers, e.g. ``[4, 3, 0]``.
 |      - A slice object with ints, e.g. ``1:7``.
 |      - A boolean array.
 |      - A ``callable`` function with one argument (the calling Series or
 |        DataFrame) and that returns valid output for indexing (one of the above).
 |        This is useful in method chains, when you don&#39;t have a reference to the
 |        calling object, but would like to base your selection on some value.
 |      
 |      ``.iloc`` will raise ``IndexError`` if a requested indexer is
 |      out-of-bounds, except *slice* indexers which allow out-of-bounds
 |      indexing (this conforms with python/numpy *slice* semantics).
 |      
 |      See more at :ref:`Selection by Position &lt;indexing.integer&gt;`.
 |      
 |      See Also
 |      --------
 |      DataFrame.iat : Fast integer location scalar accessor.
 |      DataFrame.loc : Purely label-location based indexer for selection by label.
 |      Series.iloc : Purely integer-location based indexing for
 |                     selection by position.
 |      
 |      Examples
 |      --------
 |      &gt;&gt;&gt; mydict = [{&#39;a&#39;: 1, &#39;b&#39;: 2, &#39;c&#39;: 3, &#39;d&#39;: 4},
 |      ...           {&#39;a&#39;: 100, &#39;b&#39;: 200, &#39;c&#39;: 300, &#39;d&#39;: 400},
 |      ...           {&#39;a&#39;: 1000, &#39;b&#39;: 2000, &#39;c&#39;: 3000, &#39;d&#39;: 4000 }]
 |      &gt;&gt;&gt; df = pd.DataFrame(mydict)
 |      &gt;&gt;&gt; df
 |            a     b     c     d
 |      0     1     2     3     4
 |      1   100   200   300   400
 |      2  1000  2000  3000  4000
 |      
 |      **Indexing just the rows**
 |      
 |      With a scalar integer.
 |      
 |      &gt;&gt;&gt; type(df.iloc[0])
 |      &lt;class &#39;pandas.core.series.Series&#39;&gt;
 |      &gt;&gt;&gt; df.iloc[0]
 |      a    1
 |      b    2
 |      c    3
 |      d    4
 |      Name: 0, dtype: int64
 |      
 |      With a list of integers.
 |      
 |      &gt;&gt;&gt; df.iloc[[0]]
 |         a  b  c  d
 |      0  1  2  3  4
 |      &gt;&gt;&gt; type(df.iloc[[0]])
 |      &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
 |      
 |      &gt;&gt;&gt; df.iloc[[0, 1]]
 |           a    b    c    d
 |      0    1    2    3    4
 |      1  100  200  300  400
 |      
 |      With a `slice` object.
 |      
 |      &gt;&gt;&gt; df.iloc[:3]
 |            a     b     c     d
 |      0     1     2     3     4
 |      1   100   200   300   400
 |      2  1000  2000  3000  4000
 |      
 |      With a boolean mask the same length as the index.
 |      
 |      &gt;&gt;&gt; df.iloc[[True, False, True]]
 |            a     b     c     d
 |      0     1     2     3     4
 |      2  1000  2000  3000  4000
 |      
 |      With a callable, useful in method chains. The `x` passed
 |      to the ``lambda`` is the DataFrame being sliced. This selects
 |      the rows whose index label even.
 |      
 |      &gt;&gt;&gt; df.iloc[lambda x: x.index % 2 == 0]
 |            a     b     c     d
 |      0     1     2     3     4
 |      2  1000  2000  3000  4000
 |      
 |      **Indexing both axes**
 |      
 |      You can mix the indexer types for the index and columns. Use ``:`` to
 |      select the entire axis.
 |      
 |      With scalar integers.
 |      
 |      &gt;&gt;&gt; df.iloc[0, 1]
 |      2
 |      
 |      With lists of integers.
 |      
 |      &gt;&gt;&gt; df.iloc[[0, 2], [1, 3]]
 |            b     d
 |      0     2     4
 |      2  2000  4000
 |      
 |      With `slice` objects.
 |      
 |      &gt;&gt;&gt; df.iloc[1:3, 0:3]
 |            a     b     c
 |      1   100   200   300
 |      2  1000  2000  3000
 |      
 |      With a boolean array whose length matches the columns.
 |      
 |      &gt;&gt;&gt; df.iloc[:, [True, False, True, False]]
 |            a     c
 |      0     1     3
 |      1   100   300
 |      2  1000  3000
 |      
 |      With a callable function that expects the Series or DataFrame.
 |      
 |      &gt;&gt;&gt; df.iloc[:, lambda df: [0, 2]]
 |            a     c
 |      0     1     3
 |      1   100   300
 |      2  1000  3000
 |  
 |  loc
 |      Access a group of rows and columns by label(s) or a boolean array.
 |      
 |      ``.loc[]`` is primarily label based, but may also be used with a
 |      boolean array.
 |      
 |      Allowed inputs are:
 |      
 |      - A single label, e.g. ``5`` or ``&#39;a&#39;``, (note that ``5`` is
 |        interpreted as a *label* of the index, and **never** as an
 |        integer position along the index).
 |      - A list or array of labels, e.g. ``[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;]``.
 |      - A slice object with labels, e.g. ``&#39;a&#39;:&#39;f&#39;``.
 |      
 |        .. warning:: Note that contrary to usual python slices, **both** the
 |            start and the stop are included
 |      
 |      - A boolean array of the same length as the axis being sliced,
 |        e.g. ``[True, False, True]``.
 |      - An alignable boolean Series. The index of the key will be aligned before
 |        masking.
 |      - An alignable Index. The Index of the returned selection will be the input.
 |      - A ``callable`` function with one argument (the calling Series or
 |        DataFrame) and that returns valid output for indexing (one of the above)
 |      
 |      See more at :ref:`Selection by Label &lt;indexing.label&gt;`.
 |      
 |      Raises
 |      ------
 |      KeyError
 |          If any items are not found.
 |      IndexingError
 |          If an indexed key is passed and its index is unalignable to the frame index.
 |      
 |      See Also
 |      --------
 |      DataFrame.at : Access a single value for a row/column label pair.
 |      DataFrame.iloc : Access group of rows and columns by integer position(s).
 |      DataFrame.xs : Returns a cross-section (row(s) or column(s)) from the
 |          Series/DataFrame.
 |      Series.loc : Access group of values using labels.
 |      
 |      Examples
 |      --------
 |      **Getting values**
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
 |      ...      index=[&#39;cobra&#39;, &#39;viper&#39;, &#39;sidewinder&#39;],
 |      ...      columns=[&#39;max_speed&#39;, &#39;shield&#39;])
 |      &gt;&gt;&gt; df
 |                  max_speed  shield
 |      cobra               1       2
 |      viper               4       5
 |      sidewinder          7       8
 |      
 |      Single label. Note this returns the row as a Series.
 |      
 |      &gt;&gt;&gt; df.loc[&#39;viper&#39;]
 |      max_speed    4
 |      shield       5
 |      Name: viper, dtype: int64
 |      
 |      List of labels. Note using ``[[]]`` returns a DataFrame.
 |      
 |      &gt;&gt;&gt; df.loc[[&#39;viper&#39;, &#39;sidewinder&#39;]]
 |                  max_speed  shield
 |      viper               4       5
 |      sidewinder          7       8
 |      
 |      Single label for row and column
 |      
 |      &gt;&gt;&gt; df.loc[&#39;cobra&#39;, &#39;shield&#39;]
 |      2
 |      
 |      Slice with labels for row and single label for column. As mentioned
 |      above, note that both the start and stop of the slice are included.
 |      
 |      &gt;&gt;&gt; df.loc[&#39;cobra&#39;:&#39;viper&#39;, &#39;max_speed&#39;]
 |      cobra    1
 |      viper    4
 |      Name: max_speed, dtype: int64
 |      
 |      Boolean list with the same length as the row axis
 |      
 |      &gt;&gt;&gt; df.loc[[False, False, True]]
 |                  max_speed  shield
 |      sidewinder          7       8
 |      
 |      Alignable boolean Series:
 |      
 |      &gt;&gt;&gt; df.loc[pd.Series([False, True, False],
 |      ...        index=[&#39;viper&#39;, &#39;sidewinder&#39;, &#39;cobra&#39;])]
 |                  max_speed  shield
 |      sidewinder          7       8
 |      
 |      Index (same behavior as ``df.reindex``)
 |      
 |      &gt;&gt;&gt; df.loc[pd.Index([&quot;cobra&quot;, &quot;viper&quot;], name=&quot;foo&quot;)]
 |             max_speed  shield
 |      foo
 |      cobra          1       2
 |      viper          4       5
 |      
 |      Conditional that returns a boolean Series
 |      
 |      &gt;&gt;&gt; df.loc[df[&#39;shield&#39;] &gt; 6]
 |                  max_speed  shield
 |      sidewinder          7       8
 |      
 |      Conditional that returns a boolean Series with column labels specified
 |      
 |      &gt;&gt;&gt; df.loc[df[&#39;shield&#39;] &gt; 6, [&#39;max_speed&#39;]]
 |                  max_speed
 |      sidewinder          7
 |      
 |      Callable that returns a boolean Series
 |      
 |      &gt;&gt;&gt; df.loc[lambda df: df[&#39;shield&#39;] == 8]
 |                  max_speed  shield
 |      sidewinder          7       8
 |      
 |      **Setting values**
 |      
 |      Set value for all items matching the list of labels
 |      
 |      &gt;&gt;&gt; df.loc[[&#39;viper&#39;, &#39;sidewinder&#39;], [&#39;shield&#39;]] = 50
 |      &gt;&gt;&gt; df
 |                  max_speed  shield
 |      cobra               1       2
 |      viper               4      50
 |      sidewinder          7      50
 |      
 |      Set value for an entire row
 |      
 |      &gt;&gt;&gt; df.loc[&#39;cobra&#39;] = 10
 |      &gt;&gt;&gt; df
 |                  max_speed  shield
 |      cobra              10      10
 |      viper               4      50
 |      sidewinder          7      50
 |      
 |      Set value for an entire column
 |      
 |      &gt;&gt;&gt; df.loc[:, &#39;max_speed&#39;] = 30
 |      &gt;&gt;&gt; df
 |                  max_speed  shield
 |      cobra              30      10
 |      viper              30      50
 |      sidewinder         30      50
 |      
 |      Set value for rows matching callable condition
 |      
 |      &gt;&gt;&gt; df.loc[df[&#39;shield&#39;] &gt; 35] = 0
 |      &gt;&gt;&gt; df
 |                  max_speed  shield
 |      cobra              30      10
 |      viper               0       0
 |      sidewinder          0       0
 |      
 |      **Getting values on a DataFrame with an index that has integer labels**
 |      
 |      Another example using integers for the index
 |      
 |      &gt;&gt;&gt; df = pd.DataFrame([[1, 2], [4, 5], [7, 8]],
 |      ...      index=[7, 8, 9], columns=[&#39;max_speed&#39;, &#39;shield&#39;])
 |      &gt;&gt;&gt; df
 |         max_speed  shield
 |      7          1       2
 |      8          4       5
 |      9          7       8
 |      
 |      Slice with integer labels for rows. As mentioned above, note that both
 |      the start and stop of the slice are included.
 |      
 |      &gt;&gt;&gt; df.loc[7:9]
 |         max_speed  shield
 |      7          1       2
 |      8          4       5
 |      9          7       8
 |      
 |      **Getting values with a MultiIndex**
 |      
 |      A number of examples using a DataFrame with a MultiIndex
 |      
 |      &gt;&gt;&gt; tuples = [
 |      ...    (&#39;cobra&#39;, &#39;mark i&#39;), (&#39;cobra&#39;, &#39;mark ii&#39;),
 |      ...    (&#39;sidewinder&#39;, &#39;mark i&#39;), (&#39;sidewinder&#39;, &#39;mark ii&#39;),
 |      ...    (&#39;viper&#39;, &#39;mark ii&#39;), (&#39;viper&#39;, &#39;mark iii&#39;)
 |      ... ]
 |      &gt;&gt;&gt; index = pd.MultiIndex.from_tuples(tuples)
 |      &gt;&gt;&gt; values = [[12, 2], [0, 4], [10, 20],
 |      ...         [1, 4], [7, 1], [16, 36]]
 |      &gt;&gt;&gt; df = pd.DataFrame(values, columns=[&#39;max_speed&#39;, &#39;shield&#39;], index=index)
 |      &gt;&gt;&gt; df
 |                           max_speed  shield
 |      cobra      mark i           12       2
 |                 mark ii           0       4
 |      sidewinder mark i           10      20
 |                 mark ii           1       4
 |      viper      mark ii           7       1
 |                 mark iii         16      36
 |      
 |      Single label. Note this returns a DataFrame with a single index.
 |      
 |      &gt;&gt;&gt; df.loc[&#39;cobra&#39;]
 |               max_speed  shield
 |      mark i          12       2
 |      mark ii          0       4
 |      
 |      Single index tuple. Note this returns a Series.
 |      
 |      &gt;&gt;&gt; df.loc[(&#39;cobra&#39;, &#39;mark ii&#39;)]
 |      max_speed    0
 |      shield       4
 |      Name: (cobra, mark ii), dtype: int64
 |      
 |      Single label for row and column. Similar to passing in a tuple, this
 |      returns a Series.
 |      
 |      &gt;&gt;&gt; df.loc[&#39;cobra&#39;, &#39;mark i&#39;]
 |      max_speed    12
 |      shield        2
 |      Name: (cobra, mark i), dtype: int64
 |      
 |      Single tuple. Note using ``[[]]`` returns a DataFrame.
 |      
 |      &gt;&gt;&gt; df.loc[[(&#39;cobra&#39;, &#39;mark ii&#39;)]]
 |                     max_speed  shield
 |      cobra mark ii          0       4
 |      
 |      Single tuple for the index with a single label for the column
 |      
 |      &gt;&gt;&gt; df.loc[(&#39;cobra&#39;, &#39;mark i&#39;), &#39;shield&#39;]
 |      2
 |      
 |      Slice from index tuple to single label
 |      
 |      &gt;&gt;&gt; df.loc[(&#39;cobra&#39;, &#39;mark i&#39;):&#39;viper&#39;]
 |                           max_speed  shield
 |      cobra      mark i           12       2
 |                 mark ii           0       4
 |      sidewinder mark i           10      20
 |                 mark ii           1       4
 |      viper      mark ii           7       1
 |                 mark iii         16      36
 |      
 |      Slice from index tuple to index tuple
 |      
 |      &gt;&gt;&gt; df.loc[(&#39;cobra&#39;, &#39;mark i&#39;):(&#39;viper&#39;, &#39;mark ii&#39;)]
 |                          max_speed  shield
 |      cobra      mark i          12       2
 |                 mark ii          0       4
 |      sidewinder mark i          10      20
 |                 mark ii          1       4
 |      viper      mark ii          7       1
 |  
 |  ----------------------------------------------------------------------
 |  Methods inherited from pandas.core.arraylike.OpsMixin:
 |  
 |  __add__(self, other)
 |  
 |  __and__(self, other)
 |  
 |  __eq__(self, other)
 |      Return self==value.
 |  
 |  __floordiv__(self, other)
 |  
 |  __ge__(self, other)
 |      Return self&gt;=value.
 |  
 |  __gt__(self, other)
 |      Return self&gt;value.
 |  
 |  __le__(self, other)
 |      Return self&lt;=value.
 |  
 |  __lt__(self, other)
 |      Return self&lt;value.
 |  
 |  __mod__(self, other)
 |  
 |  __mul__(self, other)
 |  
 |  __ne__(self, other)
 |      Return self!=value.
 |  
 |  __or__(self, other)
 |  
 |  __pow__(self, other)
 |  
 |  __radd__(self, other)
 |  
 |  __rand__(self, other)
 |  
 |  __rfloordiv__(self, other)
 |  
 |  __rmod__(self, other)
 |  
 |  __rmul__(self, other)
 |  
 |  __ror__(self, other)
 |  
 |  __rpow__(self, other)
 |  
 |  __rsub__(self, other)
 |  
 |  __rtruediv__(self, other)
 |  
 |  __rxor__(self, other)
 |  
 |  __sub__(self, other)
 |  
 |  __truediv__(self, other)
 |  
 |  __xor__(self, other)
 |  
 |  ----------------------------------------------------------------------
 |  Data and other attributes inherited from pandas.core.arraylike.OpsMixin:
 |  
 |  __hash__ = None
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">anes</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>x</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>x</th>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">??</span>pd.read_csv
</pre></div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
        <div class='prev-next-bottom'>
            

        </div>
        
        </div>
    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Jonathan Kropko (jkropko@virginia.edu)<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>